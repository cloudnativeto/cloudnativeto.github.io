<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>孙海洲 | 云原生社区</title>
    <link>https://cloudnative.to/translators/%E5%AD%99%E6%B5%B7%E6%B4%B2/</link>
      <atom:link href="https://cloudnative.to/translators/%E5%AD%99%E6%B5%B7%E6%B4%B2/index.xml" rel="self" type="application/rss+xml" />
    <description>孙海洲</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Mon, 27 May 2019 04:55:44 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/media/sharing.png</url>
      <title>孙海洲</title>
      <link>https://cloudnative.to/translators/%E5%AD%99%E6%B5%B7%E6%B4%B2/</link>
    </image>
    
    <item>
      <title>部署Envoy代理来为Monzo提速</title>
      <link>https://cloudnative.to/blog/deploying-envoy-proxy/</link>
      <pubDate>Mon, 27 May 2019 04:55:44 +0800</pubDate>
      <guid>https://cloudnative.to/blog/deploying-envoy-proxy/</guid>
      <description>&lt;h2 id=&#34;编者按&#34;&gt;编者按&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;本文介绍了使用Envoy来加速Monzo，对比了使用Linkerd和Envoy，通过试验证明Envoy拥有更小的延迟。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们基础设施的一个核心组件是远程过程调用(RPC)系统。它允许微服务通过网络以可伸缩和可容错的方式彼此通信。&lt;/p&gt;
&lt;p&gt;每当评估RPC系统时，通常会查看以下几个关键指标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高可用&lt;/strong&gt;，服务之间的通信应该尽可能快。RPC子系统应该做到延迟开销最小化，并在路由请求时避免路由到失败的服务副本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可伸缩性&lt;/strong&gt;，平台每秒会收到数以万计的请求，随着用户基数的增长，这些请求的数量还在不断增加。所拥有的任何子系统都需要继续支持这种增长。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可恢复性&lt;/strong&gt;，当服务副本宕机、发生bug或者网络不可靠时。子系统应该能检测到不可用的下游和异常值，让系统收到反馈并绕过失败进行路由。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可观察性&lt;/strong&gt;，RPC子系统生成大量关于平台性能的数据。与现有的&lt;a href=&#34;https://monzo.com/blog/2018/07/27/how-we-monitor-monzo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;度量标准和追踪基础设施&lt;/a&gt;集成，以在现有的服务度量标准和追踪的同时公开服务网格信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2016年，我们写了一篇关于&lt;a href=&#34;https://monzo.com/blog/2016/09/19/building-a-modern-bank-backend/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;构建现代银行后台&lt;/a&gt;的博客，其中一个关键部分是服务网格，它由&lt;a href=&#34;https://linkerd.io/1/overview/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linkerd 1.0&lt;/a&gt;提供支持。当我们在2016年选择Linkerd 1.0时，服务网格生态体系还比较年轻。&lt;/p&gt;
&lt;p&gt;从那时起，许多新项目都追随了我们这个想法。我们想重新评估Linkerd 1.0是否适合我们的需求。&lt;/p&gt;
&lt;h2 id=&#34;服务网格&#34;&gt;服务网格&lt;/h2&gt;
&lt;p&gt;我们的微服务每秒通过HTTP执行数万次RPC调用。然而，要建立一个可靠的、可容错的分布式系统，需要具有服务发现、自动重试、错误预算、负载均衡和熔断功能。&lt;/p&gt;
&lt;p&gt;我们想建立一个支持所有编程语言的平台。虽然大多数微服务都是用Go实现的，但是有些团队选择使用其他语言(例如，数据团队使用Python编写一些机器学习服务)。&lt;/p&gt;
&lt;p&gt;在我们使用的每一种语言中实现这些复杂的特性，会对我们要使用的新事物设置很高的障碍。此外，对RPC子系统的更改将意味着重新部署所有服务。&lt;/p&gt;
&lt;p&gt;我们早期做出的一个关键决定是尽可能地使这个复杂的逻辑脱离流程：Linkerd对服务透明提供了许多特性。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/deploying-envoy-proxy/envoy-blog-1.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们运行Linkerd作为&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Daemonset&lt;/a&gt;。这意味着每个服务将与每个节点上运行的Linkerd的本地服务副本通信。&lt;/p&gt;
&lt;h2 id=&#34;迁移到envoy&#34;&gt;迁移到Envoy&lt;/h2&gt;
&lt;p&gt;在我们为&lt;a href=&#34;https://monzo.com/blog/2019/01/15/crowdfunding-technology-testing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;众筹做准备&lt;/a&gt;的过程中，我们发现Linkerd无法在不赋予它不成比例的处理能力的情况下处理负载。我们必须大规模扩展我们的基础设施来应对。随着我们业务需求的不断增长，运行RPC基础设施所需的资源数量是不可持续的。即使在正常的负载模式中，Linkerd本身也是造成第99百分位延迟的主要因素。&lt;/p&gt;
&lt;p&gt;我们开始评估与RPC子系统标准相匹配的替代方案。我们研究了Linkerd 2.0、Istio和Envoy。我们最终选择了Envoy，因为它具有高性能、相对成熟和广泛应用于大型工程团队和项目的能力。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;是一个开源的高性能服务网格，最初由Lyft开发。它是用C++编写的，因此不会受到垃圾收集的影响，也不会出现编译暂停。它是支撑Istio和Ambassador等其他一些项目的核心代理。&lt;/p&gt;
&lt;p&gt;Envoy并没有对Kubernetes的任何依赖。我们编写了自己的小型控制平面，它将监视Kubernetes基础设施中的更改(例如由于新Pod而更改的端点)，并通过&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/configuration/cluster_manager/cds&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;集群发现服务&lt;/a&gt;(CDS) API将更改推送给Envoy，使其感知到新服务。&lt;/p&gt;
&lt;p&gt;我们使用为测试众筹系统而开发的&lt;a href=&#34;https://monzo.com/blog/2019/01/15/crowdfunding-technology-testing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;负载测试工具&lt;/a&gt;来测试现有的Linkerd和新的Envoy的性能。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/deploying-envoy-proxy/envoy-blog-2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在我们所有的测试中，Envoy都比我们现有的Linkerd 1.0表现得好得多，同时需要更少的处理能力和内存资源。&lt;/p&gt;
&lt;p&gt;与Linkerd相比，Envoy缺少一些功能，比如延迟感知负载均衡(而不仅仅是轮询)和基于服务的错误预算(而不仅仅是基于每个请求的自动重试)。最终，我们没有发现这些是交易破坏者，尽管我们想在未来添加它们。&lt;/p&gt;
&lt;p&gt;我们希望转换对服务是透明的。在我们的推出中，一个关键因素是如果需要回滚，该更改的可回溯性。&lt;/p&gt;
&lt;p&gt;我们设置了Envoy来接收和路由HTTP请求，就像Linkerd一样，并以Kubernetes daemonset方式将其推出。在几个月的时间里，我们在预发布环境中大量测试了这些更改。一旦到了投入生产的时候，我们就会在几天的时间里逐步推出它，以发现并解决任何在最后一刻出现的问题。&lt;/p&gt;
&lt;h2 id=&#34;可观察性&#34;&gt;可观察性&lt;/h2&gt;
&lt;p&gt;虽然Linkerd 1.0有一个很好的控制平面，但它不能很好地与基于Prometheus的监控系统集成。在Envoy投入生产之前，我们对其与Prometheus的融合给予了密切关注。&lt;/p&gt;
&lt;p&gt;我们&lt;a href=&#34;https://github.com/envoyproxy/envoy/pulls?utf8=%E2%9C%93&amp;amp;q=is%3Apr&amp;#43;author%3Asuhailpatel&amp;#43;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;回馈Envoy社区&lt;/a&gt;，完成了对Prometheus的一级支持。这允许我们拥有丰富的仪表板来增强现有的服务度量。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/deploying-envoy-proxy/envoy-blog-3.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;通过拥有这些数据，我们对首次展示获得了信心，以确保它是无缝的和无错误的。&lt;/p&gt;
&lt;p&gt;当你的应用程序与我们的后端通信时，它会经过我们的边缘层，然后启用不同数量的微服务(有时超过20个)来满足请求。当我们推出Envoy时，我们看到我们的边缘延迟减少了，这证实了我们的测试结果。这最终意味着，对于所有使用Monzo的人来说，都能获得更快的应用体验。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/deploying-envoy-proxy/envoy-blog-4.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;envoy作为sidecar&#34;&gt;Envoy作为sidecar&lt;/h2&gt;
&lt;p&gt;我们现在正在进行的一个关键项目是将服务移动到Envoy Proxy作为微服务容器的&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sidecar&lt;/a&gt;。这意味着，每个服务将拥有自己的Envoy副本，而不是与主机上的Envoy通信(这是一个共享资源)。&lt;/p&gt;
&lt;p&gt;我们采用sidecar模型，设置Envoy来处理出入口问题。传入的请求(来自另一个服务或另一个Envoy的入口)将通过本地Envoy传入，我们可以使用规则来验证流量是否合法。向外(出口)的流量将通过sidecar Envoy，sidecar Envoy像以前一样负责将流量路由到正确的地方。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/deploying-envoy-proxy/envoy-blog-5.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;转移到sidecar的一个关键优势是能够定义网络隔离规则。以前，我们无法锁定敏感的微服务，因为流量来自一个共享的Envoy，所以只能在网络级别上接收来自某些Kubernaetes Pod ip 的流量。服务必须有自己的逻辑来验证请求是否合法，是否来自可信源。&lt;/p&gt;
&lt;p&gt;通过在Pod名称空间中移动Envoy，我们能够向Pod添加&lt;a href=&#34;https://docs.projectcalico.org/v3.5/reference/calicoctl/resources/networkpolicy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Calico网络策略规则&lt;/a&gt;，从而为每个微服务有效地建立网络防火墙。在这个例子中，我们可以说流量只能进入服务。来自其他微服务Pod的特定子集的帐户Pod。通过拒绝网络级别上未知的流量，这提供了一个额外的安全层。&lt;/p&gt;
&lt;p&gt;我们使用Envoy而不使用Linkerd的一个关键原因是，使用Envoy处理能力和内存需求显著降低。我们现在在我们的基础设施中运行了数千份Envoy，随着我们将Envoy作为所有服务部署的sidecar推出，这个数字还在继续增长。&lt;/p&gt;
&lt;h2 id=&#34;我们从envoy中收获了什么&#34;&gt;我们从Envoy中收获了什么&lt;/h2&gt;
&lt;p&gt;拥有Envoy是一段伟大的旅程。我们能够在不重新构建任何现有服务的情况下进行此升级，从而获得更好的洞察力。我们对所看到的资源消耗和延迟方面的改进非常满意，并且我们相信随着用户基数的增长，Envoy能够支持我们未来的需求。&lt;/p&gt;
&lt;p&gt;我们感谢您对Envoy社区提供的帮助和支持，并希望继续作出更多贡献。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>为 Envoy 赋能——如何基于 Envoy 构建一个多用途控制平面</title>
      <link>https://cloudnative.to/blog/building-a-control-plane-for-envoy/</link>
      <pubDate>Mon, 25 Mar 2019 21:02:19 +0800</pubDate>
      <guid>https://cloudnative.to/blog/building-a-control-plane-for-envoy/</guid>
      <description>&lt;p&gt;本文为翻译文章，&lt;a href=&#34;https://medium.com/solo-io/building-a-control-plane-for-envoy-7524ceb09876&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击查看原文&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;编者案&#34;&gt;编者案&lt;/h2&gt;
&lt;p&gt;Idit Levine 作为 solo.io 创始人兼首席执行官，在本系列博客中介绍了她们的产品 Gloo。这篇博客是系列中的其中一篇，这一篇的主要内容是，如果要基于 Envoy 构建一个控制平面的话，我们需要考虑哪些问题；要用什么样的解决方案来应对这些问题。作者在本文章阐述了 Envoy 的工作原理、为什么要选择 Envoy 以及在构建一个控制平面过程中要做出的技术体系结构的抉择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在本系列博客中，我们将分享如何为 &lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy Proxy&lt;/a&gt; 构建一个多用途控制平面 &lt;a href=&#34;https://gloo.solo.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gloo&lt;/a&gt; 的经验。本系列的第一个博客关注于 Envoy 的设计，以及在构建控制平面的第一层时需要做出的技术体系结构抉择。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Envoy Proxy 是由 Lyft 研发团队设计的&lt;a href=&#34;https://blog.envoyproxy.io/the-universal-data-plane-api-d15cec7a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;通用数据平面&lt;/a&gt;。Envoy 的优势源于性能、可扩展性和动态配置的结合。然而，这种能力是以增加配置复杂性为代价的。事实上，Envoy 配置是由管理层(通常称为“控制平面”)通过机器生成的。&lt;/p&gt;
&lt;p&gt;为 Envoy 编写一个控制平面并不是一件容易的事情，就像 Ambassador 创建者最近在一篇&lt;a href=&#34;https://www.infoq.com/articles/ambassador-api-gateway-kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;文章&lt;/a&gt;中描述的那样，该文章详细描述了他们反复尝试构建这个控制平面的过程。在接下来的一系列博客中，将向你分享我们自己的经验、设计选择和实现考虑，这些让我们能够利用 Envoy 提供的强大功能。&lt;/p&gt;
&lt;h2 id=&#34;envoy-是如何工作的&#34;&gt;Envoy 是如何工作的？&lt;/h2&gt;
&lt;p&gt;在讨论如何构建控制平面之前，首先来简要回顾一下 Envoy 作为边缘代理的工作原理。&lt;/p&gt;
&lt;p&gt;当请求到达集群时，Envoy 可以使用控制平面做很多事情，包括路由、鉴权、负载平衡等等。控制平面的角色就是通过配置来告诉 Envoy 应该做什么。&lt;/p&gt;
&lt;p&gt;Envoy 处理请求的第一件事是确定它的目的地。为此，它使用虚拟主机和路由表。然后通过一系列过滤器(称为过滤器链)发送请求。链中的每个过滤器执行不同的操作，包括修改请求、保持请求直到某个事件发生、拒绝请求等等。在某些情况下，过滤器需要从外部服务器获取信息才能执行其任务。链中的最后一个过滤器一定是路由器过滤器，它向上游发送请求。下图描述了请求通过Envoy时所采取的路径示例。&lt;/p&gt;
&lt;p&gt;在响应返回的过程中，响应还能够从集群发回之前再次通过过滤器链。同样，根据需要，这些过滤器可能与外部服务器交互，也可能不与外部服务器交互。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-filter-chain&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/building-a-control-plane-for-envoy/006gLaqLly1g109jfa12cg30q10ia3zz.gif&#34; alt=&#34;filter chain&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      filter chain
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;设置过滤器链和配置不同的过滤器及其外部服务器是控制平面的工作之一。使用 xDS API 将此配置信息发送给 Envoy。控制平面的职责是确保 Envoy 总是得到更新，并将任何需要更改其配置的情况通知 Envoy。由于在分布式系统中&lt;a href=&#34;https://queue.acm.org/detail.cfm?id=2745385&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“没有现在”&lt;/a&gt;，Envoy 的策略是遵循最终一致性的配置模型来处理配置更改。&lt;/p&gt;
&lt;p&gt;所有配置信息都从控制平面异步地发送到 Envoy。这意味着当一个请求到达时，它会发现 Envoy 已经完全配置好，并且不需要等待控制平面进行干预。因此，不会因为控制平面操作而导致延迟。&lt;/p&gt;
&lt;p&gt;另一方面，过滤器和它们使用的外部服务器如果确实位于数据路径上，可能会导致延迟。可以通过缓存来缓解此类潜在问题，并且控制平面可以为这些服务设置超时。然后可以使用跟踪来诊断由过滤器和服务器引起的问题。&lt;/p&gt;
&lt;h2 id=&#34;为什么选择-envoy-&#34;&gt;为什么选择 Envoy ？&lt;/h2&gt;
&lt;p&gt;Envoy 的许多特性以前已经详细地描述过(例如，&lt;a href=&#34;https://blog.envoyproxy.io/the-universal-data-plane-api-d15cec7a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;和&lt;a href=&#34;https://blog.envoyproxy.io/envoy-graduates-a6f71879852e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;)。其中，以下是与我们最相关的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Envoy 是非常容易扩展的，使我们可以很容易地将其扩展到新的用例中(稍后将详细介绍)。&lt;/li&gt;
&lt;li&gt;即使在快速迭代的 Envoy 中，它也是一个非常稳定的软件，带有单元测试，集成测试覆盖了98%以上的代码(由 CI 保证)。&lt;/li&gt;
&lt;li&gt;最重要的是，Envoy 得到了社会的大力支持。它是几个成功的服务网格项目(包括 Istio )背后的驱动力，并受到生态系统中许多关键参与者(如 Google、Pivotal、Red Hat 和 IBM )的贡献。Envoy 社区具有真正的合作精神，这使得为该项目作出贡献成为一种有益和愉快的经历。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;安装和配置&#34;&gt;安装和配置&lt;/h2&gt;
&lt;p&gt;既然已经了解了 Envoy 如何处理请求和响应，并确定了控制平面的角色，那么接下来就开始研究控制平面的设计。下面将向你描述这个过程中涉及的抉择，并解释在设计 Gloo 时所做的抉择。&lt;/p&gt;
&lt;p&gt;首先要做的抉择是如何部署 Envoy 。Envoy 可以部署在虚拟机中，也可以部署在容器中。这两种选项都有各自的优势，而且 Gloo 支持这两种选项，以及多个容器管理平台。为了清楚起见，我们在这里只将 Envoy 作为一个由 kubernetes 管理的容器来运行。&lt;/p&gt;
&lt;p&gt;在 Kubernetes 中，Envoy 通常作为 Deployment (允许运行指定数量的容器并对其进行向上和向下伸缩)或  DaemonSet (每个集群节点只运行一个容器)运行。官方 Envoy 容器镜像可以在&lt;a href=&#34;https://hub.docker.com/r/envoyproxy/envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;找到。&lt;/p&gt;
&lt;p&gt;对于 Gloo，我们选择在集群中使用 Kubernetes Deployment 运行 Envoy。为了向外界公开 Envoy，使用 Kubernetes LoadBalancer 服务。该服务提供一个特定于云的外部负载平衡器，将流量转发给 Envoy 实例。&lt;/p&gt;
&lt;p&gt;虽然 Envoy 通常是通过控制平面配置的，但它确实需要一些初始配置，在 Envoy 术语中称为 Bootstrap 配置。该配置包含关于如何连接到控制平面(管理服务器)、当前 Envoy 实例的标识、跟踪、管理接口配置和静态资源的信息(有关 Envoy 资源的更多信息，请参阅下面的管理部分)。&lt;/p&gt;
&lt;p&gt;为了提供 Envoy 的 Bootstrap 配置，我们使用 Kubernetes ConfigMap 对象，这是在 Kubernetes 中分发配置信息的常用方法。我们将 ConfigMap 作为一个文件挂载到 Envoy pod ，它将引导配置文件与容器解耦。在 Kubernetes 环境中，我们使用模板进行配置，并为每个 Envoy 实例生成一个惟一的配置文件，其中包含特定标识。具有特定于实例的 ID 有助于提高可观察性。&lt;/p&gt;
&lt;p&gt;一旦 Envoy 启动起来之后，它就会连接到管理服务器(如引导配置中指定的那样)，以完成配置并不断更新它。&lt;/p&gt;
&lt;h2 id=&#34;管理&#34;&gt;管理&lt;/h2&gt;
&lt;p&gt;可以在不停机的情况下实现对 Envoy 的动态配置。为了实现这一点，Envoy 定义了一组通常称为 xDS 协议的 api。从 Envoy 的 v2 开始，这是一个 gRPC 流通道，Envoy 将监听来自控制平面的配置更新。这样可以配置 Envoy 的绝大多数方面。这些动态资源包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listener Discovery Service （监听器发现服务）——配置 Envoy 监听的端口以及对传入连接采取操作。&lt;/li&gt;
&lt;li&gt;Cluster Discovery Service （集群发现服务）——配置上游集群。Envoy 将把传入的连接/请求路由到这些集群。&lt;/li&gt;
&lt;li&gt;Route Discovery Service （路由发现服务）——为传入的请求配置 L7 路由。&lt;/li&gt;
&lt;li&gt;Endpoint Discovery Service （端点服务发现）——允许 Envoy 动态地发现集群成员和健康信息。&lt;/li&gt;
&lt;li&gt;Secret Discovery Service （密钥发现服务）——允许 Envoy 发现 ssl secret 。这用于独立于监听器配置 ssl secret ，并允许从本地节点而不是集中控制平面提供 ssl secret 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gloo 实现了聚合服务发现功能，称为 ADS 。 ADS 将所有 xDS 资源聚合到一个流通道中。之所以选择 ADS 是因为它使用起来很简单，并且需要从 Envoy 实例到管理服务器的单一连接。&lt;/p&gt;
&lt;h2 id=&#34;可观察性和故障排查&#34;&gt;可观察性和故障排查&lt;/h2&gt;
&lt;p&gt;Envoy 提供许多统计信息，包括一个连接统计，它指示是否连接到其管理的服务器。这些数据可以被 Prometheus 收集，或者发送到 StatsD。 Envoy 还可以发出 Zipkin 跟踪（以及其他跟踪，如 Datadog 和 OpenTracing ）。在 Gloo 的企业版本中，我们利用了这些功能，包括使用预先配置的仪表板部署 Prometheus 和 Grafana。&lt;/p&gt;
&lt;p&gt;使用 gRPC API （与以前版本的 Envoy 中可用的 REST API 相比）有很多优点，但有一个缺点：为了调试目的而手动查询比较困难。为了解决这个问题，我们开发了一个实用程序来查询管理服务器，并在将 xDS 配置提交给 Envoy 时打印出来。&lt;/p&gt;
&lt;p&gt;当处理复杂的配置时可能会发生错误。当向 Envoy 提供无效配置时，它通过在 xDS 协议中发送一个 NACK 通知管理服务器错误状态（这可能是暂时的，因为 Envoy 遵循最终一致性的配置模型）。在我们的企业版 Gloo 中，我们检测这些 NACK 并将它们作为指标公开。&lt;/p&gt;
&lt;h2 id=&#34;可扩展性&#34;&gt;可扩展性&lt;/h2&gt;
&lt;p&gt;可以通过向过滤器链添加新的过滤器来扩展 Envoy 行为，如上所述。这些过滤器可以修改请求、影响路由和发出指标。一些有趣的 Envoy 过滤器包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ratelimit——速率限制请求。一旦速率超过限制，Envoy 就不会向上传递请求，而是返回429给调用者。&lt;/li&gt;
&lt;li&gt;Gzip——支持 Gzip 编码，动态压缩响应。&lt;/li&gt;
&lt;li&gt;Buffer——缓冲区在将请求转发到上游之前完成请求。&lt;/li&gt;
&lt;li&gt;ExtAuthz——允许对请求进行可配置的身份验证/授权。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在数据路径上扩展 Envoy 的能力非常重要，因为它处理速度非常快，而不需要将请求发送到其他代理，从而减少了延迟并提高了整体性能。控制平面可以在运行时启用或禁用这些扩展，以确保数据路径只包含所需的内容。&lt;/p&gt;
&lt;p&gt;Envoy 的可扩展设计允许我们使用上游 Envoy ，并通过提供我们内部开发的一系列过滤器来扩展它。我们开发的&lt;a href=&#34;https://github.com/solo-io/envoy-gloo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一些过滤器&lt;/a&gt;包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS——允许使用 AWS v4 签名调用 AWS Lambda 函数进行身份验证。&lt;/li&gt;
&lt;li&gt;NATS Streaming——将 http 请求转换为 NATS Streaming 发布。&lt;/li&gt;
&lt;li&gt;Transformation——高级请求体和头转换。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当设计 Gloo 时，我们试图使它具有高度可扩展性，并与 Envoy 共享相同的设计原则。为此，我们基于插件构建了 Gloo 的体系结构。通常， Gloo 为每个 Envoy 过滤器提供一个插件，负责配置该过滤器。这使我们能够快速支持新的 Envoy 扩展。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.solo.io/glooe&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gloo Enterprise&lt;/a&gt; 还包括一个缓存过滤器，以及外部认证和速率限制服务器(将在以后的博客文章中讨论)。&lt;/p&gt;
&lt;h2 id=&#34;升级和回滚&#34;&gt;升级和回滚&lt;/h2&gt;
&lt;p&gt;在我们开发扩展版 Envoy 时，与上游 Envoy 保持同步对我们来说非常重要。为了实现这一点，我们的代码仓库目录结构和 CI 非常类似于 Envoy 的代码目录结构。&lt;/p&gt;
&lt;p&gt;Envoy master 分支一直被认为是 RC 质量。因此，我们经常确保可以使用最新的 master 分支代码构建 Gloo 。这确保我们始终拥有最新的 Envoy 特性和优化，并且在需要安全更新时可以快速响应。在我们使用的32个核心 CI 上构建 Envoy 大约需要10分钟。&lt;/p&gt;
&lt;p&gt;即使是经过精心设计和测试的应用程序，在部署到生产中的复杂环境时也可能遇到问题。为了降低这种风险，通常建议采用金丝雀部署方法，即首先将新特性部署到用户或系统的子集中，并在仔细观察之后才广泛部署。使用 Gloo，我们在几个层次上采用这种方法。首先，我们允许将配置的新版本最初部署到一小部分 Envoy 实例，在这些实例中我们可以测试配置。第二，当 Envoy 的新版本可用时，我们将逐步推出这个新版本。最后，当我们准备发布控制平面的新版本时，我们首先将新版本连接到少量的 Envoy 实例，在这些实例中，我们可以仔细验证预期的行为。&lt;/p&gt;
&lt;p&gt;在本系列的下一篇博客中，我们将研究 Gloo 作为 Envoy 的控制平面的设计、我们所做的体系结构选择以及它们所代表的折衷。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
