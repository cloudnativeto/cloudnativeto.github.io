<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>李昕阳 | 云原生社区（中国）</title>
    <link>https://cloudnative.to/translators/%E6%9D%8E%E6%98%95%E9%98%B3/</link>
      <atom:link href="https://cloudnative.to/translators/%E6%9D%8E%E6%98%95%E9%98%B3/index.xml" rel="self" type="application/rss+xml" />
    <description>李昕阳</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Thu, 02 Aug 2018 15:32:40 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/translators/%E6%9D%8E%E6%98%95%E9%98%B3/avatar_hue38add62c87b7486d80c9f3fda25dfc1_12220_270x270_fill_q75_lanczos_center.jpg</url>
      <title>李昕阳</title>
      <link>https://cloudnative.to/translators/%E6%9D%8E%E6%98%95%E9%98%B3/</link>
    </image>
    
    <item>
      <title>微服务中的 Sidecar 设计模式解析</title>
      <link>https://cloudnative.to/blog/sidecar-design-pattern-in-microservices-ecosystem/</link>
      <pubDate>Thu, 02 Aug 2018 15:32:40 +0800</pubDate>
      <guid>https://cloudnative.to/blog/sidecar-design-pattern-in-microservices-ecosystem/</guid>
      <description>&lt;p&gt;本文为翻译文章，&lt;a href=&#34;https://dotnetvibes.com/2018/07/23/sidecar-design-pattern-in-your-microservices-ecosystem/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击查看原文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Sidecar 设计模式已经越来越受欢迎，并在社区内得到更广泛的采用。构建具有高度可扩展性、弹性、安全性和可观察性的微服务架构具有挑战性。&lt;strong&gt;Service Mesh 架构&lt;/strong&gt;的发展已经改变了游戏规则。它降低了与微服务架构相关的复杂性，并提供了许多功能，如负载平衡、服务发现、流量管理、熔断、遥测、故障注入等。&lt;/p&gt;
&lt;p&gt;阅读我之前的博客能够了解 Service Mesh 的概念，为什么云原生应用需要它以及它受欢迎的原因——&lt;a href=&#34;https://dotnetvibes.com/2018/07/02/the-rise-of-service-mesh-architecture/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;服务网格架构的兴起&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;什么是-sidecar-模式&#34;&gt;什么是 Sidecar 模式&lt;/h2&gt;
&lt;p&gt;将应用程序的功能划分为单独的进程可以被视为 &lt;strong&gt;Sidecar 模式&lt;/strong&gt;。Sidecar 设计模式允许你为应用程序添加许多功能，而无需额外第三方组件的配置和代码。&lt;/p&gt;
&lt;p&gt;就如 Sidecar 连接着摩托车一样，类似地在软件架构中，Sidecar 应用是连接到父应用并且为其扩展或者增强功能。Sidecar 应用与主应用程序松散耦合。&lt;/p&gt;
&lt;p&gt;让我用一个例子解释一下。想象一下假如你有 6 个微服务相互通信以确定一个包裹的成本。&lt;/p&gt;
&lt;p&gt;每个微服务都需要具有可观察性、监控、日志记录、配置、断路器等功能。所有这些功能都是根据一些行业标准的第三方库在每个微服务中实现的。&lt;/p&gt;
&lt;p&gt;但再想一想，这不是多余吗？它不会增加应用程序的整体复杂性吗？如果你的应用程序是用不同的语言编写时会发生什么——如何合并那些特定用于 .Net、Java、Python 等语言的第三方库。&lt;/p&gt;
&lt;h2 id=&#34;使用-sidecar-模式的优势&#34;&gt;使用 Sidecar 模式的优势&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;通过抽象出与功能相关的共同基础设施到一个不同层降低了微服务代码的复杂度。&lt;/li&gt;
&lt;li&gt;因为你不再需要编写相同的第三方组件配置文件和代码，所以能够降低微服务架构中的代码重复度。&lt;/li&gt;
&lt;li&gt;降低应用程序代码和底层平台的耦合度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sidecar-模式是如何工作的&#34;&gt;Sidecar 模式是如何工作的&lt;/h2&gt;
&lt;p&gt;服务网格层可以存在于与应用程序一起运行的 Sidecar 容器中。每个应用程序旁边都附有相同 Sidecar 的副本。&lt;/p&gt;
&lt;p&gt;来自单个服务的所有传入和传出网络流量都流经 Sidecar 代理。因此，Sidecar 能够管理微服务之间的流量，收集遥测数据并实施相关策略。从某种意义上说，该服务不了解整个网络，只知道附加的 Sidecar 代理。这实际上就是 Sidecar 模式如何工作的本质——将网络依赖性抽象为 Sidecar。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphar3kl3j210c0imgom_hu1fffa326e90b8e9687da9625e9061b68_41902_71f3aa16ec869a495f49a26618269ae7.webp 400w,
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphar3kl3j210c0imgom_hu1fffa326e90b8e9687da9625e9061b68_41902_4fe05477b711c74cc71f6fa2e81bf8d7.webp 760w,
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphar3kl3j210c0imgom_hu1fffa326e90b8e9687da9625e9061b68_41902_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphar3kl3j210c0imgom_hu1fffa326e90b8e9687da9625e9061b68_41902_71f3aa16ec869a495f49a26618269ae7.webp&#34;
               width=&#34;760&#34;
               height=&#34;389&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在服务网格中有数据平面和控制平面的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据平面&lt;/strong&gt;的职责是处理网格内部服务之间的通信，并负责服务发现、负载均衡、流量管理、健康检查等功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;控制平面&lt;/strong&gt;的职责是管理和配置 Sidecar 代理以实施策略并收集遥测。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Kubernetes 和 Istio 世界中，你可以将 Sidecar 注入 Pod 内。&lt;strong&gt;Istio&lt;/strong&gt; 使用带有 &lt;strong&gt;Envoy&lt;/strong&gt; 的 Sidecar 模型作为代理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;来自 Lyft 的 Envoy&lt;/strong&gt; 是为云原生应用程序设计的最流行的开源代理。Envoy 依附着每项服务运行，并以平台无关的方式提供必要的功能。所有的服务流量都通过 Envoy 代理流动。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.envoyproxy.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphh5l8plj210n06taau_hub06e8212e6ed6a34a041475fe3d5644e_14154_e24623cfcc6836dcea38dcff35101951.webp 400w,
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphh5l8plj210n06taau_hub06e8212e6ed6a34a041475fe3d5644e_14154_08005793c4b44a4583f007c8d322dac0.webp 760w,
               /blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphh5l8plj210n06taau_hub06e8212e6ed6a34a041475fe3d5644e_14154_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/sidecar-design-pattern-in-microservices-ecosystem/855e972fly1ftphh5l8plj210n06taau_hub06e8212e6ed6a34a041475fe3d5644e_14154_e24623cfcc6836dcea38dcff35101951.webp&#34;
               width=&#34;760&#34;
               height=&#34;141&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;从单体服务到微服务的转变使组织能够独立且大规模地部署应用程序。在 Container 和 Kubernetes 世界中，Sidecar 设计模式更适合。Sidecar 从应用程序中抽象出了复杂性，并处理服务发现、流量管理、负载均衡、断路器等功能。&lt;/p&gt;
&lt;p&gt;在此处了解有关 Sidecar 模式的更多信息：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/architecture/patterns/sidecar&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://docs.microsoft.com/en-us/azure/architecture/patterns/sidecar&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh 如何解决微服务中的 3 个主要挑战</title>
      <link>https://cloudnative.to/blog/how-service-mesh-addresses-3-major-microservices/</link>
      <pubDate>Sat, 28 Jul 2018 17:11:16 +0800</pubDate>
      <guid>https://cloudnative.to/blog/how-service-mesh-addresses-3-major-microservices/</guid>
      <description>&lt;p&gt;本文为翻译文章，&lt;a href=&#34;https://dzone.com/articles/how-service-mesh-addresses-3-major-microservices-c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击查看原文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们都知道微服务会增加复杂性。了解服务网络如何解决这一问题和其他挑战。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我最近正在阅读 Dimensional Research 撰写的&lt;a href=&#34;https://go.lightstep.com/global-microservices-trends-report-2018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;全球微服务趋势报告&lt;/a&gt;，在阅读的同时，我个人也认为“服务网络可以帮助解决这个问题。”所以我将阐述这 3 个挑战以及服务网格是如何解决它们。报告中引用的受访者表明微服务正在得到广泛采用。同样清楚的是，除了微服务带来的无数好处之外，同样也带来了一些严峻的挑战。报告显示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;91％的企业&lt;strong&gt;正在使用&lt;/strong&gt;微服务或有计划使用&lt;/li&gt;
&lt;li&gt;99％的用户认为在使用微服务时遇到了&lt;strong&gt;挑战&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;微服务主要的挑战&#34;&gt;微服务主要的挑战&lt;/h2&gt;
&lt;p&gt;该报告指出了公司面临的一系列挑战。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/how-service-mesh-addresses-3-major-microservices/855e972fly1fto3iki07wj20zh0d9404.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;大量公司既面临着技术上的挑战，同时也面临着组织结构上的挑战。而我将专注于能够用服务网格解决的技术挑战，但值得注意的是，服务网格所做的一件事就是带来一致性，因此可以在团队之间实现相同的愿景，从而减少对某些技能的需求。&lt;/p&gt;
&lt;h2 id=&#34;每个额外的微服务都会增加运维的难度&#34;&gt;每个额外的微服务都会增加运维的难度&lt;/h2&gt;
&lt;p&gt;如果没有服务网格，这句话将成为现实！服务网格可以通过 API 提供监控，可伸缩性和高可用性，而不是通过分离设备。这种灵活的框架消除了与现代应用相关的操作复杂性。基础设施服务传统上是通过分离设备实现的，这意味着需要到达实际的设备来获得服务。因为每个设备的唯一性，导致为每个设备提供监控，扩展和高可用性有很高的难度。服务网格通过 API 在计算集群内部提供这些服务，不需要任何其他设备。实现服务网格意味着添加新的微服务不必增加复杂性。&lt;/p&gt;
&lt;h2 id=&#34;识别性能问题的根本原因更加困难&#34;&gt;识别性能问题的根本原因更加困难&lt;/h2&gt;
&lt;p&gt;服务网格工具箱为您提供了一些有助于解决此问题的方法：&lt;/p&gt;
&lt;h3 id=&#34;分布式跟踪&#34;&gt;分布式跟踪&lt;/h3&gt;
&lt;p&gt;跟踪为不同的微服务提供服务依赖性分析，并在请求穿梭于多个微服务时跟踪此请求。它也是识别性能瓶颈和放大特定请求以定义诸如哪些微服务导致请求延迟或哪些服务产生错误之类的事情的好方法。&lt;/p&gt;
&lt;h3 id=&#34;指标的集合&#34;&gt;指标的集合&lt;/h3&gt;
&lt;p&gt;通过服务网格能够获得的另一个有用的功能是收集指标的能力。指标是在各个时间维度上了解应用程序中发生了什么，以及何时它们是健康的或者不健康的关键。服务网格可以从网格中收集遥测数据，并为每一跳产生一致的指标。这样可以更轻松地快速解决问题，并在将来构建更具弹性的应用程序。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/how-service-mesh-addresses-3-major-microservices/855e972fly1ftobpzbxnzj20rl0b2mya.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;不同的开发语言和框架&#34;&gt;不同的开发语言和框架&lt;/h2&gt;
&lt;p&gt;报告受访者指出的另一个主要挑战是在多语言世界中维护分布式架构的挑战。当从单体服务到微服务的转变时，许多公司都面临着一个现实就是，他们必须使用不同的语言和工具来让系统工作起来。大型企业尤其受此影响，因为他们拥有许多大型分布式团队。服务网格通过提供编程语言不可知性来提供一致性，这解决了多语言世界中的不一致性，其中不同的团队（每个团队都有自己的微服务）可能使用不同的编程语言和框架。网格还提供了统一的、覆盖整个应用程序的观测点，用于将可见性和控制性引入应用程序，同时将服务间的通信从隐含的基础架构领域移出到一个可以轻松查看，监视，管理和控制的位置。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/servicemesher/website/master/content/blog/how-service-mesh-addresses-3-major-microservices/855e972fly1ftobqt0wv7j20ry0ce0uc.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;微服务很酷，但服务网格使得它更酷。如果您正处于微服务的路途中并且发现难以应付基础架构挑战，那么服务网格可能是正确的答案。如果您对如何充分利用服务网格有任何疑问，请告诉我们，我们的工程团队随时可以与您交流。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>速率限制 part2—作用于 API 网关的速率限制</title>
      <link>https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/</link>
      <pubDate>Tue, 03 Jul 2018 12:11:49 +0800</pubDate>
      <guid>https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/</guid>
      <description>&lt;p&gt;本文为翻译文章，&lt;a href=&#34;https://blog.getambassador.io/rate-limiting-for-api-gateways-892310a2da02&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击查看原文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在本速率限制系列的&lt;a href=&#34;https://cloudnative.to/blog/rate-limiting-a-useful-tool-with-distributed-systems-part1&#34;&gt;第一篇文章&lt;/a&gt;中，介绍了实施速率限制的动机，并讨论了几种实施方案（取决于你是否同时作为通信的发送端和接收端）以及相关的权衡。本文会更加深入地探讨 API 网关速率限制的需求。&lt;/p&gt;
&lt;h2 id=&#34;为什么-api-网关需要速率限制&#34;&gt;为什么 API 网关需要速率限制&lt;/h2&gt;
&lt;p&gt;在第一篇文章中，我讨论了在何处实施速率限制的几个选项：发送端、接收端或中间层（字面意思可以理解为发送端和接收端中间的服务）。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof0emvx9j20oj04jgli_huaacb742d5c34e65a89b1645d1f4973f3_10190_17888f6a28555005d1e6d6ba74a7abc9.webp 400w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof0emvx9j20oj04jgli_huaacb742d5c34e65a89b1645d1f4973f3_10190_979d2708e832522337f2b29ff039f801.webp 760w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof0emvx9j20oj04jgli_huaacb742d5c34e65a89b1645d1f4973f3_10190_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof0emvx9j20oj04jgli_huaacb742d5c34e65a89b1645d1f4973f3_10190_17888f6a28555005d1e6d6ba74a7abc9.webp&#34;
               width=&#34;760&#34;
               height=&#34;140&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

当通过公共 API 暴露你的应用程序时，通常你必须在接收端或中间层中实施速率限制。即使你控制了源代码（客户端）应用程序，你也希望防止会导致过多 API 请求的错误产生，同时应付可能会试图破坏客户端应用程序的不良行为者。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof2hv9hgj20jk06tdgn_hu9a55e17f793ed0c5833126b5d562d46a_18968_870098643d1688cdba58e32939984b87.webp 400w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof2hv9hgj20jk06tdgn_hu9a55e17f793ed0c5833126b5d562d46a_18968_6e38d8ebbab178d7101a0374c44d7871.webp 760w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof2hv9hgj20jk06tdgn_hu9a55e17f793ed0c5833126b5d562d46a_18968_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof2hv9hgj20jk06tdgn_hu9a55e17f793ed0c5833126b5d562d46a_18968_870098643d1688cdba58e32939984b87.webp&#34;
               width=&#34;704&#34;
               height=&#34;245&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Stripe 博客有一篇精彩的关于“&lt;a href=&#34;https://stripe.com/blog/rate-limiters&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;用限速器扩展你的 API&lt;/a&gt;”的文章，我将在本文中引用这篇文章，那篇文章的开头部分讨论了速率限制会如何帮助你在以下情况中让你的 API 更加可靠：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;某位用户制造了流量洪峰，导致你的应用过载，而你的应用此时还需要为其他用户提供服务。&lt;/li&gt;
&lt;li&gt;某位用户因为使用了行为不当的脚本，无意中向你发送了很多请求（相信我，这比你想象的要更频繁 - 我曾经亲自创建的压测脚本就意外触发了拒绝服务！）。又或者，更糟的情况是，某位用户试图故意让你的服务器过载。&lt;/li&gt;
&lt;li&gt;用户向你发送很多优先级较低的请求，而你需要确保它不会影响高优先级的通信。例如，发送大量分析数据请求的用户可能会影响其他用户的关键事务。&lt;/li&gt;
&lt;li&gt;系统中出现了某些内部问题，因此无法提供所有常规流量服务，并且需要丢弃低优先级的请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Datawire 工作期间，我们通常能够第一手地发现以上这些情况，特别是在那些暴露“免费”公共 API 的公司或者组织中，同时在这些组织中，也存在着明确的业务需求，即让付费用户优先使用流量，并且防止不良行为者（无论是有意或无意）。&lt;/p&gt;
&lt;h2 id=&#34;速率限制和负载削减的基础知识&#34;&gt;速率限制和负载削减的基础知识&lt;/h2&gt;
&lt;p&gt;基本上，要理解速率限制的概念很简单。对于每个要限制的请求属性，只需统计属性的唯一实例出现次数，并在每个时间单位超过指定的计数时拒绝服务相关的请求。例如，如果你想限制每个客户端发出的请求数量，你将使用“客户端标识”属性（可能通过字符串键值为 &lt;code&gt;clientID&lt;/code&gt; 的请求参数或直接包含在请求头部中），并为标识符保留一个计数器。&lt;/p&gt;
&lt;p&gt;你还可以指定单位时间的最大请求数，并且定义一个计数递减算法，而不是在每个单位时间开始时重置计数器（稍后会详细介绍）。当请求到达 API 网关时，它会递增相应的请求计数器并检查这个递增是否超过单位时间内最大允许请求数。如果超过，则拒绝这个请求，最常见的情况是向调用客户端返回 &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Too Many Requests”HTTP 429 状态码&lt;/a&gt;。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof4rdz1qj20lg07jt8w_huf5a9eb12dec080ef7b405482e3193537_22355_475d899739f9c75ba2f4784623d5b239.webp 400w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof4rdz1qj20lg07jt8w_huf5a9eb12dec080ef7b405482e3193537_22355_01dca38eecc3eecfdca84c116f2402cb.webp 760w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof4rdz1qj20lg07jt8w_huf5a9eb12dec080ef7b405482e3193537_22355_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof4rdz1qj20lg07jt8w_huf5a9eb12dec080ef7b405482e3193537_22355_475d899739f9c75ba2f4784623d5b239.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;与速率限制密切相关的是“负载削减”。两者的主要区别在于判定拒绝请求的条件。速率限制是基于单个请求的属性（例如 clientId），而负载削减是基于应用的总体状态（例如，处于高负载的数据库）。如果系统仍处于部分运行状态，但是需要时间来恢复（或修复），则在流量入口点削减负载可以大量减少线上事故。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof5go9vvj20mq07dt8y_hu6485f23e60e2e8e9568294bae27898e8_25036_7895fec259eb9dccabd6c575e18244f1.webp 400w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof5go9vvj20mq07dt8y_hu6485f23e60e2e8e9568294bae27898e8_25036_04198db154d7c4b6b0f87673fbf5d560.webp 760w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof5go9vvj20mq07dt8y_hu6485f23e60e2e8e9568294bae27898e8_25036_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof5go9vvj20mq07dt8y_hu6485f23e60e2e8e9568294bae27898e8_25036_7895fec259eb9dccabd6c575e18244f1.webp&#34;
               width=&#34;760&#34;
               height=&#34;246&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;api-网关存在的挑战&#34;&gt;API 网关存在的挑战&lt;/h2&gt;
&lt;p&gt;大多数开源和商业 API 网关都提供速率限制，但在众多实现中，普遍存在的挑战之一就是可扩展性。在单个计算实例上运行 API 网关相对简单，这意味着你可以将速率限制的计数器保留在单机内存中。比如你是对 clientId 进行速率限制，则只需在内存映射中检查并设置（增加）关联 clientId 的整数计数器即可。但是，此方法不能扩展单个实例到网关实例集群。&lt;/p&gt;
&lt;p&gt;我见过一些开发人员试图通过使用粘性会话或将可允许请求的总数除以速率限制实例的数量来解决此限制。但是，这样做的问题在于，在高度动态的“云原生”环境中部署和运行应用程序时，这些方法都无法可靠地工作，因为在这种环境中，实例随时会被销毁并按需重建，或是动态扩容的。&lt;/p&gt;
&lt;p&gt;克服此限制的最佳解决方案是使用某种形式的高性能集中式数据存储来管理请求计数。例如，在 Lyft，该团队使用 &lt;a href=&#34;https://redis.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Redis&lt;/a&gt;（大概是作为高可用的 Redis Sentinel 集群运行），通过他们的 Envoy 代理统计&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/global_rate_limiting.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;速率限制的指标&lt;/a&gt;，而该代理通过 sidecar 模式部署到所有服务和数据存储上。这种方法需要注意一些潜在的问题，特别是在 Redis 的检查和设置操作的原子性方面。出于性能原因通常建议避免使用锁机制，而 &lt;a href=&#34;https://gist.github.com/ptarjan/e38f45f2dfe601419ca3af937fff574d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stripe&lt;/a&gt; 和 &lt;a href=&#34;https://blog.figma.com/an-alternative-approach-to-rate-limiting-f8a06cf7c94c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figma&lt;/a&gt; 通过在 Redis 引擎中使用 Lua 脚本功能保证原子性。&lt;/p&gt;
&lt;p&gt;另一个经常遇到的挑战涉及如何提取请求（元）数据用于决策速率限制，或者指定（或实现）用于确定是否应该拒绝特定请求的相关算法。理想情况下，你希望能够通过客户端属性（例如请求 HTTP 方法，位置，设备等）和后台属性（例如服务端点，由用户还是应用程序发起的请求等类似的语义信息以及期望的有效负载）来决策速率限制。&lt;/p&gt;
&lt;h2 id=&#34;通过外部服务实施速率限制&#34;&gt;通过外部服务实施速率限制&lt;/h2&gt;
&lt;p&gt;针对上一节讨论的许多挑战，&lt;a href=&#34;https://eng.lyft.com/announcing-ratelimit-c2e8f3182555&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lyft 工程团队&lt;/a&gt;去年提出了一个有趣的解决方案，当时他们谈论了他们如何使用 Envoy 代理（我们现在叫的名字）作为服务网格，通过为每个请求调用外部 &lt;a href=&#34;https://github.com/lyft/ratelimit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RateLimit&lt;/a&gt; 服务来实现限制速率。RateLimit 服务符合&lt;a href=&#34;https://github.com/lyft/ratelimit/blob/master/proto/ratelimit/ratelimit.proto&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;定义的速率限制 Protobuf 协议，而这实际上就是一个速率限制 API。Datawire 团队已经在 Envoy 代理之上构建了开源 Ambassador API 网关，同时最近 &lt;a href=&#34;https://twitter.com/alex_gervais&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alex Gervais&lt;/a&gt; 已经为 Ambassador 提供了相同的&lt;a href=&#34;https://blog.getambassador.io/ambassador-adds-rate-limiting-support-in-0-31-595cc8f91e49&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;速率限制支持&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;由于你现在可以访问一个基于 Protobuf 速率限制服务 API，因此你可以使用任何你喜欢的语言（或至少是任何支持 Protobuf 的现代化语言）来实现拥有速率限制的服务。你现在还可以完全自由地在服务中实现任何你喜欢的速率限制算法，并且基于任何你想要传递给服务的元数据来制定速率限制策略。Lyft RateLimit 服务中的&lt;a href=&#34;https://github.com/lyft/ratelimit#user-content-examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;示例&lt;/a&gt;提供了一些有趣的灵感！值得一提的是，由于 Ambassador API 网关在 Kubernetes 内部运行，你创建的任何限制速率的服务都可以利用 Kubernetes 来处理扩展和容错。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof69xqimj20h80bemxj_hu2a3766f1e4b0e2a3cfdc7242573887ba_23549_aecff21725ce0546cd3dd1ab42af329e.webp 400w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof69xqimj20h80bemxj_hu2a3766f1e4b0e2a3cfdc7242573887ba_23549_21f1e4ac38c720d7c9ccb06fd73db0b8.webp 760w,
               /blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof69xqimj20h80bemxj_hu2a3766f1e4b0e2a3cfdc7242573887ba_23549_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/rate-limiting-for-api-gateway-daniel-bryant-part2/855e972fly1fsof69xqimj20h80bemxj_hu2a3766f1e4b0e2a3cfdc7242573887ba_23549_aecff21725ce0546cd3dd1ab42af329e.webp&#34;
               width=&#34;620&#34;
               height=&#34;410&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;关于系列文章的下一篇&#34;&gt;关于系列文章的下一篇&lt;/h2&gt;
&lt;p&gt;在我们的速率限制系列的第二篇文章中，阐述了在 API 网关实施速率限制和负载削减的动机，并且还探讨了实施过程中可能遇到的一些挑战。在文章的最后一节中，我提出了一些在现代云平台（如 Kubernetes，ECS 等）中部署集成有速率限制 API 网关的想法，并讨论了如何使用外部服务来实现这一切，以达到在实施你对速率限制算法的要求的同时，还能提供很大灵活性。&lt;/p&gt;
&lt;p&gt;下周我们将发布本系列的最后一部分，我们将介绍如何利用 Java 为 Ambassador API 网关实施速率限制服务（&lt;a href=&#34;https://github.com/danielbryantuk/ambassador-java-rate-limiter/blob/master/src/main/java/io/datawire/ambassador/ratelimiter/simpleimpl/RateLimitServer.java&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;代码链接&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;同时，请随时通过电子邮件发送任何问题，或到 Ambassador 的 &lt;a href=&#34;https://gitter.im/datawire/ambassador&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gitter 频道&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
