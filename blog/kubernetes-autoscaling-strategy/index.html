<!DOCTYPE html><html lang="zh" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="云原生社区" />

  
  
  
    
  
  <meta name="description" content="本文讲述了 Kubernetes 集群自动伸缩策略的一些最佳实践。" />

  
  <link rel="alternate" hreflang="zh" href="https://cloudnative.to/blog/kubernetes-autoscaling-strategy/" />

  
  
  
    <meta name="theme-color" content="#0a55a7" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.2f500d272ea4379dca952215a5d02351.css" />

  



  


  


  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f3dc895ea3bd6186cd835841d365c103";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu12a4295615259de83f102fd096a49a31_6281_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu12a4295615259de83f102fd096a49a31_6281_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://cloudnative.to/blog/kubernetes-autoscaling-strategy/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@CloudNativeCN" />
    <meta property="twitter:creator" content="@CloudNativeCN" />
  
  <meta property="og:site_name" content="云原生社区（中国）" />
  <meta property="og:url" content="https://cloudnative.to/blog/kubernetes-autoscaling-strategy/" />
  <meta property="og:title" content="如何选择最佳的 Kubernetes 集群自动伸缩策略 | 云原生社区（中国）" />
  <meta property="og:description" content="本文讲述了 Kubernetes 集群自动伸缩策略的一些最佳实践。" /><meta property="og:image" content="https://cloudnative.to/media/sharing.png" />
    <meta property="twitter:image" content="https://cloudnative.to/media/sharing.png" /><meta property="og:locale" content="zh" />
  
    
      <meta
        property="article:published_time"
        content="2021-06-30T18:00:00&#43;08:00"
      />
    
    <meta property="article:modified_time" content="2023-04-06T14:23:48&#43;08:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://cloudnative.to/blog/kubernetes-autoscaling-strategy/"
  },
  "headline": "如何选择最佳的 Kubernetes 集群自动伸缩策略",
  
  "datePublished": "2021-06-30T18:00:00+08:00",
  "dateModified": "2023-04-06T14:23:48+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Daniele Polencic"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "云原生社区（中国）",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cloudnative.to/media/logo.svg"
    }
  },
  "description": "本文讲述了 Kubernetes 集群自动伸缩策略的一些最佳实践。"
}
</script>

  

  

  

  





  <title>如何选择最佳的 Kubernetes 集群自动伸缩策略 | 云原生社区（中国）</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="cc4c66a52ce4fd10a0ae66de3b5dc1f8" >
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden="true"></i></button>
  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.62d6f8dfe8493f1c68557dde65bec362.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6 search-title">
          <p>搜索</p>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="关闭"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="搜索..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="搜索...">
        
      </div>

      
      

      
    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

      <div id="search-common-queries">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    











  


<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"><img src="/media/logo.svg" alt="云原生社区（中国）"
            
            ></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="切换导航">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"><img src="/media/logo.svg" alt="云原生社区（中国）"
          
          ></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/community"><span>社区</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/blog"><span>博客</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>资料</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/envoy/"><span>Envoy 中文文档</span></a>
              
                <a class="dropdown-item" href="/kubebuilder/"><span>Kubebuilder 中文文档</span></a>
              
                <a class="dropdown-item" href="https://lib.jimmysong.io/"><span>云原生资料库</span></a>
              
                <a class="dropdown-item" href="https://istio.io/latest/zh/"><span>Istio 中文文档</span></a>
              
            </div>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/event"><span>活动</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#feed"><span>更新</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#tags"><span>标签</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>关于</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        <li class="nav-item">
            <a class="nav-link" href="/community/join/" data-toggle="tooltip" data-placement="bottom" title="加入社区" aria-label="主站"><i class="fa-brands fa-weixin" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item">
            <a class="nav-link js-search" href="#" data-toggle="tooltip" data-placement="bottom" title="搜索" aria-label="搜索"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://github.com/cloudnativeto/cloudnative.to" target="_blank" rel="noopener" data-toggle="tooltip" data-placement="bottom" title="查看源码" aria-label="查看源码" aria-label="GitHub"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item">
          <a href="#" class="nav-link set-theme">
            <i class="fa fa-sun" aria-hidden="true" id="theme-icon"></i>
          </a>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <div class="container-xl">
    <div class="post-container">
        












  

  
  
  
<div class="article-container pt-3">
  <h1>如何选择最佳的 Kubernetes 集群自动伸缩策略</h1>

  

  
    


<div class="article-metadata">

  <div>
  
  
  
  
    <i class="fa-solid fa-feather"></i>
    

  <span >
      <a href="/author/daniele-polencic/">Daniele Polencic</a></span>
    
    <span class="middot-divider"></span>
    
  
  
  
  
  
  
    <i class="fa fa-language"></i>
    

  <span >
      <a href="/translators/%E9%83%AD%E5%8D%AB%E4%B8%9C/">郭卫东</a></span>
    <span class="middot-divider"></span>
  
  
  
  
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/kubernetes/" class="text-capitalize">kubernetes</a></span>
  
  </div>

  
  <span class="article-date">
    
    
      
          
          发布于
      
    
    2021-06-30
  </span>
  

  

  
  <span class="middot-divider"></span>
  字数 6637
  <span class="middot-divider"></span>
  <span class="article-reading-time">
      阅读时长 30 分钟
  </span>
  

  
  
  
  

</div>

    





  
</div>


    </div>
    <div class="border-bottom mb-2"></div>
    <div class="row flex-xl-nowrap">
        <div class="col-3 d-none d-xl-block docs-toc">
            <!-- toc -->
            
<div class="">
    <ul class="nav toc-top">
        <li>
            <a href="#" id="back_to_top" class="docs-toc-title">目录</a>
        </li>
    </ul>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#前言">前言</a></li>
    <li><a href="#目录">目录</a>
      <ul>
        <li><a href="#当自动伸缩的-pod-报错">当自动伸缩的 Pod 报错</a></li>
        <li><a href="#kubernetes-的-cluster-autoscaler-是如何工作的">Kubernetes 的 Cluster Autoscaler 是如何工作的</a></li>
        <li><a href="#探索-pod-自动伸缩前置期">探索 Pod 自动伸缩前置期</a></li>
        <li><a href="#为-kubernetes-节点选择最佳实例大小">为 Kubernetes 节点选择最佳实例大小</a></li>
        <li><a href="#在-kubernetes-集群中过度配置节点">在 Kubernetes 集群中过度配置节点</a></li>
        <li><a href="#为-pod-选择正确的内存和cpu资源">为 Pod 选择正确的内存和CPU资源</a></li>
        <li><a href="#关于集群的缩容">关于集群的缩容</a></li>
        <li><a href="#为什么不基于内存或cpu进行自动伸缩">为什么不基于内存或CPU进行自动伸缩</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
</div>

            <!-- /toc -->
            
            <div class="subscribe-module col-12 mt-1">
    <img src="/img/wechat.jpg" alt="image" title="云原生社区的微信公众号"/>
    <p class="text-center pt-1">关注「云原生社区动态」微信公众号，获取本站更新</p>
</div>

            
        </div>
        <main class="article-body col-9 container docs-content" role="main">
            <article class="article">
                <div class="article-style">
                    
                    <details class="toc-inpage d-print-none d-show-block mb-0">
  <summary class="font-weight-bold">点击查看目录</summary>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#前言">前言</a></li>
    <li><a href="#目录">目录</a>
      <ul>
        <li><a href="#当自动伸缩的-pod-报错">当自动伸缩的 Pod 报错</a></li>
        <li><a href="#kubernetes-的-cluster-autoscaler-是如何工作的">Kubernetes 的 Cluster Autoscaler 是如何工作的</a></li>
        <li><a href="#探索-pod-自动伸缩前置期">探索 Pod 自动伸缩前置期</a></li>
        <li><a href="#为-kubernetes-节点选择最佳实例大小">为 Kubernetes 节点选择最佳实例大小</a></li>
        <li><a href="#在-kubernetes-集群中过度配置节点">在 Kubernetes 集群中过度配置节点</a></li>
        <li><a href="#为-pod-选择正确的内存和cpu资源">为 Pod 选择正确的内存和CPU资源</a></li>
        <li><a href="#关于集群的缩容">关于集群的缩容</a></li>
        <li><a href="#为什么不基于内存或cpu进行自动伸缩">为什么不基于内存或CPU进行自动伸缩</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
</details>

                    
                    <h2 id="前言">前言</h2>
<p>这篇内容篇幅比较长，如果不想深入探讨或时间有限，这是全文简述：
在默认设置下，扩展 Kubernetes 集群中的 pod 和节点可能需要几分钟时间。
了解如何调整集群节点的大小、配置水平和集群自动缩放器以及过度配置集群以加快扩展速度。</p>
<h2 id="目录">目录</h2>
<ul>
<li>当自动伸缩的 Pod 报错</li>
<li>Kubernetes 的 Cluster Autoscaler 是如何工作的</li>
<li>探索 Pod 自动伸缩提前期</li>
<li>为 Kubernetes 节点选择最佳实例大小</li>
<li>在 Kubernetes 集群中过度配置节点</li>
<li>为 Pod 选择正确的内存和CPU资源</li>
<li>关于集群的缩容</li>
<li>为什么不基于内存或CPU进行自动伸缩</li>
</ul>
<p>在 Kubernetes 中, 自动伸缩功能包括:</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener">Pod水平自动伸缩（Horizontal Pod Autoscaler，HPA）</a></li>
<li><a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler" target="_blank" rel="noopener">Pod垂直自动伸缩（Vertical Pod Autoscaler，VPA）</a></li>
<li><a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler" target="_blank" rel="noopener">集群自动伸缩（Cluster Autoscaler，CA）</a></li>
</ul>
<p>这些自动伸缩组件属于不同的类别，关注点也不同。</p>
<p>Horizontal Pod Autoscaler 负责增加 Pod 的副本数量。随着你的应用接收到的流量越来越多，你可以让自动伸缩组件调整副本数量来处理更多的请求。</p>
<p>Vertical Pod Autoscaler 的使用场景是，当资源不足无法创建更多的 Pod 副本时，而又仍然需要处理更多的流量。
一个简单的例子，你无法通过简单地添加更多的 Pod 副本来扩容数据库。数据库可能需要进行数据分片或者配置只读节点。
但你可以通过增加内存和CPU资源来让数据库能够处理更多的连接数。
这正是 VPA 的目的，增加 Pod 的资源大小。</p>
<p>最后，我们要说说集群自动伸缩组件了。
当你的集群资源不足时，Cluster Autoscaler 会配置一个新的计算单元并将其添加到集群中。如果空节点过多，会移除它们以降低成本。</p>
<p>虽然这三个组件都 “自动伸缩” 了一些东西，但它们并不造成相互之间的干扰。它们各自都有自己使用场景，定义和工作机制。并且它们是在独立的项目中开发的，独立的使用。
然而，更重要的是，为了最好的 scaling 你的集群，你必须花些心思去设置好这些 Autoscaler，让我们看个例子。</p>
<h3 id="当自动伸缩的-pod-报错">当自动伸缩的 Pod 报错</h3>
<p>想象一下，有一个应用程序始终需要并使用 1.5GB 内存和 0.25 个 vCPU。
你配置了一个具有 8GB 和 2 个 vCPU 的单个节点的集群 —— 它应该能够完美地容纳四个 pod（并且还有一点额外的空间）。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/single-node_hu249e6136c0857e803b8f27b723043a99_73312_24965148d8394969f9c530ce6b2dc1d5.webp 400w,
               /blog/kubernetes-autoscaling-strategy/single-node_hu249e6136c0857e803b8f27b723043a99_73312_c8095f18337055175ee8e8359d258109.webp 760w,
               /blog/kubernetes-autoscaling-strategy/single-node_hu249e6136c0857e803b8f27b723043a99_73312_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/single-node_hu249e6136c0857e803b8f27b723043a99_73312_24965148d8394969f9c530ce6b2dc1d5.webp"
               width="760"
               height="502"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>现在，你部署了一个 Pod 并且配置如下：</p>
<ol>
<li>HPA 配置每 10 个请求进来就添加一个 Pod 副本（例如：如果有 40 个并发请求涌入，会扩容到 4 个 Pod 副本）。</li>
<li>CA 配置在资源不足时，创建更多的 Node 节点。</li>
</ol>
<blockquote>
<p>HPA 可以通过在 deployment 文件中使用 Custom Metrics（例如在 Ingress Controller 中的 queries per second（QPS）） 来扩容 Pod 副本数量。</p>
</blockquote>
<p>现在，你开始为集群增加 30 个并发请求，并观察一下情况：</p>
<ol>
<li>HPA 开始扩容 Pod。</li>
<li>创建了两个 Pod 副本。</li>
<li>CA 没有触发 - 没有新增集群 Node 节点。</li>
</ol>
<p>这很好理解，因为现在有足够的内存和 CPU 资源来支持更多的 Pod。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="node-enogh.png" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>你进一步将流量增加到 40 个并发请求，并再次观察：</p>
<ol>
<li>HPA 又创建了一个 Pod。</li>
<li>这个 Pod 是 pending 状态并且无法被部署。</li>
<li>CA 触发创建了一个新的 Node 节点。</li>
<li>新 Node 节点启动 4 分钟后开始工作。之后，pending Pod 也成功被部署了。</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/pending-pod_hu2eac3b555b4e2c6dcea897ccad6d26bd_100624_4a665b309f6233871f2f1093f4d8a6d7.webp 400w,
               /blog/kubernetes-autoscaling-strategy/pending-pod_hu2eac3b555b4e2c6dcea897ccad6d26bd_100624_97d18770acf41f0ff49b5e9da1746a86.webp 760w,
               /blog/kubernetes-autoscaling-strategy/pending-pod_hu2eac3b555b4e2c6dcea897ccad6d26bd_100624_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/pending-pod_hu2eac3b555b4e2c6dcea897ccad6d26bd_100624_4a665b309f6233871f2f1093f4d8a6d7.webp"
               width="760"
               height="551"
               loading="lazy" data-zoomable /></div>
  </div></figure>

















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/pending-pod-2_hubb601206bd1ea92f7c29004438f8f127_94267_af972ca784ad53e96e5dece8b0c72ab1.webp 400w,
               /blog/kubernetes-autoscaling-strategy/pending-pod-2_hubb601206bd1ea92f7c29004438f8f127_94267_8ec3fb3204baa4556b05c6cd91fc5e67.webp 760w,
               /blog/kubernetes-autoscaling-strategy/pending-pod-2_hubb601206bd1ea92f7c29004438f8f127_94267_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/pending-pod-2_hubb601206bd1ea92f7c29004438f8f127_94267_af972ca784ad53e96e5dece8b0c72ab1.webp"
               width="760"
               height="561"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>为什么第四个 Pod 没有部署在第一个 Node 节点上呢？</p>
<p>Pod 部署在集群上需要消耗内存，CPU，硬盘空间等资源，在同一个 Node 上，操作系统和 kubelet 组件也需要消耗内存和 CPU 资源。</p>
<p>Kubernetes 中一个 Worker Node 节点的内存和 CPU 等资源使用分布如下：</p>
<ol>
<li>需要运行操作系统和一些系统级的守护进程，例如 SSH，Systemd 等。</li>
<li>需要运行 Kubernetes Agent 组件，例如 Kubelet，Container Runtime，<a href="https://github.com/kubernetes/node-problem-detector" target="_blank" rel="noopener">Node Problem Detector</a> 等。</li>
<li>需要运行 Pod。</li>
<li>需要保留一些资源用来<a href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#eviction-thresholds" target="_blank" rel="noopener">驱逐阀值</a> 之用。</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt=""
           src="/blog/kubernetes-autoscaling-strategy/eviction-threshold.svg"
           loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>你猜的没错，所有这些配额都是可定制的，但你需要好好计算一下。</p>
<p>在一个 8GB 内存和 2vCPU 的单个节点的，可以按如下估算：</p>
<ul>
<li>操作系统运行大概需要 100MB 内存和 0.1vCPU。</li>
<li>kubelet 运行大概需要 1.8GB 内存和 0.07vCPU。</li>
<li>驱逐阀值大概需要 100MB 内存。</li>
</ul>
<p>剩余的大约 6GB 内存空间和 1.83vCPU 是提供给 Pod 使用的。</p>
<p>如果你的集群需要运行 DaemonSet 资源，像 kube-proxy，那么你应该进一步减少提供给 Pod 的资源。考虑到 kube-proxy 大概需要 128MB 内存和 0.1vCPU，那么剩余大约 5.9GB 内存空间和 1.73vCPU 是提供给 Pod 使用的。</p>
<p>另外，如果还需要运行 CNI 组件（例如：Flannel）和日志收集组件（Flentd），又会进一步减少提供给 Pod 的资源。</p>
<p>在统计完所有其他的资源占用情况后，集群的剩余空间就只够运行三个 Pod 了。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/left-space-pod_hub02aa49573785d4a8215002a09b59d44_120739_e4e4119b9e3ef0d768b59155481edfb5.webp 400w,
               /blog/kubernetes-autoscaling-strategy/left-space-pod_hub02aa49573785d4a8215002a09b59d44_120739_7ab420d00d0182414fb45376c5d2d5f8.webp 760w,
               /blog/kubernetes-autoscaling-strategy/left-space-pod_hub02aa49573785d4a8215002a09b59d44_120739_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/left-space-pod_hub02aa49573785d4a8215002a09b59d44_120739_e4e4119b9e3ef0d768b59155481edfb5.webp"
               width="760"
               height="444"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>所以第四个会一直保持 “pending” 状态，直到它被调度到其他的 Node 节点上。</p>
<p>既然 Cluster Autoscaler 知道没有空间容纳第四个 Pod，为什么不提前配置一个新节点？
为什么它要在 Pod 处于 “pending” 状态之后再触发创建新 Node 节点的操作？</p>
<h3 id="kubernetes-的-cluster-autoscaler-是如何工作的">Kubernetes 的 Cluster Autoscaler 是如何工作的</h3>
<p>Cluster Autoscaler 不是通过观察内存或 CPU 的使用情况来触发自动伸缩的。相反地，是通过对事件的响应和每 10s 对不可调度的 Pod 进行检查。</p>
<p>当 Scheduler 无法找到可以容纳它的 Node 节点时，Pod 就会变成不可调度状态。例如，当一个 Pod 需要 1vCPU 资源而集群只有 0.5vCPU 资源可用，Scheduler 就会把该 Pod 标记为不可调度状态。</p>
<p>这时，Cluster Autoscaler 会开始创建新 Node 节点。创建完成后，它会扫描集群中的不可调度状态的 Pod，<a href="https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-are-expanders" target="_blank" rel="noopener">检查是否可以将这些 Pod 调度到新节点上</a>。</p>
<p>如果你的集群具有多种节点类型（通常也称为节点组或节点池），则 Cluster Autoscaler 将使用以下策略选择其中一种：</p>
<ul>
<li>Random - 随机选择一种节点类型（默认策略）。</li>
<li>Most Pods - 选择将调度最多 Pod 的节点组。</li>
<li>Least waste - 选择扩容后空闲 CPU 最少的节点组。</li>
<li>Price - 选择成本最低的节点组（目前仅适用于 GCP）。</li>
<li>Priority - 选择优先级最高的节点组（优先级可以手动设置）。</li>
</ul>
<p>一旦确定了节点类型，Cluster Autoscaler 将调用相关 API 来提供新的计算资源。</p>
<p>如果你使用的是 AWS，Cluster Autoscaler 将预置一个新的 EC2 实例。在 Azure 上，它将创建一个新的虚拟机，并在 GCP 上创建一个新的计算引擎。</p>
<p>创建的节点可能需要一些时间才能出现在 Kubernetes 中。计算资源准备就绪后，节点将被初始化并添加到可以部署未被调度 Pod 的集群中。</p>
<p>不幸的是，配置一个新节点通常会很慢。它可能会花费好几分钟来做这件事。</p>
<p>让我们来看看这几分钟到底干了什么。</p>
<h3 id="探索-pod-自动伸缩前置期">探索 Pod 自动伸缩前置期</h3>
<p>在新节点上创建新 Pod 所需的时间由四个主要因素决定：</p>
<ol>
<li>HPA 的反应时间。</li>
<li>CA 的反应时间。</li>
<li>Node 节点的反应时间。</li>
<li>Pod 创建的时间。</li>
</ol>
<p>默认地，<a href="https://github.com/kubernetes/kubernetes/blob/2da8d1c18fb9406bd8bb9a51da58d5f8108cb8f7/pkg/kubelet/kubelet.go#L1855" target="_blank" rel="noopener">kubelet 每 10 秒抓取一次 Pod 的 CPU 和内存使用情况</a>。每分钟，<a href="https://github.com/kubernetes-sigs/metrics-server/blob/master/FAQ.md#how-often-metrics-are-scraped" target="_blank" rel="noopener">Metrics Server 都会聚合这些指标</a>并将它们发送给 Kubernetes API 的其他组件。</p>
<p>Horizontal Pod Autoscaler 控制器负责检查指标并决定扩大或缩小副本数量。</p>
<p>默认地，<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#how-does-the-horizontal-pod-autoscaler-work" target="_blank" rel="noopener">Horizontal Pod Autoscaler 每 15 秒检查一次 Pod 指标</a>。</p>
<p><a href="https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-scale-up-work" target="_blank" rel="noopener">Cluster Autoscaler 每 10 秒检查一次集群中不可调度的 Pod</a>。</p>
<p>一旦 CA 检测到不可调度的 Pod，它就会运行一个算法来做决策：</p>
<ol>
<li>需要多少个节点来将所有的不可调度 Pod 部署完成。</li>
<li>需要创建那种类型的节点组。</li>
</ol>
<p>整个过程的时间花费应该是：</p>
<ul>
<li>在少于 100 个节点且每个节点最多 30 个 Pod 的集群上不超过 30 秒。 平均延迟应该是大约 5 秒。</li>
<li>在具有 100 到 1000 个节点的集群上不超过 60 秒。 平均延迟应约为 15 秒。</li>
</ul>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time_hu0ac249f4dd4d727642bdfdc65f4a0ebc_50587_97b27be8ce6253b3f8bd56f60e88caab.webp 400w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time_hu0ac249f4dd4d727642bdfdc65f4a0ebc_50587_d6395541c187a7cfb5d58ffce7ab4f50.webp 760w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time_hu0ac249f4dd4d727642bdfdc65f4a0ebc_50587_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/hpa-ca-time_hu0ac249f4dd4d727642bdfdc65f4a0ebc_50587_97b27be8ce6253b3f8bd56f60e88caab.webp"
               width="760"
               height="327"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>然后是节点配置时间，这主要取决于云提供商。在 3-5 分钟内供应新的计算资源是非常标准的。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-2_hu47fc0e9119c83c608cb11f6f2879cb31_60928_704bde90a4eb3e21de8ede6ec0b9e7f1.webp 400w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-2_hu47fc0e9119c83c608cb11f6f2879cb31_60928_79100a0e40095d8cf6bb11f6367279b0.webp 760w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-2_hu47fc0e9119c83c608cb11f6f2879cb31_60928_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/hpa-ca-time-2_hu47fc0e9119c83c608cb11f6f2879cb31_60928_704bde90a4eb3e21de8ede6ec0b9e7f1.webp"
               width="760"
               height="357"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>最后，Pod 必须由容器运行时创建。启动一个容器应该不会超过几毫秒，但下载容器镜像可能需要几秒钟。
如果没有缓存容器映像，则从容器注册表下载映像可能需要几秒钟到一分钟的时间，具体取决于层的大小和数量。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-3_hu9b62db9a6e38a9589d229567270fbca3_63047_1cbb6e52d055a911c849aa295891e3f5.webp 400w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-3_hu9b62db9a6e38a9589d229567270fbca3_63047_02d0429c2cf545080f10154b1e1b0018.webp 760w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-3_hu9b62db9a6e38a9589d229567270fbca3_63047_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/hpa-ca-time-3_hu9b62db9a6e38a9589d229567270fbca3_63047_1cbb6e52d055a911c849aa295891e3f5.webp"
               width="760"
               height="332"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>因此，当集群中没有空间而触发自动伸缩的时间消耗如下：</p>
<ol>
<li>Horizontal Pod Autoscaler 可能需要长达 1min30s 来增加副本数量。</li>
<li>对于少于 100 个节点的集群，Cluster Autoscaler 应该花费不到 30s 的时间，对于超过 100 个节点的集群，应该不到 1min。</li>
<li>云提供商可能需要 3-5min 来创建计算机资源。</li>
<li>容器运行时可能需要长达 30s 才能下载容器映像。</li>
</ol>
<p>如果你的集群规模不是很大，在最坏的情况下，时间消耗：</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-4_hua4091a42bbf88f1e4856ec5c3b5fe70e_67340_89dd1f39a45b8e609ce0772d7802b485.webp 400w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-4_hua4091a42bbf88f1e4856ec5c3b5fe70e_67340_496fb65c294d3fde0a4e8ee3b60d6bea.webp 760w,
               /blog/kubernetes-autoscaling-strategy/hpa-ca-time-4_hua4091a42bbf88f1e4856ec5c3b5fe70e_67340_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/hpa-ca-time-4_hua4091a42bbf88f1e4856ec5c3b5fe70e_67340_89dd1f39a45b8e609ce0772d7802b485.webp"
               width="760"
               height="286"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>对于超过 100 个节点的集群，总延迟可能高达 7 分钟。在有更多 Pod 来处理突然激增的流量之前，您是否愿意等待这 7 分钟？</p>
<p>这里提供了几种减少 scaling 时间的方法：</p>
<ul>
<li>调整 Horizontal Pod Autoscaler 的刷新时间（由 &ndash;horizontal-pod-autoscaler-sync-period 参数控制，默认 15s）。</li>
<li>调整抓取 Pod 的 CPU 和内存使用情况的间隔频率（由 metric-resolution 变量控制，默认 60s）。</li>
<li>调整 Cluster Autoscaler 扫描未被调度 Pod 的间隔频率（由 scan-interval 变量控制，默认10s）。</li>
<li>调整 Node 节点上缓存容器镜像的方式（<a href="https://github.com/senthilrch/kube-fledged" target="_blank" rel="noopener">通过诸如 kube-fledged 等工具</a>）。</li>
</ul>
<p>但即使将这些设置调整为很小的值，你仍然会收到云提供商创建计算资源的时间限制。有什么方式优化这个部分吗？</p>
<p>这里可以做两件事：</p>
<ol>
<li>尽可能地避免创建新地 Node 节点。</li>
<li>主动提前创建节点，以便在需要时能直接使用。</li>
</ol>
<h3 id="为-kubernetes-节点选择最佳实例大小">为 Kubernetes 节点选择最佳实例大小</h3>
<p>选择正确的节点实例类型对集群的扩展策略有很大的影响。</p>
<p>考虑一个这样的场景。
你有一个应用需要 1GB 的内存资源和 0.1 vCPU 资源。
你提供的 Node 节点有 4GB 的内存资源和 1 vCPU 资源。
在为操作系统、kubelet 和驱逐阀值保留内存和 CPU 后，将拥有约 2.5GB 的内存资源和 0.7 vCPU 可用于运行 Pod。
所以你的 Node 节点只能承载 2 个 Pod 的运行。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance_hudd5956c99fa92b6e64089653bba31de1_78900_a248be8331c75771b804c79f9d90194a.webp 400w,
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance_hudd5956c99fa92b6e64089653bba31de1_78900_77d16ba8d8ce997b97fc9ee34181330b.webp 760w,
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance_hudd5956c99fa92b6e64089653bba31de1_78900_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/k8s-node-instance_hudd5956c99fa92b6e64089653bba31de1_78900_a248be8331c75771b804c79f9d90194a.webp"
               width="760"
               height="509"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>每次扩展 Pod 副本时，都可能会产生最多 7 分钟的延迟（触发 HPA，CA 和云提供商配置计算资源的前置时间）。</p>
<p>让我们来看看如果改成提供 64GB 的内存和 16 vCPU 的节点会发生什么。</p>
<p>在为操作系统、kubelet 和驱逐阀值保留内存和 CPU 后，将拥有约 58.32GB 的内存资源和 15.8 vCPU 可用于运行 Pod。</p>
<p>Node 节点可以承载 58 个 Pod 的运行，只有超过 58 个 Pod 副本时，才需要一个新的节点。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance-2_hucbc698e93c871aaac077374756752b51_81053_46adad813bbaa3ce6334454d71f70363.webp 400w,
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance-2_hucbc698e93c871aaac077374756752b51_81053_82855e0cdced66d58c822c8c25772bc2.webp 760w,
               /blog/kubernetes-autoscaling-strategy/k8s-node-instance-2_hucbc698e93c871aaac077374756752b51_81053_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/k8s-node-instance-2_hucbc698e93c871aaac077374756752b51_81053_46adad813bbaa3ce6334454d71f70363.webp"
               width="760"
               height="588"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>此外，每次向集群中添加节点时，都可以部署多个 Pod。再次触发 Cluster Autoscaler 的机会更少。</p>
<p>选择大型节点实例类型还有另一个好处。
为 kubelet 预留的资源、操作系统和驱逐阀值与运行 Pod 的可用资源之间的比率更大。
看看这张图，它描绘了 Pod 可用的内存。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/node-available-to-pod_hu7d52aca9badfd6dc07352544c3f6caf3_101817_edf07ee8f3de4e1781c841cd4f238acf.webp 400w,
               /blog/kubernetes-autoscaling-strategy/node-available-to-pod_hu7d52aca9badfd6dc07352544c3f6caf3_101817_8bb9afa4d03ae04322a9de81863585db.webp 760w,
               /blog/kubernetes-autoscaling-strategy/node-available-to-pod_hu7d52aca9badfd6dc07352544c3f6caf3_101817_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/node-available-to-pod_hu7d52aca9badfd6dc07352544c3f6caf3_101817_edf07ee8f3de4e1781c841cd4f238acf.webp"
               width="760"
               height="500"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>随着 Node 实例大小的增加，你可以注意到（按比例）可用于 Pod 的资源增加。换句话说，与拥有两个大小一半的实例相比，可以更高效地利用资源。</p>
<p>那应该一直选择最大的实例吗？</p>
<p>节点上可以拥有的 Pod 数量决定了效率的峰值。</p>
<p>一些云提供商将 Pod 的数量限制为 110 个（比如 GKE）。其他一些限制是由底层网络基于每个实例（即AWS）规定的。</p>
<blockquote>
<p><a href="https://docs.google.com/spreadsheets/d/1RPpyDOLFmcgxMCpABDzrsBYWpPYCIBuvAoUQLwOGoQw/edit#gid=907731238" target="_blank" rel="noopener">你可以在这里查看大多数云提供商的限制</a></p>
</blockquote>
<p>所以选择更大的实例类型并不总是一个好的选择。</p>
<p>我们还需要考虑：</p>
<ol>
<li>爆炸半径 - 如果你只有几个节点，那么一个失败节点的影响比你有很多节点的影响更大。</li>
<li>自动伸缩的成本更高，因为下一个增量是（非常）大的节点。</li>
</ol>
<p>假设你为集群选择了正确的实例类型，你在配置新计算单元时可能仍然会遇到延迟。</p>
<p>如果不是在需要扩展时创建新节点，而是提前创建相同的节点会怎么样？</p>
<h3 id="在-kubernetes-集群中过度配置节点">在 Kubernetes 集群中过度配置节点</h3>
<p>如果你可以负担得起随时可用的备用节点的话，你可以：</p>
<ol>
<li>提前创建一个空的 Node 节点。</li>
<li>一旦空的 Node 节点上有 Pod 了，就会创建另一个空的 Node 节点。</li>
</ol>
<p>换句话说，让 Cluster Autoscaler 总是保持有一个备用的空 Node 节点。</p>
<p>这是一种权衡：你会产生额外的成本，但扩展新节点的速度会提高。</p>
<p>但有坏消息和好消息。</p>
<p>坏消息是 Cluster Autoscaler 没有内置此功能。它不能被显式的配置，并且也没有提供相应的参数。</p>
<p>好消息是你仍然可以通过一些 trick 的方式来达到这个目的。</p>
<p>你可以运行具有足够请求的 Deployment 来保留一个完整的 Node 节点。你可以将这些 Pod 视为占位符 - 它旨在保留空间，而不是使用资源。</p>
<p>一旦创建了真正的 Pod，就可以驱逐占位符并部署真正的 Pod。</p>
<p>请注意，这一次你仍然需要等待 5 分钟才能将节点添加到集群中，但你可以继续使用当前节点。同时，在后台又提供了一个新的节点。</p>
<p>如何做到这一点呢？</p>
<p>可以使用运行永久休眠的 pod 的部署来配置过度配置。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/overprovision_hucf70b3a1843d1091f6dc9b43f3adc6a8_175768_af304fe0272fa2dee29552698a1bd5a6.webp 400w,
               /blog/kubernetes-autoscaling-strategy/overprovision_hucf70b3a1843d1091f6dc9b43f3adc6a8_175768_fecebd3188c6c3df9d279b06b1d39399.webp 760w,
               /blog/kubernetes-autoscaling-strategy/overprovision_hucf70b3a1843d1091f6dc9b43f3adc6a8_175768_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/overprovision_hucf70b3a1843d1091f6dc9b43f3adc6a8_175768_af304fe0272fa2dee29552698a1bd5a6.webp"
               width="760"
               height="593"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>上图中，你需要特别关注内存和 CPU 配置。Scheduler 会使用这些值来决定部署 Pod 的位置。在这种特殊情况下，它们用于保留空间。</p>
<p>你可以配置一个大型 Pod，该 Pod 的请求大致与可用节点资源相匹配。同时要确保你考虑了 kubelet、操作系统、kube-proxy 等消耗的资源。</p>
<p>如果你的节点实例是 2 vCPU 和 8GB 内存，并且 pod 的可用空间是 1.73 vCPU 和 ~5.9GB 内存，则该节点就无法承载这个 Pod，因为实际的 Pod 可用资源是要小于所需资源的。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/placeholder_hu20e39b12dbbcade89a08c5d9a6255370_85120_9dcf03ff5ccb07e7cd3b4aa0df9c95b7.webp 400w,
               /blog/kubernetes-autoscaling-strategy/placeholder_hu20e39b12dbbcade89a08c5d9a6255370_85120_cd2466489e93d107514913ba653f01ee.webp 760w,
               /blog/kubernetes-autoscaling-strategy/placeholder_hu20e39b12dbbcade89a08c5d9a6255370_85120_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/placeholder_hu20e39b12dbbcade89a08c5d9a6255370_85120_9dcf03ff5ccb07e7cd3b4aa0df9c95b7.webp"
               width="760"
               height="510"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>为了确保在创建真正的 Pod 时能快速的驱逐占位Pod，可以使用<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/" target="_blank" rel="noopener">优先级和抢占</a>。</p>
<p>Pod Priority 表示一个 Pod 相对于其他 Pod 的重要性。</p>
<p>当一个 Pod 无法被调度时，Scheduler 会尝试抢占（驱逐）较低优先级的 Pod 以调度 “pending” 的 Pod。</p>
<p>可以使用 PodPriorityClass 在集群中配置 Pod 优先级：</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/podpriority_hu6f369ee53bb1f0fdc34e6e718fc64e31_98298_bce169ea075ee6986df698b50339fae4.webp 400w,
               /blog/kubernetes-autoscaling-strategy/podpriority_hu6f369ee53bb1f0fdc34e6e718fc64e31_98298_cab892a194eb54e1610cdc62c44d90bd.webp 760w,
               /blog/kubernetes-autoscaling-strategy/podpriority_hu6f369ee53bb1f0fdc34e6e718fc64e31_98298_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/podpriority_hu6f369ee53bb1f0fdc34e6e718fc64e31_98298_bce169ea075ee6986df698b50339fae4.webp"
               width="760"
               height="306"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>由于 Pod 的默认优先级为 0，而过度配置的 PriorityClass 值为 -1，因此当集群空间不足时，这些 Pod 将首先被逐出。</p>
<p>PriorityClass 还有两个可选字段：globalDefault 和 description。</p>
<ul>
<li>description 字段是提供给人阅读的关于 PriorityClass 的描述信息。</li>
<li>globalDefault 字段表示这个 PriorityClass 的值应该用于没有 priorityClassName 的 Pod。系统中只能存在一个 global Default 设置为 true 的 PriorityClass。</li>
</ul>
<p>你可以使用下面的命令为你的 Pod 指定优先级：</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/priorityClassName_hu6c3389f8a2fb137af9ab3b5b289244c5_191065_c36aed5f3ee1fcffd3143610e5dde6c6.webp 400w,
               /blog/kubernetes-autoscaling-strategy/priorityClassName_hu6c3389f8a2fb137af9ab3b5b289244c5_191065_2891ed0eeab145ae46af427498d715d1.webp 760w,
               /blog/kubernetes-autoscaling-strategy/priorityClassName_hu6c3389f8a2fb137af9ab3b5b289244c5_191065_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/priorityClassName_hu6c3389f8a2fb137af9ab3b5b289244c5_191065_c36aed5f3ee1fcffd3143610e5dde6c6.webp"
               width="760"
               height="630"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>设置完成！</p>
<p>当集群中没有足够的资源时，Pause Pod 会被抢占，并由新的 Pod 取而代之。</p>
<p>由于 Pause pod 变得不可调度，它会强制 Cluster Autoscaler 向集群添加更多节点。</p>
<p>现在，你已准备好过度配置集群，该是时候考虑优化应用程序以进行扩展了。</p>
<h3 id="为-pod-选择正确的内存和cpu资源">为 Pod 选择正确的内存和CPU资源</h3>
<p>Cluster Autoscaler 会根据 “pending” Pod 的出现来做出 scaling 决策。</p>
<p>Kubernetes Scheduler 根据 Node 节点的内存和 CPU 负载情况决定将 Pod 分配（或不分配）给节点。</p>
<p>因此，必须为你的工作负载设置正确的资源使用请求，否则您可能会过晚（或过早）触发自动伸缩机制。</p>
<p>让我们看一个例子。</p>
<p>您决定要测试一个应用程序，并发现：</p>
<ul>
<li>在平均负载下，应用程序消耗 512MB 内存和 0.25 vCPU。</li>
<li>在高峰期，应用程序应最多消耗 4GB 内存和 1 vCPU。</li>
</ul>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/app-workload_hu4ea65a06597e7d0a7d05f6125966a5ed_91492_9c5821c555add2be8646690326e4e467.webp 400w,
               /blog/kubernetes-autoscaling-strategy/app-workload_hu4ea65a06597e7d0a7d05f6125966a5ed_91492_2cf517838c7349e7946d7f0f3379778c.webp 760w,
               /blog/kubernetes-autoscaling-strategy/app-workload_hu4ea65a06597e7d0a7d05f6125966a5ed_91492_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/app-workload_hu4ea65a06597e7d0a7d05f6125966a5ed_91492_9c5821c555add2be8646690326e4e467.webp"
               width="760"
               height="554"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>你的容器的限制应该是 4GB 内存和 1 个 vCPU。但是，请求呢？</p>
<p>Scheduler 在创建 Pod 之前使用 Pod 的内存和 CPU 请求来选择最佳节点。</p>
<p>所以你可以：</p>
<ol>
<li>将请求设置为低于实际平均使用量。</li>
<li>保守一点，分配更接近限制的请求。</li>
<li>设置请求以匹配实际的限制。</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/cpu-requests-1_hu2a84569c6788ba0761350037e4bd819c_127293_3172a968a4e3df60ea0886e83ba98f2c.webp 400w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-1_hu2a84569c6788ba0761350037e4bd819c_127293_920a5b45d8259d29946e3be7783c1684.webp 760w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-1_hu2a84569c6788ba0761350037e4bd819c_127293_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/cpu-requests-1_hu2a84569c6788ba0761350037e4bd819c_127293_3172a968a4e3df60ea0886e83ba98f2c.webp"
               width="760"
               height="607"
               loading="lazy" data-zoomable /></div>
  </div></figure>

















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/cpu-requests-2_hu3c9f92b0c148980c4ee34f85c780ec2b_119513_14f9614f3f461202ebcf804902faa0c6.webp 400w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-2_hu3c9f92b0c148980c4ee34f85c780ec2b_119513_56f157235a2cf2f1317683885504d22d.webp 760w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-2_hu3c9f92b0c148980c4ee34f85c780ec2b_119513_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/cpu-requests-2_hu3c9f92b0c148980c4ee34f85c780ec2b_119513_14f9614f3f461202ebcf804902faa0c6.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div></figure>

















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="" srcset="
               /blog/kubernetes-autoscaling-strategy/cpu-requests-3_hu3616fcb61c67255a7a9cf611340e303a_104990_59fcea04cbe17ce2323c1e51b2b75ac6.webp 400w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-3_hu3616fcb61c67255a7a9cf611340e303a_104990_d18828f46304634a9790159518082cbd.webp 760w,
               /blog/kubernetes-autoscaling-strategy/cpu-requests-3_hu3616fcb61c67255a7a9cf611340e303a_104990_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/blog/kubernetes-autoscaling-strategy/cpu-requests-3_hu3616fcb61c67255a7a9cf611340e303a_104990_59fcea04cbe17ce2323c1e51b2b75ac6.webp"
               width="760"
               height="604"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>定义低于实际使用的请求是有问题的，因为你的节点经常会被过度使用。</p>
<p>例如，你可以分配 256MB 的内存作为内存请求。Scheduler 可以为每个节点安装两倍的 Pod。然而，Pod 在实践中使用两倍的内存并开始竞争资源 (CPU) 并被驱逐（节点上没有足够的内存）。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://learnk8s.io/a/22fdf4559d43e563b3b9b0472ea68969.svg" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>过度使用节点会导致过多的驱逐、更多的 kubelet 工作和大量的重新调度。</p>
<p>如果将请求设置为与限制相同的值会发生什么？</p>
<p>在 Kubernetes 中，这通常被称为 Guaranteed Quality of Service 类，指的是 pod 不太可能被终止和驱逐。Scheduler 将为分配的节点上的 Pod 保留整个 CPU 和内存。该类 Pod 运行稳定，但同时该节点的使用效率就会比较低。</p>
<p>如果你的应用平均使用 512MB 的内存，但为它预留了 4GB，那么大部分时间有 3.5GB 未使用。</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://learnk8s.io/a/3661626fe6a72a79770b9f8e2139e015.svg" alt="" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>这值得么？</p>
<p>如果你想要更多的稳定性，是值得的。</p>
<p>如果你想要效率，你可能希望降低请求并在这些请求与限制之间找到平衡。</p>
<p>这通常被称为 Burstable Quality of Service 类，指的是 Pod 消耗稳定但偶尔会突然使用更多内存和 CPU。</p>
<p>当你的请求与应用的实际使用相匹配时，Scheduler 将高效地将你的 Pod 打包到你的节点中。</p>
<p>有时，应用程序可能需要更多内存或 CPU。</p>
<ol>
<li>如果 Node 中有资源，应用程序将会在达到最低消耗之前使用它们。</li>
<li>如果 Node 中资源不足，Pod 将竞争资源（CPU），kubelet 可能会尝试驱逐 Pod（内存）。</li>
</ol>
<p>此时，你应该使用 Guaranteed Quality of Service 还是 Burstable Quality of Service？</p>
<p>这取决于如下两点：</p>
<ol>
<li>当你希望最小化 Pod 的重新调度和驱逐时，请使用 Guaranteed Quality of Service（请求等于限制）。 一个很好的例子是用于数据库的 Pod。</li>
<li>当你想要优化集群并明智地使用资源时，请使用 Burstable Quality of Service（请求匹配实际平均使用情况）。 如果您有 Web 应用程序或 REST API，您可能希望使用 Burstable Quality of Service。</li>
</ol>
<p>那如何选择正确的请求和限制值？</p>
<p>你应该分析应用程序并测量空闲、负载和峰值时的内存和 CPU 消耗。更直接的策略包括部署 Vertical Pod Autoscaler 并等待它建议正确的值。</p>
<p>Vertical Pod Autoscaler 从 Pod 收集数据并应用回归模型来推断请求和限制。</p>
<p><a href="https://learnk8s.io/setting-cpu-memory-limits-requests" target="_blank" rel="noopener">您可以在本文中了解有关如何执行此操作的更多信息</a>。</p>
<h3 id="关于集群的缩容">关于集群的缩容</h3>
<p>每 10 秒，只有当请求利用率低于 50% 时，Cluster Autoscaler 才会决定删除节点。</p>
<p>换句话说，对于同一节点上的所有 Pod，它会汇总 CPU 和内存请求。</p>
<p>如果它们低于节点容量的一半，Cluster Autoscaler 将考虑当前节点进行缩减。</p>
<blockquote>
<p>值得注意的是，Cluster Autoscaler 不考虑实际的 CPU 和内存使用或限制，而只查看资源请求。</p>
</blockquote>
<p>在移除节点之前，Cluster Autoscaler 执行：</p>
<ul>
<li>Pod 检查以确保 Pod 可以移动到其他节点。</li>
<li>Node 节点检查以防止节点过早被破坏。</li>
</ul>
<p>如果检查通过，Cluster Autoscaler 将从集群中删除节点。</p>
<h3 id="为什么不基于内存或cpu进行自动伸缩">为什么不基于内存或CPU进行自动伸缩</h3>
<p>在扩缩容时，基于 CPU 或内存的 Cluster Autoscaler 不关心 pod。</p>
<p>想象一下，有一个只有一个节点的集群，并设置 Autoscaler 来添加一个新节点当 CPU 使用率达到总容量的 80%。</p>
<p>然后你决定创建一个具有 3 个副本的 Deployment。三个 Pod 的总资源使用率达到了 CPU 的 85%。</p>
<p>一个新的 Node 节点被提供。如果你不需要更多 Pod 怎么办？你有一个完整节点处于空闲的状态——这不是很好。这种使用 Autoscaler 的方式是不鼓励的。</p>
<h2 id="总结">总结</h2>
<p>在 Kubernetes 中定义和实施成功的扩缩容策略需要您掌握几个主题：</p>
<ul>
<li>熟悉 Kubernetes 节点中的可分配资源。</li>
<li>微调 Metrics Server、Horizontal Pod Autoscaler 和 Cluster Autoscalers 的刷新间隔。</li>
<li>规划集群和节点实例大小。</li>
<li>做好容器镜像的缓存。</li>
<li>做好应用程序基准测试和分析。</li>
</ul>
<p>但是上面这些还不够，你还需要使用适当的监控工具，反复测试您的扩缩容策略并调整集群的节点创建速度和成本。</p>

                </div>
                

<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/kubernetes/">kubernetes</a>
  
</div>











  
  
    



  
  
  
  
  
  <div class="media author-card content-widget-hr mb-4">
    
      
      <a href="/author/daniele-polencic/"><img class="avatar mr-3 avatar-circle" src="/author/daniele-polencic/avatar_hue38add62c87b7486d80c9f3fda25dfc1_12220_270x270_fill_q75_lanczos_center.jpg" alt="Daniele Polencic"></a>
    

    <div class="media-body">
      <p class="card-title"><a href="/author/daniele-polencic/">Daniele Polencic</a></p>
      
      
      
    </div>
  </div>


  


  
  
    




  




<div class="article-widget">
  
<div class="container-xl row post-nav">
  
  
  
  <a class="col-6 post-nav-item btn btn-lg mb-md-1" href="/blog/discovery-selectors/" rel="next">
    <div class="meta-nav">下一页</div>
    <p>使用发现选择器来为你的 Istio 服务网格配置命名空间</p></a>
  
  
  
  <a class="col-6 post-nav-item btn btn-lg mb-md-1"  href="/blog/introducing-policy-as-code-the-open-policy-agent-opa/" rel="prev">
    <div class="meta-nav">上一页</div>
    <p>策略即代码——Open Policy Agent（开放策略代理 OPA）简介</p></a>
  
</div>

</div>










  

<p class="edit-page">
  <a href="https://github.com/cloudnativeto/cloudnative.to/edit/master/content/blog/kubernetes-autoscaling-strategy/index.md">
    <i class="fas fa-pen pr-2"></i>编辑本页
  </a>
</p>




  
  
  <div class="article-widget content-widget-hr">
    <p class="related-title">相关推荐</p>
    <ul>
      
      <li><a href="/blog/egress-for-k8s/">是时候思考 Kubernetes 出向流量安全了</a></li>
      
      <li><a href="/blog/does-kubernetes-really-give-you-multicloud-portability/">Kubernetes 真的能提供多云可移植性吗？</a></li>
      
      <li><a href="/blog/container-insights-2022/">2022 年容器生态系统的 9 大趋势洞察</a></li>
      
      <li><a href="/blog/authentication-k8s/">彻底搞懂 Kubernetes 中的认证</a></li>
      
      <li><a href="/blog/apiserver-handler-register/">Kubernetes API Server handler 注册过程分析</a></li>
      
    </ul>
  </div>
  





  
  
  

  

  
  <section id="comments" class="mb-3 pt-0">
    <script>
  let themeNumber = localStorage.getItem('wcTheme');
  var giscusTheme = "light";
  if (themeNumber == 1){
    giscusTheme = "dark";
  }
  let giscusAttributes = {
    "src": "https://giscus.app/client.js",
    "data-theme": giscusTheme,
    "data-repo":"cloudnativeto\/cloudnative.to",
    "data-repo-id":"MDEwOlJlcG9zaXRvcnkyMzc3NDUxOTA=",
    "data-category":"General",
    "data-category-id":"MDE4OkRpc2N1c3Npb25DYXRlZ29yeTMyMDU5MzUy",
    "data-mapping":"pathname",
    "data-reactions-enabled":"",
    "data-emit-metadata":"0",
    "data-input-position":"top",
    "data-theme":giscusTheme,
    "data-lang":"zh-CN",
    "data-loading":"lazy",
    "crossorigin":"annoymous",
    "origins":"https://cloudnative.to",
    "originsRegex":"http://localhost:[0-9]+",
    "async": "",
  };

  let giscusScript = document.createElement("script");
  Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
  document.querySelector('#comments').appendChild(giscusScript);
</script>

  </section>
  



            </article>
        </main>
    </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  
  <div class="copyright py-4 bg-footer">
      <div class="row justify-content-center">
        <div class="text-center footer-color">
          <p class="mb-0">© 2020-2023 云原生社区保留所有权利</p>
        </div>
    </div>
  </div>

</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  

  
  

  

  
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
    
    
  










  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <div class="article-metadata search-hit-type">{{relpermalink}}</div>
          <a href="{{relpermalink}}">{{title}}</a>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":false}</script>










  
  


<script src="/zh/js/wowchemy.min.24983018b0e5661cd5fe1822254286ea.js"></script>







<script>

var mybutton = document.getElementById("backTopBtn");


window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}


function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>






<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
<script>
  anchors.add();
</script>



<script>



(function() {
  'use strict';

  if(!document.queryCommandSupported('copy')) {
    return;
  }

  function flashCopyMessage(el, msg) {
    el.className = "highlight-copy-btn";
    el.textContent = msg;
    setTimeout(function() {
      el.textContent = "";
      el.className = "highlight-copy-btn fa fa-copy";
    }, 1000);
  }

  function selectText(node) {
    var selection = window.getSelection();
    var range = document.createRange();
    range.selectNodeContents(node);
    selection.removeAllRanges();
    selection.addRange(range);
    return selection;
  }

  function addCopyButton(containerEl) {
    var copyBtn = document.createElement("button");
    copyBtn.className = "highlight-copy-btn fa fa-copy";
    copyBtn.textContent = "";

    var codeEl = containerEl.firstElementChild;
    copyBtn.addEventListener('click', function() {
      try {
        var selection = selectText(codeEl);
        document.execCommand('copy');
        selection.removeAllRanges();
        
        flashCopyMessage(copyBtn, '已复制')
        
      } catch(e) {
        console && console.log(e);
        flashCopyMessage(copyBtn, 'Failed :\'(')
      }
    });

    containerEl.appendChild(copyBtn);
  }

  
  var highlightBlocks = document.getElementsByClassName('highlight');
  Array.prototype.forEach.call(highlightBlocks, addCopyButton);
})();
</script>



<script>

function Collapse(e){
  var node = document.getElementById(e);
  if (node.className.indexOf('fa-angle-down') > -1){
    node.setAttribute("class", "fa-solid fa-angle-right");
    }else{
    node.setAttribute("class", "fa-solid fa-angle-down");
    }
}
</script>


</body>
</html>
