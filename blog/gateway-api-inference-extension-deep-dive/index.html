<!DOCTYPE html><html lang="zh" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="深入解读 Gateway API Inference Extension，通过自定义 CRD 实现基于实时指标的智能路由。" />

  
  <link rel="alternate" hreflang="zh" href="https://cloudnativecn.com/blog/gateway-api-inference-extension-deep-dive/" />

  
  
  
    <meta name="theme-color" content="#0a55a7" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.008259417e6adf8980695ebbbb46553f.css" />

  



  


  


  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f3dc895ea3bd6186cd835841d365c103";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu_5687ba431e9f3ad9.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu_e6256ffc27bfd989.png" />

  <link rel="canonical" href="https://cloudnativecn.com/blog/gateway-api-inference-extension-deep-dive/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@CloudNativeCN" />
    <meta property="twitter:creator" content="@CloudNativeCN" />
  
  <meta property="og:site_name" content="云原生社区（中国）" />
  <meta property="og:url" content="https://cloudnativecn.com/blog/gateway-api-inference-extension-deep-dive/" />
  <meta property="og:title" content="深入解析 Gateway API Inference Extension（推理扩展） | 云原生社区（中国）" />
  <meta property="og:description" content="深入解读 Gateway API Inference Extension，通过自定义 CRD 实现基于实时指标的智能路由。" /><meta property="og:image" content="https://cloudnativecn.com/media/sharing.png" />
    <meta property="twitter:image" content="https://cloudnativecn.com/media/sharing.png" /><meta property="og:locale" content="zh" />
  
    
      <meta
        property="article:published_time"
        content="2025-04-22T15:00:00&#43;08:00"
      />
    
    <meta property="article:modified_time" content="2025-04-25T15:09:43&#43;08:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://cloudnativecn.com/blog/gateway-api-inference-extension-deep-dive/"
  },
  "headline": "深入解析 Gateway API Inference Extension（推理扩展）",
  
  "datePublished": "2025-04-22T15:00:00+08:00",
  "dateModified": "2025-04-25T15:09:43+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Christian Posta"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "云原生社区（中国）",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cloudnativecn.com/media/logo.svg"
    }
  },
  "description": "深入解读 Gateway API Inference Extension，通过自定义 CRD 实现基于实时指标的智能路由。"
}
</script>

  

  

  

  





  <title>深入解析 Gateway API Inference Extension（推理扩展） | 云原生社区（中国）</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="a16b1cbbc4d8c89da62b8c2cca1e3d98" >
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden="true"></i></button>
  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.62d6f8dfe8493f1c68557dde65bec362.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6 search-title">
          <p>搜索</p>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="关闭"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="搜索..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="搜索...">
        
      </div>

      
      

      
    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

      <div id="search-common-queries">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    











  


<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"><img src="/media/logo.svg" alt="云原生社区（中国）"
            
            ></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="切换导航">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"><img src="/media/logo.svg" alt="云原生社区（中国）"
          
          ></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/community"><span>社区</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/blog"><span>博客</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>资料</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/envoy/"><span>Envoy 中文文档</span></a>
              
                <a class="dropdown-item" href="/kubebuilder/"><span>Kubebuilder 中文文档</span></a>
              
                <a class="dropdown-item" href="https://istio.io/latest/zh/"><span>云原生资料库</span></a>
              
            </div>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/event"><span>活动</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>关于</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        <li class="nav-item">
            <a class="nav-link" href="/community/join/" data-toggle="tooltip" data-placement="bottom" title="加入社区" aria-label="主站"><i class="fa-brands fa-weixin" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item">
            <a class="nav-link js-search" href="#" data-toggle="tooltip" data-placement="bottom" title="搜索" aria-label="搜索"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://github.com/cloudnativeto/cloudnative.to" target="_blank" rel="noopener" data-toggle="tooltip" data-placement="bottom" title="查看源码" aria-label="查看源码" aria-label="GitHub"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item">
          <a href="#" class="nav-link set-theme">
            <i class="fa fa-sun" aria-hidden="true" id="theme-icon"></i>
          </a>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <div class="container-xl">
    <div class="post-container">
        












  

  
  
  
<div class="article-container pt-3">
  <h1>深入解析 Gateway API Inference Extension（推理扩展）</h1>

  

  
    


<div class="article-metadata">

  <div>
  
  
  
  
    <i class="fa-solid fa-feather"></i>
    

  <span >
      <a href="/author/christian-posta/">Christian Posta</a></span>
    
    <span class="middot-divider"></span>
    
  
  
  
  
  
  
    <i class="fa fa-language"></i>
    

  <span >
      <a href="/translators/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%A4%BE%E5%8C%BA/">云原生社区</a></span>
    <span class="middot-divider"></span>
  
  
  
  
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/kubernetes/" class="text-capitalize">Kubernetes</a>, <a href="/category/ai/" class="text-capitalize">AI</a></span>
  
  </div>

  
  <span class="article-date">
    
    
      
          
          发布于
      
    
    2025-04-22
  </span>
  

  

  
  <span class="middot-divider"></span>
  字数 1988
  <span class="middot-divider"></span>
  <span class="article-reading-time">
      阅读时长 9 分钟
  </span>
  

  
  
  
  

</div>

    




<div class="btn-links mb-2">
  
  








  


















  
  
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header" href="https://www.cncf.io/blog/2025/04/21/deep-dive-into-the-gateway-api-inference-extension/" target="_blank" rel="noopener">
    <i class="fa fa-language mr-1"></i>阅读英文版原文</a>


</div>


  
</div>


    </div>
    <div class="border-bottom mb-2"></div>
    <div class="row flex-xl-nowrap">
        <div class="col-3 d-none d-xl-block docs-toc">
            <!-- toc -->
            
<div class="">
    <ul class="nav toc-top">
        <li>
            <a href="#" id="back_to_top" class="docs-toc-title">目录</a>
        </li>
    </ul>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#推理扩展如何扩展-gateway-api">推理扩展如何扩展 Gateway API</a></li>
    <li><a href="#端点选择机制详解">端点选择机制详解</a>
      <ul>
        <li><a href="#示例分析">示例分析</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
</div>

            <!-- /toc -->
            
            <div class="subscribe-module col-12 mt-1">
    <img src="/img/wechat.jpg" alt="image" title="云原生社区的微信公众号"/>
    <p class="text-center pt-1">关注「云原生社区动态」微信公众号，获取本站更新</p>
</div>

            
        </div>
        <main class="article-body col-9 container docs-content" role="main">
            <article class="article">
                <div class="article-style">
                    
                    <details class="toc-inpage d-print-none d-show-block my-4">
  <summary class="font-weight-bold">点击查看目录</summary>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#推理扩展如何扩展-gateway-api">推理扩展如何扩展 Gateway API</a></li>
    <li><a href="#端点选择机制详解">端点选择机制详解</a>
      <ul>
        <li><a href="#示例分析">示例分析</a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
</details>

                    
                    <p>在 Kubernetes 上运行 AI 推理工作负载具有一些独特的特点和挑战，Gateway API Inference Extension 项目旨在解决其中的一些问题。我最近在 <a href="https://kgateway.dev/blog/smarter-ai-reference-kubernetes-gateway-api/" target="_blank" rel="noopener">kgateway 项目</a> 中写过关于这些新能力的文章，而本文将深入讲解其工作原理。</p>
<p>大多数人将 Kubernetes 中的请求路由理解为基于 Gateway API、Ingress 或 Service Mesh（统称为 L7 路由器）的机制。这些实现的原理类似：你定义一些根据请求属性（如 header、path 等）进行匹配的路由规则，L7 路由器会基于这些规则决定请求应发送到哪个后端，并使用某种负载均衡算法（如 <a href="https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/load_balancing/load_balancing" target="_blank" rel="noopener">轮询、最少请求、环哈希、区域感知、优先级</a> 等）。</p>
<p>















<figure  id="figure-负载均衡算法">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="负载均衡算法" srcset="
               /blog/gateway-api-inference-extension-deep-dive/f0_hu_23d316aa77a75702.webp 400w,
               /blog/gateway-api-inference-extension-deep-dive/f0_hu_eedd08f6f7565af.webp 760w,
               /blog/gateway-api-inference-extension-deep-dive/f0_hu_e74b667536db7155.webp 1200w"
               src="/blog/gateway-api-inference-extension-deep-dive/f0_hu_23d316aa77a75702.webp"
               width="760"
               height="517"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      负载均衡算法
    </figcaption></figure>
</p>
<p>然而，传统的负载均衡算法并不适合 AI/LLM 模型后端。与典型的无状态 Web API 不同，基于 GPU 的 LLM 运行方式特殊，处理方式不当将导致资源浪费与高成本。如果我们能够利用模型和 GPU 的实时指标做出更智能的路由与负载均衡决策，会怎样？例如，当某个后端 LLM 已加载某个特定的 LoRA 微调适配器时，相关请求应该优先路由至该实例，以避免其他实例因动态加载适配器而浪费 GPU 时间。再如，当某个后端请求队列已积压过多，请求继续发送只会拖慢响应。如果所有后端都已饱和，是否可以启用“负载丢弃”机制，保障系统稳定？</p>
<p>















<figure  id="figure-实现负载丢弃">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="实现负载丢弃" srcset="
               /blog/gateway-api-inference-extension-deep-dive/f1_hu_61f7f8878282ae88.webp 400w,
               /blog/gateway-api-inference-extension-deep-dive/f1_hu_7626eca0698c0896.webp 760w,
               /blog/gateway-api-inference-extension-deep-dive/f1_hu_44d7d76e07fcd2ad.webp 1200w"
               src="/blog/gateway-api-inference-extension-deep-dive/f1_hu_61f7f8878282ae88.webp"
               width="760"
               height="500"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      实现负载丢弃
    </figcaption></figure>
</p>
<p>这正是 <a href="https://gateway-api-inference-extension.sigs.k8s.io/" target="_blank" rel="noopener">Gateway API Inference Extension</a> 项目所实现的功能。它引入了两个新的 Kubernetes CRD：<a href="https://gateway-api-inference-extension.sigs.k8s.io/concepts/api-overview/" target="_blank" rel="noopener">InferenceModel 和 InferencePool</a>，并提出了“endpoint picker（端点选择器）”的概念，可以扩展 L7 路由能力。该选择器可以结合底层 LLM 的指标做出更合理的路由决策，支持项目如 <a href="https://kgateway.dev/" target="_blank" rel="noopener">kgateway</a> 和 <a href="https://istio.io/" target="_blank" rel="noopener">Istio</a> 的集成。</p>
<h2 id="推理扩展如何扩展-gateway-api">推理扩展如何扩展 Gateway API</h2>
<p>Gateway API Inference Extension 引入了两个新的自定义资源定义（CRD）：<code>InferenceModel</code> 和 <code>InferencePool</code>。结合端点选择器使用，可将现有 L7 路由架构升级为“推理网关”，以支持自托管的大模型/生成式 AI（GenAI）服务，采用“模型即服务”的架构理念。</p>
<p><a href="https://gateway-api-inference-extension.sigs.k8s.io/api-types/inferencemodel/" target="_blank" rel="noopener">InferenceModel CRD</a> 主要面向 AI 工程师，用于定义逻辑模型的推理入口。它支持将用户可见的模型名映射到实际后端模型，并支持在多个微调模型之间进行流量切分。例如，你想将模型 <code>llama2</code> 提供给用户，而实际后端模型可能叫做 <code>vllm-llama2-7b-2024-11-20</code> 或 <code>vllm-llama2-7b-2025-03-24</code>，使用 InferenceModel 即可实现：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">inference.networking.x-k8s.io/v1alpha2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">InferenceModel</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">inferencemodel-llama2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">modelName</span><span class="p">:</span><span class="w"> </span><span class="l">llama2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">criticality</span><span class="p">:</span><span class="w"> </span><span class="l">Critical</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">poolRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b-pool</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">targetModels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b-2024-11-20</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">75</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b-2025-03-24</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">25</span><span class="w">
</span></span></span></code></pre></div><p>此外，它还允许工作负载所有者为请求指定“重要性等级”，确保实时服务优先于批量处理任务。后续我们会看到该设置如何结合 LLM 实时指标进行调度。</p>
<p><a href="https://gateway-api-inference-extension.sigs.k8s.io/api-types/inferencepool/" target="_blank" rel="noopener">InferencePool CRD</a> 则面向平台运维人员，表示一组模型服务实例，是 AI 工作负载的后端服务。借助该 CR，可将 HTTPRoute 请求路由至一个推理实例池，并通过定义 <code>endpoint picker</code> 实现根据实时指标（如请求队列长度、GPU 内存使用等）做出智能决策：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">inference.networking.x-k8s.io/v1alpha2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">InferencePool</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b-pool</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">targetPortNumber</span><span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">extensionRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b-endpoint-picker</span><span class="w">
</span></span></span></code></pre></div><p>要实现从推理网关到 LLM 后端的流量转发，需定义一个将流量引导至 InferencePool 的 HTTPRoute：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">gateway.networking.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HTTPRoute</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">llm-route</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">parentRefs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">inference-gateway</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">rules</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">backendRefs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">group</span><span class="p">:</span><span class="w"> </span><span class="l">inference.networking.x-k8s.io</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">InferencePool</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">vllm-llama2-7b</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matches</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">path</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">PathPrefix</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">/</span><span class="w">
</span></span></span></code></pre></div><p>一旦请求到达推理网关，匹配规则后将转发至 InferencePool，此时请求会首先进入一个名为 “Endpoint Selection Extension”（ESE）的组件。这个 ESE 根据 LLM 的实时指标来选择具体的后端 Pod。我们来深入了解其工作机制。</p>
<h2 id="端点选择机制详解">端点选择机制详解</h2>
<p>当请求到达 Endpoint Selection Extension（ESE）时，它会从请求体中提取 <code>modelName</code> 字段，目前该请求体需符合 <a href="https://platform.openai.com/docs/api-reference/chat/create" target="_blank" rel="noopener">OpenAI API 格式</a>。识别出模型名后，ESE 会比对现有的 InferenceModel 资源，定位对应的后端模型名或 LoRA 微调适配器。</p>
<p>如请求中指定了 <code>llama2</code>，ESE 会查找并选择对应的后端模型，如 <code>vllm-llama2-7b-2024-11-20</code> 或 <code>vllm-llama2-7b-2025-03-24</code>。</p>
<p>选择后端的逻辑由一系列“过滤器”组成，ESE 会依次评估以下指标：</p>
<ul>
<li>请求的关键性（Critical 或 Sheddable）</li>
<li>LLM 的请求队列长度</li>
<li>LoRA 适配器是否已加载</li>
<li>KV 缓存占用率</li>
</ul>
<p>















<figure  id="figure-评估流程图">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="评估流程图" srcset="
               /blog/gateway-api-inference-extension-deep-dive/f2_hu_1406b505e34593f0.webp 400w,
               /blog/gateway-api-inference-extension-deep-dive/f2_hu_83a55039c76a99a4.webp 760w,
               /blog/gateway-api-inference-extension-deep-dive/f2_hu_e51d8806c2ee7a9f.webp 1200w"
               src="/blog/gateway-api-inference-extension-deep-dive/f2_hu_1406b505e34593f0.webp"
               width="760"
               height="362"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      评估流程图
    </figcaption></figure>
</p>
<p>评估流程示意如下：</p>
<ol>
<li>判断请求是否为 Critical。</li>
<li>如果是 Critical，请求只会进入队列长度 &lt; 50 的实例。</li>
<li>再判断是否已加载对应的 LoRA。</li>
<li>若没有加载，也会尝试选择能加载的备选。</li>
<li>如果是 Sheddable 请求，则只选择 KV 缓存占用率 &lt; 80%、队列长度 &lt; 5 的实例；否则请求会被丢弃。</li>
</ol>
<p>















<figure  id="figure-丢弃低优先级请求">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="丢弃低优先级请求" srcset="
               /blog/gateway-api-inference-extension-deep-dive/f3_hu_e7fe980ddab58af.webp 400w,
               /blog/gateway-api-inference-extension-deep-dive/f3_hu_5bc828615308e30.webp 760w,
               /blog/gateway-api-inference-extension-deep-dive/f3_hu_7e9a6378161623e2.webp 1200w"
               src="/blog/gateway-api-inference-extension-deep-dive/f3_hu_e7fe980ddab58af.webp"
               width="760"
               height="504"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      丢弃低优先级请求
    </figcaption></figure>
</p>
<h3 id="示例分析">示例分析</h3>
<h4 id="示例1critical-请求--lora-适配器要求">示例1：Critical 请求 + LoRA 适配器要求</h4>
<p>假设有以下 Pod：</p>
<ul>
<li>Pod A: 队列=10，KV 缓存=30%，已加载 LoRA-X</li>
<li>Pod B: 队列=5，KV 缓存=70%，未加载 LoRA-X</li>
<li>Pod C: 队列=60，KV 缓存=20%，已加载 LoRA-X</li>
</ul>
<p>最终选择：<strong>Pod A</strong></p>
<h4 id="示例2非-critical-请求">示例2：非 Critical 请求</h4>
<ul>
<li>Pod A: 队列=6，KV=85%</li>
<li>Pod B: 队列=4，KV=75%</li>
<li>Pod C: 队列=7，KV=60%</li>
</ul>
<p>最终选择：<strong>Pod B</strong></p>
<h4 id="示例3critical-请求--所有队列都很高">示例3：Critical 请求 + 所有队列都很高</h4>
<ul>
<li>Pod A: 队列=70，KV=40%，有 LoRA-Y</li>
<li>Pod B: 队列=80，KV=60%，有 LoRA-Y</li>
<li>Pod C: 队列=65，KV=70%，无 LoRA-Y</li>
</ul>
<p>最终选择：<strong>Pod A</strong></p>
<h2 id="总结">总结</h2>
<p>Gateway API Inference Extension 项目为 Kubernetes 上运行的大模型和 GPU 提供了智能模型选择和负载均衡能力。在 GPU 资源紧缺、成本高昂的背景下，该项目可以大幅提升吞吐性能和资源利用率，并节省企业成本。你可以在 <a href="https://gateway-api-inference-extension.sigs.k8s.io/performance/benchmark/" target="_blank" rel="noopener">项目网站</a> 上查看最新性能基准测试数据。</p>

                </div>
                

<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/gateway-api/">Gateway API</a>
  
  <a class="badge badge-light" href="/tag/llm/">LLM</a>
  
  <a class="badge badge-light" href="/tag/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1/">推理服务</a>
  
  <a class="badge badge-light" href="/tag/kubernetes/">Kubernetes</a>
  
  <a class="badge badge-light" href="/tag/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">负载均衡</a>
  
</div>











  
  
    



  
  
  
  
  
  <div class="media author-card content-widget-hr mb-4">
    
      
      <a href="/author/christian-posta/"><img class="avatar mr-3 avatar-circle" src="/author/christian-posta/avatar_hu_8bfb7e2fdd9fd454.jpg" alt="Christian Posta"></a>
    

    <div class="media-body">
      <p class="card-title"><a href="/author/christian-posta/">Christian Posta</a></p>
      
      
      
    </div>
  </div>


  


  
  
    




  




<div class="article-widget">
  
<div class="container-xl row post-nav">
  
  
  
  <a class="col-6 post-nav-item btn btn-lg mb-md-1" href="/blog/semantics-matter-exposing-openapi-as-mcp-tools/" rel="next">
    <div class="meta-nav">下一页</div>
    <p>语义至关重要：如何将 OpenAPI 规范转化为 MCP 工具</p></a>
  
  
  
  <a class="col-6 post-nav-item btn btn-lg mb-md-1"  href="/blog/how-llms-work-explained-without-math/" rel="prev">
    <div class="meta-nav">上一页</div>
    <p>大语言模型是怎么工作的？通俗解释版</p></a>
  
</div>

</div>










  

<p class="edit-page">
  <a href="https://github.com/cloudnativeto/cloudnative.to/edit/master/content/blog/gateway-api-inference-extension-deep-dive/index.md">
    <i class="fas fa-pen pr-2"></i>编辑本页
  </a>
</p>




  
  
  <div class="article-widget content-widget-hr">
    <p class="related-title">相关推荐</p>
    <ul>
      
      <li><a href="/blog/why-we-decided-to-start-fresh-with-our-nginx-gateway-fabric/">为什么我们决定从新开始我们的 NGINX Gateway Fabric</a></li>
      
      <li><a href="/blog/how-llms-work-explained-without-math/">大语言模型是怎么工作的？通俗解释版</a></li>
      
      <li><a href="/blog/kubernetes-resource-orchestration-kro/">Kro 项目：一次三大云厂商联合赋能 Kubernetes 用户的范例</a></li>
      
      <li><a href="/blog/a-gentle-introduction-to-llms-for-platform-engineers/">平台工程师的 LLM 入门指南</a></li>
      
      <li><a href="/blog/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/">KEDA vs. 原生 Kubernetes：谁是云原生应用的自动伸缩王者？</a></li>
      
    </ul>
  </div>
  





  
  
  

  

  
  <section id="comments" class="mb-3 pt-0">
    <script>
  let themeNumber = localStorage.getItem('wcTheme');
  var giscusTheme = "light";
  if (themeNumber == 1){
    giscusTheme = "dark";
  }
  let giscusAttributes = {
    "src": "https://giscus.app/client.js",
    "data-theme": giscusTheme,
    "data-repo":"cloudnativeto\/cloudnative.to",
    "data-repo-id":"MDEwOlJlcG9zaXRvcnkyMzc3NDUxOTA=",
    "data-category":"General",
    "data-category-id":"MDE4OkRpc2N1c3Npb25DYXRlZ29yeTMyMDU5MzUy",
    "data-mapping":"pathname",
    "data-reactions-enabled":"",
    "data-emit-metadata":"0",
    "data-input-position":"top",
    "data-theme":giscusTheme,
    "data-lang":"zh-CN",
    "data-loading":"lazy",
    "crossorigin":"annoymous",
    "origins":"https://cloudnativecn.com",
    "originsRegex":"http://localhost:[0-9]+",
    "async": "",
  };

  let giscusScript = document.createElement("script");
  Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
  document.querySelector('#comments').appendChild(giscusScript);
</script>

  </section>
  



            </article>
        </main>
    </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  
  <div class="copyright py-4 bg-footer">
      <div class="row justify-content-center">
        <div class="text-center footer-color">
          <p class="mb-0">© 2020-2024 云原生社区保留所有权利</p>
        </div>
    </div>
  </div>

</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.0965c02a44d7bc3f6aebc3730ec59495.js"></script>




  

  
  

  

  
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
    
    
  










  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <div class="article-metadata search-hit-type">{{relpermalink}}</div>
          <a href="{{relpermalink}}">{{title}}</a>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":false}</script>










  
  


<script src="/zh/js/wowchemy.min.1f4bda0700ff78dcd04ab5307750c948.js"></script>







<script>

var mybutton = document.getElementById("backTopBtn");


window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}


function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>






<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
<script>
  anchors.add();
</script>



<script>



(function() {
  'use strict';

  if(!document.queryCommandSupported('copy')) {
    return;
  }

  function flashCopyMessage(el, msg) {
    el.className = "highlight-copy-btn";
    el.textContent = msg;
    setTimeout(function() {
      el.textContent = "";
      el.className = "highlight-copy-btn fa fa-copy";
    }, 1000);
  }

  function selectText(node) {
    var selection = window.getSelection();
    var range = document.createRange();
    range.selectNodeContents(node);
    selection.removeAllRanges();
    selection.addRange(range);
    return selection;
  }

  function addCopyButton(containerEl) {
    var copyBtn = document.createElement("button");
    copyBtn.className = "highlight-copy-btn fa fa-copy";
    copyBtn.textContent = "";

    var codeEl = containerEl.firstElementChild;
    copyBtn.addEventListener('click', function() {
      try {
        var selection = selectText(codeEl);
        document.execCommand('copy');
        selection.removeAllRanges();
        
        flashCopyMessage(copyBtn, '已复制')
        
      } catch(e) {
        console && console.log(e);
        flashCopyMessage(copyBtn, 'Failed :\'(')
      }
    });

    containerEl.appendChild(copyBtn);
  }

  
  var highlightBlocks = document.getElementsByClassName('highlight');
  Array.prototype.forEach.call(highlightBlocks, addCopyButton);
})();
</script>



<script>

function Collapse(e){
  var node = document.getElementById(e);
  if (node.className.indexOf('fa-angle-down') > -1){
    node.setAttribute("class", "fa-solid fa-angle-right");
    }else{
    node.setAttribute("class", "fa-solid fa-angle-down");
    }
}
</script>


</body>
</html>
