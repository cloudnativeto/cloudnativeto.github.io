[{"categories":["Istio","Service Mesh"],"contents":"本篇主要探讨上一篇源码分析中留下的问题，如 EnvoyXdsServer 是如何工作的，以及 xDS 的下发流程。对推送事件的防抖、SidecarScope 的运用做一些细致的分析。\nEnvoyXdsServer EnvoyXdsServer 主要负责 Pilot 中 xDS 协议的生成和下发，接收并处理 configController 和 serviceController 推送的 PushRequest ，与集群中所有的数据面代理进行 gRPC 通信，并处理它们的请求。在 Pilot Server 中的定义如下：\n// Server contains the runtime configuration for the Pilot discovery service. type Server struct { EnvoyXdsServer *xds.DiscoveryServer } EnvoyXdsServer 只是 Pilot Server 中的别名，真正的 xds.DiscoveryServer 结构在 istio/pilot/pkg/xds/discovery.go:71 中，这里只保留关键的字段进行说明：\n// DiscoveryServer is Pilot\u0026#39;s gRPC implementation for Envoy\u0026#39;s v2 xds APIs type DiscoveryServer struct { Env *model.Environment // 与 Pilot Server 中的 Environment 一样  ConfigGenerator core.ConfigGenerator // xDS 数据的生成器接口  // Endpoint 的缓存，以服务名和 namespace 作为索引，主要用于 EDS 更新  EndpointShardsByService map[string]map[string]*EndpointShards // 统一接收其他组件发来的 PushRequest 的 channel  pushChannel chan *model.PushRequest // pushQueue 主要是在真正 xDS 推送前做防抖缓存  pushQueue *PushQueue // 保存了所有生效的 gRPC 连接  adsClients map[string]*Connection ... } Initialization 回忆一下 pilot-discovery 的启动流程：\n在初始化 grpcServer 的时候，调用了 DiscoveryServer.Register() 方法，向 grpcServer 注册了以下几个服务（以 v2 版本为例）：\nservice AggregatedDiscoveryService { // 全量 ADS Stream 接口  rpc StreamAggregatedResources(stream api.v2.DiscoveryRequest) returns (stream api.v2.DiscoveryResponse) { } // 增量 ADS Stream 接口  rpc DeltaAggregatedResources(stream api.v2.DeltaDiscoveryRequest) returns (stream api.v2.DeltaDiscoveryResponse) { }}上面的 proto 文件可以在 ads.proto 找到。熟悉 gRPC 的读者可以看到这个服务定义了两个 RPC 接口：\n StreamAggregatedResources 接收 DiscoveryRequest ，返回 DiscoveryResponse 流，包含全量的 xDS 数据 DeltaAggregatedResources 接收 DeltaDiscoveryRequest ，返回 DeltaDiscoveryResponse 流，包含增量的 xDS 数据  xDS 相关的介绍可以参考 Envoy 的文档：xDS REST and gRPC protocol ，写的很详细。\nEnvoyXdsServer 在启动方法 Start() 中开启了两个比较重要的协程 handleUpdates 和 sendPushes 。 handleUpdates 主要用来处理 pushChannel 中收到的推送请求以及防抖。 sendPushes 则负责具体的推送。\nfunc (s *DiscoveryServer) Start(stopCh \u0026lt;-chan struct{}) { adsLog.Infof(\u0026#34;Starting ADS server\u0026#34;) go s.handleUpdates(stopCh) go s.periodicRefreshMetrics(stopCh) go s.sendPushes(stopCh) } Receive Connection 当服务实例的代理（ Sidecar 模式） 启动的时候，会和 grpcServer 建立连接并调用 StreamAggregatedResources 方法：\nStreamAggregatedResources 会和当前的 Proxy 创建一个连接，并创建一个接受请求的 reqChannel 。同时开启一个新的协程 receiveThread 处理客户端主动发起的请求：\nfunc (s *DiscoveryServer) StreamAggregatedResources(stream discovery.AggregatedDiscoveryService_StreamAggregatedResourcesServer) error { // ...  con := newConnection(peerAddr, stream) var receiveError error reqChannel := make(chan *discovery.DiscoveryRequest, 1) go s.receiveThread(con, reqChannel, \u0026amp;receiveError) // ... } Receive Change 一切准备就绪之后， EnvoyXdsServer 开始接收来自 configController 和 serviceController 的配置变化事件，包括服务数据的变化和配置数据的变化，都会创建 PushRequest 发送至 EnvoyXdsServer 的 pushChannel :\nPushRequest 包含是否全量推送的标识以及主要更改的资源类型。全部统一推送到 pushChannel 之后，就由 EnvoyXdsServer 启动时创建的协程 handleUpdates 来处理了。\nHandle Updates handleUpdates 最重要的功能就是防抖，避免因过快的推送带来的问题和压力。\n// Debouncing and push request happens in a separate thread, it uses locks // and we want to avoid complications, ConfigUpdate may already hold other locks. // handleUpdates processes events from pushChannel // It ensures that at minimum minQuiet time has elapsed since the last event before processing it. // It also ensures that at most maxDelay is elapsed between receiving an event and processing it. func (s *DiscoveryServer) handleUpdates(stopCh \u0026lt;-chan struct{}) { debounce(s.pushChannel, stopCh, s.Push) } 什么是防抖（ Debounce ）呢？举一个简单的例子，我们每天上班都要坐电梯，当你第一个进电梯后，想上 5 楼，按下了 5 楼并关闭了电梯门，门还没关上的时候，突然碰到一个同事，电梯门又打开，同事进来后你们一起去了 5 楼。这样两个人两次去 5 楼的事件，电梯跑了一趟就解决了。试想如果电梯的门都是秒关不等人，每次只装一个人，第二个人必须等电梯把上一个人送到之后才能重新乘坐，就算写字楼有很多电梯也会在早高峰的时候产生拥挤。\n假设电梯容量无限大，你有无数个同事，今天好巧不巧每次电梯快关上的时候都有个同事要进来，门永远关不上，电梯也一直不走，那好了大家今天谁也别想上班，也是个很大的问题。那我们做一个规定，每趟电梯在 1 楼的时候最多等待 3 分钟，到时间了电梯就走，这样电梯的利用率就提升了，大家也不用等太久就可以上班打卡。\n如果优化的更好一点，把所有电梯分成奇偶两组，奇组只在奇数层停，偶组只在偶数层停。这样就可以最大化的提升资源利用率。但还有一种情况，如果我们进电梯后，后面没有人进电梯了，白白等待了 3 分钟电梯才走，浪费了时间，这也不行。\n那我们就再给电梯系统加一个时间，让电梯在有人进电梯后等待 10 秒，如果过了 10 秒还没有下一个人进来，电梯就不等了。 如有有人进来就重新计时 10 秒钟。\n从上面这个例子可以引申出几个概念，一个是最小静默时间，一个是最大延迟时间。最小静默时间就是上面的 10 秒钟，从上一个进电梯的人开始计时，10 秒内有新的人进来就接着等，否则就不等，每进一个人就重新计算这个时间。最大延迟时间就是上面电梯等待的 3 分钟，到了这个时间就算还有很多人没有进电梯，电梯也必须走。另外一个防抖中的重要概念就是分组合并，比如把都去偶数层的人统一在一趟电梯上。\nEnvoyXdsServer 的防抖函数也一样，把要推送的请求根据资源类型、事件类型分组或者合并，并在 minQuite 时间内等待下一个请求，超过 maxDelay 时间就进行下一步处理。\n在 Pilot 中最小静默时间可以通过 PILOT_DEBOUNCE_AFTER 这个环境变量设置，默认为 100 毫秒，最大延迟时间可以通过 PILOT_DEBOUNCE_MAX 设置，默认为 10 秒。\n// isti/pilot/pkg/features/pilot.go  DebounceAfter = env.RegisterDurationVar( \u0026#34;PILOT_DEBOUNCE_AFTER\u0026#34;, 100*time.Millisecond, \u0026#34;The delay added to config/registry events for debouncing. This will delay the push by \u0026#34;+ \u0026#34;at least this internal. If no change is detected within this period, the push will happen, \u0026#34;+ \u0026#34; otherwise we\u0026#39;ll keep delaying until things settle, up to a max of PILOT_DEBOUNCE_MAX.\u0026#34;, ).Get() DebounceMax = env.RegisterDurationVar( \u0026#34;PILOT_DEBOUNCE_MAX\u0026#34;, 10*time.Second, \u0026#34;The maximum amount of time to wait for events while debouncing. If events keep showing up with no breaks \u0026#34;+ \u0026#34;for this time, we\u0026#39;ll trigger a push.\u0026#34;, ).Get() 来看一下 debounce 方法中定义的 pushWorker ，主要的判断逻辑就定义在这里：\npushWorker := func() { eventDelay := time.Since(startDebounce) quietTime := time.Since(lastConfigUpdateTime) // it has been too long or quiet enough  if eventDelay \u0026gt;= debounceMax || quietTime \u0026gt;= debounceAfter { if req != nil { pushCounter++ adsLog.Infof(\u0026#34;Push debounce stable[%d] %d: %v since last change, %v since last push, full=%v\u0026#34;, pushCounter, debouncedEvents, quietTime, eventDelay, req.Full) free = false go push(req) req = nil debouncedEvents = 0 } } else { timeChan = time.After(debounceAfter - quietTime) } } 可以看到当事件的延迟时间大于等于最大延迟时间或静默时间大于等于最小静默时间，才会执行 push() 方法。 push() 方法也是 debounce 方法中包装的一个过程函数，它会在真正的 pushFn() 完成后向 freeCh 发送消息表示这次防抖处理完成了，可以开始下一次防抖。\npush := func(req *model.PushRequest) { pushFn(req) freeCh \u0026lt;- struct{}{} } debounce() 方法等待各个 channel 的逻辑如下：\nfor { select { case \u0026lt;-freeCh: free = true pushWorker() case r := \u0026lt;-ch: // If reason is not set, record it as an unknown reason  if len(r.Reason) == 0 { r.Reason = []model.TriggerReason{model.UnknownTrigger} } if !enableEDSDebounce \u0026amp;\u0026amp; !r.Full { // trigger push now, just for EDS  go pushFn(r) continue } lastConfigUpdateTime = time.Now() if debouncedEvents == 0 { timeChan = time.After(debounceAfter) startDebounce = lastConfigUpdateTime } debouncedEvents++ req = req.Merge(r) case \u0026lt;-timeChan: if free { pushWorker() } case \u0026lt;-stopCh: return } } 先看 case r:= \u0026lt;-ch 这个分支，当收到第一个 PushRequest 的时候，通过一个延时器 timeChan 先延迟一个最小静默时间（100 毫秒），期间接收新的请求直接进行 Merge ，同时累加已防抖的事件个数。当第一个 100 毫秒计时结束就会进入 case \u0026lt;-timeChan 分支，会判断是否有正在执行的防抖过程，没有的话就执行 pushWorker() 做一次防抖判断看是否需要推送。如果第一个请求的延迟时间还没有超过最大延迟时间（10 秒钟）并且距离处理上一次 PushRequest 的时间不足最小静默时间（100 毫秒），则继续延时，等待 debouncedAfter - quietTime 也就是不足最小静默时间的部分，再进行下一次 pushWorker() 操作。\n在看真正的 pushFn 函数之前，我们先了解下防抖函数是怎么合并 PushRequest 的。\n// istio/pilot/pkg/model/push_context.go:250 // Merge two update requests together func (first *PushRequest) Merge(other *PushRequest) *PushRequest { // ...  merged := \u0026amp;PushRequest{ // Keep the first (older) start time  Start: first.Start, // If either is full we need a full push  Full: first.Full || other.Full, // The other push context is presumed to be later and more up to date  Push: other.Push, // Merge the two reasons. Note that we shouldn\u0026#39;t deduplicate here, or we would under count  Reason: append(first.Reason, other.Reason...), } // Do not merge when any one is empty  if len(first.ConfigsUpdated) \u0026gt; 0 \u0026amp;\u0026amp; len(other.ConfigsUpdated) \u0026gt; 0 { merged.ConfigsUpdated = make(map[ConfigKey]struct{}, len(first.ConfigsUpdated)+len(other.ConfigsUpdated)) for conf := range first.ConfigsUpdated { merged.ConfigsUpdated[conf] = struct{}{} } for conf := range other.ConfigsUpdated { merged.ConfigsUpdated[conf] = struct{}{} } } return merged } 合并后的 PushRequest 会保存第一个 PushRequest 的时间以及最新一个 PushRequest 的 PushContext ，如果合并的请求中有一个需要全量推送那合并后的请求也必须是全量， Reason 描述的是触发这次推送请求的原因，有以下几种：\ntype TriggerReason string const ( // Describes a push triggered by an Endpoint change  EndpointUpdate TriggerReason = \u0026#34;endpoint\u0026#34; // Describes a push triggered by a config (generally and Istio CRD) change.  ConfigUpdate TriggerReason = \u0026#34;config\u0026#34; // Describes a push triggered by a Service change  ServiceUpdate TriggerReason = \u0026#34;service\u0026#34; // Describes a push triggered by a change to an individual proxy (such as label change)  ProxyUpdate TriggerReason = \u0026#34;proxy\u0026#34; // Describes a push triggered by a change to global config, such as mesh config  GlobalUpdate TriggerReason = \u0026#34;global\u0026#34; // Describes a push triggered by an unknown reason  UnknownTrigger TriggerReason = \u0026#34;unknown\u0026#34; // Describes a push triggered for debugging  DebugTrigger TriggerReason = \u0026#34;debug\u0026#34; ) 这里做一个小的拓展：追踪上面所有的原因，可以查询到所有可能发送到 pushChannel 的来源：\n而 ConfigsUpdated 跟踪了所有已经发生变化的配置，这个 Map 主要被用于那些被 Sidecar 限定了服务可见性的数据面代理，来过滤不必接收的 xDS 推送。只有与这些代理相关的服务（如 Sidecar 中定义的 Egress 和 Ingress ）发生变化时，才推送到特定的客户端。当 ConfigsUpdated 为空时，则表示所有的数据面代理都会收到这次推送。\n所以才有上面代码中 if len(first.ConfigsUpdated) \u0026gt; 0 \u0026amp;\u0026amp; len(other.ConfigsUpdated) \u0026gt; 0 这个判断，只要有一个请求需要推送至所有代理，就不会合并 ConfigUpdated 。\n对 PushRequest 做完防抖之后，再来看真正的 pushFn :\n// Push is called to push changes on config updates using ADS. This is set in DiscoveryService.Push, // to avoid direct dependencies. func (s *DiscoveryServer) Push(req *model.PushRequest) { if !req.Full { req.Push = s.globalPushContext() go s.AdsPushAll(versionInfo(), req) return } // ...  oldPushContext := s.globalPushContext() if oldPushContext != nil { oldPushContext.OnConfigChange() } push, err := s.initPushContext(req, oldPushContext) // ...  req.Push = push go s.AdsPushAll(versionLocal, req) } 可以看到先处理了不是全量推送的请求 if !req.Full ，结合之前分析所有 PushRequest 的来源可知， Full=false 只在 EDSUpdate 的时候才有可能推送，还记得之前分析 ServiceEntryStore 里的 workloadEntryHandler 吗？ EDS 的变化不需要更新 PushContext ，所以这里获取了全局的 globalPushContext 后就直接处理了。说到这里读者可能会对 PushContext 感到疑惑，这个是用来做什么的呢，为什么 EDS 的增量更新就不用更新它呢？我们先来看看 PushContext 的定义：\ntype PushContext struct { // ...  // privateServices are reachable within the same namespace, with exportTo \u0026#34;.\u0026#34;  privateServicesByNamespace map[string][]*Service // publicServices are services reachable within the mesh with exportTo \u0026#34;*\u0026#34;  publicServices []*Service // servicesExportedToNamespace are services that were made visible to this namespace  // by an exportTo explicitly specifying this namespace.  servicesExportedToNamespace map[string][]*Service // ServiceByHostnameAndNamespace has all services, indexed by hostname then namespace.  ServiceByHostnameAndNamespace map[host.Name]map[string]*Service `json:\u0026#34;-\u0026#34;` ServiceByHostname map[host.Name]*Service `json:\u0026#34;-\u0026#34;` // ServiceAccounts contains a map of hostname and port to service accounts.  ServiceAccounts map[host.Name]map[int][]string `json:\u0026#34;-\u0026#34;` // VirtualService related  // This contains all virtual services visible to this namespace extracted from  // exportTos that explicitly contained this namespace. The keys are namespace,gateway.  virtualServicesExportedToNamespaceByGateway map[string]map[string][]Config // this contains all the virtual services with exportTo \u0026#34;.\u0026#34; and current namespace. The keys are namespace,gateway.  privateVirtualServicesByNamespaceAndGateway map[string]map[string][]Config // This contains all virtual services whose exportTo is \u0026#34;*\u0026#34;, keyed by gateway  publicVirtualServicesByGateway map[string][]Config // destination rules are of three types:  // namespaceLocalDestRules: all public/private dest rules pertaining to a service defined in a given namespace  // exportedDestRulesByNamespace: all dest rules pertaining to a service exported by a namespace  namespaceLocalDestRules map[string]*processedDestRules exportedDestRulesByNamespace map[string]*processedDestRules // sidecars for each namespace  sidecarsByNamespace map[string][]*SidecarScope // envoy filters for each namespace including global config namespace  envoyFiltersByNamespace map[string][]*EnvoyFilterWrapper // gateways for each namespace  gatewaysByNamespace map[string][]Config allGateways []Config PushContext 里定义了大量对 Service 、 VirtualService 等的缓存，当服务发生变化时，必须要更新，而 EDS 的增量推送则不用。\n在 Push() 方法更新了 PushContext 之后便调用 AdsPushAll() 和 startPush(req) 将 PushRequest 重新入队到了 DiscoveryServer.pushQueue :\n// Send a signal to all connections, with a push event. func (s *DiscoveryServer) startPush(req *model.PushRequest) { pending := []*Connection{} for _, v := range s.adsClients { pending = append(pending, v) } // ...  req.Start = time.Now() for _, p := range pending { s.pushQueue.Enqueue(p, req) } } PushQueue 的结构是什么样的呢？\ntype PushQueue struct { mu *sync.RWMutex cond *sync.Cond // eventsMap stores all connections in the queue. If the same connection is enqueued again, the  // PushEvents will be merged.  eventsMap map[*Connection]*model.PushRequest // connections maintains ordering of the queue  connections []*Connection // inProgress stores all connections that have been Dequeue(), but not MarkDone().  // The value stored will be initially be nil, but may be populated if the connection is Enqueue().  // If model.PushRequest is not nil, it will be Enqueued again once MarkDone has been called.  inProgress map[*Connection]*model.PushRequest } 其中 eventsMap 保存了所有代理 gRPC 连接的 PushRequest ，如果相同连接的 PushRequest 再次入队，将会被合并。 inProgress 保存了所有连接正在处理的 PushRequest 。这里合并的操作和上面 debounce 逻辑一样，调用的是同一个函数。\nSend Pushes 当所有的 PushRequest 经过防抖等一系列处理后，重新入队到 pushQueue ，这时在 EnvoyXdsServer 启动时创建的协程 sendPushes 就开始工作了。\nfunc (s *DiscoveryServer) Start(stopCh \u0026lt;-chan struct{}) { adsLog.Infof(\u0026#34;Starting ADS server\u0026#34;) go s.handleUpdates(stopCh) go s.periodicRefreshMetrics(stopCh) go s.sendPushes(stopCh) } func (s *DiscoveryServer) sendPushes(stopCh \u0026lt;-chan struct{}) { doSendPushes(stopCh, s.concurrentPushLimit, s.pushQueue) } 这里传入了节流的参数 s.concurrentPushLimit ，它是由环境变量 PILOT_PUSH_THROTTLE 控制的，默认为 100 。 doSendPushes 的逻辑如图：\n首先从 pushQueue 中通过 Dequeue() 方法获取需要处理的代理客户端和对应的 PushRequest ，再根据 PushRequest 生成 Event 传入客户端的 pushChannel 中，注意和 EnvoyXdsServer 的 pushChannel 不同，这里的是针对当前客户端连接的 pushChannel 。\nfunc doSendPushes(stopCh \u0026lt;-chan struct{}, semaphore chan struct{}, queue *PushQueue) { for { select { case \u0026lt;-stopCh: return default: semaphore \u0026lt;- struct{}{} client, info := queue.Dequeue() doneFunc := func() { queue.MarkDone(client) \u0026lt;-semaphore } go func() { pushEv := \u0026amp;Event{ full: info.Full, push: info.Push, done: doneFunc, start: info.Start, configsUpdated: info.ConfigsUpdated, noncePrefix: info.Push.Version, } select { case client.pushChannel \u0026lt;- pushEv: return case \u0026lt;-client.stream.Context().Done(): // grpc stream was closed  doneFunc() adsLog.Infof(\u0026#34;Client closed connection %v\u0026#34;, client.ConID) } }() } } } 当 client.stream 返回 gRPC 完成的消息后，标记此次 PushRequest 完成。那么这里传入的 pushEv 事件最后在哪里处理了呢？回想最初客户端创建 gRPC 连接的地方，即调用 StreamAggregatedResources() 方法时：\n// istio/pilot/pkg/xds/ads.go func (s *DiscoveryServer) StreamAggregatedResources(stream discovery.AggregatedDiscoveryService_StreamAggregatedResourcesServer) error { // ...  con := newConnection(peerAddr, stream) var receiveError error reqChannel := make(chan *discovery.DiscoveryRequest, 1) go s.receiveThread(con, reqChannel, \u0026amp;receiveError) for { select { case req, ok := \u0026lt;-reqChannel: if !ok { return receiveError } err := s.processRequest(req, con) if err != nil { return err } case pushEv := \u0026lt;-con.pushChannel: err := s.pushConnection(con, pushEv) pushEv.done() if err != nil { return nil } } } } 这里处理了两个 channel 的消息，一个是 reqChannel ，另一个就是我们刚提到的 con.pushChannel 了。 reqChannel 之后再讨论，它主要是处理来自客户端的 gRPC 请求的。\n从 con.pushConnection 中获取到 pushEv 事件后，调用 s.pushConnection() 进行处理。首先会处理增量推送 EDS 的情况：\nif !pushEv.full { if !ProxyNeedsPush(con.node, pushEv) { adsLog.Debugf(\u0026#34;Skipping EDS push to %v, no updates required\u0026#34;, con.ConID) return nil } edsUpdatedServices := model.ConfigNamesOfKind(pushEv.configsUpdated, gvk.ServiceEntry) // Push only EDS. This is indexed already - push immediately  // (may need a throttle)  if len(con.Clusters()) \u0026gt; 0 \u0026amp;\u0026amp; len(edsUpdatedServices) \u0026gt; 0 { if err := s.pushEds(pushEv.push, con, versionInfo(), edsUpdatedServices); err != nil { return err } } return nil } 通过 ProxyNeedsPush 判断代理是否需要推送，判断的逻辑主要是检查推送事件 pushEv 的 configsUpdated 是否和代理相关。之前提到的在大规模下发场景下起很大作用的 Sidecar 就在这里生效。注意这里说的是 Istio 的一种流控配置，不是数据面的边车模式。\n  SidecarScope\n书接上文，我们着重分析下 SidecarScope 的处理流程。这里接着看是怎么检测代理依赖的配置文件的：\nfunc checkProxyDependencies(proxy *model.Proxy, config model.ConfigKey) bool { // Detailed config dependencies check.  switch proxy.Type { case model.SidecarProxy: if proxy.SidecarScope.DependsOnConfig(config) { return true } else if proxy.PrevSidecarScope != nil \u0026amp;\u0026amp; proxy.PrevSidecarScope.DependsOnConfig(config) { return true } default: // TODO We\u0026#39;ll add the check for other proxy types later.  return true } return false } SidecarScope.DependsOnConfig() 方法内容如下：\n// DependsOnConfig determines if the proxy depends on the given config. // Returns whether depends on this config or this kind of config is not scoped(unknown to be depended) here. func (sc *SidecarScope) DependsOnConfig(config ConfigKey) bool { if sc == nil { return true } // This kind of config will trigger a change if made in the root namespace or the same namespace  if _, f := sidecarScopeNamespaceConfigTypes[config.Kind]; f { return config.Namespace == sc.RootNamespace || config.Namespace == sc.Config.Namespace } // This kind of config is unknown to sidecarScope.  if _, f := sidecarScopeKnownConfigTypes[config.Kind]; !f { return true } _, exists := sc.configDependencies[config.HashCode()] return exists } 它先是判断了变化的配置是否和 SidecarScope 是同个命名空间，不过这只针对 Sidecar 和 EnvoyFilter 等特殊配置。再处理一些不常见的配置，如果这些配置不在 SidecarScope 管理范围内的话，作为 unknown 类型也返回 true 。 SidecarScope 管理的流控配置主要是以下三种：\nsidecarScopeKnownConfigTypes = map[resource.GroupVersionKind]struct{}{ gvk.ServiceEntry: {}, gvk.VirtualService: {}, gvk.DestinationRule: {}, } 处理完了特殊情况，就会检测上面三种流控配置是否与当前的代理有关联：\n_, exists := sc.configDependencies[config.HashCode()] return exists configDependencies 里保存的就是跟当前代理相关的所有流控配置，它是在初始化代理时创建的。还记得当数据面代理第一次连接至控制面时 StreamAggregatedResources() 方法里创建的 receiveThread 协程吗？\nfunc (s *DiscoveryServer) StreamAggregatedResources(stream discovery.AggregatedDiscoveryService_StreamAggregatedResourcesServer) error { // ...  con := newConnection(peerAddr, stream) var receiveError error reqChannel := make(chan *discovery.DiscoveryRequest, 1) go s.receiveThread(con, reqChannel, \u0026amp;receiveError) // ... } receiveThread 里有个 initConnection 方法：\nfunc (s *DiscoveryServer) receiveThread(con *Connection, reqChannel chan *discovery.DiscoveryRequest, errP *error) { firstReq := true for { // ...  if firstReq { firstReq = false if err := s.initConnection(req.Node, con); err != nil { *errP = err return } // ...  } // ...  } } initConnection 刚开始就会做 initProxy 的操作初始化代理，中间会设置代理的状态：\n// initProxy initializes the Proxy from node. func (s *DiscoveryServer) initProxy(node *core.Node) (*model.Proxy, error) { // ...  if err = s.setProxyState(proxy, s.globalPushContext()); err != nil { return nil, err } // ...  return proxy, nil } 到这里就能看到它在设置 SidecarScope 了：\nfunc (s *DiscoveryServer) setProxyState(proxy *model.Proxy, push *model.PushContext) error { if err := proxy.SetWorkloadLabels(s.Env); err != nil { return err } if err := proxy.SetServiceInstances(push.ServiceDiscovery); err != nil { return err } proxy.SetSidecarScope(push) proxy.SetGatewaysForProxy(push) return nil } 如果代理是 SidecarProxy 的话（其他还有诸如 Gateway 等模式）,调用 PushContext.getSidecarScope 初始化 SidecarScope :\nfunc (node *Proxy) SetSidecarScope(ps *PushContext) { sidecarScope := node.SidecarScope if node.Type == SidecarProxy { workloadLabels := labels.Collection{node.Metadata.Labels} node.SidecarScope = ps.getSidecarScope(node, workloadLabels) } else { // Gateways should just have a default scope with egress: */*  node.SidecarScope = DefaultSidecarScopeForNamespace(ps, node.ConfigNamespace) } node.PrevSidecarScope = sidecarScope } 因为 PushContext 里保存了当前这次推送所用到的所有上下文，通过 PushContext.sidecarsByNamespace 就能拿到当前代理所在命名空间的所有 Sidecar 配置。再检查当前代理所依附的实例的 Labels 是否符合 Sidecar 定义的 workloadSelector :\nfunc (ps *PushContext) getSidecarScope(proxy *Proxy, workloadLabels labels.Collection) *SidecarScope { if sidecars, ok := ps.sidecarsByNamespace[proxy.ConfigNamespace]; ok { var defaultSidecar *SidecarScope for _, wrapper := range sidecars { if wrapper.Config != nil \u0026amp;\u0026amp; wrapper.Config.Spec != nil { // ...  if sidecar.GetWorkloadSelector() != nil { workloadSelector := labels.Instance(sidecar.GetWorkloadSelector().GetLabels()) if !workloadLabels.IsSupersetOf(workloadSelector) { continue } return wrapper } defaultSidecar = wrapper continue } // Not sure when this can happen (Config = nil ?)  if defaultSidecar != nil { return defaultSidecar // still return the valid one  } return wrapper } if defaultSidecar != nil { return defaultSidecar // still return the valid one  } } return DefaultSidecarScopeForNamespace(ps, proxy.ConfigNamespace) } 这时就把 SidecarScope 和 Proxy 关联起来了，这里的 SidecarScope 已经是 PushContext 处理过的了，里面 configDependencies 都是有值的。这个值是在哪里设置的呢？在 InitContext 的时候，有个 PushContext.initSidecarScope() 方法，这个方法就是解析 Sidecar 里的具体内容，调用 ConvertToSidecarScope 将 Engress 和 Ingress 里的定义的服务找出来后，逐个调用 AddConfigDependencies 写入 configuDependencies 中。\nConvertToSidecarScope 函数的代码位于 istio/pilot/pkg/model/sidecar.go:226 中，限于篇幅，感兴趣的读者可以自行研读。\n到这里 SidecarScope 的整个处理流程就处理完了，在生产环境中运用好 SidecarScope 能极大的减小数据面收到的 xDS 的数量，希望这段代码分析能帮助各位读者更好的理解，在实际运用过程中可以更好的定位问题。\n  PushConnection\n回到 pushConnection 的主流程，在 Full=false 下判断 ProxyNeedsPush ，确定需要推送后调用 pushEds 增量推送 EDS 。\n详细分析下 pushEds 的过程，首先遍历所有的 Clusters ，构建生成器生成 EDS ，然后调用 con.send() 进行推送：\nfunc (s *DiscoveryServer) pushEds(push *model.PushContext, con *Connection, version string, edsUpdatedServices map[string]struct{}) error { // ...  for _, clusterName := range con.Clusters() { // ...  builder := createEndpointBuilder(clusterName, con.node, push) l := s.generateEndpoints(builder) if l == nil { continue } for _, e := range l.Endpoints { endpoints += len(e.LbEndpoints) } if len(l.Endpoints) == 0 { empty++ } loadAssignments = append(loadAssignments, l) } // ...  response := endpointDiscoveryResponse(loadAssignments, version, push.Version, con.node.RequestedTypes.EDS) err := con.send(response) // ... } 最后调用 conn.steam.Send() 就将 EDS 发送至数据面的客户端了。\n// Send with timeout func (conn *Connection) send(res *discovery.DiscoveryResponse) error { done := make(chan error, 1) t := time.NewTimer(SendTimeout) go func() { err := conn.stream.Send(res) // ...  done \u0026lt;- err }() // ... } 如果是增量推送的话这里就退出了，全量推送和只推送 EDS 一样，也会先判断下 ProxyNeedsPush ，确定需要后开始全量推送，根据 pushTypes 的不同分别推送 CDS 、 EDS 、 LDS 和 RDS :\npushTypes := PushTypeFor(con.node, pushEv) if con.Watching(v3.ClusterShortType) \u0026amp;\u0026amp; pushTypes[CDS] { err := s.pushCds(con, pushEv.push, currentVersion) if err != nil { return err } } else if s.StatusReporter != nil { s.StatusReporter.RegisterEvent(con.ConID, ClusterEventType, pushEv.noncePrefix) } if len(con.Clusters()) \u0026gt; 0 \u0026amp;\u0026amp; pushTypes[EDS] { err := s.pushEds(pushEv.push, con, currentVersion, nil) if err != nil { return err } } else if s.StatusReporter != nil { s.StatusReporter.RegisterEvent(con.ConID, EndpointEventType, pushEv.noncePrefix) } if con.Watching(v3.ListenerShortType) \u0026amp;\u0026amp; pushTypes[LDS] { err := s.pushLds(con, pushEv.push, currentVersion) if err != nil { return err } } else if s.StatusReporter != nil { s.StatusReporter.RegisterEvent(con.ConID, ListenerEventType, pushEv.noncePrefix) } if len(con.Routes()) \u0026gt; 0 \u0026amp;\u0026amp; pushTypes[RDS] { err := s.pushRoute(con, pushEv.push, currentVersion) if err != nil { return err } } else if s.StatusReporter != nil { s.StatusReporter.RegisterEvent(con.ConID, RouteEventType, pushEv.noncePrefix) } proxiesConvergeDelay.Record(time.Since(pushEv.start).Seconds()) return nil 推送的逻辑和 EDS 一样，这里就不再赘述。至此，所有 xDS 的下发就完成了。\n  Client Request 这部分的内容比较简单，核心推送和上面的 sendPushes 一样，流程先是从 reqChannel 中获取 DiscoveryRequest 看客户端订阅了哪些 xDS ，组装推送即可。\nfunc (s *DiscoveryServer) processRequest(discReq *discovery.DiscoveryRequest, con *Connection) error { // ...  switch discReq.TypeUrl { case v2.ClusterType, v3.ClusterType: if err := s.handleTypeURL(discReq.TypeUrl, \u0026amp;con.node.RequestedTypes.CDS); err != nil { return err } if err := s.handleCds(con, discReq); err != nil { return err } case v2.ListenerType, v3.ListenerType: if err := s.handleTypeURL(discReq.TypeUrl, \u0026amp;con.node.RequestedTypes.LDS); err != nil { return err } if err := s.handleLds(con, discReq); err != nil { return err } case v2.RouteType, v3.RouteType: if err := s.handleTypeURL(discReq.TypeUrl, \u0026amp;con.node.RequestedTypes.RDS); err != nil { return err } if err := s.handleRds(con, discReq); err != nil { return err } case v2.EndpointType, v3.EndpointType: if err := s.handleTypeURL(discReq.TypeUrl, \u0026amp;con.node.RequestedTypes.EDS); err != nil { return err } if err := s.handleEds(con, discReq); err != nil { return err } default: err = s.handleCustomGenerator(con, discReq) if err != nil { return err } } return nil 总结 xDS 的推送流程到这里就讲完了。我们从 EnvoyXdsServer 的结构开始，对其启动流程、怎么与客户端建立连接、怎么感知配置和服务变化、怎么防抖、怎么推送、SidecarScope 如何工作等都做了比较细致的分析，虽然已经阅读了源码，但是距离服务网格化的实际落地、实践中的各种性能问题、针对业务的优化，我们还有很长一段路要走。\n限于篇幅， xDS 的生成逻辑我们将在下一篇源码分析中讲解，也就是生成器中构建 xDS 的地方，这部分涉及到很多数据的转化，内容繁杂，需要整篇分析才能讲解的清楚。\n","permalink":"https://cloudnative.to/blog/istio-pilot-3/","tags":["istio","pilot","cloudnative","servermesh"],"title":"Istio Pilot 源码分析（三）"},{"categories":["Istio","Service Mesh"],"contents":"了解了 Pilot 源码的基本结构和启动流程之后，我们可以深入探索 Pilot 究竟是怎么下发 xDS 协议的，以及协议的生成逻辑。相信大家都会有这些疑问：控制面与数据面详细的交互过程是什么？到底什么时候才会增量推送？增量推送判断的逻辑是什么？ 非 Kubernetes 原生的服务（如存在于虚拟机的服务、 Dubbo 服务等）到底是怎么注册并且经过一系列转化下发至数据面的？\n带着这些问题，开始我们今天对 Pilot 的探索。\n注：本文基于 istio release-1.7 分支分析，其他版本的代码结构会有所不同。\nServiceEntryStore 在多点落地 ServiceMesh 的过程中，大量的用到了 ServiceEntry ，每一个 Dubbo 服务都会映射一个 ServiceEntry 创建在 Kubernetes 里。 ServiceEntry 的作用就是将集群外部的服务注册到 Pilot 中，再统一由 ServiceController 进行管理。相应的，管理外部服务实例的对象为 WorkloadEntry ， ServiceEntry 可以通过 LabelSelector 筛选出自身对应的实例。\nServiceEntry 是作为 CR (Custome Resource) 保存在 Kubernetes 集群里的（也可以通过 MCP 服务直接发送给 Pilot ），暂时只讨论在集群中创建 CR 的情况。在上一篇源码分析中我们介绍到， Pilot 是通过 ConfigController 来监听创建在集群中的 CR 的， ServiceEntry 也不例外，保存这些 CR 的 ConfigStore 会被转化为 ServiceEntryStore 中的 store （转化的详情见上一篇源码分析），这就是最终 Pilot 存储 ServiceEntry 的地方。当监听的资源推送更改的事件时，会触发 ServiceEntryStore 对应的 handler 处理后续的流程。\n我们先来看一下 ServiceEntryStore 的结构和它提供的方法：\n// istio/pilot/pkg/serviceregistry/serviceentry/servicediscovery.go:61  // ServiceEntryStore communicates with ServiceEntry CRDs and monitors for changes type ServiceEntryStore struct { XdsUpdater model.XDSUpdater // 用来接收 EnvoyXdsServer 的接口，主要用来 Push 相应的 xDS 更新请求  store model.IstioConfigStore // 保存 ServiceEntry 实例的地方  storeMutex sync.RWMutex // 读写 store 时需要的锁  // 以 hostname/namespace 以及类型（是服务还是实例）等作为索引的服务实例表  instances map[instancesKey]map[configKey][]*model.ServiceInstance // seWithSelectorByNamespace 保存了每个 namespace 里所有的 ServiceEntry，也是作为一个索引供 handler 使用  seWithSelectorByNamespace map[string][]servicesWithEntry refreshIndexes bool ... } 可以看到除了 XdsUpdater 和 store 两个必须的结构外，其余大部分都是些资源的缓存和索引（索引键不同），为后续 handler 处理事件时提供便利。除了结构，还需要关注两个比较重要的 handler :\n// WorkloadEntry 变化时的处理逻辑 func (s *ServiceEntryStore) workloadEntryHandler(old, curr model.Config, event model.Event) {} // ServiceEntry 变化时的处理逻辑 func (s *ServiceEntryStore) serviceEntryHandler(old, curr model.Config, event model.Event) {} 这两个 handler 的业务逻辑后文中再详细讨论，先来回忆下 ServiceEntryStore 的初始化流程：\n在 Server 初始化 ServiceController 的时候，通过调用 NewServiceDiscovery() 方法初始化 ServiceEntryStore ，这里除了将 EnvoyXdsServer 和 IstioConfigStore 与 ServiceEntryStore 关联起来外，最重要的就是向 ConfigController 注册了 ServiceEntry 和 WorkloadEntry 的事件 Handler:\nfunc NewServiceDiscovery(configController model.ConfigStoreCache, store model.IstioConfigStore, xdsUpdater model.XDSUpdater) *ServiceEntryStore { s := \u0026amp;ServiceEntryStore{ XdsUpdater: xdsUpdater, store: store, ip2instance: map[string][]*model.ServiceInstance{}, instances: map[instancesKey]map[configKey][]*model.ServiceInstance{}, workloadInstancesByIP: map[string]*model.WorkloadInstance{}, refreshIndexes: true, } if configController != nil { configController.RegisterEventHandler(gvk.ServiceEntry, s.serviceEntryHandler) configController.RegisterEventHandler(gvk.WorkloadEntry, s.workloadEntryHandler) } return s } 这样在 ConfigController 监听到资源变化的时候，就会调用 serviceEntryHandler 和 workloadEntryHandler 来处理事件了。这两个 handler 的目的都是向 EnvoyXdsServer 推送相应的 xDS 资源变化。\nworkloadEntryHandler 首先来分析服务实例 WorkloadEntry 的更新是如何下发 xDS 的：\nseWithSelectorByNamespace 和 instances 如上述 ServiceEntryStore 结构介绍中的注释，前者缓存了各个 namespace 中所有的 ServiceEntry ，后者则是所有服务节点 WorkloadEntry 的缓存。\n当有新的 WorkloadEntry 变化时，先从 seWithSelectorByNamespace 中读取同一 namespace 中的 ServiceEntry ，遍历它们并与 WorkloadEntry 的 Label 进行比对，确定是关联的服务后，依据获取的服务创建 ServiceInstance 。 ServiceInstance 是 Pilot 抽象出的描述具体服务对应实例的结构:\ntype ServiceInstance struct { Service *Service `json:\u0026#34;service,omitempty\u0026#34;` ServicePort *Port `json:\u0026#34;servicePort,omitempty\u0026#34;` Endpoint *IstioEndpoint `json:\u0026#34;endpoint,omitempty\u0026#34;` } 创建了新的 ServiceInstance 后，需要及时更新实例的索引表 s.instances :\nif event != model.EventDelete { s.updateExistingInstances(key, instances) } else { s.deleteExistingInstances(key, instances) } 之后将新创建的 ServiceInstance 传入 ServiceEntryStore 专门处理 EDS 的函数 s.edsUpdate() 。在做进一步处理时，需要再刷新一遍索引表，调用 maybeRefreshIndexes() 避免其他协程的工作导致索引表更新不及时，完成后开启读锁，从服务实例索引表 s.Instances 中查找我们要处理的实例。如果是删除事件，先前更新索引表的时候已经删除了，所以这里是查不到 allInstances 的，直接向 EnvoyXdsServer 发送删除 EDS 的请求。\n// edsUpdate triggers an EDS update for the given instances func (s *ServiceEntryStore) edsUpdate(instances []*model.ServiceInstance) { allInstances := []*model.ServiceInstance{} // Find all keys we need to lookup  keys := map[instancesKey]struct{}{} for _, i := range instances { keys[makeInstanceKey(i)] = struct{}{} } s.maybeRefreshIndexes() s.storeMutex.RLock() for key := range keys { for _, i := range s.instances[key] { allInstances = append(allInstances, i...) } } s.storeMutex.RUnlock() // This was a delete  if len(allInstances) == 0 { for k := range keys { _ = s.XdsUpdater.EDSUpdate(s.Cluster(), string(k.hostname), k.namespace, nil) } return } ... } 如果实例有更新则直接发送更新 EDS 的请求：\n// edsUpdate triggers an EDS update for the given instances func (s *ServiceEntryStore) edsUpdate(instances []*model.ServiceInstance) { ... endpoints := make(map[instancesKey][]*model.IstioEndpoint) for _, instance := range allInstances { port := instance.ServicePort key := makeInstanceKey(instance) endpoints[key] = append(endpoints[key], \u0026amp;model.IstioEndpoint{ Address: instance.Endpoint.Address, EndpointPort: instance.Endpoint.EndpointPort, ServicePortName: port.Name, Labels: instance.Endpoint.Labels, UID: instance.Endpoint.UID, ServiceAccount: instance.Endpoint.ServiceAccount, Network: instance.Endpoint.Network, Locality: instance.Endpoint.Locality, LbWeight: instance.Endpoint.LbWeight, TLSMode: instance.Endpoint.TLSMode, }) } for k, eps := range endpoints { _ = s.XdsUpdater.EDSUpdate(s.Cluster(), string(k.hostname), k.namespace, eps) } } 完整的 workloadEntryHandler() 代码如下：\nfunc (s *ServiceEntryStore) workloadEntryHandler(old, curr model.Config, event model.Event) { wle := curr.Spec.(*networking.WorkloadEntry) key := configKey{ kind: workloadEntryConfigType, name: curr.Name, namespace: curr.Namespace, } ... s.storeMutex.RLock() // We will only select entries in the same namespace  entries := s.seWithSelectorByNamespace[curr.Namespace] s.storeMutex.RUnlock() // if there are no service entries, return now to avoid taking unnecessary locks  if len(entries) == 0 { return } log.Debugf(\u0026#34;Handle event %s for workload entry %s in namespace %s\u0026#34;, event, curr.Name, curr.Namespace) instances := []*model.ServiceInstance{} for _, se := range entries { workloadLabels := labels.Collection{wle.Labels} if !workloadLabels.IsSupersetOf(se.entry.WorkloadSelector.Labels) { // Not a match, skip this one  continue } instance := convertWorkloadEntryToServiceInstances(wle, se.services, se.entry) instances = append(instances, instance...) } if event != model.EventDelete { s.updateExistingInstances(key, instances) } else { s.deleteExistingInstances(key, instances) } s.edsUpdate(instances) } 接下来就是 EnvoyXdsServer 来处理这次 EDS 的更新请求了。首先 EnvoyXdsServer 会判断此次 EDS 更新是全量下发还是增量下发，然后创建 PushRequest 发送至 EnvoyXdsServer 统一用来接收推送请求的 pushChannel 。\nfunc (s *DiscoveryServer) EDSUpdate(clusterID, serviceName string, namespace string, istioEndpoints []*model.IstioEndpoint) error { inboundEDSUpdates.Increment() // 判断是否是全量下发  fp := s.edsUpdate(clusterID, serviceName, namespace, istioEndpoints) s.ConfigUpdate(\u0026amp;model.PushRequest{ Full: fp, ConfigsUpdated: map[model.ConfigKey]struct{}{{ Kind: gvk.ServiceEntry, Name: serviceName, Namespace: namespace, }: {}}, Reason: []model.TriggerReason{model.EndpointUpdate}, }) return nil } pushChannel 后续的处理流程和 EDS 是否增量更新将在下文讨论 EnvoyXdsServer 的时候再分析，这里不再赘述。\nserviceEntryHandler 了解了 WorkloadEntry 的更新是如何处理之后，我们再来看下 serviceEntryHandler 是如何处理 ServiceEntry 的：\nserviceEntryHandler 会将 ServiceEntry 转化为一组 Pilot 内部抽象的服务，每个不同的 Hosts 、 Address 都会对应一个 Service ，并且初始化一个名为 configsUpdated 的 map 来保存是否有 ServiceEntry 需要更新，以及创建了多个 slice 分别保存该新增、删除、更新和没有变化的服务：\nfunc (s *ServiceEntryStore) serviceEntryHandler(old, curr model.Config, event model.Event) { cs := convertServices(curr) configsUpdated := map[model.ConfigKey]struct{}{} var addedSvcs, deletedSvcs, updatedSvcs, unchangedSvcs []*model.Service ... } 根据不同的事件类型，更新不同的 slice :\nswitch event { case model.EventUpdate: os := convertServices(old) if selectorChanged(old, curr) { // Consider all services are updated.  mark := make(map[host.Name]*model.Service, len(cs)) for _, svc := range cs { mark[svc.Hostname] = svc updatedSvcs = append(updatedSvcs, svc) } for _, svc := range os { if _, f := mark[svc.Hostname]; !f { updatedSvcs = append(updatedSvcs, svc) } } } else { addedSvcs, deletedSvcs, updatedSvcs, unchangedSvcs = servicesDiff(os, cs) } case model.EventDelete: deletedSvcs = cs case model.EventAdd: addedSvcs = cs default: // this should not happen  unchangedSvcs = cs } 比较特别的是，当事件为更新事件时，会和老的 Service 列表进行比对。先看是否有某个服务的 Selector 发生了变化，如果发生了变化，需要将新老服务列表里的所有服务都加入到更新列表中。如果 Selector 没有发生变化，通过 serviceDiff() 挨个比对新老服务列表中的服务，对应保存至新增、删除、更新和未变化的 slice 中。\n将服务归类后，把需要变化的服务都写入 configsUpdated 中：\nfor _, svcs := range [][]*model.Service{addedSvcs, deletedSvcs, updatedSvcs} { for _, svc := range svcs { configsUpdated[model.ConfigKey{ Kind: gvk.ServiceEntry, Name: string(svc.Hostname), Namespace: svc.Attributes.Namespace}] = struct{}{} } } 由于 serviceDiff() 只会比对 Service 结构，并不会对比 Endpoints 是否变化，所以当有 unchangedSvcs 时，可能需要对这些服务的 xDS 做增量更新（只更新 EDS ），也可能是全量更新。什么时候会全量更新呢？当服务的 Resolution 为 DNS 时（可以阅读文档了解 Resolution ）， Endpoint 的 address 都是全域名，需要更新 CDS 才行。\nif len(unchangedSvcs) \u0026gt; 0 { // If this service entry had endpoints with IPs (i.e. resolution STATIC), then we do EDS update.  // If the service entry had endpoints with FQDNs (i.e. resolution DNS), then we need to do  // full push (as fqdn endpoints go via strict_dns clusters in cds).  currentServiceEntry := curr.Spec.(*networking.ServiceEntry) oldServiceEntry := old.Spec.(*networking.ServiceEntry) if currentServiceEntry.Resolution == networking.ServiceEntry_DNS { if !reflect.DeepEqual(currentServiceEntry.Endpoints, oldServiceEntry.Endpoints) { // fqdn endpoints have changed. Need full push  for _, svc := range unchangedSvcs { configsUpdated[model.ConfigKey{ Kind: gvk.ServiceEntry, Name: string(svc.Hostname), Namespace: svc.Attributes.Namespace}] = struct{}{} } } } } 当 unchangedSvcs 的 Resolution 为 STATIC 时，只需要增量的更新 EDS 即可：\nif len(unchangedSvcs) \u0026gt; 0 \u0026amp;\u0026amp; !fullPush { // IP endpoints in a STATIC service entry has changed. We need EDS update  // If will do full-push, leave the edsUpdate to that.  // XXX We should do edsUpdate for all unchangedSvcs since we begin to calculate service  // data according to this \u0026#34;configsUpdated\u0026#34; and thus remove the \u0026#34;!willFullPush\u0026#34; condition.  instances := convertInstances(curr, unchangedSvcs) key := configKey{ kind: serviceEntryConfigType, name: curr.Name, namespace: curr.Namespace, } // If only instances have changed, just update the indexes for the changed instances.  s.updateExistingInstances(key, instances) s.edsUpdate(instances) return } 如果 configsUpdated 中有值，则需要做 fullPush ，先更新这些服务的 EDS ，再向 pushChannel 发送 fullPush 的 PushRequest :\nif fullPush { // When doing a full push, for added and updated services trigger an eds update  // so that endpoint shards are updated.  var instances []*model.ServiceInstance if len(addedSvcs) \u0026gt; 0 { instances = append(instances, convertInstances(curr, addedSvcs)...) } if len(updatedSvcs) \u0026gt; 0 { instances = append(instances, convertInstances(curr, updatedSvcs)...) } if len(unchangedSvcs) \u0026gt; 0 { currentServiceEntry := curr.Spec.(*networking.ServiceEntry) oldServiceEntry := old.Spec.(*networking.ServiceEntry) // Non DNS service entries are sent via EDS. So we should compare and update if such endpoints change.  if currentServiceEntry.Resolution != networking.ServiceEntry_DNS { if !reflect.DeepEqual(currentServiceEntry.Endpoints, oldServiceEntry.Endpoints) { instances = append(instances, convertInstances(curr, unchangedSvcs)...) } } } s.edsUpdate(instances) // If service entry is deleted, cleanup endpoint shards for services.  for _, svc := range deletedSvcs { s.XdsUpdater.SvcUpdate(s.Cluster(), string(svc.Hostname), svc.Attributes.Namespace, model.EventDelete) } pushReq := \u0026amp;model.PushRequest{ Full: true, ConfigsUpdated: configsUpdated, Reason: []model.TriggerReason{model.ServiceUpdate}, } s.XdsUpdater.ConfigUpdate(pushReq) } 至此， ServiceEntryStore 是如何处理 ServiceEntry 和 WorkloadEntry 的逻辑就介绍完了。其余像 ServiceEntry 选择集群内的 Pods 、 Kubernetes 原生 Service 选择 WorkloadEntry 的用法读者感兴趣可以自行研究相关源码。\n其余注册中心的处理逻辑如 kube 、 mcp 等可继续关注本系列的其他文章。读者也可以自行尝试走读分析：\n// 相关源码目录 kube: pilot/pkg/serviceregistry/kube mcp: pilot/pkg/serviceregistry/mcp 接下来我们介绍 Pilot Server 中的核心， EnvoyXdsServer 。\n","permalink":"https://cloudnative.to/blog/istio-pilot-2/","tags":["istio","pilot","cloudnative","servermesh"],"title":"Istio Pilot 源码分析（二）"},{"categories":null,"contents":"地平线简介 地平线是边缘人工智能芯片的全球领导者。得益于前瞻性的软硬结合理念，地平线自主研发兼具极致效能与开放易用性的边缘人工智能芯片及解决方案，可面向智能驾驶以及更广泛的通用 AI 应用领域提供全面开放的赋能服务。目前，地平线是国内唯一一家实现车规级人工智能芯片量产前装的企业。\n后端研发工程师（北京 / 南京） 工作职责  参与开发公司一站式AI平台，对内支撑生产，对外赋能客户； 参与资源管理以及调度系统研发，提高资源利用率，降低研发成本； 跟踪业界最新的技术方向，提升平台核心竞争力。  职位要求  本科及以上学历，具备较强的代码能力； 扎实的计算机基础知识，包括系统架构/编译/操作系统/数据结构/基础算法等； 曾经使用过两种以上语言来解决实际的项目问题，如 c++/golang/java等； 精通Docker、Kubernetes者优先，有Kubeflow、Volcano、Argo等项目落地经验者更佳 精通资源调度算法者优先  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/horizon/","tags":null,"title":"[社招] 地平线艾迪平台部"},{"categories":null,"contents":"你想要加入由世界级工程师组成的团队吗？使用 Istio、Envoy、Apache SkyWalking 等开源项目来定义下一代云原生网络。下面是我们正在招聘的部分职位。\n分布式系统工程师，企业基础架构（数据平面）GoLang 或 C++ 开发者 我们正在寻找有使用 Golang 和 gRPC 构建分布式系统经验的后端工程师。我们正在为财富 500 强企业的关键业务构建安全、高可用的服务网格（Service Mesh）平台，横跨传统和现代基础设施。您应具备较强的分布式系统和网络的基础知识。熟悉 Kubernetes、Istio 和 Envoy 等技术，有为开源项目做贡献的经验更佳。\n要求  有使用 C++、Golang、gRPC 构建分布式系统平台的经验。 熟悉 Kubernetes，Istio、Envoy 等服务网格技术。 对网络协议、概念、分布式系统的一致性、识别和协调配置漂移的技术有很好的理解。 有为开源项目做贡献的经验更佳。 熟悉以下内容更佳：WebAssembly、Authorization、NGAC、RBAC、ABAC。 熟悉硬件/软件负载均衡器（F5、NGINX）、HSM 模块、Active Directory/LDAP 者更佳。  站点可靠性工程师（SRE） 站点可靠性工程（SRE）将软件和系统工程结合起来，构建和运行可扩展、大规模分布式、容错系统。作为团队的一员，你将致力于确保 Tetrate 平台具有适合用户需求的可靠性/正常运行时间，以及快速的改进速度。此外，我们的工程工作主要集中在建设基础设施，提高平台故障排除能力，并通过自动化减少人工干预。\n要求  有系统的解决问题的方法，加上优秀的沟通技巧，有主人翁意识/完成感和自我导向的动力。 熟悉分布式系统（有状态和/或无状态）和网络的操作、调试和故障排除。 熟悉 Kubernetes、服务网格技术（如 Istio 和 Envoy）能够调试、优化代码、自动化日常任务。 至少有以下一种语言的编程经验：C++、Rust、Python、Go。 熟悉使用 SLO 和 SLI 以规范的方式量化故障和可用性的概念。 有性能分析和调优经验者优先。  工作地点 全球\n远程工作，在中国、印尼、印度、日本、美国、加拿大、爱尔兰、荷兰、西班牙和乌克兰都有业务。\n投递简历 请将展示你代码风格的 GitHub 或在线链接与你的简历一起发送至：careers@tetrate.io 或联系 Jimmy Song 了解详情。\n关于 Tetrate 基于 Istio、Envoy、Apache SkyWalking 等开源项目，Tetrate 的旗舰产品Tetrate Service Bridge（TSB）可以实现传统和现代工作负载的桥接。在任何环境下，客户都可以为所有工作负载获得一致的内置可观察性、运行时安全性和流量管理。\n除了技术之外，Tetrate 还带来了一个世界级的团队，领导开放的 Istio、Envoy、Apache SkyWalking 等项目，提供企业可以用来实现人员和流程现代化的最佳实践。\nTetrate 是数学术语 Tetration（迭代幂次） 的变体，Tetrate 员工自称 Tetrant。想要了解更多，请访问 tetrate.io。\n","permalink":"https://cloudnative.to/job/tetrate/","tags":null,"title":"企业级服务网格提供商 Tetrate 公司招聘"},{"categories":["Kubernetes"],"contents":"DevOps简述 顾名思义，DevOps就是开发（Development）与运维（Operations）的结合体，其目的就是打通开发与运维之间的壁垒，促进开发、运营和质量保障（QA）等部门之间的沟通协作，以便对产品进行小规模、快速迭代式地开发和部署，快速响应客户的需求变化。它强调的是开发运维一体化，加强团队间的沟通和快速反馈，达到快速交付产品和提高交付质量的目的。\nDevOps并不是一种新的工具集，而是一种思想，一种文化，用以改变传统开发运维模式的一组最佳实践。一般做法是通过一些CI/CD（持续集成、持续部署）自动化的工具和流程来实现DevOps的思想，以流水线（pipeline）的形式改变传统开发人员和测试人员发布软件的方式。随着Docker和Kubernetes（以下简称k8s）等技术的普及，容器云平台基础设施越来越完善，加速了开发和运维角色的融合，使云原生的DevOps实践成为以后的趋势。下面我们基于混合容器云平台详细讲解下云平台下DevOps的落地方案。\n云原生DevOps特点 DevOps是PaaS平台里很关键的功能模块，包含以下重要能力：支持代码克隆、编译代码、运行脚本、构建发布镜像、部署yaml文件以及部署Helm应用等环节；支持丰富的流水线设置，比如资源限额、流水线运行条数、推送代码以及推送镜像触发流水线运行等，提供了用户在不同环境下的端到端高效流水线能力；提供开箱即用的镜像仓库中心；提供流水线缓存功能，可以自由配置整个流水线或每个步骤的运行缓存，在代码克隆、编译代码、构建镜像等步骤时均可利用缓存大大缩短运行时间，提升执行效率。具体功能清单如下：\n 缓存加速：自研容器化流水线的缓存技术，通过代码编译和镜像构建的缓存复用，平均加速流水线3~5倍； 细粒度缓存配置：任一阶段、步骤可以控制是否开启缓存及缓存路径； 支持临时配置：用户无需提交即可运行临时配置，避免频繁提交配置文件污染代码仓库； 开箱即用的镜像仓库； 提供完整的日志功能； 可视化编辑界面，灵活配置流水线； 支持多种代码仓库授权：GitHub、GitLab、Bitbucket等； 多种流水线触发方式：代码仓库触发，镜像推送触发等； 网络优化，加快镜像或依赖包的下载速度；  云原生DevOps实现 简单地说，云原生DevOps内部功能的设计基本上均是通过k8s提供的自定义controller功能来实现的，基本逻辑就是根据业务需要抽象出多个CRD（Custom Resource Definition，自定义资源对象），并编写对应的controller来实现业务逻辑。为了实现CI/CD功能，我们抽象出了多个CRD对象，如下图所示：\n我们知道配置流水线通常需要对接代码仓库，包括仓库地址，仓库授权信息等，因此我们需要有3个CRD对象来记录源代码仓库的相关信息。\n sourceCodeProviderConfig：记录仓库OAuth Apps的客户端ID、客户端秘钥； sourceCodeCredential：记录仓库的认证信息； sourceCodeRepository：记录仓库地址等信息。  设计好了DevOps中与仓库相关的3个CRD对象后，我们需要再定义3个CRD对象来描述流水线相关的信息。\n pipeline：记录该流水线的配置信息：仓库的认证信息、钩子触发配置以及项目代码地址等等； pipelineExecution：记录流水线运行时信息与执行结果信息等； pipelineSetting：记录整个项目下pipeline运行环境信息：内存、CPU的限制，最大流水线并行运行个数等等。  pipeline步骤功能有很多种类型，包括运行脚本、构建发布镜像、发布应用模板、部署YAML、部署应用等等。为了提供这些功能，我们采用Jenkins作为底层的CI/CD工具，docker registry 作为镜像仓库中心，minio作为日志存储中心等等。这些服务是运行在pipeline所在项目的命名空间下。综上，我们设计的CI/CD系统功能的实现逻辑如图所示：\n如上，当第一次运行流水线时，系统会在数据面k8s中部署Jenkins、minio等基础工具的服务，同时在管理面启动一个goroutine，实时同步数据面中流水线的作业状态到管理面的CRD对象中。当触发pipeline执行逻辑时，会产生一个pipelineExecution CRD对象，以记录本次运行pipeline的状态信息。当goroutine（syncState）发现有新的执行实例产生时，就会通过Jenkins引擎接口启动Jenkins server端流水线作业的运行，Jenkins server端收到信息后会启动单独的一个Jenkins slave pod进行流水线作业的响应。同时，goroutine（syncState）会不断地通过引擎接口轮询pipeline执行实例的运行情况进而更新 pipelineExecution CRD的状态（运行成功或失败等等）。当pipeline执行实例发生状态变化时，就会触发其对应的controller业务逻辑，进而通过Jenkins引擎接口与Jenkins server 通信进行不同的操作，比如，暂停流水线的运行，运行完清除不需要的资源等等。当流水线作业发生状态变化时，又会通过goroutine（syncState）更改pipeline执行实例的状态，进而又触发对应的controller业务代码进行不同的业务逻辑处理，往复循环，直到流水线运行结束。这就是整个pipeline执行时的一个逻辑流程。\nCRD定义 下面是详细的CRD结构体讲解，敏感信息使用了\u0026rsquo;*\u0026lsquo;代替。\npipelineSetting：该结构体保存着整个项目下所有pipeline的运行环境信息，比如CPU/内存资源限额、缓存路径以及流水线运行的最大并行个数等等，不同功能的配置信息保存在不同的CRD下。\ndevops-cache-dir 12d executor-cpu-limit 12d executor-cpu-request 12d executor-memory-limit 12d executor-memory-request 12d executor-quota 12d ... // 比如，看下executor-quota详细信息 apiVersion: project.cubepaas.com/v3 kind: PipelineSetting metadata: labels: cubepaas.com/creator: linkcloud name: executor-quota namespace: p-zwmcv default: \u0026#34;2\u0026#34; // 默认最多可同时运行2个pipeline projectName: c-86tgg:p-zwmcv value: \u0026#34;3\u0026#34; // 自定义设置，最多可同时运行3个pipeline，没有值会取上面默认值 pipeline：该结构体记录着流水线的配置元信息，比如该流水线对接哪个项目代码、与仓库通信的认证信息以及上次该流水线运行的结果等等。如下图所示：\n详细的结构字段讲解如下：\napiVersion: project.cubepaas.com/v3 kind: Pipeline metadata: labels: cubepaas.com/creator: linkcloud name: p-d5frn namespace: p-zwmcv spec: currentBranch: master // 流水线运行时默认代码分支  imageWebHookToken: // 这是推送镜像时触发该流水线运行的设置信息  - branches: - master comment: a imageType: harbor // 支持 harbor dockerhub aliyun等镜像仓库  token: 7c102c82-66d9-44c1-8718-**** // 推送镜像触发流水线运行时的 token 认证  trigger: nginx // 当推送 nginx 镜像时会触发流水线运行  projectName: c-86tgg:p-zwmcv repositoryUrl: https://github.com/gophere/devops-go.git // 项目代码地址  sourceCodeCredentialName: u-8sq**:p-zwmcv-github-gophere // 指向对应的用户认证信息  triggerWebhookPush: true // 钩子操作，当push代码到仓库时会触发该流水线执行 status: lastRunState: Success // 最新一次运行的最后结果  nextRun: 2 // 下次运行时执行实例对应的序号  pipelineState: active // 该流水线处于有效状态  sourceCodeCredential: // 上述已介绍，此处不再赘述  ... ... token: e667bbb9-7230-48d4-9d29-***** // 用于代码仓库触发流水线运行时的 token 认证  webhookId: \u0026#34;245901183\u0026#34; // 代码仓库的钩子信息 pipelineExecution：流水线执行实例，每当流水线运行一次，会产生一个该对象记录着流水线的执行结果等信息。如下图所示：\n详细的结构字段讲解如下：\napiVersion: project.cubepaas.com/v3 kind: PipelineExecution metadata: labels: cubepaas.com/creator: linkcloud pipeline.project.cubepaas.com/finish: \u0026#34;true\u0026#34; name: p-d5frn-2 namespace: p-zwmcv spec: branch: master // 本次运行的代码分支  commit: f5b78969586cd90918020cb7a138fe88c7e25f9d // 代码 commitid  message: Update .cubepaas-devops.yml // 代码 commit 说明  pipelineConfig: // 以下是pipeline具体的stage和step的配置信息，每次运行时从代码仓库的配置文件（.cubepaas.devops.ymal）拉取下来填充该结构  stages: - name: Clone // 克隆代码  steps: - sourceCodeConfig: {} - name: Build // 运行脚本编译代码  ... pipelineName: p-zwmcv:p-d5frn projectName: c-86tgg:p-zwmcv ref: master repositoryUrl: https://github.com/gophere/devops-go.git // 项目代码地址  run: 2 // 此次运行序号  triggerUserName: u-8sq** // 触发用户  triggeredBy: user status: // 以下记录着pipeline每个stage和step的运行结果信息  executionState: Success stages: - ended: 2020-09-03T06:01:01Z state: Success steps: - ended: 2020-09-03T06:01:01Z state: Success ... ... 至此，我们完成了流水线功能的基础对象定义。\ncontroller 实现 除了抽象出对应的CRD外，我们还需要编写对应的controller代码实现对应的业务逻辑，比如当pipeline运行时，我们需要产生pipeline执行实例，并实时同步其运行的状态信息等等。\n当触发流水线执行逻辑时，系统会根据pipeline CRD对象和该流水线对应的代码仓库中的配置文件（.cubepaas.devops.ymal）产生一个pipelineExecution CRD对象，这时会触发pipelineExecution对应的controller运行业务逻辑。下面只摘取重要的代码逻辑，如下所示：\nfunc (l *Lifecycle) Sync(obj *v3.PipelineExecution) (runtime.Object, error) { ... // 如果 pipeline 执行实例被暂停，则会停止流水线作业  if obj.Status.ExecutionState == utils.StateAborted { if err := l.doStop(obj); err != nil { return obj, err } } // 如果 pipeline 执行实例运行完毕，则会清理流水线作业的一些资源  // 比如，产生的Jenkins slave pod  if obj.Labels != nil \u0026amp;\u0026amp; obj.Labels[utils.PipelineFinishLabel] == \u0026#34;true\u0026#34; { return l.doFinish(obj) } // 如果 pipeline 执行实例正在运行中，则直接返回，无操作  if v3.PipelineExecutionConditionInitialized.GetStatus(obj) != \u0026#34;\u0026#34; { return obj, nil } // 判断流水线作业是否超出资源限额  exceed, err := l.exceedQuota(obj) if err != nil { return obj, err } // 如果超出资源限额，则会设置当前 pipeline 执行实例为阻塞状态  if exceed { obj.Status.ExecutionState = utils.StateQueueing obj.Labels[utils.PipelineFinishLabel] = \u0026#34;\u0026#34; if err := l.newExecutionUpdateLastRunState(obj); err != nil { return obj, err } return obj, nil } else if obj.Status.ExecutionState == utils.StateQueueing { obj.Status.ExecutionState = utils.StateWaiting } // 更新 pipeline 执行实例的状态: 比如运行序号+1  if err := l.newExecutionUpdateLastRunState(obj); err != nil { return obj, err } v3.PipelineExecutionConditionInitialized.CreateUnknownIfNotExists(obj) obj.Labels[utils.PipelineFinishLabel] = \u0026#34;false\u0026#34; // 在数据面部署pipeline功能所需资源  if err := l.deploy(obj.Spec.ProjectName); err != nil { obj.Labels[utils.PipelineFinishLabel] = \u0026#34;true\u0026#34; obj.Status.ExecutionState = utils.StateFailed v3.PipelineExecutionConditionInitialized.False(obj) v3.PipelineExecutionConditionInitialized.ReasonAndMessageFromError(obj, err) } // 将 configMap 存储的docker镜像仓库端口信息同步到pipeline执行实例中去.  if err := l.markLocalRegistryPort(obj); err != nil { return obj, err } return obj, nil } 其中，deploy函数的逻辑就是第一次运行时通过判断数据面中是否存在pipeline的命名空间，如果存在就代表基础资源已经配置完成，直接走reconcileRb函数，该函数的逻辑见下面；如果不存在，就会在数据面中初始化必要的基础资源，比如：pipeline命名空间, Jenkins docker minio服务, 配置configMap, secret等等。\nfunc (l *Lifecycle) deploy(projectName string) error { clusterID, projectID := ref.Parse(projectName) ns := getPipelineNamespace(clusterID, projectID) // 如果该pipeline的namespace已经有了，说明下面的资源部署已经完成了，则直接走reconcileRb流程  // 否则走下面的资源部署流程  if _, err := l.namespaceLister.Get(\u0026#34;\u0026#34;, ns.Name); err == nil { return l.reconcileRb(projectName) } else if !apierrors.IsNotFound(err) { return err } // 创建pipeline对应的命名空间，如p-qqxs7-pipeline  if _, err := l.namespaces.Create(ns); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the pipeline namespace\u0026#34;) } ... // 随机产生一个token，用于配置下面的secret  token, err := randomtoken.Generate() nsName := utils.GetPipelineCommonName(projectName) ns = getCommonPipelineNamespace() // 创建用于部署docker镜像仓库的代理服务的命名空间  if _, err := l.namespaces.Create(ns); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the cattle-pipeline namespace\u0026#34;) } // 在 pipeline namespace 内创建secret : pipeline-secret  secret := getPipelineSecret(nsName, token) l.secrets.Create(secret); ... // 获取管理面项目的系统用户token  apikey, err := l.systemAccountManager.GetOrCreateProjectSystemToken(projectID) ... // 在 pipeline namespace 内创建secret: pipeline-api-key，用于数据面与管理面通信的凭证  secret = GetAPIKeySecret(nsName, apikey) l.secrets.Create(secret); // 调谐 docker 镜像仓库的证书配置（在控制面中）  if err := l.reconcileRegistryCASecret(clusterID); err != nil { return err } // 将控制面中的 docker 镜像仓库的证书配置同步到数据面中  if err := l.reconcileRegistryCrtSecret(clusterID, projectID); err != nil { return err } // 在 pipeline namespace 内创建 serviceAccount : jenkins  sa := getServiceAccount(nsName) if _, err := l.serviceAccounts.Create(sa); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating a pipeline service account\u0026#34;) } ... // 在 pipeline namespace 内创建 service: jenkins  jenkinsService := getJenkinsService(nsName) if _, err := l.services.Create(jenkinsService); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the jenkins service\u0026#34;) } // 在 pipeline namespace 内创建 deployment: jenkins  jenkinsDeployment := GetJenkinsDeployment(nsName) if _, err := l.deployments.Create(jenkinsDeployment); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the jenkins deployment\u0026#34;) } // 在 pipeline namespace 内创建 service: docker-registry  registryService := getRegistryService(nsName) if _, err := l.services.Create(registryService); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the registry service\u0026#34;) } // 在 pipeline namespace 内创建 deployment: docker-registry  registryDeployment := GetRegistryDeployment(nsName) if _, err := l.deployments.Create(registryDeployment); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the registry deployment\u0026#34;) } // 在 pipeline namespace 内创建 service: minio  minioService := getMinioService(nsName) if _, err := l.services.Create(minioService); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the minio service\u0026#34;) } // 在 pipeline namespace 内创建 deployment: minio  minioDeployment := GetMinioDeployment(nsName) if _, err := l.deployments.Create(minioDeployment); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the minio deployment\u0026#34;) } // 调谐 configMap: proxy-mappings，用于配置docker镜像仓库代理服务的端口信息  if err := l.reconcileProxyConfigMap(projectID); err != nil { return err } // 创建secret: devops-docker-registry，存储访问docker仓库的认证信息  if err := l.reconcileRegistryCredential(projectName, token); err != nil { return err } // 创建 daemonset: registry-proxy，每个节点部署一套docker镜像仓库的nginx代理服务  // 可以在任意一个节点上通过不同的端口即可访问到不同的docker镜像仓库  nginxDaemonset := getProxyDaemonset() if _, err := l.daemonsets.Create(nginxDaemonset); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error creating the nginx proxy\u0026#34;) } return l.reconcileRb(projectName) } reconcileRb函数的功能就是遍历所有namespace, 对其调谐rolebindings, 目的是让 pipeline serviceAccount(jenkins) 对该project下的所有namespace具有所需要的操作权限，这样Jenkins server才能够在数据面中正常提供CI/CD基础服务。\nfunc (l *Lifecycle) reconcileRb(projectName string) error { ... var namespacesInProject []*corev1.Namespace for _, namespace := range namespaces { parts := strings.Split(namespace.Annotations[projectIDLabel], \u0026#34;:\u0026#34;) if len(parts) == 2 \u0026amp;\u0026amp; parts[1] == projectID { // 过滤出属于该project下的所有namespace  namespacesInProject = append(namespacesInProject, namespace) } else { // 对非该project下的namespace, 清除有关该 pipeline 的 rolebinding  if err := l.roleBindings.DeleteNamespaced(namespace.Name, commonName, \u0026amp;metav1.DeleteOptions{}); err != nil \u0026amp;\u0026amp; !apierrors.IsNotFound(err) { return err } } } for _, namespace := range namespacesInProject { // 对属于该project下的namespace, 创建 rolebinding: 对 jenkins serviceAccount 绑定角色  // 即赋予 jenkins serviceAccount 对该project下的所有namespace所需要的操作权限  rb := getRoleBindings(namespace.Name, commonName) if _, err := l.roleBindings.Create(rb); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error create role binding\u0026#34;) } } // 赋予 jenkins serviceAccount 在 cluster 内创建和修改 namespace 的权限  // 当部署应用时可以指定创建新的命名空间  clusterRbs := []string{roleCreateNs, projectID + roleEditNsSuffix} for _, crbName := range clusterRbs { crb := getClusterRoleBindings(commonName, crbName) if _, err := l.clusterRoleBindings.Create(crb); err != nil \u0026amp;\u0026amp; !apierrors.IsAlreadyExists(err) { return errors.Wrapf(err, \u0026#34;Error create cluster role binding\u0026#34;) } } return nil } goroutine（syncState）的代码逻辑比较简单，当产生新的pipeline执行实例时就会启动Jenkins server端流水线作业的运行并实时同步其运行状态到pipeline执行实例中。代码逻辑如下：\nfunc (s *ExecutionStateSyncer) syncState() { set := labels.Set(map[string]string{utils.PipelineFinishLabel: \u0026#34;false\u0026#34;}) allExecutions, err := s.pipelineExecutionLister.List(\u0026#34;\u0026#34;, set.AsSelector()) executions := []*v3.PipelineExecution{} // 遍历该cluster下的 pipeline 执行实例  for _, e := range allExecutions { if controller.ObjectInCluster(s.clusterName, e) { executions = append(executions, e) } } for _, execution := range executions { if v3.PipelineExecutionConditionInitialized.IsUnknown(execution) { // 检查数据面k8s中 Jenkins pod 是否正常，正常则运行该 pipeline job  s.checkAndRun(execution) } else if v3.PipelineExecutionConditionInitialized.IsTrue(execution) { e := execution.DeepCopy() // 如果已经启动了，则同步运行状态  updated, err := s.pipelineEngine.SyncExecution(e) if updated { // 更新最新的状态到 pipelineExecution crd 中  s.updateExecutionAndLastRunState(e); } } else { // 更新最新的状态到 pipelineExecution crd 中  s.updateExecutionAndLastRunState(execution); } } logrus.Debugf(\u0026#34;Sync pipeline execution state complete\u0026#34;) } 缓存支持 云环境下的流水线是通过启动容器来运行具体的功能步骤，每次运行流水线可能会被调度到不同的计算节点上，这会导致一个问题：容器运行完是不会保存数据的，每当流水线重新运行时，又会重新拉取代码、编译代码、下载依赖包等等，失去了本地宿主机编译代码、构建镜像时缓存的作用，大大延长了流水线运行时间，浪费很多不必要的时间、网络和计算成本等。为了提高用户使用流水线的体验，加入支持缓存的功能。\n为了让流水线具有缓存功能，我们需要在流水线运行时加入持久化数据的能力。首先想到的就是k8s提供的本地持久化存储（即Local Persistent Volume，以下简称Local PV），或依赖远程存储服务器来提供持久化，远程存储效率依赖于网络，并且还需要保证远程存储高可用，这回带来很多复杂性，也一定程度上失去了缓存的作用。综合考虑，我们选择本地存储实现缓存，但是k8s提供的Local PV是需要和节点绑定在一起的，也就是说一旦流水线调度到某个节点上运行，那么下次运行还会绑定到该节点运行，虽然实现了缓存的作用，但是也造成了流水线每次只能在该节点上运行，如果有多条流水线同时跑，可能会导致该节点资源耗尽或者缓存冲突，失去了云平台本身根据资源使用情况平衡调度的特性。\n因此，为了平衡缓存与调度间的关系，我们采用了挂载hostPath Volume方式，这样依托于k8s强大的容器调度能力，我们可以同时运行很多条流水线而不用担心资源耗尽或缓存冲突的问题，但是流水线每次运行时可能会被调度到不同的节点上，如果当前节点没有运行过流水线，则起不到缓存的作用。那么如何解决hostPath Volume缓存与调度间的尴尬关系呢？我们巧妙地利用了k8s提供的亲和性调度特性，当流水线运行时我们会记录当前运行节点，下次运行时通过设置Pod的亲和性优先调度到该节点上，随着流水线运行次数越来越多，我们会得到一个运行节点列表。如下所示：\n// 按时间排序，最近运行流水线的节点排在最前面 executionScheduledInfo: - creationTimestamp: \u0026#34;2020-09-02T06:42:45Z\u0026#34; executionId: 8 nodeName: ****** - creationTimestamp: \u0026#34;2020-08-26T14:19:21Z\u0026#34; executionId: 7 nodeName: ****** - creationTimestamp: \u0026#34;2020-08-26T10:52:15Z\u0026#34; executionId: 5 nodeName: ****** - creationTimestamp: \u0026#34;2020-08-26T10:48:43Z\u0026#34; executionId: 4 nodeName: ****** - creationTimestamp: \u0026#34;2020-08-25T07:47:27Z\u0026#34; executionId: 3 nodeName: ****** - creationTimestamp: \u0026#34;2020-08-25T07:16:29Z\u0026#34; executionId: 1 nodeName: ****** ...... 执行实例调度信息会保存到pipeline CRD对象中，每次运行流水线时，系统会根据节点列表设置Pod的亲和性，默认我们会取最近运行流水线的10个节点，原则是最近运行流水线的节点优先级越高。代码如下：\n// 获取流水线的节点调度列表 esi := c.pipeline.Status.ExecutionScheduledInfo nodes := make([]v1.PreferredSchedulingTerm, 0) for i, v := range esi { // 设置亲和性 \tn := v1.PreferredSchedulingTerm{ Weight: int32(100 - i*10), // 最近运行的节点权重越高 \tPreference: v1.NodeSelectorTerm{ MatchExpressions: []v1.NodeSelectorRequirement{ { Key: \u0026#34;kubernetes.io/hostname\u0026#34;, Operator: v1.NodeSelectorOpIn, Values: []string{v.NodeName}, }, }, }, } nodes = append(nodes, n) } nodeAff.PreferredDuringSchedulingIgnoredDuringExecution = nodes 创新性的“Hostpath Volume + 亲和性调度”缓存设计方案，不仅实现了流水线的并发性缓存功能，而且实现复杂度低，可自由配置任一阶段、步骤的缓存开关以及缓存路径。无缓存与有缓存运行的对比如下图所示，可见通过缓存加速大大提高了流水线的运行效率。\nHCaaS DevOps使用 以上设计在HCaaS平台上得到实现（https://cubepaas.com）在HCaaS控制台上点击DevOps标签，通过代码授权后，即可通过UI界面轻松地编辑流水线，也可通过编辑yaml文件配置具体的功能步骤，如图所示：\n通过点击查看日志，你可以看到pipeline各个阶段运行的详细日志信息，如下图所示：\n【注意】首次运行pipeline时系统会从网络下载Jenkins、docker、minio以及其他pipeline-tools镜像，请稍作等待。如果长时间未运行，请查看网络是否有问题。\n","permalink":"https://cloudnative.to/blog/cloudnative-devops/","tags":["DevOps","CICD"],"title":"云原生DevOps落地方案"},{"categories":["Envoy"],"contents":"随着云原生发展的深入，服务网格的发展也如火如荼，其中的翘楚之才——Istio 也是备受大家的关注与喜爱，部分企业已经将 Istio 在生产上进行了使用。虽然 Istio 经历了架构变化、捐赠风波，但是不影响广大IT从业者对其的热爱。\n云原生社区为了能够给国内服务网格热爱者提供一个交流学习的机会，并秉承云原生社区的宗旨——普及和推广云原生相关技术，云原生决定成立 Envoy SIG（目前已经有Operator SIG、OAM SIG），并在时机成熟时（会在云原生社区 Envoy SIG 微信群及社区公众号进行公布）招募志愿者翻译 Envoy 的最新版本（Envoy 有1.7中文版本，但是版本过老），并举办更多的 Envoy 技术交流活动。\n为什么加入 Envoy SIG 如果你：\n 热爱云原生技术，广交天下云原生同好 关注服务网格 追踪 Envoy 最新进展 讨论负载均衡和网络代理技术  那就加入 Envoy SIG 吧。我们一起搞事情。\nEnvoy SIG 仓库：cloudnativeto/sig-envoy\n如何加入 Envoy SIG  加入云原生社区组织，详情请看云原生社区的这个GitHub Issue。 加入 Envoy SIG 微信群（添加微信 jimmysongio 或者 majinghe11，备注姓名-公司，并说明加入 Envoy SIG）。  我们等你哦！！！\n","permalink":"https://cloudnative.to/blog/sig-envoy-announcement/","tags":["Envoy"],"title":"云原生社区 Envoy SIG 成立啦！"},{"categories":null,"contents":"谐云科技简介 谐云科技是国内为数不多掌握底层核心技术的容器云产品及解决方案提供商. 杭州谐云科技有限公司成立于2016年7月，其核心团队来自浙江大学SEL实验室。2013年成为Cloud Foundry中国唯一两家核心代码贡献组织，2015年成为谷歌发起的云原生计算组织CNCF创始成员。谐云核心团队活跃在国际顶级开源社区，其中为Kubernetes等项目贡献代码1400多万行，代码贡献量曾排行国内第一，全球第四。团队曾著书国内第一本深度分析Docker技术的专业书籍《Docker：容器与容器云》，被评为人民邮电出版社2015年最受欢迎技术类新书。2020年完成由阿里巴巴集团战略领投的B轮融资。\n 容器云架构师 薪资18K/月-30K/月 base: 郑州 工作职责  对接业务需求，带领团队完成项目系统设计、开发、交付； 主导技术方案和系统设计，有能力解决性能、网络、分布式等引起的技术问题； 指导和培训技术人员，提升团队的技术分析、设计能力和系统架构能力； 带领团队做好技术文档管理、Code Review，保证代码质量.  职位要求  对微服务、云生态有深入理解，熟练掌握docker、k8s的使用、管理、Go语言编码、开发、调优等； 有中大型项目的docker、kubernetes、虚拟化等技术框架实际项目应用经验，并参与过核心技术研究或架构搭建等关键内容； 精通linux、shell脚本、网络、存储、操作系统； 从事过中大型大数据、高并发、分布式系统的建设，和技术方案评审等优先考虑； 对云原生、云计算等领域有相关的行业经验，并且有深刻理解；如银行项目、医疗项目等容器云项目经验等优先考虑； 良好的沟通能力和技术文档、方案等表达能力； 5年左右工作经验、3年左右容器云项目经验者优先考虑。   devops开发工程师 薪资：9K/月—18K/月 base: 杭州、郑州 工作职责  参与公司devops平台升级维护 参与公司devops平台新功能研发 支持驻场同事实施落地devops  职位要求  java基础知识扎实 熟练使用IDEA、maven、git等开发工具 掌握mysql/oracle数据库技术 掌握Redis、MongoDB等中间件技术 掌握Mybiatis、hibernate ORM技术 熟悉Spring核心技术AOP、IOC 精通JAVA WEB技术 熟悉spring boot/spring cloud 熟悉devops文化及理念 熟悉devops常用工具链，如：jira、gitlab、Jenkins、nexus、sonarqube等 掌握docker、k8s容器化技术 熟悉敏捷开发模式  投递简历 欢迎邮件简历hr@harmonycloud.cn，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/harmony-cloud-native/","tags":null,"title":"[社招] 杭州谐云科技有限公司"},{"categories":["Istio","Service Mesh"],"contents":"Istio 作为目前 Service Mesh 方案中的翘楚，吸引着越来越多的企业及开发者。越来越多的团队想将其应用于微服务的治理，但在实际落地时却因为不了解 Istio 黑盒中的运行机制而左右为难，本文将基于 1.7 的源码讲解 Istio 的核心组件 Pilot 的结构及运行流程，希望对读者应用 Istio 有所助益。\n注：本文基于 istio release-1.7 分支分析，其他版本的代码结构会有所不同。\n背景 随着 Istio 1.7 的发布，内部组件精简后的 istiod 日趋稳定，越来越多的公司将其应用到自身微服务的流量治理、安全通信及监测中。多点也不例外，应用 Istio 来落地业务系统所有 Dubbo 服务的网格化，下沉 SDK 逻辑，解决基础中间件与业务系统过于耦合等痛点。 目前，我们是通过自己开发的 Controller 组件对接 Zookeeper 等注册中心，将注册到 Zookeeper 的节点实时转化为 ServiceEntry 及 WorkloadEntry 等 Istio 配置类型写入 kube-apiserver，再由 Pilot 转化为 xDS 协议下发至数据面，同时对集群、虚拟机中的服务进行治理。随着公司服务网格化的逐步落地，对 Istio 及数据面组件源码级掌握的诉求越来越高，没有足够的深度及广度很难解决开发过程中遇到的难题，让我们一起揭开 Istio 神秘的面纱，看看黑箱内部是如何运作的。\n本文作为 Istio 控制面组件 Pilot 的源码分析系列，主要面向刚接触 Istio 或仅停留在使用 Istio 基本配置类型（如 VirtualService、DestinationRule 等）的同学，需要熟悉 Istio 的一些 基础概念及名词 。文章会涉及较多的代码细节，我们会以不同的篇幅分别介绍以下内容：\n pilot-discovery 宏观架构及启动流程梳理 pilot-discovery 接口设计及关键接口分析 pilot-discovery xDS 生成及下发流程梳理 pilot-agent 流程梳理 pilot 中的身份认证及安全通信解析  相信通过源码一步一步分析，能消除读者对 Pilot 的陌生感，在基于 Pilot 做适配开发时会更加清楚的了解其底层运行逻辑，碰到问题时也能更好的定位。\nPilot 的代码主要分为两部分:\n pilot-discovery pilot-agent  其中 pilot-agent 负责数据面 Sidecar 实例的生命周期管理，而 pilot-discovery 负责控制面流量管理配置及路由规则的生成和下发。\n宏观架构 pilot-discovery 的核心组件如图： 其中 Server 为 pilot-discovery 的主服务，包含了三个比较重要的组件：\n Config Controller：从不同来源接收流量控制和路由规则等 Istio 的配置，并响应各类事件。 Service Controller：从不同注册中心同步服务及实例，并响应各类事件。 EnvoyXdsServer：核心的 xDS 协议推送服务，根据上面组件的数据生成 xDS 协议并下发。  Config Controller 比较核心的就是对接 Kubernetes，从 kube-apiserver 中 Watch 集群中的 VirtualService、ServiceEntry、DestinationRules 等配置信息，有变化则生成 PushRequest 推送至 EnvoyXdsServer 中的推送队列。除此之外，还支持对接 MCP(Mesh Configuration Protocol) 协议的 gRPC Server，如 Nacos 的 MCP 服务等，只需要在 meshconfig 中配置 configSources 即可。最后一种是基于内存的 Config Controller 实现，通过 Watch 一个文件目录，加载目录中的 yaml 文件生成配置数据，主要用来测试。\nService Controller 目前原生支持 Kubernetes 和 Consul，注册在这些注册中心中的服务可以无痛接入 Mesh，另外一种比较特殊，就是 ServiceEntryStore，它本质是储存在 Config Controller 中的 Istio 配置数据，但它描述的却是集群外部的服务信息，详情可阅读文档 ServiceEntry，Istio 通过它将集群外部，如部署在虚拟机中的服务、非 Kubernetes 的原生服务同步到 Istio 中，纳入网格统一进行流量控制和路由，所以 ServiceEntryStore 也可以视为一种注册中心。还有一种就是 Mock Service Registry，主要用来测试。\nServiceEntryStore 从 Config Controller 到 Service Controller 的转化流程大致如图（后续会做详细的代码分析，这里简单了解一下即可）：\nConfigStores 是一个列表，里面存储了各类 Istio 配置文件，包括 ServiceEntry 、WorkloadEntry 等服务数据，也包括 VirtualService、DestinationRules、Sidecar 等流量控制、路由规则的配置数据，pilot-discovery 将这些 ConfigStores 聚合成一个 configController 统一进行管理，之后再从其中衍生出 IstioConfigStore，将其作为 serviceEntryStore 的配置源。serviceEntryStore 其实就是 ServiceEntry Controller，响应 ServiceEntry 和 WorkloadEntry 这类服务信息的变化。\nEnvoyXdsServer 比较核心，一切与 xDS 协议相关的接收、转换、下发操作都由它完成。EnvoyXdsServer 对接所有集群中的边车代理，如 Envoy、MOSN 等，当配置或服务发生变化时主动推送，也会响应代理发送的请求，依据请求的信息下发相应的 xDS 配置。\n理解了这三个核心组件的定义，就能比较好的理解下面分析的各类流程了。\npilot-discovery 的整个业务流程梳理如下，可以先大概浏览一遍，之后我们逐一进行分析: 启动流程梳理 首先详细看一下 pilot-discovery 的启动流程。pilot-discovery 组件的入口代码在 istio/pilot/cmd/pilot-discovery 中。该目录中包含两个文件: main.go 和 request.go。main.go 中定义了 pilot-discovery 根命令及 discovery 命令，是启动服务发现及配置下发的主流程; 另一个文件 request.go 中定义了 request 命令，用来请求 Pilot 中的 metrics/debug 接口，多用来调试。\nmain.go 中 discoveryCmd的 RunE 函数定义了启动过程，代码如下：\n// 创建一个接收空结构的 stop channel 用来停止所有 servers stop := make(chan struct{}) // 创建服务发现的 Server discoveryServer, err := bootstrap.NewServer(serverArgs) if err != nil { return fmt.Errorf(\u0026#34;failed to create discovery service: %v\u0026#34;, err) } // 运行 Server 中注册的所有服务 if err := discoveryServer.Start(stop); err != nil { return fmt.Errorf(\u0026#34;failed to start discovery service: %v\u0026#34;, err) } // 等待 SIGINT 和 SIGTERM 信号并关闭 stop channel cmd.WaitSignal(stop) 启动流程如图所示： 初始化流程 接下来介绍 discoveryServer ，即 pilot-discovery 组件的核心。在这之前先看下 Server 的结构，代码位于 istio/pilot/pkg/bootstrap/server.go 文件中。\nServer 的关键字段如下：\ntype Server struct { XDSServer *xds.DiscoveryServer // Xds 服务  environment *model.Environment // Pilot 环境所需的 API 集合  kubeRegistry *kubecontroller.Controller // 处理 Kubernetes 主集群的注册中心  multicluster *kubecontroller.Multicluster // 处理 Kubernetes 多个集群的注册中心  configController model.ConfigStoreCache // 统一处理配置数据（如 VirtualService 等) 的 Controller  ConfigStores []model.ConfigStoreCache // 不同配置信息的缓存器，提供 Get、List、Create 等方法  serviceEntryStore *serviceentry.ServiceEntryStore // 单独处理 ServiceEntry 的 Controller  fileWatcher filewatcher.FileWatcher // 文件监听器，主要 watch meshconfig 和 networks 配置文件等  startFuncs []startFunc // 保存了上述所有服务的启动函数，便于在 Start() 方法中批量启动及管理 } 再看 NewServer() 方法中的内容，有以下几个关键步骤：\n我们对每个步骤逐一进行分析:\n  初始化 Environment\n什么是 Environment 呢？根据定义 Environment 为 Pilot 提供了一个汇总的、运行中所需的 API 集合。 Environment 中字段（接口）如下：\ntype Environment struct { ServiceDiscovery // 服务发现的接口模型，主要列出 services 和 instances  IstioConfigStore // Istio 配置文件的存储器，主要列出 ServiceEntry 等配置  mesh.Watcher // mesh config 文件的监听器  mesh.NetworksWatcher // mesh network config 文件的监听器  PushContext *PushContext // 在推送（下发 xDS）生成期间保存信息的上下文  DomainSuffix string // istio server 默认的后缀域名 } 其中 PushContext 是 Pilot 在推送 xDS 前，生成配置期间保存相关信息的上下文的地方，在全量推送配置和配置发生改变时重置。它会保存所有的错误和统计信息，并缓存一些配置的计算信息。 ServiceDiscovery 提供了枚举 Istio 中服务和实例的方法。 mesh.Watcher 和 mesh.NetworksWatcher 负责监听 istiod 启动时挂载的两个配置文件，这两个配置文件是通过 configmap 映射到 Pod 的文件系统中的，监听器将在监听到配置文件变化时运行预先注册的 Handler 。文件挂载参考 istiod 的配置文件：\napiVersion: v1 kind: Pod metadata: name: istiod-56c488887d-z9k5c namespace: istio-system spec: containers: volumeMounts: - mountPath: /etc/istio/config name: config-volume volumes: - configMap: defaultMode: 420 name: istio name: config-volume 相应的配置存储在 istio-system/istio 这个 configmap 中，里面保存了 mesh 和 meshNetworks 两种配置，样例如下:\napiVersion: v1 kind: ConfigMap metadata: name: istio namespace: istio-system data: mesh: |- accessLogEncoding: TEXT accessLogFile: \u0026#34;\u0026#34; accessLogFormat: \u0026#34;\u0026#34; defaultConfig: binaryPath: /usr/local/bin/mosn concurrency: 2 configPath: ./etc/istio/proxy ... meshNetworks: \u0026#39;networks: {}\u0026#39; 再回头看 Environment 的初始化：\ne := \u0026amp;model.Environment{ PushContext: model.NewPushContext(), DomainSuffix: args.RegistryOptions.KubeOptions.DomainSuffix, } ac := aggregate.NewController(aggregate.Options{ MeshHolder: e, }) e.ServiceDiscovery = ac 首先是初始化了一份 PushContext ，创建 PushContext 所需的各种列表和 Map 。 其次是初始化了一个聚合所有注册中心的 Controller 作为 Environment 中的 ServiceDiscovery 。 该 Controller 提供从所有注册中心（如 Kubernetes, Consul, MCP 等）获取服务和实例列表的方法。 这里传入了一个参数 MeshHolder 是想利用 Environment 中的 mesh.Watcher 将 mesh 这个配置同步过去。\n  初始化 Server\nServer 的结构之前分析过，这里将之前初始化的 Environment 传入后，开始初始化 XDSServer 。\ns := \u0026amp;Server{ clusterID: getClusterID(args), environment: e, XDSServer: xds.NewDiscoveryServer(e, args.Plugins), // 初始化 XDSServer  fileWatcher: filewatcher.NewWatcher(), httpMux: http.NewServeMux(), monitoringMux: http.NewServeMux(), readinessProbes: make(map[string]readinessProbe), } XDSServer 相关的代码在 istio/pilot/pkg/xds/discovery.go 中，对应为 DiscoveryServer ，该服务为 Envoy xDS APIs  的 gRPC 实现。 DiscoveryServer 关键定义如下：\ntype DiscoveryServer struct { Env *model.Environment // 即上述 pilot server 中的 Environment  ConfigGenerator core.ConfigGenerator // 控制面 Istio 配置的生成器，如 VirtualService 等  Generators map[string]model.XdsResourceGenerator // 针对不同配置类型的定制化生成器  concurrentPushLimit chan struct{} // 不同服务所有实例的集合，增量更新，key 为 service 和 namespace  // EndpointShards 中是以不同的注册中心名为 key 分组保存实例  EndpointShardsByService map[string]map[string]*EndpointShards pushChannel chan *model.PushRequest // 接收 push 请求的 channel  pushQueue *PushQueue // 防抖之后，真正 Push xDS 之前所用的缓冲队列  adsClients map[string]*Connection // ADS 和 EDS 的 gRPC 连接  StatusReporter DistributionStatusCache // 监听 xDS ACK 和连接断开  // xDS 状态更新的生成器（更新 connect, disconnect, nacks, acks）  // 状态更新后向所有 connection 推送 DiscoveryResponse  InternalGen *InternalGen serverReady bool // 表示缓存已同步，server 可以接受请求  debounceOptions debounceOptions // 防抖设置  cache Cache // xDS 资源的缓存，目前仅适用于 EDS，线程安全 }   初始化 MeshConfig 、 KubeClient 、 MeshNetworks 和 MeshHandlers\ns.initMeshConfiguration(args, s.fileWatcher) if err := s.initKubeClient(args); err != nil { return nil, fmt.Errorf(\u0026#34;error initializing kube client: %v\u0026#34;, err) } s.initMeshNetworks(args, s.fileWatcher) s.initMeshHandlers() 这几个初始化函数比较好理解， initMeshConfiguration 和 initMeshNetworks 都是通过 fileWatcher 对 istiod 从 configmap 中挂载的两个配置文件 mesh 和 meshNetworks 进行监听。当配置文件发生变化时重载配置并触发相应的 Handlers 。\nfilewatcher 的代码在另一个管理通用工具包的项目里： github.com/istio/pkg/filewatcher ，感兴趣的同学可以再详细研究下，底层使用到了 fsnotify 这个库来推送文件变化事件。\ninitMeshHandlers 为上述两个配置文件注册了两个 Handler ，当配置文件发生变化时触发全量 xDS 下发。\n  初始化 Controllers\n这部分比较核心，初始化了三种控制器分别处理证书、配置信息和注册信息，证书及安全相关的内容本篇先暂不讨论。主要来看 initConfigController 和 initServiceControllers 。\nfunc (s *Server) initControllers(args *PilotArgs) error { log.Info(\u0026#34;initializing controllers\u0026#34;) if err := s.initCertController(args); err != nil { return fmt.Errorf(\u0026#34;error initializing certificate controller: %v\u0026#34;, err) } if err := s.initConfigController(args); err != nil { return fmt.Errorf(\u0026#34;error initializing config controller: %v\u0026#34;, err) } if err := s.initServiceControllers(args); err != nil { return fmt.Errorf(\u0026#34;error initializing service controllers: %v\u0026#34;, err) } return nil } 配置信息大都是 Istio 定义的一系列 CRD（如 VirtualService 、 DestinationRules 等），一个控制面可以通过 MCP 同时接入多个 Kubernetes 之外的配置数据源，也可通过文件目录（主要用来调试）挂载，默认是读取 Kubernetes 中的配置数据：\nfunc (s *Server) initK8SConfigStore(args *PilotArgs) error { configController, err := s.makeKubeConfigController(args) ... s.initStatusController(args, features.EnableStatus) // 初始化上面提到的 StatusReporter  return nil } 配置数据包括以下类型，具体每个类型的含义 Istio 官网都有介绍及用例，这里不再赘述：\n// PilotServiceApi contains only collections used by Pilot, including experimental Service Api. PilotServiceApi = collection.NewSchemasBuilder(). MustAdd(IstioNetworkingV1Alpha3Destinationrules). MustAdd(IstioNetworkingV1Alpha3Envoyfilters). MustAdd(IstioNetworkingV1Alpha3Gateways). MustAdd(IstioNetworkingV1Alpha3Serviceentries). MustAdd(IstioNetworkingV1Alpha3Sidecars). MustAdd(IstioNetworkingV1Alpha3Virtualservices). MustAdd(IstioNetworkingV1Alpha3Workloadentries). MustAdd(IstioNetworkingV1Alpha3Workloadgroups). MustAdd(IstioSecurityV1Beta1Authorizationpolicies). MustAdd(IstioSecurityV1Beta1Peerauthentications). MustAdd(IstioSecurityV1Beta1Requestauthentications). MustAdd(K8SServiceApisV1Alpha1Gatewayclasses). MustAdd(K8SServiceApisV1Alpha1Gateways). MustAdd(K8SServiceApisV1Alpha1Httproutes). MustAdd(K8SServiceApisV1Alpha1Tcproutes). Build() 详细看下 initK8SConfigStore 中的 makeKubeConfigController 方法，这里初始化了一个处理 Istio CRDs 的 Client ，实现 ConfigStoreCache 这个接口中增删改查等方法。\nfunc (s *Server) makeKubeConfigController(args *PilotArgs) (model.ConfigStoreCache, error) { c, err := crdclient.New(s.kubeClient, buildLedger(args.RegistryOptions), args.Revision, args.RegistryOptions.KubeOptions) if err != nil { return nil, err } return c, nil } Client 定义如下：\ntype Client struct { schemas collection.Schemas // Istio CRDs shemas  domainSuffix string configLedger ledger.Ledger revision string kinds map[resource.GroupVersionKind]*cacheHandler // 跟踪已知类型的所有缓存 handler  queue queue.Instance istioClient istioclient.Interface serviceApisClient serviceapisclient.Interface } 再依次对这些类型创建 Informer 开启监听。回到 initConfigController ，创建好 ConfigStore 之后，再对其进一步包装：\n// 将所有 ConfigStore 聚合并缓存 aggregateConfigController, err := configaggregate.MakeCache(s.ConfigStores) // 通过 s.configController 统一操作上面聚合的 ConfigStores s.configController = aggregateConfigController // 将其包装为 IstioConfigStore 传入 environment，便于操作 ServiceEntry/Gateway 等资源 // IstioConfigStore 会在之后的 ServiceEntryStore 中用到 s.environment.IstioConfigStore = model.MakeIstioStore(s.configController) 最后将该 Controller 的启动函数注册到 startFuncs 中：\ns.addStartFunc(func(stop \u0026lt;-chan struct{}) error { go s.configController.Run(stop) return nil }) 再来看 initServiceControllers 处理服务发现的 Controller 初始化:\nfunc (s *Server) initServiceControllers(args *PilotArgs) error { serviceControllers := s.ServiceController() for _, r := range args.RegistryOptions.Registries { // ...  switch serviceRegistry { case serviceregistry.Kubernetes: if err := s.initKubeRegistry(serviceControllers, args); err != nil { return err } // ...  } // ... } 从之前初始化的 environment.ServiceDiscovery 中获取已注册的服务中心，如果是 Kubernetes 则执行 initKubeRegistry:\n// initKubeRegistry creates all the k8s service controllers under this pilot func (s *Server) initKubeRegistry(serviceControllers *aggregate.Controller, args *PilotArgs) (err error) { // ...  log.Infof(\u0026#34;Initializing Kubernetes service registry %q\u0026#34;, args.RegistryOptions.KubeOptions.ClusterID) kubeRegistry := kubecontroller.NewController(s.kubeClient, args.RegistryOptions.KubeOptions) s.kubeRegistry = kubeRegistry serviceControllers.AddRegistry(kubeRegistry) return } 进一步初始化 Kubernetes 注册中心，方法为 NewController ，先看一下这个 Controller 的结构：\ntype Controller struct { client kubernetes.Interface queue queue.Instance serviceInformer cache.SharedIndexInformer serviceLister listerv1.ServiceLister endpoints kubeEndpointsController nodeInformer cache.SharedIndexInformer nodeLister listerv1.NodeLister pods *PodCache metrics model.Metrics networksWatcher mesh.NetworksWatcher xdsUpdater model.XDSUpdater domainSuffix string clusterID string serviceHandlers []func(*model.Service, model.Event) instanceHandlers []func(*model.ServiceInstance, model.Event) workloadHandlers []func(*model.WorkloadInstance, model.Event) sync.RWMutex servicesMap map[host.Name]*model.Service nodeSelectorsForServices map[host.Name]labels.Instance nodeInfoMap map[string]kubernetesNode externalNameSvcInstanceMap map[host.Name][]*model.ServiceInstance workloadInstancesByIP map[string]*model.WorkloadInstance ranger cidranger.Ranger networkForRegistry string once sync.Once } 可以看到 Controller 对 Services 、 Nodes 、 Pods 等资源各自初始化了 Informer 、 Lister 以及对应的 Map，各类 Handlers 在 Informer 监听到增删改查时推送相应的事件到 queue ，再由 onServiceEvent 、 onNodeEvent 、 c.pods.onEvent 中更新对应的 Map 。\n回到 initServiceControllers ，初始化完 Kubernetes 注册中心之后，还需要关注 Kubernetes 集群之外的服务，这些服务基本都是通过 ServiceEntry 注册到控制面的，所有 ServiceEntry 配置数据目前还都在之前初始化的 configController 配置中心控制器中，这里将 ServiceEntry 数据单独拎出来初始化一个 ServicEntry 注册中心，加入到 serviceControllers 中：\ns.serviceEntryStore = serviceentry.NewServiceDiscovery( s.configController, s.environment.IstioConfigStore, s.XDSServer) serviceControllers.AddRegistry(s.serviceEntryStore) serviceEntryStore 相关的逻辑会在后续 xDS 下发流程的分析中再阐述。\n最后将 serviceControllers 中所有的服务注册中心的 Controller 的启动函数都注册到 startFuncs 中:\ns.addStartFunc(func(stop \u0026lt;-chan struct{}) error { go serviceControllers.Run(stop) return nil }) // Run starts all the controllers func (c *Controller) Run(stop \u0026lt;-chan struct{}) { for _, r := range c.GetRegistries() { go r.Run(stop) } \u0026lt;-stop log.Info(\u0026#34;Registry Aggregator terminated\u0026#34;) }   初始化 RegistryEventHandlers\ninitRegistryEventHandlers 设置了三个事件处理器 serviceHandler 、 instanceHandler 和 configHandler 分别响应服务、实例和配置数据的更新事件。\nserviceHandler 如下：\nserviceHandler := func(svc *model.Service, _ model.Event) { pushReq := \u0026amp;model.PushRequest{ Full: true, ConfigsUpdated: map[model.ConfigKey]struct{}{{ Kind: gvk.ServiceEntry, Name: string(svc.Hostname), Namespace: svc.Attributes.Namespace, }: {}}, Reason: []model.TriggerReason{model.ServiceUpdate}, } s.XDSServer.ConfigUpdate(pushReq) } if err := s.ServiceController().AppendServiceHandler(serviceHandler); err != nil { return fmt.Errorf(\u0026#34;append service handler failed: %v\u0026#34;, err) } 可以看到当服务本身发生变化时，会触发 xDS 的全量下发，所有与该服务相关的代理都会收到推送。\n实例的变动也会触发 xDS 的全量下发，不过仅在连接 Consul 时生效。Kubernetes 和 MCP 这两种服务发现的场景下，更新事件的 Handler 是在别的地方注册的。\ninstanceHandler := func(si *model.ServiceInstance, _ model.Event) { // TODO: This is an incomplete code. This code path is called for consul, etc.  // In all cases, this is simply an instance update and not a config update. So, we need to update  // EDS in all proxies, and do a full config push for the instance that just changed (add/update only).  s.EnvoyXdsServer.ConfigUpdate(\u0026amp;model.PushRequest{ Full: true, ConfigsUpdated: map[model.ConfigKey]struct{}{{ Kind: gvk.ServiceEntry, Name: string(si.Service.Hostname), Namespace: si.Service.Attributes.Namespace, }: {}}, Reason: []model.TriggerReason{model.ServiceUpdate}, }) } // 跳过 Kubernetes 和 MCP for _, registry := range s.ServiceController().GetRegistries() { // Skip kubernetes and external registries as they are handled separately  if registry.Provider() == serviceregistry.Kubernetes || registry.Provider() == serviceregistry.External { continue } if err := registry.AppendInstanceHandler(instanceHandler); err != nil { return fmt.Errorf(\u0026#34;append instance handler to registry %s failed: %v\u0026#34;, registry.Provider(), err) } } 上一步初始化了 configController ，它操作的对象主要是像 VirtualService 、 DestinationRules 这些 Istio 定义的配置，这些配置的变化也会触发 xDS 的全量下发，所有与该配置相关的代理都会收到推送。不过 ServiceEntry 和 WorkloadEntry 除外，这两个资源的配置下发是由 ServiceEntryStore 管理的，之前在初始化 ServiceController 时定义的 s.serviceEntryStore 会处理，之后的篇幅再做详细介绍。\nconfigHandler := func(_, curr model.Config, event model.Event) { pushReq := \u0026amp;model.PushRequest{ Full: true, ConfigsUpdated: map[model.ConfigKey]struct{}{{ Kind: curr.GroupVersionKind, Name: curr.Name, Namespace: curr.Namespace, }: {}}, Reason: []model.TriggerReason{model.ConfigUpdate}, } s.EnvoyXdsServer.ConfigUpdate(pushReq) } 下面是跳过 ServiceEntry 和 WorkloadEntry 的代码：\nfor _, schema := range schemas { // This resource type was handled in external/servicediscovery.go, no need to rehandle here.  if schema.Resource().GroupVersionKind() == collections.IstioNetworkingV1Alpha3Serviceentries. Resource().GroupVersionKind() { continue } if schema.Resource().GroupVersionKind() == collections.IstioNetworkingV1Alpha3Workloadentries. Resource().GroupVersionKind() { continue } s.configController.RegisterEventHandler(schema.Resource().GroupVersionKind(), configHandler) }   初始化 DiscoveryService\nfunc (s *Server) initDiscoveryService(args *PilotArgs) error { log.Infof(\u0026#34;starting discovery service\u0026#34;) // Implement EnvoyXdsServer grace shutdown  s.addStartFunc(func(stop \u0026lt;-chan struct{}) error { s.EnvoyXdsServer.Start(stop) return nil }) s.initGrpcServer(args.KeepaliveOptions) grpcListener, err := net.Listen(\u0026#34;tcp\u0026#34;, args.ServerOptions.GRPCAddr) if err != nil { return err } s.GRPCListener = grpcListener return nil } 这里将 EnvoyXdsServer 的启动添加至 startFuncs 中，便于后续统一启动。并初始化 gRPC 服务器，监听对应的端口。\n初始化 gRPC 服务器，并注册 xDS V2 和 xDS V3 的 ADS 服务到 gRPC 服务器上:\nfunc (s *Server) initGrpcServer(options *istiokeepalive.Options) { grpcOptions := s.grpcServerOptions(options) s.grpcServer = grpc.NewServer(grpcOptions...) s.EnvoyXdsServer.Register(s.grpcServer) reflection.Register(s.grpcServer) } func (s *DiscoveryServer) Register(rpcs *grpc.Server) { // Register v2 and v3 servers  discovery.RegisterAggregatedDiscoveryServiceServer(rpcs, s) discoveryv2.RegisterAggregatedDiscoveryServiceServer(rpcs, s.createV2Adapter()) } 可以看到 ADS 的 gRPC 服务包含两个流式方法，一个是全量推送，一个是增量推送。\nvar _AggregatedDiscoveryService_serviceDesc = grpc.ServiceDesc{ ServiceName: \u0026#34;envoy.service.discovery.v3.AggregatedDiscoveryService\u0026#34;, HandlerType: (*AggregatedDiscoveryServiceServer)(nil), Methods: []grpc.MethodDesc{}, Streams: []grpc.StreamDesc{ { StreamName: \u0026#34;StreamAggregatedResources\u0026#34;, Handler: _AggregatedDiscoveryService_StreamAggregatedResources_Handler, ServerStreams: true, ClientStreams: true, }, { StreamName: \u0026#34;DeltaAggregatedResources\u0026#34;, Handler: _AggregatedDiscoveryService_DeltaAggregatedResources_Handler, ServerStreams: true, ClientStreams: true, }, }, Metadata: \u0026#34;envoy/service/discovery/v3/ads.proto\u0026#34;, }   注册 kubeClient.RunAndWait\n将 kubeClient.RunAndWait 方法注册至 startFuncs 中， RunAndWait 启动后所有 Informer 将开始缓存，并等待它们同步完成。之所以在最后运行，可以保证所有的 Informer 都已经注册。\nif s.kubeClient != nil { s.addStartFunc(func(stop \u0026lt;-chan struct{}) error { s.kubeClient.RunAndWait(stop) return nil }) }   启动过程 启动流程比较简单，核心是依次启动初始化过程中注册到 startFuncs 中的启动函数：\nfor _, fn := range s.startFuncs { if err := fn(stop); err != nil { return err } } 然后调用 waitForCache 等待需要监听资源的 Informer 缓存完毕，完成后开启 HTTP 服务响应 readiness 事件。\n至此 pilot-discovery 的启动流程就结束了，有了大概了解后，可以大致归纳出整个 Pilot 的接口架构。\n接口设计 在接口设计方面，Pilot 主要有两类接口：一种是 Store 类接口，定义对资源的增删改查等方法；另一种是 Controller 类接口，定义了 RegisterEventHandler 和 Run 方法。\nStore 类接口主要指 ConfigStore 接口，以及它衍生出的 IstioConfigStore，后者操作的对象为 Istio 定义的配置类型，如 VirtualService、ServiceEntry 等。\n而 Controller 类接口指基于 ConfigStore 定义的 ConfigStoreCache 接口，这个接口在哪里用到了呢？之前讨论初始化流程的时候，分析过 Pilot 的 Server 的结构，其中用到该接口的有如下几个字段：\ntype Server struct { configController model.ConfigStoreCache ConfigStores []model.ConfigStoreCache serviceEntryStore *serviceentry.ServiceEntryStore } type ServiceEntryStore struct { store model.IstioConfigStore } 可以看到 ConfigStores 是存储所有配置类数据的 Controller 的地方，ConfigStores 都是在哪里添加的呢？之前分析 initConfigController 方法中提到过，可以再对照代码看一下调用的地方：\n都添加完毕后，会把这些 ConfigStoreCache 都聚合到 Server.configController 中统一处理。\n// Wrap the config controller with a cache. \taggregateConfigController, err := configaggregate.MakeCache(s.ConfigStores) if err != nil { return err } s.configController = aggregateConfigController 而 ServiceEntryStore 中用到的 IstioConfigStore 也是在这里得到的：\ns.environment.IstioConfigStore = model.MakeIstioStore(s.configController) 以上，当服务启动后，会逐个调用这些 ConfigStoreCache 中的 Run 方法处理资源的增删改事件。\n总结 pilot-discovery 的启动流程初看是比较复杂，但理清楚中间核心的步骤后结构也比较清晰。有了本篇的介绍，之后再走读几遍代码，相信就能很好的掌握 pilot-discovery 初始化的流程。\nPilot 源码分析的第一部分就到这里，后续会针对重要的组件和接口做更细致的分析，如 EnvoyXdsServer 、ServiceEntryStore 等，以及梳理 xDS 协议的生成和下发流程，会比 pilot-discovery 的启动流程复杂的多，敬请期待。\n参考  Istio Pilot 代码深度解析 - 赵化冰  ","permalink":"https://cloudnative.to/blog/istio-pilot/","tags":["istio","pilot","cloudnative","servermesh"],"title":"Istio Pilot 源码分析（一）"},{"categories":null,"contents":"携程Container\u0026amp;Server Team 我们是携程技术中心系统研发部Container\u0026amp;Service Team，负责携程容器云平台的基础设施服务研发，基于Kubernetes平台赋能业务应用高弹性与扩展性，持续推进携程整体技术架构的云原生化. 此次为团队直接招聘，面试官即是未来与你并肩作战的小伙伴.\n云原生研发工程师（上海） 工作职责  参与kuber-scheduler,kube-controll-manager等组件的二次开发和性能优化 参与K8S相关调优及troubleshooting工作 参与云原生安全模块的设计与开发工作 参与其他开源云原生系统的研发，如Service Mesh等  职位要求  本科及以上学历 至少熟练掌握Golang/C/C++/Java语言之一, 若无Golang经验，有学习意愿也可, 有golang 开发经验者优先 熟悉Docker, Kubernetes, istio等主流容器技术，有开源社区相关经验者优先；熟悉模块源码更佳 有2年以上软件设计和开发经验者优先，在云计算领域开发过微服务，实现过Kubernetes Operator更佳 有责任感，具备较强的团队沟通和协作能力  云原生技术专家(上海) 工作职责  负责云原生生态的新技术预研、架构及落地 负责云原生安全方案的设计和研发 负责弹性调度平台相关工作(HPA、VPA、混部等)的架构设计及难点攻关等工作 负责K8S相关调优及troubleshooting工作 积极参与开源社区  职位要求  本科及以上学历 3年及以上云计算、基础架构或相关工作经验 熟练掌握Golang语言开发，具备Java、Python等其他一种或多种语言开发经验 熟悉K8S原理，有K8S或相关生态源码级开发经验优先 熟悉Kernel调度器及cgroup调优技能优先 有社区代码贡献者优先(若有，提供对应社区账号) 有责任感，具备较强的团队沟通和协作能力  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/trip-cloud-native/","tags":null,"title":"[社招] 携程 Container\u0026Service Team"},{"categories":null,"contents":"eBay介绍 eBay于1995年成立于美国硅谷，是全球的电商先行者，目前依然是全球最大的电子商务网站之一。eBay为为不同规模的商家提供公平竞争与发展的机会，在全球多个国家具有上亿的买家和买家。 eBay中国研发中心 (eBay CCOE) 2004年成立于上海，是eBay最早的也是迄今为止最大的海外研发中心。这里聚集了业内顶尖人才，拥有大数据分析、大规模分布式计算、分布式数据库管理、云平台、搜索和数据科学方面专业知识和技术， 负责eBay全球平台众多重要产品的架构设计与技术开发。团队的愿景是在中国上海打造一个世界级的技术中心，用科技创造人类的亿倍可能！\n工作环境非996， 更不是养老院。 薪资open，有补充公积金。 每年15天年假，5天病假，可以随时在家办公，工作5年有额外一个月的假期，每个季度都有team building，男的都有三个月的陪产假期。\n云计算部门简介 云计算部门为公司的业务提供稳定的云平台服务。目前公司具有众多的kubernetes集群，服务于eBay的多个重要业务。\n 协助业务云原声化 维护云集群的稳定性，可靠性和可扩展性，满足各模块的SLA/SLO 挑战云原生领域世界级的难题，满足业务需求  招聘对象 本次发布的社会招聘职位不限工作年限，我们欢迎具有丰富工作经验的同学，也欢迎有潜力的新人。 希望有较强自我管理，自我驱动能力的同学加入，我们一起实现目标。\n软件工程师 岗位职责  Develop and advance the capabilities of our highly reliable and available cloud services - Compute, Network and Storage. Own the services from cradle to grave with development, test, deploy, monitor and measure. Conceive new ideas to problems and take them to market through rapid prototyping, validation, iterative development and continuous test and deployment. Challenge yourself, enrich in an environment of like minded engineers and most importantly Have fun!  任职要求  B.S/M.S/Ph.D in Computer Science or Computer Engineering. A lack of degree can be supported by an accomplished career in building software systems at scale. Solid foundations in computer science - data structures, logical thinking, algorithms, space-time complexities, Operating Systems etc., Demonstrable experience in solving problems in the areas of distributed systems at scale preferably at systems level (Application level experience with systems orientation is also welcomed) - optional if you are a new college grad. Experience with Docker container is a plus. Experience working in the Kubernetes as a consumer or a provider (public or private clouds) is a plus. Programming languages - Go, Python, Java. Expertise in Linux Kernel, Networking stacks is a plus.  Cloud Reliability Engineer 岗位职责  Accountable for eBay Cloud systems reliability, minimize impact to the business and cloud customers by keeping the reliability high according to SLOs Run, operate, and upkeep eBay Cloud systems Gatekeeper for product release acceptance criteria and rolling out releases to production Building and ensuring SLO/SLI metrics. Driving reliability focus with engineering teams to define and sustain overall and per component SLO/SLI Building, practising, and maintaining the devops culture and principles for efficiency and automations. Always focus on automation to upkeep the reliability Proactively predict, triage, and debug system issues  任职要求：  Strong background of large scale distributed systems, schedulers, operating systems and modern cloud platforms in general. Strong understanding of infrastructural aspects and experience with infrastructure including operating systems, containers, cluster-management platforms such as Kubernetes. Strong knowledge of industry trends and innovations in cluster management and cloud technology. Demonstrable experience in building automations to manage large infrastructure environments and maintaining systems reliability at a high standard. Programming languages: Go, Python, and Shell/Bash, etc. Master at least one of the scripting languages. Ability to thrive in a high-pressured environment and crisis situations. Ability to quickly debug and identify issues at distributed systems. (troubleshooting). Ability to multi-task multiple projects at once and drive for results independently. Experience in Kubernetes, systems monitoring, config management, and CI/CD pipelines - is a big plus. Excellent communication, presentation and relationship skills.  Cloud Solution Engineer 岗位职责 As a Cloud Solution Engineer, you will have the opportunity to play a crucial role in our emerging Cloud practice on Kubernetes. You will work with customers in a wide variety of domains to help transform their business requirements into a state-of-the-art cloud solution that will enable their organization to exploit new opportunities. This critical role will be primarily technical but will also allow you to show your business acumen. Typical responsibilities in this role will include:\n Working in a fast-paced professional services environment implementing next-gen cloud infrastructure and acting as a subject matter expert in cloud infra. Analyzing customer requirements (both new and legacy applications) and working with the development team optimizing Cloud services architecture. Work as the main point of contact from the Infrastructure Cloud team for customer support and analyze gaps based on collected data with optimized proposals to the whole Cloud team. Performing research and development activities to evaluate new technologies. ● Gaining a deep specialization in Cloud Infrastructure and Kubernetes.  任职要求：  5+ years of experience in a cloud engineering role Experience using Infrastructure technologies to run modern applications such as Docker, Kubernetes, or Serverless. Broad subject matter expertise across cloud computing, infrastructure, applications, enterprise architecture, data management, and cloud governance models with ability to advise on industry-leading approaches. Hands-on experience leading migrations to public clouds is a plus Excellent communication, interpersonal \u0026amp; documentation skills to articulate the solution architecture and roadmap. Solid multi-tasking, troubleshooting and problem resolution abilities Ability to work within a collaborative team and a fast-paced dynamic environment Ability to be a self-motivated, continuous learner with expertise in the cloud  投递简历 欢迎邮件简历, 如果还有其他的疑问，可以加WX：cgroups 详细沟通。\n","permalink":"https://cloudnative.to/job/ebay-cloud-native/","tags":null,"title":"[社会招聘] eBay上海-云计算部门招聘"},{"categories":null,"contents":"深圳支流科技有限公司简介 Apache APISIX 的贡献者来自全球各地，我们深知开源爱好者都具有强大的自驱力，不喜欢被打卡、996束缚自己的创造力，所以这些职位也都可以远程。\n联系时请随信附上您的简历和 GitHub 账号。\n高级研发工程师 岗位描述  研发基于 Apache APISIX 的下一代 API 管理和分析平台； 在 API 的大数据、行为分析、安全防护、云原生等领域保持技术创新； 参与 Apache APISIX 的研发，成为核心贡献者。  岗位要求  对 Apache APISIX、Kong、Envoy、Nginx 等网关或者 web server 项目有深入的了解，具备二次开发能力； 良好的编码习惯，认同测试驱动开发； 良好的英文读写能力； 开源项目贡献者优先。  技术支持工程师 岗位描述  为 Apache APISIX、APISEVEN 等 API 网关产品和解决方案，提供技术支持工作，解决用户问题，保证系统稳定运行； 排查用户环境的问题和故障，进行重现和定位。完善文档和手册，帮助用户更好的使用产品。  岗位要求  熟悉 Linux 系统的操作； 良好的英文读写能力； 具备问题定位和重现的能力； 良好的口头和书面沟通能力； 熟悉 API 网关产品，对开源有兴趣者优先。  高级 Nginx 开发工程师 岗位描述  负责针对 Apache APISIX 的 Nginx 底层优化； 负责 Nginx 内核和第三方模块的开发、维护和升级。  岗位要求  熟悉 Nginx 原理和具体实现； 开发过 Nginx C 模块； 热爱开源，对技术有浓厚兴趣； Nginx、OpenResty 代码贡献者优先。  Go 开发工程师 岗位描述  负责 Apache APISIX 控制平面的设计和架构； 配合前后端的开发一起完成控制平面的功能开发； 参与 Apache APISIX 的研发，成为核心贡献者。  岗位要求  熟悉 Istio、MSI 等控制平面的项目和规范； 良好的编码习惯，认同测试驱动开发； 良好的英文读写能力； 开源项目贡献者优先。  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/api7/","tags":null,"title":"深圳支流科技有限公司研发工程师（高级）"},{"categories":null,"contents":"基础研发部简介 基础研发部负责集团部分基础服务研发，并支撑PaaS平台架构升级，提供高扩展性基础组件，为集团业务提供基础能力和稳定保障。\n招聘对象 本次社会招聘的要求为不限工作年限的同学。\n云服务技术专家 岗位职责  负责基于Kubernetes的容器平台、Service mesh的产品需规划、架构设计和技术难点攻关 按时保质完成研发任务，负责容器平台的线上维护工作，高效定位和解决线上问题，确保基础设施的稳定与高效 收集业务需求，不定期对系统进行分析，推动系统不断迭代演进 培养和驱动团队成员不断成长  任职要求  熟练掌握Golang语言开发，具备Java、Python等其他一种或多种语言开发经验； 技术基础扎实，有Go语言开发经验 精通Docker Engine, Swarm、Kubernetes、istio等主流容器技术，有开源社区相关经验者优先；熟悉模块源码更佳； 熟悉istio 与其周边社区(kiali、prometheus、jaeger、ELK、grafana等)，有开源社区相关经验者优先，熟悉开源源码更佳； 对Linux系统有深入的理解，在linux系统上具备丰富docker管理经验； 熟悉DevOps流程，关注开源CI/CD技术工具； 有强烈责任感，结果导向，具备较强的团队沟通和协作能力，较强的自我驱动能力；  分布式存储研发专家 岗位职责  负责公司级底层分布式文件系统 (Hbase、MySQL、Elasticsearch、TensorFlow、Spark等 on FS) 架构设计和技术难点攻关 负责kubernetes的容器平台存储(CSI Driver)：PV on FS、 RookFS等 负责中台通用存储服务: 对象存储服务 培养和驱动团队成员不断成长  任职要求：  5年以上大规模分布式存储系统的架构设计经验; 熟练掌握分布式存储系统ChubaoFS、MinIO、HDFS、Ceph等； 熟练掌握Golang、C++/C、Rust等其他一种或多种语言开发经验； 有使用公有云存储经验: 腾讯云、阿里云 OSS； AWS S3等； 熟悉云原生相关技术：Kubernetes, RookFS，有大中型分布式存储系统在云原生中实践的经历； 熟悉分布式系统（熟知Paxos, Raft 等协议），有高可用系统建设和运维经验； 具备较强的沟通协作能力；优秀的分析和解决问题能力，能引导和培养新人； 有开源社区相关经验是加分项；  DevOps技术专家 岗位职责  负责公司级监控服务(Metric)、调用链追踪(OpenTracing)、日志检索(Logging)等架构设计和技术难点攻关； 负责公司级CMDB构建，与周边平台打通； 基于成本运营平台、基于可靠性的运维平台； 逐步构建Chaos Engineer 能力； 培养和驱动团队成员不断成长；  任职要求：  5年以上云服务DevOps的架构设计经验; 熟练掌握Golang、Java、Python等其他一种或多种语言开发经验； 熟悉Cloud Native 运维、运营和可观察性体系工具 和 研发： –\texporter + Prometheus Operator / Istio Addon + Prometheus + TSDB + Grafana –\tEFK –\tJaeger/Zipkin –\tCMDB –\tJenkinsX（ Tekton pipeline Deployment） 熟悉时序数据库运维使用: M3DB、LinDB等; 对微服务、Docker、Kubernetes等主流研发技术，有开源社区相关经验者优先； 熟悉Chaos Engineer Toolkits： ChaosToolkit、ChaosBlade等; 具备较强的沟通协作能力；优秀的分析和解决问题能力，能引导和培养新人; 有开源社区相关经验是加分项;  中间件研发工程师 岗位职责  负责负责公司级底层分布式文件系统（数据存储、数据迁移、数据隔离）、通用SaaS服务（媒体处理、DevOps、微服务、中间件等）架构设计和研发 收集业务需求，不定期对系统进行分析，推动系统不断迭代演进 培养和驱动团队成员不断成长  任职要求：  熟练掌握Golang、C++/C、Rust等其他一种或多种语言开发经验； 深度熟悉各种中间件底层原理，对高可用、高并发有深度认识，善于抽象及设计，善于发现问题并解决 有使用公有云存储经验: 腾讯云、阿里云 OSS； AWS S3等； 有开源社区相关经验加分；有云原生开发经验加分；  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/beike-cloud-component/","tags":null,"title":"[社会招聘] 贝壳-基础研发部招聘"},{"categories":null,"contents":"云原生研发工程师（北京） 工作职责  设计研发百度集团的Cloud Native解决方案和微服务中间件，云原生可观测产品（分布式监控、调用链分析、日志管理），支持百度集团云、公有云、行业云 参与开源云原生系统的研发，如Kubernetes、Docker、Service Mesh等技术 设计大规模服务运维场景下数据采集\u0026amp;压缩\u0026amp;传输系统、分布式时序数据存储\u0026amp;计算系统、分布式任务执行系统 研发高效的资源调度算法和架构, 提升集群资源利用率, 提升服务容量和稳定性 探索、研究业界最新的技术方向，开源技术产品，多云生态，提升百度智能云核心竞争力  职位要求  本科及以上学历，熟悉C/C++、Java或者Go中至少一门语言 熟悉或者了解虚拟化容器技术，有Kubernetes、Mesos、Yarn、Docker、OpenStack 等社区开发经验优先 深刻理解数据结构和算法设计，精通 Java、Go、C/C++、PHP 中至少一门编程语言 良好的沟通能力和团队协作精神，严谨的工作态度与高质量意识 善于学习新的知识，动手能力强，有强烈的责任心，喜欢钻研技术 符合以下条件之一优先考虑：分布式系统理论与实践、云计算相关组件经验、开源社区活跃、项目经验丰富  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/baidu-cloud-native/","tags":null,"title":"[社招] 百度基础架构部"},{"categories":["Kubernetes"],"contents":"一、简介 在kubernetes系统中，组件之间通过http协议进行通信，通过informer来做到了消息的实时性、可靠性、顺序性， 通过informer机制与api-server进行通信。\n二、架构设计 1.Reflector (1)简介 informer可以对kubernetes api server 的资源执行监控（watch）操作 ，类型可以是kubernetes内置资源也可以是crd 自定义资源 ，其中最核心的功能是Reflector，Reflector用于监控指定资源的kubernetes资源，当资源发生变化的时候，例如发生了Added 资源添加等事件 会将其资源对象存放在本地缓存DeltaFIFO中。\n(2)核心介绍（listandwatch） 第一部分首先获取资源列表数据。 第二部分通过watchhandler 来监控资源对象。\n// path: staging/src/k8s.io/client-go/tools/cache/reflector.go // ListAndWatch首先列出所有项目，并在调用时获取资源版本，然后使用资源版本进行观看。 //如果ListAndWatch甚至没有尝试初始化watch，它将返回错误。 func (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { klog.V(3).Infof(\u0026#34;Listing and watching %v from %s\u0026#34;, r.expectedType, r.name) var resourceVersion string //从所要同步数据的资源对象的第0个版本开始 \toptions := metav1.ListOptions{ResourceVersion: \u0026#34;0\u0026#34;} if err := func() error { initTrace := trace.New(\u0026#34;Reflector ListAndWatch\u0026#34;, trace.Field{\u0026#34;name\u0026#34;, r.name}) defer initTrace.LogIfLong(10 * time.Second) var list runtime.Object var err error listCh := make(chan struct{}, 1) panicCh := make(chan interface{}, 1) go func() { defer func() { if r := recover(); r != nil { panicCh \u0026lt;- r } }() //如果listerWatcher支持，则尝试以块的形式收集列表；如果不支持，则尝试第一个 \t//列表请求将返回完整的响应。 \tpager := pager.New(pager.SimplePageFunc(func(opts metav1.ListOptions) (runtime.Object, error) { return r.listerWatcher.List(opts) })) if r.WatchListPageSize != 0 { pager.PageSize = r.WatchListPageSize } //返回完整列表 \tlist, err = pager.List(context.Background(), options) close(listCh) }() select { case \u0026lt;-stopCh: return nil case r := \u0026lt;-panicCh: panic(r) case \u0026lt;-listCh: } if err != nil { return fmt.Errorf(\u0026#34;%s: Failed to list %v: %v\u0026#34;, r.name, r.expectedType, err) } initTrace.Step(\u0026#34;Objects listed\u0026#34;) //通过list 转换我们得到listMetaInterface \tlistMetaInterface, err := meta.ListAccessor(list) if err != nil { return fmt.Errorf(\u0026#34;%s: Unable to understand list result %#v: %v\u0026#34;, r.name, list, err) } //listMetaInterface 可以获取groupversion 然后从而转换为kind \tresourceVersion = listMetaInterface.GetResourceVersion() initTrace.Step(\u0026#34;Resource version extracted\u0026#34;) //得到[]runtime.Object \titems, err := meta.ExtractList(list) if err != nil { return fmt.Errorf(\u0026#34;%s: Unable to understand list result %#v (%v)\u0026#34;, r.name, list, err) } initTrace.Step(\u0026#34;Objects extracted\u0026#34;) //然后存入缓存 \t/* func (r *Reflector) syncWith(items []runtime.Object, resourceVersion string) error { found := make([]interface{}, 0, len(items)) for _, item := range items { found = append(found, item) } //调用store的replace来替换 return r.store.Replace(found, resourceVersion) } */ if err := r.syncWith(items, resourceVersion); err != nil { return fmt.Errorf(\u0026#34;%s: Unable to sync list result: %v\u0026#34;, r.name, err) } initTrace.Step(\u0026#34;SyncWith done\u0026#34;) r.setLastSyncResourceVersion(resourceVersion) initTrace.Step(\u0026#34;Resource version updated\u0026#34;) return nil }(); err != nil { return err } ... //调用api的接口 watch \tw, err := r.listerWatcher.Watch(options) if err != nil { switch err { case io.EOF: // watch closed normally \tcase io.ErrUnexpectedEOF: klog.V(1).Infof(\u0026#34;%s: Watch for %v closed with unexpected EOF: %v\u0026#34;, r.name, r.expectedType, err) default: utilruntime.HandleError(fmt.Errorf(\u0026#34;%s: Failed to watch %v: %v\u0026#34;, r.name, r.expectedType, err)) } //如果出现“连接被拒绝”错误，则意味着最有可能的apiserver没有响应。 重新列出所有对象没有任何意义，因为很可能我们将能够在结束的地方重新开始监视。 如果是这种情况，请等待并重新发送监视请求。 \tif utilnet.IsConnectionRefused(err) { time.Sleep(time.Second) continue } return nil } if err := r.watchHandler(start, w, \u0026amp;resourceVersion, resyncerrc, stopCh); err != nil { if err != errorStopRequested { switch { case apierrs.IsResourceExpired(err): klog.V(4).Infof(\u0026#34;%s: watch of %v ended with: %v\u0026#34;, r.name, r.expectedType, err) default: klog.Warningf(\u0026#34;%s: watch of %v ended with: %v\u0026#34;, r.name, r.expectedType, err) } } return nil } } } (3)流程介绍 通过给NewRefector传入一个listerwatcher数据接口对象来实例化一个Reflector对象。 Reflector具备list和watch方法 最重要的是ListAndWatch。 list主要是用来获取资源列表数据。 watch主要是用来监控资源对象，发生event的时候插入本地缓存DeltaFIFO中并更新ResourceVersion。\n2.DeltaFIFO (1)简介 DeltaFIFO可以拆分开来理解 FIFO是一个先进先出的队列。Delta是一个资源对象存储，它可以保存资源对象的操作类型。\n// path: staging/src/k8s.io/client-go/tools/cache/delta_fifo.go type DeltaFIFO struct { ... items map[string]Deltas queue []string ... } (2)生产者 在生产者方法中 queueActionLocked 内部通过keyof拿到对应obj的一个id，items是一个map[string]Deltas 的一个map 那么就以这个id为map的key ，value([]Delta)的话 初始化一个[]Delta 切片并且以f.items[id]为初始切片 再添加一个Delta{actionType, obj}，然后使用dedupDeltas对newDeltas做去重操作。我们会对f.items[id] ，items这个map中是否存在这个key(id)，如果不存在就在队列中添加一个id，添加完之后将 newDeltas 赋值给items[id]，并且调用cond.Broadcast()通知所有消费者并且解除阻塞。\n// path: staging/src/k8s.io/client-go/tools/cache/delta_fifo.go //这里queue负责存放的是id （这里主要是负责先进先出） //items存放的是对应id的 同一个obj的多种操作如图所示 objkey1中对应obj1的先added然后updated func (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { ... if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas f.cond.Broadcast() ... } (3)消费者 这里cond.Wait() 如果队列中没有数据那么就等待，当队列中有了数据之后从queue 里面拿出来第0个id，并且从队列（queue）中删除第0个元素，然后从items中做key的有效判断，如果不存在则跳过，存在的话那么我们就需要从map中把这个key给删除掉。这里主要是为了防止比如items中obj1 有added 有updated 忽然从生产者加了一个deleted，这里删除之后即使加deleted也是新的key会重新从队列中等待，这是对应objkey1的[]delta 中只有一个Deleted的操作，然后调用传入的回调函数process 做操作。\n// path: staging/src/k8s.io/client-go/tools/cache/delta_fifo.go func (f *DeltaFIFO) Pop(process PopProcessFunc) (interface{}, error) { f.lock.Lock() defer f.lock.Unlock() for { //如果队列长度为0 且队列不是关闭 那么就等待 \tfor len(f.queue) == 0 { if f.IsClosed() { return nil, ErrFIFOClosed } f.cond.Wait() } id := f.queue[0] f.queue = f.queue[1:] if f.initialPopulationCount \u0026gt; 0 { f.initialPopulationCount-- } //取出队列头部第一个元素 \titem, ok := f.items[id] if !ok { continue } delete(f.items, id) err := process(item) if e, ok := err.(ErrRequeue); ok { f.addIfNotPresent(id, item) err = e.Err } return item, err } } (4)回调函数process handleDeltas函数作为proess回调函数，当资源对象的操作类型为Added、Updated、Deleted时，将该资源对象存储值indexer（并发安全的存储），并通过distribute函数将资源对象分发至Sharedinformer，distribute函数将资源对象分发到该事件的处理函数中。\n// path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go func (s *sharedIndexInformer) HandleDeltas(obj interface{}) error { s.blockDeltas.Lock() defer s.blockDeltas.Unlock() //这里循环的目的是因为我们传入的obj是一个Deltas 也就是一个[]Deltas 那么就是一个obj的多个操作 \tfor _, d := range obj.(Deltas) { switch d.Type { case Sync, Added, Updated: isSync := d.Type == Sync s.cacheMutationDetector.AddObject(d.Object) if old, exists, err := s.indexer.Get(d.Object); err == nil \u0026amp;\u0026amp; exists { if err := s.indexer.Update(d.Object); err != nil { return err } s.processor.distribute(updateNotification{oldObj: old, newObj: d.Object}, isSync) } else { if err := s.indexer.Add(d.Object); err != nil { return err } s.processor.distribute(addNotification{newObj: d.Object}, isSync) } case Deleted: if err := s.indexer.Delete(d.Object); err != nil { return err } s.processor.distribute(deleteNotification{oldObj: d.Object}, false) } } return nil } (5)distribute函数处理 这段代码表示了通过区分是否是sync操作 通过遍历listener，并且调用add方法把obj写入了一个addch的管道中。\n// path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go func (p *sharedProcessor) distribute(obj interface{}, sync bool) { p.listenersLock.RLock() defer p.listenersLock.RUnlock() if sync { for _, listener := range p.syncingListeners { listener.add(obj) } } else { for _, listener := range p.listeners { listener.add(obj) } } } type sharedProcessor struct { listenersStarted bool listenersLock sync.RWMutex listeners []*processorListener syncingListeners []*processorListener clock clock.Clock wg wait.Group } func (p *processorListener) add(notification interface{}) { p.addCh \u0026lt;- notification } processor 是 sharedIndexInformer 中一个非常有趣的组件，Controller Manager 通过一个 Informer 单例工厂来保证不同的 Controller 共享了同一个 Informer，但是不同的 Controller 对该共享的 Informer 注册的 Handler 不同sharedProcessor 的工作核心是围绕着 listeners 这个 Listener 切片展开的。\n(6)addch // path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go type processorListener struct { nextCh chan interface{} addCh chan interface{} } 将事件源源不断地 从addCh 到 nextCh，因为无法预知生产者的生产速度，所以这里pendingNotifications 承担了一个buffer的角色，通过pendingNotifications 来控制生产者与消费者之间的平衡。\n// path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go func (p *processorListener) pop() { defer utilruntime.HandleCrash() defer close(p.nextCh) // Tell .run() to stop  var nextCh chan\u0026lt;- interface{} var notification interface{} for { select { case nextCh \u0026lt;- notification: // Notification dispatched \tvar ok bool notification, ok = p.pendingNotifications.ReadOne() if !ok { // Nothing to pop \tnextCh = nil // Disable this select case \t} case notificationToAdd, ok := \u0026lt;-p.addCh: if !ok { return } if notification == nil { // No notification to pop (and pendingNotifications is empty) \t// Optimize the case - skip adding to pendingNotifications \tnotification = notificationToAdd nextCh = p.nextCh } else { // There is already a notification waiting to be dispatched \tp.pendingNotifications.WriteOne(notificationToAdd) } } } } 因为 listener 包含了 Controller 注册进来的 Handler 方法，因此 listener 最重要的职能就是当事件发生时来触发这些方法，而 listener.run 就是不停的从 nextCh 这个 channel 中拿到事件并执行对应的 handler可以看到，listener.run 不停的从 nextCh 这个 channel 中拿到事件。\n// path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go func (p *processorListener) run() { stopCh := make(chan struct{}) wait.Until(func() { err := wait.ExponentialBackoff(retry.DefaultRetry, func() (bool, error) { for next := range p.nextCh { switch notification := next.(type) { case updateNotification: p.handler.OnUpdate(notification.oldObj, notification.newObj) case addNotification: p.handler.OnAdd(notification.newObj) case deleteNotification: p.handler.OnDelete(notification.oldObj) default: utilruntime.HandleError(fmt.Errorf(\u0026#34;unrecognized notification: %T\u0026#34;, next)) } } // the only way to get here is if the p.nextCh is empty and closed \treturn true, nil }) // the only way to get here is if the p.nextCh is empty and closed \tif err == nil { close(stopCh) } }, 1*time.Minute, stopCh) } 从图中可以看出当有一个新的event 这里新的event指的是从delta队列中通过distribute分发给所有Listener通过调用add 来对addch有一个写入的操作，然后通过缓存判定（也就是为了防止listener.handler生产速度大于消费速度 这里加了一层缓存层 如果没有缓存直接写入nextch ，有缓存就写入缓存还会对缓存的剩余量做判断），并执行对应的 handler。\n(7)DeltaFIFO总结 总体来看，DeltaFIFO 的入队列方法，会先判断该资源是否已经在 items 中， 如果已经存在，说明该资源还没有被消费（还在 queue 中排队），则直接将事件 append 到 items[resource_id] 中即可。如果发现不在 items 中，便会创建 items[resource_id]，并将资源 id append 到 queue 中。而 DeltaFIFO 出队列方法，会从 queue 中拿到队列最前面的资源 id，然后从 items 中拿走该资源所有的事件，最后调用 Pop 方法传入的 PopProcessFunc 类型的处理函数。因此，DeltaFIFO 的特点在于，入队列的是（资源的）事件，而出队列时是拿到的是最早入队列的资源的所有事件。这样的设计保证了不会因为有某个资源疯狂的制造事件，导致其他资源没有机会被处理而产生饥饿\n3.Indexer (1)简介 indexer是client-go用来存储资源对象并自带索引功能的本地存储，Reflector从DeltaFIFO中江晓飞出来的资源对象存储至indexer，indexer要与etcd中的数据保持一致，这样无须每次都走etcd交互式拿到数据，能减轻api-server的压力。\n(2)例子 这里是一个indexer的一个测试用例。\n//这就是一个keyfunc的定义 func testUsersIndexFunc(obj interface{}) ([]string, error) { pod := obj.(*v1.Pod) //拿到一个pod obj 并且从pod中拿到 注释key是users的值 \tusersString := pod.Annotations[\u0026#34;users\u0026#34;] //以，作为分隔符 做一个切片返回 \treturn strings.Split(usersString, \u0026#34;,\u0026#34;), nil } func TestMultiIndexKeys(t *testing.T) { //我们初始化一个indexer MetaNamespaceKeyFunc是一个获取ns和资源对象的的keyfunc //indexer的key是byUser value 是一个keyfunc(testUsersIndexFunc) \tindex := NewIndexer(MetaNamespaceKeyFunc, Indexers{\u0026#34;byUser\u0026#34;: testUsersIndexFunc}) //初始化3个pod obj \tpod1 := \u0026amp;v1.Pod{ObjectMeta: metav1.ObjectMeta{Name: \u0026#34;one\u0026#34;, Annotations: map[string]string{\u0026#34;users\u0026#34;: \u0026#34;ernie,bert\u0026#34;}}} pod2 := \u0026amp;v1.Pod{ObjectMeta: metav1.ObjectMeta{Name: \u0026#34;two\u0026#34;, Annotations: map[string]string{\u0026#34;users\u0026#34;: \u0026#34;bert,oscar\u0026#34;}}} pod3 := \u0026amp;v1.Pod{ObjectMeta: metav1.ObjectMeta{Name: \u0026#34;tre\u0026#34;, Annotations: map[string]string{\u0026#34;users\u0026#34;: \u0026#34;ernie,elmo\u0026#34;}}} //调用add 插入缓存 \tindex.Add(pod1) index.Add(pod2) index.Add(pod3) ... //我们通过map中的indexfunc（这个func主要就是从pod的注释字段中拿到注释key是users的值，keyfunc返回的是一个[]string） 那么通过indexfunc我们获得了注释key是users的值 然后通过我们第二个参数判断users中存不存在 ernie这个string \terniePods, err := index.ByIndex(\u0026#34;byUser\u0026#34;, \u0026#34;ernie\u0026#34;) if err != nil { t.Errorf(\u0026#34;unexpected error: %v\u0026#34;, err) } if len(erniePods) != 1 { t.Errorf(\u0026#34;Expected 1 pods but got %v\u0026#34;, len(erniePods)) } //可能有多个pod注释中都有users:ernie,xxx,xxx 类似的只要包含ernie 通过上面的byindex就可以拿出来 然后遍历 打印 \tfor _, erniePod := range erniePods { if erniePod.(*v1.Pod).Name != \u0026#34;one\u0026#34; { t.Errorf(\u0026#34;Expected only \u0026#39;one\u0026#39; but got %s\u0026#34;, erniePod.(*v1.Pod).Name) } } } 简单来说就是indefunc 我们自己定义一些逻辑 实现对一个obj 做一些取值或者操作，然后通过传入一个indexfunc初始化一个indexer 。 这里的indexer是一个map[string]indexfunc 我的理解就是可以自定义indexfun 然后添加map里面 需要做什么操作就调用那个key对应的func 就比如 index.ByIndex(\u0026ldquo;byUser\u0026rdquo;, \u0026ldquo;ernie\u0026rdquo;)。 indefunc 是一个对注释key是users取value的操作 那么调用这个indefunc 并且比较取出来的值中是否有ernie这个string。\n(3)ByIndex的核心实现 // path: staging/src/k8s.io/client-go/tools/cache/store.go //前面说过了cache是一个store的实现 然后它本身有嵌套了ThreadSafeStore 接口 //threadSafeMap 是ThreadSafeStore 接口的一个实现 //我们可以从newstroe看到 就是把threadSafeMap 赋给了store的ThreadSafeStore 字段 //go的特性当他这个结构体实现了一个接口的所有方法那么就可以把结构体赋给接口 func (c *cache) ByIndex(indexName, indexKey string) ([]interface{}, error) { return c.cacheStorage.ByIndex(indexName, indexKey) } // path: staging/src/k8s.io/client-go/tools/cache/thread_safe_store.go //接收2个参数 indexname 索引器名称 indexkey 需要检索的key func (c *threadSafeMap) ByIndex(indexName, indexKey string) ([]interface{}, error) { //加锁 \tc.lock.RLock() defer c.lock.RUnlock() //通过indexname 我们拿到对应的indexfunc \tindexFunc := c.indexers[indexName] if indexFunc == nil { return nil, fmt.Errorf(\u0026#34;Index with name %s does not exist\u0026#34;, indexName) } //从indeices中通过indexname我们拿到index \t//indices是一个map[string]index \t//index是map[string]sets.String \tindex := c.indices[indexName] //sets本身也是一个map[string]Empty \t//empty是一个struct{} \t//从index中我们取到sets \tset := index[indexKey] list := make([]interface{}, 0, set.Len()) //通过遍历set 我们拿到所有的key 然后从items 通过key拿出来 \t//item是map[string]interface{} \tfor key := range set { list = append(list, c.items[key]) } //把所有符合的结果返回 \treturn list, nil } index中的缓存数据为set集合数据结构，set本质与slice相同，但是set是一个map 不存在相同元素，kubernetes通过map结构类型的key作为set数据结构 ，实现set去重特性\n4.工作流程  controller manager在启动的时候会启动一个sharedInformerFactory这是一个informer的集合（informers map[reflect.Type]cache.SharedIndexInformer）。 controller在run的时候会调用reflector的run，reflector 在run的时候会listen and watch，当有event的时候插入本地缓存DeltaFIFO中并更新ResouVersion。 controller manager会watch and listen api-server的event，当有事件产生的时候，会通过reflector 插入deltafifo， DeltaFIFO是一个先进先出的队列 ，通过生产者 （add等等） 消费者（pop） 之后通过 sharedProcessor.distribute分发给所有listener 然后通过不同controller注册的handler来做逻辑处理。 最后indexer 去做操作调用treadsafestore 也就是底层存储的操作逻辑。  三、informer 1.资源informer 每一个kubernetes资源都实现了informer机制 ，每一个informer上都会事先informer的lister方法 例如pod informer。\n//path: staging/src/k8s.io/client-go/informers/core/v1/pod.go type PodInformer interface { Informer() cache.SharedIndexInformer Lister() v1.PodLister } 2.shared informer （1）简介 informer 也被称为shared informer ，他是可以共享使用的，如果每一个informer使用一个reflector 那么会运行相当多的listandwatch 会增加api的复杂。shared informer 可以使同一类资源informer 共享一个reflector 可以节约资源。\n//path: staging/src/k8s.io/client-go/informers/factory.go type sharedInformerFactory struct { client kubernetes.Interface namespace string tweakListOptions internalinterfaces.TweakListOptionsFunc lock sync.Mutex defaultResync time.Duration customResync map[reflect.Type]time.Duration //通过map 来存储 资源类型与 SharedIndexInformer 的对应关系 \tinformers map[reflect.Type]cache.SharedIndexInformer // startedInformers is used for tracking which informers have been started. \t// This allows Start() to be called multiple times safely. \tstartedInformers map[reflect.Type]bool } //通过informer 方法添加不同资源的informer 如果已存在则返回当前的informer 不再继续添加 func (f *sharedInformerFactory) InformerFor(obj runtime.Object, newFunc internalinterfaces.NewInformerFunc) cache.SharedIndexInformer { f.lock.Lock() defer f.lock.Unlock() //拿到obj 的type \tinformerType := reflect.TypeOf(obj) //通过obj type 获取informer 如果存在直接返回 \tinformer, exists := f.informers[informerType] if exists { return informer } resyncPeriod, exists := f.customResync[informerType] if !exists { resyncPeriod = f.defaultResync } informer = newFunc(f.client, resyncPeriod) //在map中添加一个新的type 跟informer的映射关系 \tf.informers[informerType] = informer return informer } （2）启动informer 调用informer的start方法让 所有informers 中的informer 通过goroutine持久运行。\n//path: staging/src/k8s.io/client-go/informers/factory.go func (f *sharedInformerFactory) Start(stopCh \u0026lt;-chan struct{}) { f.lock.Lock() defer f.lock.Unlock() for informerType, informer := range f.informers { //遍历 informers 如果他的状态时true 那么它属于启动状态 如果不是那么run起来并且修改他的状态 \tif !f.startedInformers[informerType] { go informer.Run(stopCh) f.startedInformers[informerType] = true } } } //path: staging/src/k8s.io/client-go/tools/cache/shared_informer.go //这里的run调用了shared informer的run方法 func (s *sharedIndexInformer) Run(stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() //创建fifo队列  fifo := NewDeltaFIFO(MetaNamespaceKeyFunc, s.indexer) //初始化config  cfg := \u0026amp;Config{ Queue: fifo, ListerWatcher: s.listerWatcher, ObjectType: s.objectType, FullResyncPeriod: s.resyncCheckPeriod, RetryOnError: false, ShouldResync: s.processor.shouldResync, Process: s.HandleDeltas, } ... //调用controller.run  s.controller.Run(stopCh) } //path: staging/src/k8s.io/client-go/tools/cache/controller.go func (c *controller) Run(stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() go func() { \u0026lt;-stopCh c.config.Queue.Close() }() //初始化一个reflector \tr := NewReflector( c.config.ListerWatcher, c.config.ObjectType, c.config.Queue, c.config.FullResyncPeriod, ) r.ShouldResync = c.config.ShouldResync r.clock = c.clock c.reflectorMutex.Lock() c.reflector = r c.reflectorMutex.Unlock() var wg wait.Group defer wg.Wait() //controller 最后也是调用的 reflector的run \twg.StartWithChannel(stopCh, r.Run) wait.Until(c.processLoop, time.Second, stopCh) } //path: staging/src/k8s.io/client-go/tools/cache/reflector.go //controller run的时候会把reflector run起来,调用reflector 的listandwatch func (r *Reflector) Run(stopCh \u0026lt;-chan struct{}) { klog.V(3).Infof(\u0026#34;Starting reflector %v (%s) from %s\u0026#34;, r.expectedType, r.resyncPeriod, r.name) wait.Until(func() { if err := r.ListAndWatch(stopCh); err != nil { utilruntime.HandleError(err) } }, r.period, stopCh) } 四、通过一个例子来理解informer机制 package main import ( \u0026#34;fmt\u0026#34; v1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/client-go/informers\u0026#34; \u0026#34;k8s.io/client-go/kubernetes\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; \u0026#34;time\u0026#34; \u0026#34;k8s.io/client-go/tools/cache\u0026#34; ) func main() { config ,err := clientcmd.BuildConfigFromFlags(\u0026#34;\u0026#34;,\u0026#34;config\u0026#34;) if err != nil { panic(err) } //通过config 拿到client set客户端 \tclientset ,err := kubernetes.NewForConfig(config) if err != nil { panic(err) } stopch := make(chan struct{}) defer close(stopch) //通过client set客户端以及一个rsync（多久设置一次重新同步 也就是同步间隔时间 如果是0 那么禁用同步功能） 我们拿到一个informer的集合 \tsharedinformers := informers.NewSharedInformerFactory(clientset,time.Minute) //通过sharedinfomers 我们获取到pod的informer \tpodinfomer := sharedinformers.Core().V1().Pods().Informer() //为pod informer添加 controller的handlerfunc 触发回调函数之后 会通过addch 传给nextCh 管道然后调用controller的对应的handler来做处理 \tpodinfomer.AddEventHandler(cache.ResourceEventHandlerFuncs{ //pod资源对象创建的时候出发的回调方法 \tAddFunc: func(obj interface{}) { obja := obj.(v1.Object) fmt.Println(obja) }, //更新回调 \tUpdateFunc: func(oldObj, newObj interface{}) { ... }, //删除回调 \tDeleteFunc: func(obj interface{}) { ... }, }) //这里会调用reflector的run listandwatch 然后以goroutine的方式运行 \tpodinfomer.Run(stopch) } 五、总结 通过对informer的架构的学习，我们引出了reflector 、deltafifo、indexer 几个核心的知识点，可以让我们更加深入的了解informer的工作流程，以此来熟悉controller，并且对于我们自己开发controller 也非常有帮助。\n参考资料  https://blog.ihypo.net/15763910382218.html http://www.broadview.com.cn/book/6104  ","permalink":"https://cloudnative.to/blog/client_go-informer/","tags":["client-go","informer"],"title":"Kubernetes client-go informer架构介绍"},{"categories":["云原生"],"contents":"本文是 2020 年 8 月 15 号在深圳 GIAC（GLOBAL INTERNET ARCHITECTURE CONFERENCE）全球互联网架构大会，由宋净超（Jimmy Song）出品的云原生专场中的现场实录。\n王发康（毅松）蚂蚁集团可信原生技术部 技术专家，专注于高性能网络服务器研发，是 MOSN、Tengine 开源项目核心成员，目前关注云原生 Service Mesh、Nginx、Istio 等相关领域，喜欢开源，乐于分享，GItHub：https://github.com/wangfakang 。\n以下是分享全文。\n前言 MOSN 在蚂蚁集团的 Service Mesh 大规模落地后，通过对接 UDPA 打造为 Istio 的数据面之一，本文就其在演进过程中遇到的问题及思考进行展开。对接 UDPA，实现 Istio 融合，并增强 MOSN 服务治理及流量控制能力对接云原生周边组件，实现 MOSN 开箱即用。\n大家下午好，我叫王发康，来自蚂蚁集团可信云原生应用网络团队，之前几年一直从事南北向网关（接入层）的开发和维护，说来也是和流量有着别样的渊缘，现在主要做东西向的流量网关（Service Mesh）开发和设计。今天演讲的主题是《云原生网络代理 MOSN 的进化之路》，主要从如下几点介绍：\n MOSN 介绍 云原生演进 总结与展望  MOSN 介绍 接下来，就 MOSN 的诞生背景、发展历程、MOSN 具备的功能和架构以及内部的落地情况这几个维度介绍下 MOSN。\nMOSN 诞生背景 随着云计算、物联网等技术迅速发展，也促使着微服务的架构一直在进化，其演进过程通常经历了如下四个阶段：\n单体：一般起始阶段业务很简单，流量也不大，所有的处理都可以在一个服务中完成；\n分布式：随着业务操作的多样化以及流量的日益增长，不得不按照服务维度进行拆分，这样相同的服务资源消耗可对等，方便容量评估及管理；\n微服务：随着服务的拆分粒度越来越细，其服务的数量一直在增加，由此出现各种微服务治理的需求（限流、鉴权、路由等），于是便出现各种治理组件并以 SDK 插件的方式集成到不同应用中；\nService Mesh：伴随着服务治理的 SDK 种类、版本、重复等一系列问题，于是把 SDK 的能力剥离到 Sidecar，和业务进行解耦，从而实现业务和中间件能力的并行迭代；\n业务痛点\n 多语言，中间件组件开发适配成本高 SDK 升级困难 服务治理能力弱 技术不通用，无法复用  业界解决方案\n Envoy (C++) Linkerd (活跃度较低) NginxMesh (活跃度低)  综合以上业务痛点以及业界现有方案的评估，于是 MOSN 就诞生了。MOSN（Modular Open Smart Network）是用 GoLang 编写的网络代理服务器。作为 Sidecar、API Gateway、云原生 Ingress、Layer 4 或 Layer 7 负载均衡器等场景构建的。随着时间的推移，我们添加了额外的功能，例如多协议框架，多进程插件机制，DSL 以及对 xDS API 等的支持，支持 xDS 意味着我们现在可以将 MOSN 用作 Istio 的数据平面。\nMOSN 发展历程 从 2017 年底开始 Service Mesh 技术调研，2018 年 3 月份 MOSN 雏形问世并进行了小规模试点，秉着让更多的用户能够享受这一技术红利的思路，于是 2018 年 6 月正式开源 MOSN。2019 年 618 进行了规模化落地，并在同年的双 11 大促达到了核心支付链路的全覆盖。在通过大规模验证后，MOSN 社区开始在其标准化以及生态方面进行发展和演进。\nMOSN 功能视图 MOSN 作为一个通用的数据转发平面，提供多协议卸载、动态服务发现、服务治理（Trace、限流、重试、重写、超时控制等）、丰富的负载均衡算法等功能，可用于 Sidecar、API Gateway、云原生 Ingress、Layer 4 或 Layer 7 负载均衡器等场景。\nMOSN 架构解析 MOSN 采用的是分层的体系结构，其系统分为 NET/IO、Protocol、Stream、Proxy 四层：\n NET/IO 作为网络层，监测连接和数据包的到来，同时作为 listener filter 和 network filter 的挂载点; Protocol 作为多协议引擎层，对数据包进行检测，并使用对应协议做 decode/encode 处理; Stream 对 decode 的数据包做二次封装为 stream，作为 stream filter 的挂载点; Proxy 作为 MOSN 的转发框架，对封装的 stream 做 proxy 处理;  其中，每一层通过工厂设计模式向外暴露其接口，方便用户灵活地注册自身的需求。通过协程池的方式使得用户以同步的编码风格实现异步功能特性。通过区分协程类型，MOSN 实现了 read 和 proxy worker 两大类协程，read 协程主要是处理网络的读取及协议解析，proxy worker 协程用来完成读取后数据的加工、路由、转发等。其架构如下图所示：\nMOSN 为了降低 Runtime GC 带来的卡顿，自身做了内存池的封装方便多种对象高效地复用，另外为了提升服务网格之间的建连性能还设计了多种协议的连接池从而方便地实现连接复用及管理。 在连接管理方面，MOSN 设计了多协议连接池， 当 Proxy 模块在 Downstream 收到 Request 的时候，在经过路由、负载均衡等模块处理获取到 Upstream Host 以及对应的转发协议时，通过 Cluster Manager 获取对应协议的连接池 ，如果连接池不存在则创建并加入缓存中，之后在长连接上创建 Stream，并发送数据，如下图所示：\n在内存管理方面，MOSN 在 sync.Pool 之上封装了一层资源对的注册管理模块，可以方便的扩展各种类型的对象进行复用和管理。其中 bpool 是用来存储各类对象的构建方法，vpool 用来存放 bpool 中各个实例对象具体的值。运行时通过 bpool 里保存的构建方法来创建对应的对象通过 index 关联记录到 vpool 中，使用完后通过 sync.Pool 进行空闲对象的管理达到复用，如下图所示：\nMOSN 落地情况 服务在做了 Mesh 化后，有人可能会质疑，增加一跳 Sidecar 转发是否会导致性能下降，其实不然，在蚂蚁的部分业务场景中，部分业务上了 Mesh 后，其 CPU 消耗还比之前低了，原因是之前的一些通用 SDK 能力都下沉到 Sidecar 中，并统一做了一定的优化。另一个好处是，由于 MOSN 使用 GoLang 开发，天然具备其高开发效率，所以也大大的提升了中间件相关能力的研发速度。\nMOSN 云原生演进 在 MOSN 大规模落地并通过双 11 大考后，MOSN 也开始在实践的道路上进行标准化演进。并通过和 Istio 社区的合作，MOSN 实现了 xDS 的适配，可方便的实现 Istio 作为 MOSN 的控制面进行服务配置的管理。另一方面，我们也在积极参加 Istio 相关社区，并贡献了一些通用能力及问题修复的 PR。\nCould Native 架构 如下图所示，最下面是基础设施层（物理机等），上层进行抽象出 Kubernetes 进行容器资源的调度和管理，再上层就是部署在容器里面的各种服务了，Istio 的能力（服务治理）就在这一层进行发挥的。\nIstio 简介 在介绍 Istio 前，先说下它为什么会出现。10 年前，一般应用都是直接部署在物理机上的，但是随着时间的推移，机型一直变化（如 CPU 核数）就出现了机型对等、环境部署以及弹性扩容等一系列问题，于是就出现了 Docker。但是 Docker 涉及到容器编排、调度、管理等问题， Kubernetes 便随之出现。Kubernetes 在容器管理领域的用途是毋庸置疑的，但是其在微服务治理方面存在一些不足，于是 Istio 便专职解决微服务治理的问题而问世。\nIstio 弥补了 Kubernetes 在服务治理上的短板，提供服务互连、流量安全、流量控制、可观测性功能。\nMOSN 和 Istio 通过 MOSN 社区几个月的努力及推进，MOSN v0.14.0 版本可以使用 Istio 1.5.x 作为云原生控制面，从而方便的进行微服务的治理。如下是 Istio 官方在 2020 年 7 月 28 号发布了在 Istio 中使用 MOSN：另一个数据平面博文，即 Istio 数据平面的另一个选择 —— MOSN。\n如下是 MOSN 在 Istio 1.5 版本中的架构图，MOSN 通过 xDS 协议从 Istio 动态的获取各种服务配置，从而实现服务治理的效果。\n在 Service Mesh 领域，使用 Istio 作为控制平面已成为主流。Istio 通过 xDS 协议和数据面进行交互，因此，通过在 MOSN 中实现 xDS，我们就可以使用 Istio 作为 MOSN 的控制面。Istio 的第三方数据平面集成可以通过以下三个步骤实现：\n 实现 xDS 协议，对齐数据面相关服务治理能力; 使用 Istio 的脚本并设置相关 SIDECAR 等参数构建 proxyv2 镜像; 通过 istioctl 工具并设置 proxy 相关配置指定具体的数据面;  有了对应的改造方案后，于是我们成立了相关 Working Group ，带领社区的同学一起进行讨论和改造。\n除了对 Istio 进行改造（相关能力已经合入 Istio 官方仓库），MOSN 也需要在负载均衡、服务治理及相关框架上做一些适配和增强，其适配列表如下所示：\nMOSN 在功能上对齐 Istio 后，就可以使用其进行微服务治理了。在使用前，我们先看看 Istio 中的 VirtualService 等相关策略是如何和 MOSN 进行关联的。如下图所示，在 Istio 中的 VirtualService 做为一个服务的转发描述，其对应到 MOSN 中就是一个 Listener 以及一组对应的路由策略 Routes。\n在初步了解 MOSN 如何同 Istio 结合后，我们来看看 MOSN 在 Bookinfo 实例中可以做什么：如下是一个经典的多语言服务使用 Istio 做服务治理，在该场景中，MOSN 不仅独立的作为 Ingress Gateway，还作为 Sidecar。\n通过 MOSN 作为 Istio 的数据平面运行 Bookinfo 事例，实现如下服务治理通用能力：\n 按 version路由能力 按照权重路由能力 按照特定 header路由能力 故障注入能力 服务熔断自护能力 透明劫持能力 超时重试机制 etc  在这里，你可以通过演示教程《MOSN with Istio》来学习 MOSN 如何作为 Istio 的数据面进行服务治理。\n开源生态建设 MOSN 在对接完 Istio 的同时，也和周边的开源生态进行了紧密的合作，如 Dubbo、Sentinel、Skywalking 等。\nMOSN With Dubbo\nMOSN 中提供 Kubernes 和 非 Kubernes 体系下的 Dubbo 服务治理方案。如下图所示，方案 1 是在非 Kubernes 体系下，MOSN 通过集成 dubbo-go 支持服务的 pub/sub，并复用原有的服务注册中心。方案 2 则是在 Kubernes 体系下使用 Istio 进行一步到位的服务治理，MOSN 通过支持 Istio 下的路由策略，实现服务的治理。\nMOSN With Sentinel\n限流是微服务治理中的一个重要功能， MOSN 通过集成 Sentinel 并复用其底层的限流能力，从而实现单机限流（令牌桶/漏桶结合）、服务熔断保护（依据服务的成功率）、自适应限流（依据机器的负载），同时目前 Istio 的限流规则也没有一个成熟的 API，我们也和 UDPA 进行了一些限流规则的规范讨论。\nMOSN With Skywalking\n调用依赖以及服务与服务之的调用状态是微服务管理中一个重指标，MOSN 社区通过和 Skywalking 合作，把 Skywalking 的 GoLang SDK 集成到 MOSN 中，从而实现 HTTP 系调用链路拓扑展示、QPS 监控、细粒度 RT 如下图所示，同时该功能也在持续演进，接下来会支持 Dubbo Tracing。\n标准化演进 除了开源生态的适配外，MOSN 也在其标准化方面做了一些贡献（如限流、路由的 UDPA 策略提议等）。谷歌在数据面和控制面之间标准化出 UDPA 规范，微软在控制面和应用及工具层面之间标准出 SMI 规范，这所做的一切其实都是围绕“防止锁定，方便用户灵活切换”。\n可见“标准”、“规范”的重要性，当然 MOSN 社区也在其相关的标准下做了一些演进和贡献。\n  云原生标准 Sidecar 的打造；\n  标准化参与和建设；\n  针对第一点，MOSN 社区持续在进行 Istio 能力的对齐工作，包括 Istio 侧多 Sidecar 支持以及 MOSN 侧功能对齐 Istio，控制面方面支持注入 MOSN Sidecar、Pilot-agent 的适配以及 Istio 编译构建的适配、负载均衡算法、流量管理体系、流量检测、服务治理等。\n在标准化方面，我们也参与了 UDPA 相关规范讨论，并提出限流通用 API 规范讨论，社区会议讨论组织中。\n同时 MOSN 社区也积极地在和 Istio 社区进行沟通以及寻求合作，我们的目标是希望能成为 Istio 官方推荐的 Sidecar 产品，对此我们在 Istio Github 上提了相关 ISSUE，引发了比较大的关注，Istio 官方 Member 成员 @howardjohn 对此问题进行了非常详细的回答和探讨。\n综合 MOSN 社区和 Istio 官方的讨论后，MOSN 社区主导并会参与 Istio 中数据面解耦的事情（比如测试集、镜像构建等），这样使得 Istio 更容易集成第三方的数据面，即 MOSN 社区的用户更方便的集成 Istio 使用。对此 MOSN with Istio 适配的 Roadmap 中新增如下事项：\n 推动 Istio 的镜像构建和数据面解耦，相关 Issue 推动 Istio 的测试框架和数据面解耦，相关 Issue  针对第一点，MOSN 社区向 Istio 贡献 PR，并已合入主干，通过该 PR 可以更方便的让 Istio 的 proxyv2 镜像集成其它数据面。\n2020 年 7 月 14 号 Istio TOC（Istio 技术委员会）成员 @ShriramRajagopalan 最新回复： “也是支持 Istio 中支持多数据面的方案，而且也建议先把 MOSN 做为实验性第三方数据平面纳入到 Istio 的官方博客中，方便用户来试用”：\n经过 MOSN 社区不断的努力，在 7月底，Istio 官方博客正式上线了 在 Istio 中使用 MOSN：另一个数据平面 博文，取到了 Istio 官方的一定认可。\n总结及展望 从 Service Mesh 技术调研，到 MOSN 诞生并小规模试点，再到双 11 规模化落地，并走向开源到标准化演进，一路走来实属不易，这个过程中也离不开 MOSN 开源社区开发者和使用者的贡献与支持。\n合作伙伴及用户 秉着借力开源，反哺开源的思想，MOSN 社区在众多的合作伙伴的共同努力下，在实践的道路上，一步步的走向标准化。\n总结及未来展望 接下来，MOSN 社区不仅会持续兼容适配新版本的 Istio 的功能，而且还将在以下几个方面进行发力：\n 可编程，如支持面向业务层的 DSL，可方便的控制请求的处理流程，另外也会在 WASM 上进行预研； Dapr 模式作为微服务运行时，使得面向 MOSN 编程的服务更轻、更小、启动速度更快； 被集成，遵循 UDPA 规范，可方便的被 Istio 、 Kuma 集成，另外 MOSN 里面的通用工具链剥离为 package，方便其它 GoLang 项目复用； 更多场景 Mesh 化方案支持，Cache Mesh/Message Mesh/Block-chain Mesh 等；  MOSN 是一个开源项目，社区中的任何人都可以使用，参与和改进。我们希望您能加入社区！可以通过这里介绍的几种方式了解 MOSN 正在做的事情并参与其中。\n MOSN 官网 http://mosn.io MOSN Github http://github.com/mosn/mosn Service Mesh https://www.servicemesher.com  欢迎加入 MOSN 开源交流群\n","permalink":"https://cloudnative.to/blog/cloud-native-mosn/","tags":["Cloud Native","MOSN","Istio"],"title":"云原生网络代理 MOSN 的进化之路"},{"categories":["Kubernetes"],"contents":"Overview 这篇文章主要是学习Informer机制并且理解Informer各个组件的设计。\n背景 为什么Kubernetes需要Informer机制？我们知道Kubernetes各个组件都是通过REST API跟API Server交互通信的，而如果每次每一个组件都直接跟API Server交互去读取/写入到后端的etcd的话，会对API Server以及etcd造成非常大的负担。 而Informer机制是为了保证各个组件之间通信的实时性、可靠性，并且减缓对API Server和etcd的负担。\nInformer 流程 这个流程，建议先看看《From Controller Study Informer》\n这里我们以CoreV1. Pod资源为例子：\n 第一次启动Informer的时候，Reflector 会使用List从API Server主动获取CoreV1. Pod的所有资源对象信息，通过resync将资源存放在Store中 持续使用Reflector建立长连接，去Watch API Server发来的资源变更事件 当2 监控到CoreV1.Pod的资源对象有增加/删除/修改之后，就把资源对象存放在DeltaFIFO中 DeltaFIFO是一个先进先出队列，只要这个队列有数据，就被Pop到Controller中, 将这个资源对象存储至Indexer中，并且将该资源对象分发至ShareInformer Controller会触发Process回调函数  打脸 所以，我自己之前写代码的时候，一直以为是ShareInformer去主动watch API Server, 而现在正正打脸了，是Reflector做的List\u0026amp;Watch。\nListAndWatch 思考 为什么Kubernetes里面是使用ListAndWatch呢？我们所知道的其他分布式系统常常使用RPC来触发行为。\n我们来分析下如果不这样做，而是采用API Server轮询推送消息给各个组件，或者各个组件轮询去访问API Server的话，那么实时性就得不到保证，并且对API Server造成很大的负载，很有可能需要开启大量的端口造成端口浪费。\n从实时性出发的话：\n我们希望是有任何资源的新增/改动/删除，都需要马上获取并且放入消息队列。可以对应我们Informer中的Reflector组件，去主动获取消息，并且放入DeltaFIFO队列被消费。\n从减轻负载出发的话：\n需要上缓存，这里可以对应我们的Store组件。\n从设计扩展性出发的话：\n作为一个“资源管理系统”的Kubernetes，我们的对象数量可能会无限扩大，那么我们需要设计一个高效扩展的组件，去应对对象的种类无限扩大，并且同一种对象可能会被用户实例化非常多次的行为。 这里可以对应我们的ShareInformer。\n从消息的可靠性出发的话：\n刚刚说了这么多，都是进行长连接去Watch的，万一网络出错怎么办？这个时候我们的List机制就很明显发挥作用，一旦感知跟API Server中断，或者第一次启动，都是使用List机制的， List作为一个短连接去获取资源信息，Watch 作为长连接去持续接收资源的变更并且处理。（用List\u0026amp;Watch可以保证不会漏掉任何事件）\nWatch的实现 Watch是通过HTTP 长连接接收API Server发送的资源变更事件，使用的Chunked transfer coding， 代码位置./staging/src/k8s.io/apiserver/pkg/endpoints/handlers/watch.go，源码如下\ne := streaming.NewEncoder(framer, s.Encoder) // ensure the connection times out \ttimeoutCh, cleanup := s.TimeoutFactory.TimeoutCh() defer cleanup() // begin the stream \tw.Header().Set(\u0026#34;Content-Type\u0026#34;, s.MediaType) w.Header().Set(\u0026#34;Transfer-Encoding\u0026#34;, \u0026#34;chunked\u0026#34;) w.WriteHeader(http.StatusOK) flusher.Flush() 我们通过curl来看看, 在response的Header中设置Transfer-Encoding的值是chunked\n# curl -i http://127.0.0.1:8001/api/v1/watch/namespaces?watch=yes HTTP/1.1 200 OK Cache-Control: no-cache, private Content-Type: application/json Date: Sun, 09 Aug 2020 02:44:07 GMT Transfer-Encoding: chunked {\u0026#34;type\u0026#34;:\u0026#34;ADDED\u0026#34;,\u0026#34;object\u0026#34;:{\u0026#34;kind\u0026#34;:\u0026#34;Namespace\u0026#34;,\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;... 监听事件 Reflector 我的理解，Reflector是实现对指定的类型对象的监控，既包括Kubernetes内置资源，也可以是CRD自定义资源。\n数据结构 我们来看看Reflector的数据结构， 代码块staging/src/k8s.io/client-go/tools/cache/reflector.go\nlisterWatcher其实就是从API Server里面去做List跟Watch的操作去获取对象的变更。\ntype Reflector struct { name string // 监控的对象类型，比如Pod \texpectedType reflect.Type // 存储 \tstore Store // ListerWatcher是针对某一类对象，比如Pod \tlisterWatcher ListerWatcher period time.Duration resyncPeriod time.Duration ShouldResync func() bool ... } Run Run是循环一直把数据存储到DeltaFIFO中。\nfunc (r *Reflector) Run(stopCh \u0026lt;-chan struct{}) { klog.V(3).Infof(\u0026#34;Starting reflector %v (%s) from %s\u0026#34;, r.expectedType, r.resyncPeriod, r.name) wait.Until(func() { if err := r.ListAndWatch(stopCh); err != nil { utilruntime.HandleError(err) } }, r.period, stopCh) } 也就是说，Reflector是一直在执行ListAndWatch, 除非收到消息stopCh要被关闭，Run才会退出。\nListAndWatch 书上把这一段讲得很详细了，我贴这段代码，是为了给下面的Kubernetes并发的章节用的，这里用到了GetResourceVersion setLastSyncResourceVersion等\nfunc (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { klog.V(3).Infof(\u0026#34;Listing and watching %v from %s\u0026#34;, r.expectedType, r.name) var resourceVersion string // Explicitly set \u0026#34;0\u0026#34; as resource version - it\u0026#39;s fine for the List() \t// to be served from cache and potentially be delayed relative to \t// etcd contents. Reflector framework will catch up via Watch() eventually. \toptions := metav1.ListOptions{ResourceVersion: \u0026#34;0\u0026#34;} if err := func() error { initTrace := trace.New(\u0026#34;Reflector \u0026#34; + r.name + \u0026#34; ListAndWatch\u0026#34;) defer initTrace.LogIfLong(10 * time.Second) var list runtime.Object var err error listCh := make(chan struct{}, 1) panicCh := make(chan interface{}, 1) go func() { defer func() { if r := recover(); r != nil { panicCh \u0026lt;- r } }() // 先List \tlist, err = r.listerWatcher.List(options) close(listCh) }() select { case \u0026lt;-stopCh: return nil case r := \u0026lt;-panicCh: panic(r) case \u0026lt;-listCh: } if err != nil { return fmt.Errorf(\u0026#34;%s: Failed to list %v: %v\u0026#34;, r.name, r.expectedType, err) } initTrace.Step(\u0026#34;Objects listed\u0026#34;) listMetaInterface, err := meta.ListAccessor(list) if err != nil { return fmt.Errorf(\u0026#34;%s: Unable to understand list result %#v: %v\u0026#34;, r.name, list, err) } resourceVersion = listMetaInterface.GetResourceVersion() initTrace.Step(\u0026#34;Resource version extracted\u0026#34;) items, err := meta.ExtractList(list) if err != nil { return fmt.Errorf(\u0026#34;%s: Unable to understand list result %#v (%v)\u0026#34;, r.name, list, err) } initTrace.Step(\u0026#34;Objects extracted\u0026#34;) if err := r.syncWith(items, resourceVersion); err != nil { return fmt.Errorf(\u0026#34;%s: Unable to sync list result: %v\u0026#34;, r.name, err) } initTrace.Step(\u0026#34;SyncWith done\u0026#34;) r.setLastSyncResourceVersion(resourceVersion) initTrace.Step(\u0026#34;Resource version updated\u0026#34;) return nil }(); err != nil { return err } resyncerrc := make(chan error, 1) cancelCh := make(chan struct{}) defer close(cancelCh) go func() { resyncCh, cleanup := r.resyncChan() defer func() { cleanup() // Call the last one written into cleanup \t}() for { select { case \u0026lt;-resyncCh: case \u0026lt;-stopCh: return case \u0026lt;-cancelCh: return } if r.ShouldResync == nil || r.ShouldResync() { klog.V(4).Infof(\u0026#34;%s: forcing resync\u0026#34;, r.name) if err := r.store.Resync(); err != nil { resyncerrc \u0026lt;- err return } } cleanup() resyncCh, cleanup = r.resyncChan() } }() for { // give the stopCh a chance to stop the loop, even in case of continue statements further down on errors \tselect { case \u0026lt;-stopCh: return nil default: } timeoutSeconds := int64(minWatchTimeout.Seconds() * (rand.Float64() + 1.0)) options = metav1.ListOptions{ ResourceVersion: resourceVersion, // We want to avoid situations of hanging watchers. Stop any wachers that do not \t// receive any events within the timeout window. \tTimeoutSeconds: \u0026amp;timeoutSeconds, } w, err := r.listerWatcher.Watch(options) if err != nil { switch err { case io.EOF: // watch closed normally \tcase io.ErrUnexpectedEOF: klog.V(1).Infof(\u0026#34;%s: Watch for %v closed with unexpected EOF: %v\u0026#34;, r.name, r.expectedType, err) default: utilruntime.HandleError(fmt.Errorf(\u0026#34;%s: Failed to watch %v: %v\u0026#34;, r.name, r.expectedType, err)) } // If this is \u0026#34;connection refused\u0026#34; error, it means that most likely apiserver is not responsive. \t// It doesn\u0026#39;t make sense to re-list all objects because most likely we will be able to restart \t// watch where we ended. \t// If that\u0026#39;s the case wait and resend watch request. \tif urlError, ok := err.(*url.Error); ok { if opError, ok := urlError.Err.(*net.OpError); ok { if errno, ok := opError.Err.(syscall.Errno); ok \u0026amp;\u0026amp; errno == syscall.ECONNREFUSED { time.Sleep(time.Second) continue } } } return nil } if err := r.watchHandler(w, \u0026amp;resourceVersion, resyncerrc, stopCh); err != nil { if err != errorStopRequested { klog.Warningf(\u0026#34;%s: watch of %v ended with: %v\u0026#34;, r.name, r.expectedType, err) } return nil } } } Kubernetes并发 从ListAndWatch的代码，有一段关于syncWith的方法，比较重要，原来Kubernetes的并发是通过ResourceVersion来实现的，每次对这个对象的改动，都会把该对象的ResourceVersion加一。\n二级缓存DeltaFIFO 和 Store DeltaFIFO 我们通过数据结构来理解DeltaFIFO，我们先来理解一下Delta。\n代码块staging/src/k8s.io/client-go/tools/cache/delta_fifo.go\n通过下面的代码块，我们可以非常清晰看得出，Delta其实是一个资源对象存储，保存例如Pod的Added操作等。用白话来说其实就是记录Kubernetes每一个对象的变化。\ntype Delta struct { Type DeltaType Object interface{} } type DeltaType string const ( Added DeltaType = \u0026#34;Added\u0026#34; Updated DeltaType = \u0026#34;Updated\u0026#34; Deleted DeltaType = \u0026#34;Deleted\u0026#34; Sync DeltaType = \u0026#34;Sync\u0026#34; ) FIFO就比较容易理解了，就是一个先进先出的队列。也可以看看代码块staging/src/k8s.io/client-go/tools/cache/fifo.go去看他的实现，如下\ntype Queue interface { Store // 可以看出来Queue是在Store的基础上扩展了Pop，可以让对象弹出。这里如果对比一下Indexer的数据结构发现很有意思，Indexer是在Store的基础上加了索引，去快速检索对象 \tPop(PopProcessFunc) (interface{}, error) AddIfNotPresent(interface{}) error HasSynced() bool Close() } 结合起来，DeltaFIFO其实就是一个先进先出的Kubernetes对象变化的队列，这个队列中存储不同操作类型的同一个资源对象。\nDeltaFIFO中的GET方法或者GetByKey都比较简单，接下来对queueActionLocked()函数重点说明。\nqueueActionLocked func (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { // 拿到对象的Key \tid, err := f.KeyOf(obj) if err != nil { return KeyError{obj, err} } // 把同一个对象的不同的actionType，都添加到newDeltas列表中 \tnewDeltas := append(f.items[id], Delta{actionType, obj}) // 合并去重 \tnewDeltas = dedupDeltas(newDeltas) // 我一开始理解不了，觉得不可能存在\u0026lt;=0的情况，最新的Kubernetes的代码里面注释说了，正常情况下不会出现\u0026lt;=0， 加这个判断属于冗余判断 \tif len(newDeltas) \u0026gt; 0 { if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas f.cond.Broadcast() } else { delete(f.items, id) } return nil } 看看去重的代码\nfunc dedupDeltas(deltas Deltas) Deltas { n := len(deltas) // 少于2个也就是得一个，不需要合并了，直接返回 \tif n \u0026lt; 2 { return deltas } a := \u0026amp;deltas[n-1] b := \u0026amp;deltas[n-2] // 这里，最后调了isDeletionDup，这个是判断一个资源对象的两次操作是否都是删除，如果是，就去重，不需要删除两次 \tif out := isDup(a, b); out != nil { d := append(Deltas{}, deltas[:n-2]...) return append(d, *out) } return deltas } func isDup(a, b *Delta) *Delta { if out := isDeletionDup(a, b); out != nil { return out } // TODO: Detect other duplicate situations? Are there any? \treturn nil } 之前群里有人问为什么dedupDeltas只是去这个列表的倒数第一个跟倒数第二个去进行合并去重的操作，这里说明一下，dedupDeltas是被queueActionLocked函数调用的，而queueActionLocked为什么我们拿出来讲，是因为在Delete/Update/Add里面去调用了queueActionLocked，合并是对某一个obj的一系列操作，而去重是只针对delete。\n我们可以拿一个例子来看看，假设是[obj1]: [add: delta1, update: delta2, delete: delta3, delete: delta3] 在经过queueActionLocked之后会变成[obj1]: [add: delta1, update: delta2, delete: delta3]\n消费者方法 func (f *DeltaFIFO) Pop(process PopProcessFunc) (interface{}, error) { f.lock.Lock() defer f.lock.Unlock() for { for len(f.queue) == 0 { // 任何时候判断队列是否被关闭之前，都需要先判断队列的长度，看上方的len \tif f.IsClosed() { return nil, FIFOClosedError } f.cond.Wait() } id := f.queue[0] f.queue = f.queue[1:] if f.initialPopulationCount \u0026gt; 0 { f.initialPopulationCount-- } item, ok := f.items[id] if !ok { // Item may have been deleted subsequently. \tcontinue } // 取出第一个f.queue[0]对象，从队列删除，将该对象交给process处理对象 \tdelete(f.items, id) err := process(item) if e, ok := err.(ErrRequeue); ok { // 处理失败，就重新入队 \tf.addIfNotPresent(id, item) err = e.Err } // Don\u0026#39;t need to copyDeltas here, because we\u0026#39;re transferring \t// ownership to the caller. \treturn item, err } } LocalStore 缓存机制，但LocalStore是被Lister的List/Get方法访问\nShare Informer 共享机制 从流程上我们说了，因为是DeltaFIFO把消息分发至ShareInformer中，因此我们可以用Informer添加自定义的回调函数，也就是我们经常看到的OnAdd OnUpdate和OnDelete\nKubernetes内部的每一个资源都实现了Informer机制，如下是一个Namespace的Informer的例子\n代码块staging/src/k8s.io/client-go/informers/core/v1/namespace.go\ntype NamespaceInformer interface { Informer() cache.SharedIndexInformer Lister() v1.NamespaceLister } Indexer 以下是Indexer的数据结构，清晰的看见Indexer继承了Store接口， 还增加了索引的功能。\ntype Indexer interface { Store Index(indexName string, obj interface{}) ([]interface{}, error) ... } 看看我们流程第四个步骤： DeltaFIFO是一个先进先出队列，只要这个队列有数据，就被Pop到Controller中, 将这个资源对象存储至Indexer中。 这个步骤说明了Indexer存储的数据来源。\n我们看看Indexer关键的几个索引函数\n// 索引函数，传入的是对象，返回的是检索结果的列表，例如我们可以通过IndexFunc去查某个Annotation/label的configmap type IndexFunc func(obj interface{}) ([]string, error) // 索引函数，key是索引器名词，value是索引器的实现函数 type Indexers map[string]IndexFunc // 索引函数name 对应多个索引键 多个对象键 真正对象 type Indices map[string]Index // 索引缓存，map类型 type Index map[string]sets.String 总结一下：\nIndexers: 索引函数name \u0026ndash;\u0026gt; 索引实现函数\u0026ndash;\u0026gt;索引key值 Indices: 索引函数name \u0026ndash;\u0026gt; 对应多个索引key值 \u0026ndash;\u0026gt; 每个索引key值对应不同的资源\n举个例子来说明的话：对象Pod有一个标签app=version1，这里标签就是索引键，Indexer会把相同标签的所有Pod放在一个集合里面，然后我们实现对标签分类就是我们Indexer的核心内容。\nReference 《Kubernetes 源码剖析》第五章\n","permalink":"https://cloudnative.to/blog/informer-study/","tags":["Kubernetes","源码理解","Informer"],"title":"Kubernetes Informer 机制源码解析"},{"categories":["Kubernetes"],"contents":"不管你关注不关注，云原生它走来了，它乘着万丈光芒的 Kubernetes 走来了；不管你承认不承认，Kubernetes 已经成为了云计算时代的操作系统。对于 Kubernetes，最为大家所熟知的就是它强大的容器编排能力（同为容器编排的还有 Mesos、Docker Swarm，但是 Kubernetes 已成一枝独秀），其实 Kubernetes 还有一个更强大的能力——扩展能力。如果只是利用 Kubernetes 内置的资源及 controller 类型，也就只能做到将应用“挪”到 Kubernetes 上，而不是真正的 Kubernetes 原生。如果利用 Kubernetes 的扩展能力，就可以将应用变成 Kubernetes 原生的了。\nKubernetes 扩展之 Operator Kubernetes 的扩展可以通过 Operator（Kubernetes API + CRD）来实现。在早期，为了实现一个 Operator，用户需要自己完成很多 Kubernetes 功能的实现，比如 Kubernetes Client 的创建，Kubernetes API Server 的监听等（这一点付业成老师在云原生社区直播分享 TiDB Operator 架构与实现的时候提到了，由于 TiDB Operator 开发初期，没有像本文要讲的主角—— Kubebuilder 等 Operator 框架出现的时候，很多功能都是由他们自己开发实现的。关于付业成老师的直播分享的相关文档，可以点击这儿查看。直播视频链接在文档底部，如下图）。\n但是在整个开发过程中，有些逻辑是所有 Operator 实现过程所必须的，因此就有了将这些所有 Operator 实现所必须的逻辑封装和抽象成了公共的库和工具，从而形成一些 Operator SDK，这样开发人员就可以将更多的精力放在 Operator 中与自己应用程序相关的逻辑实现上，加速了开发流程。而Kubebuilder正是这些 SDK 中的其中一个（其他的还有Operator SDK）。Kubebuilder 能够帮助我们生成一些 Scaffolding（脚手架）代码帮助初始化 CRD 功能，自动生成相应的配置，而且还提供了一些封装好的库供使用。\nKubebuilder 官网翻译 为了让国内用户学习 Kubebuilder 变得快捷，同时秉承云原生社区立社的宗旨——向中文用户推广普及云原生相关知识。云原生社区将 Kubebuilder 官方文档进行了汉化，整个翻译过程前后历时一个多月，由来自多个城市，多家公司的志愿者共同完成。Kubebuilder中文网站，可由下图指示直达：\n由于时间、人员分布及翻译习惯等因素，Kubebuilder 中文文档可能存在一些翻译问题，我们非常欢迎大家能在阅读的过程中给我们多提意见，我们会持续改进。可以通过微信找我们反映翻译问题，也可以在 GitHub上提 Issue，提 Issue 的方式和模版在中文文档页首，点击相应的链接即可，如下图所示：\n在此，非常感谢十多位志愿者的无私奉献，同时，为了响应社区大众想读 Envoy 中文版的要求（有1.7中文版，但距离最新版，差多个版本），云原生社区决定开启Enovy最新版的中文翻译工作，我们热忱欢迎对云原生感兴趣的志愿者加入我们，我们一起搞事情（可加微信 \u0026ldquo;jimmysongio\u0026quot;或者\u0026quot;majinghe11\u0026quot;并注明“Enovy 翻译”，我们拉你进群)。\n加入云原生社区，一起搞事情，我们等你！！！\n特别感谢 再次感谢以下参与 Kubebuilder 翻译的志愿者(排名不分先后，按字母排序)\n   姓名 GitHub 账号 姓名 GitHub 账号 姓名 GitHub 账号     官余棚 3ks 厉辉 Miss-you 梁斌 hzliangbin   刘晓敏 dk-lockdown 马景贺 lhb008 尚坤 skyshang1   申红磊 shenhonglei 宋净超 rootsongjc 文彦 vsxen   徐龙 long0419 许振文 helight 姚沈结 Luffy110   曾祥龙 alandtsang 张浩 zhangguanzhang      ","permalink":"https://cloudnative.to/blog/kubebuilder-summary/","tags":["Kubebuilder"],"title":"Kubebuilder 中文翻译总结"},{"categories":["Kubernetes"],"contents":" 本文主要根据书籍 《Kubernetes 源码剖析》的基础上，对 Client-go 部分的 Informer 机制进行了解与学习。\n Informer 机制 Kubernetes 中使用 http 进行通信，如何不依赖中间件的情况下保证消息的实时性，可靠性和顺序性等呢？答案就是利用了 Informer 机制。Informer 的机制，降低了了 Kubernetes 各个组件跟 Etcd 与 Kubernetes API Server 的通信压力。\nInformer 机制架构设计 图片源自 Client-go under the hood\n⚠️ 这张图分为两部分，黄色图标是开发者需要自行开发的部分，而其它的部分是 client-go 已经提供的，直接使用即可。\n Reflector：用于 Watch 指定的 Kubernetes 资源，当 watch 的资源发生变化时，触发变更的事件，比如 Added，Updated 和 Deleted 事件，并将资源对象存放到本地缓存 DeltaFIFO； DeltaFIFO：拆开理解，FIFO 就是一个队列，拥有队列基本方法（ADD，UPDATE，DELETE，LIST，POP，CLOSE 等），Delta 是一个资源对象存储，保存存储对象的消费类型，比如 Added，Updated，Deleted，Sync 等； Indexer：Client-go 用来存储资源对象并自带索引功能的本地存储，Reflector 从 DeltaFIFO 中将消费出来的资源对象存储到 Indexer，Indexer 与 Etcd 集群中的数据完全保持一致。从而 client-go 可以本地读取，减少 Kubernetes API 和 Etcd 集群的压力。  看书本上的一个例子，想使用 Informer 的关键流程如下：\nclientset, err := kubernetes.NewForConfig(config) stopCh := make(chan struct{}) defer close(stopch) sharedInformers := informers.NewSharedInformerFactory(clientset, time.Minute) informer := sharedInformer.Core().V1().Pods().Informer() informer.AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: func(obj interface{} { // ...  }, UpdateFunc: func(obj interface{} { // ...  }, DeleteFunc : func(obj interface{} { // ...  }) informer.Run(stopCh) })  Informer 需要通过 ClientSet 与 Kubernetes API Server 交互； 创建 stopCh 是用于在程序进程退出前通知 Informer 提前退出，Informer 是一个持久运行的 goroutine； NewSharedInformerFactory 实例化了一个 SharedInformer 对象，用于进行本地资源存储； sharedInformer.Core().V1().Pods().Informer() 得到了具体 Pod 资源的 informer 对象； AddEventHandler 即图中的第6步，这是一个资源事件回调方法，上例中即为当创建/更新/删除 Pod 时触发事件回调方法； 一般而言，其他组件使用 Informer 机制触发资源回调方法会将资源对象推送到 WorkQueue 或其他队列中，具体推送的位置要去回调方法里自行实现。  上面这个示例，当触发了 Add，Update 或者 Delete 事件，就通知 Client-go，告知 Kubernetes 资源事件发生变更并且需要进行相应的处理。\n 资源 Informer  每一个 k8s Resource 都实现了 Informer 机制，均有 Informer 和 Lister 方法，以 PodInformer 为例：\ntype PodInformer interface { Informer() cache.SharedIndexInformer Lister() v1.PodLister } Shared Informer 共享机制  Informer 又称为 Shared Informer，表明是可以共享使用的，在使用 client-go 写代码时，若同一资源的 Informer 被实例化太多次，每个 Informer 使用一个 Reflector，会运行过多的相同 ListAndWatch（即图中的第一步），太多重复的序列化和反序列化会导致 k8s API Server 负载过重。\n而 Shared Informer 通过对同一类资源 Informer 共享一个 Reflector 可以节约很多资源，这通过 map 数据结构即可实现这样一个共享 Informer 机制。\nvendor/k8s.io/client-go/informers/factory.go\ntype sharedInformerFactory struct { // ...  // map 数据结构 \tinformers map[reflect.Type]cache.SharedIndexInformer // ... } // ... // InternalInformerFor returns the SharedIndexInformer for obj using an internal client. // 当示例中调用 xxx.Informer() 时，内部调用了该方法 func (f *sharedInformerFactory) InformerFor(obj runtime.Object, newFunc internalinterfaces.NewInformerFunc) cache.SharedIndexInformer { f.lock.Lock() defer f.lock.Unlock() informerType := reflect.TypeOf(obj) informer, exists := f.informers[informerType] if exists { return informer } resyncPeriod, exists := f.customResync[informerType] if !exists { resyncPeriod = f.defaultResync } informer = newFunc(f.client, resyncPeriod) f.informers[informerType] = informer return informer } Reflector Reflector 用于 Watch 指定的 Kubernetes 资源，当 watch 的资源发生变化时，触发变更的事件，并将资源对象存放到本地缓存 DeltaFIFO。\n通过 NewReflector 实例化 Reflector 对象，实例化过程必须传入 ListerWatcher 数据接口对象，它拥有 List 和 Watch 方法。Reflector 对象通过 Run 行数启动监控并处理监控事件，在实现中，其核心为 ListAndWatch 函数。\n以 Example 的代码为例，我们在最后一步执行了 informer.Run(stopCh)，内部会执行一个 ListAndWatch 方法：\nvendor/k8s.io/client-go/tools/cache/reflector.go\n// Run 执行一个 watch 并且把握所有的 watch events，watch 关闭后会重启 // stopCh 关闭时 Run 退出 func (r *Reflector) Run(stopCh \u0026lt;-chan struct{}) { klog.V(3).Infof(\u0026#34;Starting reflector %v (%s) from %s\u0026#34;, r.expectedType, r.resyncPeriod, r.name) wait.Until(func() { if err := r.ListAndWatch(stopCh); err != nil { utilruntime.HandleError(err) } }, r.period, stopCh) }  获取资源数据列表  以之前提过的 Example 的代码为例，通过 Run 获取了所有 Pod 的资源数据，List 流程如下：\n r.ListWatcher.List 获取资源数据； listMetaInterface.GetResourceVersion 获取资源版本号； meta.ExtractList 将资源数据转换为资源对象列表； r.SyncWith 将资源对象列表的资源对象和资源版本号存储到 DeltaFIFO 中； r.setLastSyncResourceVersion 设置最新的资源版本号。  具体的，\n r.ListWatcher.List 根据 ResourceVersion 获取资源下的所有对象数据。以 Example 为例，该方法调用的就是 Pod Informer 下的 ListFunc 函数，通过 ClientSet 客户端与 Kubernetes API Server 交互并获取 Pod 资源列表数据； listMetaInterface.GetResourceVersion 获取 ResourceVersion，即资源版本号，注意这里的资源版本号并不是指前面各个客户端的不同 kind 的不同 Version，所有资源都拥有 ResourceVersion，标识当前资源对象的版本号。每次修改 etcd 集群中存储的对象时，Kubernetes API Server 都会更改 ResourceVersion，使得 client-go 执行 watch 时可以根据 ResourceVersion 判断当前资源对象是否发生变化； meta.ExtractList 将 runtime.Object 对象转换为 []runtime.Object 对象。因为 r.ListWatcher.List 获取的是资源下所有对象的数据，因此应当是一个列表； r.SyncWith 将结果同步到 DeltaFIFO 中； r.setLastSyncResourceVersion 设置最新的资源版本号。  监控资源对象  Watch 通过 HTTP 协议与 Kubernetes API Server 建立长连接，接收 Kubernetes API Server 发来的资源变更事件。Watch 操作的实现机制使用 HTTP 协议的分块传输编码——当 client-go 调用 Kubernetes API Server 时，Kubernetes API Server 在 Response 的 HTTP Header 中设置 Transfer-Encoding 的值为 chunked，表示采用分块传输编码，客户端收到消息后，与服务端进行连接，并等待下一个数据块。\n在源码中关键为 watch 和 watchHandler 函数：\nstaging/src/k8s.io/client-go/tools/cache/reflector.go\nfunc (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { // 前面提到的 list 部分代码  // watch part \tfor { // 收到 stopCh 停止循环 \tselect { case \u0026lt;-stopCh: return nil default: } // ... \toptions = metav1.ListOptions{ ResourceVersion: resourceVersion, // 设置超时时间避免将 watchers 挂起 \tTimeoutSeconds: \u0026amp;timeoutSeconds, } w, err := r.listerWatcher.Watch(options) // error handling 部分  // 另一个核心函数 watchHandler，后文介绍 \tif err := r.watchHandler(w, \u0026amp;resourceVersion, resyncerrc, stopCh); err != nil { if err != errorStopRequested { klog.Warningf(\u0026#34;%s: watch of %v ended with: %v\u0026#34;, r.name, r.expectedType, err) } return nil } } } 以之前的 Example 为例子，r.listerWatcher.Watch 实际调用了 Pod Informer 下的 Watch 函数，通过 ClientSet 客户端与 Kubernetes API Server 建立长链接，监控指定资源的变更事件，如下：\nstaging/src/k8s.io/client-go/informers/core/v1/pod.go\nfunc NewFilteredPodInformer(...) cache.SharedIndexInformer { return cache.NewSharedIndexInformer( // ... \tWatchFunc: func(options metav1.ListOptions) (watch.Interface, error) { if tweakListOptions != nil { tweakListOptions(\u0026amp;options) } return client.CoreV1().Pods(namespace).Watch(options) }, }, // ... \t) } r.watchHandler 处理资源的变更事件，将对应资源更新到本地缓存 DeltaFIFO 并更新 ResourceVersion 资源版本号。\n// watchHandler watches w and keeps *resourceVersion up to date. func (r *Reflector) watchHandler(w watch.Interface, resourceVersion *string, errc chan error, stopCh \u0026lt;-chan struct{}) error { start := r.clock.Now() eventCount := 0 defer w.Stop() // 循环嵌套循环时，在 break 后指定标签。用标签决定哪个循环被终止 loop: for { select { case \u0026lt;-stopCh: return errorStopRequested case err := \u0026lt;-errc: return err case event, ok := \u0026lt;-w.ResultChan(): if !ok { // 直接跳出 for 循环 \tbreak loop } // ... \tnewResourceVersion := meta.GetResourceVersion() switch event.Type { case watch.Added: err := r.store.Add(event.Object) // ... \tcase watch.Modified: err := r.store.Update(event.Object) // ... \tcase watch.Deleted: err := r.store.Delete(event.Object) // ... \tdefault: // ... \t} *resourceVersion = newResourceVersion r.setLastSyncResourceVersion(newResourceVersion) eventCount++ } } // ... } DeltaFIFO DeltaFIFO 拆开理解，FIFO 就是一个队列，拥有队列基本方法（ADD，UPDATE，DELETE，LIST，POP，CLOSE 等），Delta 是一个资源对象存储，保存存储对象的消费类型，比如 Added，Updated，Deleted，Sync 等。\n看 DeltaFIFO 的数据结构：\nvendor/k8s.io/client-go/tools/cache/delta_fifo.go\ntype DeltaFIFO struct { // lock/cond protects access to \u0026#39;items\u0026#39; and \u0026#39;queue\u0026#39;. \tlock sync.RWMutex cond sync.Cond // We depend on the property that items in the set are in \t// the queue and vice versa, and that all Deltas in this \t// map have at least one Delta. \titems map[string]Deltas queue []string // ... } 其中，Deltas 部分的数据结构如下：\nstaging/src/k8s.io/client-go/tools/cache/delta_fifo.go\n// DeltaType is the type of a change (addition, deletion, etc) type DeltaType string // Delta is the type stored by a DeltaFIFO. It tells you what change // happened, and the object\u0026#39;s state after* that change. type Delta struct { Type DeltaType Object interface{} } // Deltas is a list of one or more \u0026#39;Delta\u0026#39;s to an individual object. // The oldest delta is at index 0, the newest delta is the last one. type Deltas []Delta DeltaFIFO 会保留所有关于资源对象（obj）的操作类型，队列中会存在拥有不同操作类型的同一资源对象，使得消费者在处理该资源对象时能够了解资源对象所发生的事情。queue 字段存储资源对象的 key，这个 key 通过 KeyOf 函数计算得到，items 字段通过 map 数据结构的方式存储，value 存储的是对象 Deltas 数组，一个结构示例图如下：\n ┌───────┐┌───────┐┌───────┐ queue │ObjKey1││ObjKey2││ObjKey3│ └───────┘└───────┘└───────┘ ┌─────────────────────────────────────────────────────────────┐ itmes │ObjKey1: [{\u0026quot;Added\u0026quot;,Obj1} {\u0026quot;Updated\u0026quot;,Obj1}] │ ├─────────────────────────────────────────────────────────────┤ │ObjKey2: [{\u0026quot;Added\u0026quot;,Obj2},{\u0026quot;Deleted\u0026quot;,Obj2},{\u0026quot;Sync\u0026quot;,Obj2}] │ ├─────────────────────────────────────────────────────────────┤ │ObjKey3: [{\u0026quot;Added\u0026quot;,Obj3},{\u0026quot;Updated\u0026quot;,Obj3},{\u0026quot;Deleted\u0026quot;,Obj3}] │ └─────────────────────────────────────────────────────────────┘ 作为一个 FIFO 的队列，有数据的生产者和消费者，其中生产者是 Reflector 调用的 Add 方法，消费者是 Controller 调用的 Pop 方法。三个核心方法为生产者方法，消费者方法和 Resync 机制。\n生产者方法 DeltaFIFO 队列中的资源对象在调用 Added，Updated，Deleted 等事件时都调用了 queueActionLocked 函数：\n它是 DeltaFIFO 实现的关键：\nvendor/k8s.io/client-go/tools/cache/delta_fifo.go\n// queueActionLocked 为一个 delta list 添加一个 object // 调用方必须先上锁 func (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { // 通过 KeyOf 函数计算出对象的 key \tid, err := f.KeyOf(obj) if err != nil { return KeyError{obj, err} } // 将 actionType 以及对应的 id 添加到 items 中，并通过 dedupDeltas 对数组中最新的两次添加进行去重 \tnewDeltas := append(f.items[id], Delta{actionType, obj}) newDeltas = dedupDeltas(newDeltas) // 一般不会出现 \u0026lt;= 0， 属冗余判断 \tif len(newDeltas) \u0026gt; 0 { if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas // 广播所有消费者解除阻塞 \tf.cond.Broadcast() } else { delete(f.items, id) } return nil }  通过 KeyOf 函数计算出对象的 key； 将 actionType 以及对应的 id 添加到 items 中，并通过 dedupDeltas 对数组中最新的两次添加进行去重； 更新构造后的 Deleta 并通过 cond.Broadcast() 广播所有消费者解除阻塞。  消费者方法 Pop 函数作为消费者使用方法，从 DeltaFIFO 的头部取出最早进入队列中的资源对象数据。Pop 方法必须传入 process 函数，用于接收并处理对象的回调方法，如下：\nvendor/k8s.io/client-go/tools/cache/delta_fifo.go\nfunc (f *DeltaFIFO) Pop(process PopProcessFunc) (interface{}, error) { f.lock.Lock() defer f.lock.Unlock() for { for len(f.queue) == 0 { // 空队列时阻塞 Pop 方法 \tif f.IsClosed() { return nil, FIFOClosedError } f.cond.Wait() } id := f.queue[0] f.queue = f.queue[1:] if f.initialPopulationCount \u0026gt; 0 { f.initialPopulationCount-- } item, ok := f.items[id] if !ok { // Item may have been deleted subsequently. \tcontinue } // 注意这里在执行之前会把该 obj 旧的 delta 数据清空 \tdelete(f.items, id) err := process(item) if e, ok := err.(ErrRequeue); ok { f.addIfNotPresent(id, item) err = e.Err } return item, err } } 首先，使用 f.lock.Lock() 确保了数据的同步，当队列不为空时，取出 f.queue 的头部数据，将对象传入 process 回调函数，由上层消费者进行处理，如果 process 回调方法处理出错，将该对象重新存入队列。\nController 的 processLoop 方法负责从 DeltaFIFO 队列中取出数据传递给 process 回调函数，process 函数的类型如下：\ntype PopProcessFunc func(interface{}) error 一个 process 回调函数代码示例如下：\nvendor/k8s.io/client-go/tools/cache/shared_informer.go\nfunc (s *sharedIndexInformer) HandleDeltas(obj interface{}) error { s.blockDeltas.Lock() defer s.blockDeltas.Unlock() // from oldest to newest \tfor _, d := range obj.(Deltas) { switch d.Type { case Sync, Added, Updated: isSync := d.Type == Sync s.cacheMutationDetector.AddObject(d.Object) if old, exists, err := s.indexer.Get(d.Object); err == nil \u0026amp;\u0026amp; exists { if err := s.indexer.Update(d.Object); err != nil { return err } s.processor.distribute(updateNotification{oldObj: old, newObj: d.Object}, isSync) } else { if err := s.indexer.Add(d.Object); err != nil { return err } s.processor.distribute(addNotification{newObj: d.Object}, isSync) } case Deleted: if err := s.indexer.Delete(d.Object); err != nil { return err } s.processor.distribute(deleteNotification{oldObj: d.Object}, false) } } return nil } 在这个例子中，HandleDeltas 作为 process 的一个回调函数，当资源对象操作类型为 Added，Updated 和 Delted 时，该资源对象存储至 Indexer（它是并发安全的），并通过 distribute 函数将资源对象分发到 SharedInformer，在之前 Informer 机制架构设计的示例代码中，通过 informer.AddEventHandler 函数添加了对资源事件进行处理的函数，distribute 函数将资源对象分发到该事件处理函数。\nResync 机制  本节内容主要参考自 【提问】Informer 中为什么需要引入 Resync 机制？\n Resync 机制会将 Indexer 本地存储中的资源对象同步到 DeltaFIFO 中，并将这些资源对象设置为 Sync 的操作类型，\n// 重新同步一次 Indexer 缓存数据到 Delta FIFO func (f *DeltaFIFO) Resync() error { f.lock.Lock() defer f.lock.Unlock() if f.knownObjects == nil { return nil } // 遍历 indexer 中的 key，传入 syncKeyLocked 中处理 \tkeys := f.knownObjects.ListKeys() for _, k := range keys { if err := f.syncKeyLocked(k); err != nil { return err } } return nil } func (f *DeltaFIFO) syncKeyLocked(key string) error { obj, exists, err := f.knownObjects.GetByKey(key) if err != nil { klog.Errorf(\u0026#34;Unexpected error %v during lookup of key %v, unable to queue object for sync\u0026#34;, err, key) return nil } else if !exists { klog.Infof(\u0026#34;Key %v does not exist in known objects store, unable to queue object for sync\u0026#34;, key) return nil } // 若 FIFO 队列中已经有相同 key 的 event 进来了，说明该资源对象有了新的 event， \t// Indexer 中旧的缓存失效，直接返回 nil \tid, err := f.KeyOf(obj) if err != nil { return KeyError{obj, err} } if len(f.items[id]) \u0026gt; 0 { return nil } // 重新放入 FIFO 队列中 \tif err := f.queueActionLocked(Sync, obj); err != nil { return fmt.Errorf(\u0026#34;couldn\u0026#39;t queue object: %v\u0026#34;, err) } return nil } 为什么需要 Resync 机制呢？因为在处理 SharedInformer 事件回调时，可能存在处理失败的情况，定时的 Resync 让这些处理失败的事件有了重新 onUpdate 处理的机会。\n那么经过 Resync 重新放入 Delta FIFO 队列的事件，和直接从 apiserver 中 watch 得到的事件处理起来有什么不一样呢？在消费者方法中有介绍过 HandleDeltas，其中就有关于 Resync 的部分：\nfunc (s *sharedIndexInformer) HandleDeltas(obj interface{}) error { // 上锁  for _, d := range obj.(Deltas) { // 判断事件类型 \tswitch d.Type { case Sync, Replaced, Added, Updated: s.cacheMutationDetector.AddObject(d.Object) if old, exists, err := s.indexer.Get(d.Object); err == nil \u0026amp;\u0026amp; exists { if err := s.indexer.Update(d.Object); err != nil { return err } isSync := false switch { case d.Type == Sync: // 如果是通过 Resync 重新同步得到的事件则做个标记 \tisSync = true case d.Type == Replaced: ... } // 如果是通过 Resync 重新同步得到的事件，则触发 onUpdate 回调 \ts.processor.distribute(updateNotification{oldObj: old, newObj: d.Object}, isSync) } else { if err := s.indexer.Add(d.Object); err != nil { return err } s.processor.distribute(addNotification{newObj: d.Object}, false) } case Deleted: if err := s.indexer.Delete(d.Object); err != nil { return err } s.processor.distribute(deleteNotification{oldObj: d.Object}, false) } } return nil } 从上面对 Delta FIFO 的队列处理源码可看出，当从 Resync 重新同步到 Delta FIFO 队列的事件，会分发到 updateNotification 中触发 onUpdate 的回调。Resync 机制的引入，定时将 Indexer 缓存事件重新同步到 Delta FIFO 队列中，在处理 SharedInformer 事件回调时，让处理失败的事件得到重新处理。并且通过入队前判断 FIFO 队列中是否已经有了更新版本的 event，来决定是否丢弃 Indexer 缓存不进行 Resync 入队。在处理 Delta FIFO 队列中的 Resync 的事件数据时，触发 onUpdate 回调来让事件重新处理。\nIndexer Client-go 用来存储资源对象并自带索引功能的本地存储，Reflector 从 DeltaFIFO 中将消费出来的资源对象存储到 Indexer，Indexer 与 Etcd 集群中的数据完全保持一致。从而 client-go 可以本地读取，减少 Kubernetes API 和 Etcd 集群的压力。\n了解 Indexer 之前，先了解 ThreadSafeMap，ThreadSafeMap 是实现并发安全存储，就像 Go 1.9 后推出 sync.Map 一样。Kubernetes 开始编写的时候还没有 sync.Map。Indexer 在 ThreadSafeMap 的基础上进行了封装，继承了 ThreadSafeMap 的存储相关的增删改查相关操作方法，实现了 Indexer Func 等功能，例如 Index，IndexKeys，GetIndexers 等方法，这些方法为 ThreadSafeMap 提供了索引功能。如下图：\n ┌───────────────┐ ┌──────────────┐ │ Indeices │---\u0026gt;│ Index │ └───────────────┘ └──────────────┘ ┌───────────────┐ ┌──────────────┐ │ Indexers │---\u0026gt;│ IndexFun │ └───────────────┘ └──────────────┘ ┌───────────────────────────────────┐ │ ThreadSafeStore │ └───────────────────────────────────┘ ThreadSafeStore ThreadSafeStore 是一个内存中存储，数据不会写入本地磁盘，增删改查都会加锁，保证数据一致性。结构如下：\nvendor/k8s.io/client-go/tools/cache/store.go\n// threadSafeMap implements ThreadSafeStore type threadSafeMap struct { lock sync.RWMutex items map[string]interface{} // indexers maps a name to an IndexFunc \tindexers Indexers // indices maps a name to an Index \tindices Indices } items 字段存储资源对象数据，其中 items 的 key 通过 keyFunc 函数计算得到，计算默认使用 MetaNamespaceKeyFunc 函数，该函数根据资源对象计算出 \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; 格式的 key，value 用于存储资源对象。\n而后面两个字段的定义类型如下：\nvendor/k8s.io/client-go/tools/cache/index.go\n// Index maps the indexed value to a set of keys in the store that match on that value type Index map[string]sets.String // Indexers maps a name to a IndexFunc type Indexers map[string]IndexFunc // Indices maps a name to an Index type Indices map[string]Index Indexer 索引器 每次增删改 ThreadSafeStore 的数据时，都会通过 updateIndices 或 deleteFormIndices 函数变更 Indexer。Indexer 被设计为可以自定义索引函数，他有重要的四个数据结构，Indexers，IndexFunc，Indices 和 Index。\n看下面这个例子的关键流程：\nfunc UsersIndexFunc(obj interfaces{}) ([]string, error) { pod := obj.(*v1.Pod) usersString := pod.Annotations[\u0026#34;users\u0026#34;] return strings.Split(userString, \u0026#34;,\u0026#34;), nil } func main() { index := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{\u0026#34;byUser\u0026#34;: UsersIndexFunc}) pod1 := \u0026amp;v1.Pod{ObjectMeta: metav1.ObjectMeta{Name: \u0026#34;one\u0026#34;, Annotations: map[string]string{\u0026#34;users\u0026#34;: \u0026#34;ernie,bert\u0026#34;}}} // Initialize pod2 and pod3  index.Add(pod1) // Add pod2 and pod3  erniePods, err := omdex.ByIndex(\u0026#34;byUser\u0026#34;, \u0026#34;ernie\u0026#34;) } 首先定义了一个索引器函数（IndexFunc），UsersIndexFunc。该函数定义查询所有 Pod 资源下 Annotations 字段的 key 为 users 的 Pod：\nfunc UsersIndexFunc(obj interfaces{}) ([]string, error) { pod := obj.(*v1.Pod) usersString := pod.Annotations[\u0026#34;users\u0026#34;] return strings.Split(userString, \u0026#34;,\u0026#34;), nil } Main 函数中 cache.NewIndexer 实例化了一个 Indexer 对象：\nindex := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{\u0026#34;byUser\u0026#34;: UsersIndexFunc}) 第一个参数计算资源对象的 key，默认就是 MetaNamespaceKeyFunc，第二个参数是一个 Indexers 对象，如上一节展示的定义那样，key 为索引器（IndexFunc）的名称，value 为索引器函数。\n通过 index.Add 添加了三个 Pod，再通过 index.ByIndex 函数查询使用 byUser 索引器下匹配 ernie 字段的 Pod 列表：\nerniePods, err := index.ByIndex(\u0026#34;byUser\u0026#34;, \u0026#34;ernie\u0026#34;) 回看这四个类型：\n// Indexers maps a name to a IndexFunc type Indexers map[string]IndexFunc // IndexFunc knows how to provide an indexed value for an object. type IndexFunc func(obj interface{}) ([]string, error) // Indices maps a name to an Index type Indices map[string]Index // Index maps the indexed value to a set of keys in the store that match on that value type Index map[string]sets.String  Indexers：存储索引器，key 为 索引器名称，value 为索引器实现函数； IndexFunc：索引器函数，定义为接收一个资源对象，返回检索结果列表； Indices：存储缓存器，key 为缓存器名称，value 为缓存数据； Index：存储缓存数据，结构为 K/V。  Indexer 索引器核心实现 vendor/k8s.io/client-go/tools/cache/thread_safe_store.go\n// ByIndex returns a list of items that match an exact value on the index function func (c *threadSafeMap) ByIndex(indexName, indexKey string) ([]interface{}, error) { c.lock.RLock() defer c.lock.RUnlock() indexFunc := c.indexers[indexName] if indexFunc == nil { return nil, fmt.Errorf(\u0026#34;Index with name %s does not exist\u0026#34;, indexName) } index := c.indices[indexName] set := index[indexKey] list := make([]interface{}, 0, set.Len()) for _, key := range set.List() { list = append(list, c.items[key]) } return list, nil } ByIndex 接收两个参数：indexName（索引器名字）以及 indexKey（需要检索的 key），首先从 c.indexers 查找制定的索引器函数，然后从 c.indices 查找返回的缓存器函数，最后根据需要索引的 indexKey 从缓存数据中查到并返回。\n⚠️ K8s 将 map 结构类型的 key 作为 Set 数据结构，实现 Set 去重特性。\n总结 本文从 Informer 的整体架构开始说起，介绍了各个核心组件的功能和作用，Kubernetes 之所以设计这样一个机制架构，核心是为了减少 Ectd 和 Kubernetes API Server 的压力，增强集群的稳定性。\n","permalink":"https://cloudnative.to/blog/client-go-informer-source-code/","tags":["Kubernetes","源码理解","Informer"],"title":"深入了解 Kubernetes Informer"},{"categories":["Kubernetes"],"contents":"Informer原理图 为了便于理解，先上两张图。\n源码的调用流程图 可以对照着图中的代码文件及代码行数跟下代码。\n注: 图中的代码行数基于1.15版。\n数据结构图 Informer 工厂 先来看下cmd/kube-controller-manager/app/controllermanager.go:162的Run方法。\nfunc Run(c *config.CompletedConfig, stopCh \u0026lt;-chan struct{}) error { ... run := func(ctx context.Context) { rootClientBuilder := controller.SimpleControllerClientBuilder{ ClientConfig: c.Kubeconfig, } var clientBuilder controller.ControllerClientBuilder if c.ComponentConfig.KubeCloudShared.UseServiceAccountCredentials { if len(c.ComponentConfig.SAController.ServiceAccountKeyFile) == 0 { // It\u0026#39;s possible another controller process is creating the tokens for us. \t// If one isn\u0026#39;t, we\u0026#39;ll timeout and exit when our client builder is unable to create the tokens. \tklog.Warningf(\u0026#34;--use-service-account-credentials was specified without providing a --service-account-private-key-file\u0026#34;) } if shouldTurnOnDynamicClient(c.Client) { klog.V(1).Infof(\u0026#34;using dynamic client builder\u0026#34;) //Dynamic builder will use TokenRequest feature and refresh service account token periodically \tclientBuilder = controller.NewDynamicClientBuilder( restclient.AnonymousClientConfig(c.Kubeconfig), c.Client.CoreV1(), \u0026#34;kube-system\u0026#34;) } else { klog.V(1).Infof(\u0026#34;using legacy client builder\u0026#34;) clientBuilder = controller.SAControllerClientBuilder{ ClientConfig: restclient.AnonymousClientConfig(c.Kubeconfig), CoreClient: c.Client.CoreV1(), AuthenticationClient: c.Client.AuthenticationV1(), Namespace: \u0026#34;kube-system\u0026#34;, } } } else { clientBuilder = rootClientBuilder } controllerContext, err := CreateControllerContext(c, rootClientBuilder, clientBuilder, ctx.Done()) if err != nil { klog.Fatalf(\u0026#34;error building controller context: %v\u0026#34;, err) } saTokenControllerInitFunc := serviceAccountTokenControllerStarter{rootClientBuilder: rootClientBuilder}.startServiceAccountTokenController if err := StartControllers(controllerContext, saTokenControllerInitFunc, NewControllerInitializers(controllerContext.LoopMode), unsecuredMux); err != nil { klog.Fatalf(\u0026#34;error starting controllers: %v\u0026#34;, err) } controllerContext.InformerFactory.Start(controllerContext.Stop) controllerContext.GenericInformerFactory.Start(controllerContext.Stop) close(controllerContext.InformersStarted) select {} } } ... 上面代码中比较重要的几个方法CreateControllerContext, StartControllers, controllerContext.InformerFactory.Start。\n创建ControllerContext 再次进入CreateControllerContext方法中, 一直跟下去, 最终会调用到vendor/k8s.io/client-go/informers/factory.go:108的NewSharedInformerFactoryWithOptions方法。\nfunc NewSharedInformerFactoryWithOptions(client kubernetes.Interface, defaultResync time.Duration, options ...SharedInformerOption) SharedInformerFactory { factory := \u0026amp;sharedInformerFactory{ client: client, namespace: v1.NamespaceAll, defaultResync: defaultResync, informers: make(map[reflect.Type]cache.SharedIndexInformer), startedInformers: make(map[reflect.Type]bool), customResync: make(map[reflect.Type]time.Duration), } // Apply all options \tfor _, opt := range options { factory = opt(factory) } return factory } 从上面的代码中, sharedInformerFactory结构体中，有一个informers的map，这个map的key为资源类型，value为关注该资源类型的Informer。\n启动所有内置的Controller 再来看StartControllers方法, 调用StartControllers之前, 会先调用NewControllerInitializers方法。\nfunc NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc { controllers := map[string]InitFunc{} ... controllers[\u0026#34;deployment\u0026#34;] = startDeploymentController ... return controllers } 通过这个方法可以返回所有的内置controller, 这里map中的value存的只是相应的回调函数, 此时还没调用, 在StartControllers方法中会实际调用。\n接下来调用StartControllers方法。\nfunc StartControllers(ctx ControllerContext, startSATokenController InitFunc, controllers map[string]InitFunc, unsecuredMux *mux.PathRecorderMux) error { ... for controllerName, initFn := range controllers { ... debugHandler, started, err := initFn(ctx) ... } return nil } 这里循环NewControllerInitializers方法返回的所有controller, 取到map的value, 然后调用.\n启动各个Controller 再来看上一步的initFn, 也就是各个startXXXController方法, 我们以startDeploymentController为例,\nfunc startDeploymentController(ctx ControllerContext) (http.Handler, bool, error) { if !ctx.AvailableResources[schema.GroupVersionResource{Group: \u0026#34;apps\u0026#34;, Version: \u0026#34;v1\u0026#34;, Resource: \u0026#34;deployments\u0026#34;}] { return nil, false, nil } dc, err := deployment.NewDeploymentController( ctx.InformerFactory.Apps().V1().Deployments(), ctx.InformerFactory.Apps().V1().ReplicaSets(), ctx.InformerFactory.Core().V1().Pods(), ctx.ClientBuilder.ClientOrDie(\u0026#34;deployment-controller\u0026#34;), ) if err != nil { return nil, true, fmt.Errorf(\u0026#34;error creating Deployment controller: %v\u0026#34;, err) } go dc.Run(int(ctx.ComponentConfig.DeploymentController.ConcurrentDeploymentSyncs), ctx.Stop) return nil, true, nil } deployment.NewDeploymentController函数创建了Deployment Controller，而该创建函数的前三个参数分别为 Deployment、ReplicaSet、Pod 的 Informer. 可以看到, Informer的单例工厂以 ApiGroup 为路径提供了不同资源的 Informer.\n.Apps().V1().Deployments()方法返回的虽然叫DeploymentInformer, 但这不是真正的Informer\nfunc (v *version) Deployments() DeploymentInformer { return \u0026amp;deploymentInformer{factory: v.factory, namespace: v.namespace, tweakListOptions: v.tweakListOptions} } 真正的Informer是在调用NewDeploymentController -\u0026gt; dInformer.Informer() -\u0026gt; f.factory.InformerFor方法创建的\nfunc NewDeploymentController(dInformer appsinformers.DeploymentInformer, rsInformer appsinformers.ReplicaSetInformer, podInformer coreinformers.PodInformer, client clientset.Interface) (*DeploymentController, error) { eventBroadcaster := record.NewBroadcaster() eventBroadcaster.StartLogging(klog.Infof) eventBroadcaster.StartRecordingToSink(\u0026amp;v1core.EventSinkImpl{Interface: client.CoreV1().Events(\u0026#34;\u0026#34;)}) if client != nil \u0026amp;\u0026amp; client.CoreV1().RESTClient().GetRateLimiter() != nil { if err := metrics.RegisterMetricAndTrackRateLimiterUsage(\u0026#34;deployment_controller\u0026#34;, client.CoreV1().RESTClient().GetRateLimiter()); err != nil { return nil, err } } dc := \u0026amp;DeploymentController{ client: client, eventRecorder: eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource{Component: \u0026#34;deployment-controller\u0026#34;}), queue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;deployment\u0026#34;), } dc.rsControl = controller.RealRSControl{ KubeClient: client, Recorder: dc.eventRecorder, } dInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: dc.addDeployment, UpdateFunc: dc.updateDeployment, // This will enter the sync loop and no-op, because the deployment has been deleted from the store. \tDeleteFunc: dc.deleteDeployment, }) rsInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: dc.addReplicaSet, UpdateFunc: dc.updateReplicaSet, DeleteFunc: dc.deleteReplicaSet, }) podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ DeleteFunc: dc.deletePod, }) dc.syncHandler = dc.syncDeployment dc.enqueueDeployment = dc.enqueue dc.dLister = dInformer.Lister() dc.rsLister = rsInformer.Lister() dc.podLister = podInformer.Lister() dc.dListerSynced = dInformer.Informer().HasSynced dc.rsListerSynced = rsInformer.Informer().HasSynced dc.podListerSynced = podInformer.Informer().HasSynced return dc, nil } # staging/src/k8s.io/client-go/informers/apps/v1/deployment.go:83 func (f *deploymentInformer) Informer() cache.SharedIndexInformer { return f.factory.InformerFor(\u0026amp;appsv1.Deployment{}, f.defaultInformer) } # staging/src/k8s.io/client-go/informers/apps/v1/deployment.go:79 func (f *deploymentInformer) defaultInformer(client kubernetes.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer { return NewFilteredDeploymentInformer(client, f.namespace, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}, f.tweakListOptions) } # staging/src/k8s.io/client-go/informers/factory.go:163 func (f *sharedInformerFactory) InformerFor(obj runtime.Object, newFunc internalinterfaces.NewInformerFunc) cache.SharedIndexInformer { f.lock.Lock() defer f.lock.Unlock() informerType := reflect.TypeOf(obj) informer, exists := f.informers[informerType] if exists { return informer } resyncPeriod, exists := f.customResync[informerType] if !exists { resyncPeriod = f.defaultResync } informer = newFunc(f.client, resyncPeriod) f.informers[informerType] = informer return informer } 从上面的InformerFor方法可以看到,\n 如果Informer工厂里已经存在informer, 就直接返回了, 也就是说一种资源始终只有一个informer 如果不存在, 则调用传进来的参数newFunc实例化informer(注: newFunc即为defaultInformer, 返回的类型为cache.SharedIndexInformer  至此, DeploymentInformer被实例化，并真正的承担Informer的职责, 同时添加到Informer工厂的map中.\nInformerFactory启动 func (f *sharedInformerFactory) Start(stopCh \u0026lt;-chan struct{}) { f.lock.Lock() defer f.lock.Unlock() for informerType, informer := range f.informers { if !f.startedInformers[informerType] { go informer.Run(stopCh) f.startedInformers[informerType] = true } } } # staging/src/k8s.io/client-go/tools/cache/shared_informer.go:242 func (s *sharedIndexInformer) Run(stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() fifo := NewDeltaFIFO(MetaNamespaceKeyFunc, s.indexer) cfg := \u0026amp;Config{ Queue: fifo, ListerWatcher: s.listerWatcher, ObjectType: s.objectType, FullResyncPeriod: s.resyncCheckPeriod, RetryOnError: false, ShouldResync: s.processor.shouldResync, Process: s.HandleDeltas, } func() { s.startedLock.Lock() defer s.startedLock.Unlock() s.controller = New(cfg) s.controller.(*controller).clock = s.clock s.started = true }() // Separate stop channel because Processor should be stopped strictly after controller \tprocessorStopCh := make(chan struct{}) var wg wait.Group defer wg.Wait() // Wait for Processor to stop \tdefer close(processorStopCh) // Tell Processor to stop \twg.StartWithChannel(processorStopCh, s.cacheMutationDetector.Run) wg.StartWithChannel(processorStopCh, s.processor.run) defer func() { s.startedLock.Lock() defer s.startedLock.Unlock() s.stopped = true // Don\u0026#39;t want any new listeners \t}() s.controller.Run(stopCh) } sharedIndexInformer的Run方法代码不多，但是很重要，这块逻辑即为第一张图中粉红色的地方，主要做了下面几件事：\n 初始化fifo队列 初始化controller 启动cacheMutationDetector 启动processor 运行controller(此controller非XXXController)  接下来, 看下这几件事情的详细过程\nsharedIndexInformer 我们先把视线拉回到上面第一张图片的最右侧, 因为这块做了一些初始化的工作，以便后面的逻辑使用。\nfunc NewSharedIndexInformer(lw ListerWatcher, objType runtime.Object, defaultEventHandlerResyncPeriod time.Duration, indexers Indexers) SharedIndexInformer { realClock := \u0026amp;clock.RealClock{} sharedIndexInformer := \u0026amp;sharedIndexInformer{ processor: \u0026amp;sharedProcessor{clock: realClock}, indexer: NewIndexer(DeletionHandlingMetaNamespaceKeyFunc, indexers), listerWatcher: lw, objectType: objType, resyncCheckPeriod: defaultEventHandlerResyncPeriod, defaultEventHandlerResyncPeriod: defaultEventHandlerResyncPeriod, cacheMutationDetector: NewCacheMutationDetector(fmt.Sprintf(\u0026#34;%T\u0026#34;, objType)), clock: realClock, } return sharedIndexInformer } 在sharedIndexInformer的初始化逻辑中, 初始化了\n processor: 提供了 EventHandler 注册和事件分发的功能 indexer: 提供了资源缓存的功能 listerWatcher: 由模板类提供，包含特定资源的 List 和 Watch 方法 objectType: 用来标记关注哪种特定资源类型 cacheMutationDetector: 监控 Informer 的缓存  sharedProcessor type sharedProcessor struct { listenersStarted bool listenersLock sync.RWMutex listeners []*processorListener syncingListeners []*processorListener clock clock.Clock wg wait.Group } type processorListener struct { nextCh chan interface{} addCh chan interface{} handler ResourceEventHandler // pendingNotifications is an unbounded ring buffer that holds all notifications not yet distributed. \t// There is one per listener, but a failing/stalled listener will have infinite pendingNotifications \t// added until we OOM. \t// TODO: This is no worse than before, since reflectors were backed by unbounded DeltaFIFOs, but \t// we should try to do something better. \tpendingNotifications buffer.RingGrowing // requestedResyncPeriod is how frequently the listener wants a full resync from the shared informer \trequestedResyncPeriod time.Duration // resyncPeriod is how frequently the listener wants a full resync from the shared informer. This \t// value may differ from requestedResyncPeriod if the shared informer adjusts it to align with the \t// informer\u0026#39;s overall resync check period. \tresyncPeriod time.Duration // nextResync is the earliest time the listener should get a full resync \tnextResync time.Time // resyncLock guards access to resyncPeriod and nextResync \tresyncLock sync.Mutex } 在sharedProcessor结构体中, 可以看到有两个processorListener的切片\n当我们注册一个 Handler 到 Informer 时, 最终会被转换为一个名为 processorListener 结构体的实例：\nfunc newProcessListener(handler ResourceEventHandler, requestedResyncPeriod, resyncPeriod time.Duration, now time.Time, bufferSize int) *processorListener { ret := \u0026amp;processorListener{ nextCh: make(chan interface{}), addCh: make(chan interface{}), handler: handler, pendingNotifications: *buffer.NewRingGrowing(bufferSize), requestedResyncPeriod: requestedResyncPeriod, resyncPeriod: resyncPeriod, } ret.determineNextResync(now) return ret } 该实例主要包含两个 channel 和外面注册的 Handler 方法。而此处被实例化的 processorListener 对象最终会被添加到 sharedProcessor.listeners 列表中\nfunc (p *sharedProcessor) addListener(listener *processorListener) { p.listenersLock.Lock() defer p.listenersLock.Unlock() p.addListenerLocked(listener) if p.listenersStarted { p.wg.Start(listener.run) p.wg.Start(listener.pop) } } 初始化DeltaFIFO 有了前面初始化的sharedIndexInformer, 现在开始解析sharedIndexInformer的Run方法\nfifo := NewDeltaFIFO(MetaNamespaceKeyFunc, s.indexer) // s.indexer再前面已经初始化好  func NewDeltaFIFO(keyFunc KeyFunc, knownObjects KeyListerGetter) *DeltaFIFO { f := \u0026amp;DeltaFIFO{ items: map[string]Deltas{}, queue: []string{}, keyFunc: keyFunc, knownObjects: knownObjects, } f.cond.L = \u0026amp;f.lock return f } 初始化controller(注意此处的Process字段被赋值为s.HandleDeltas) cfg := \u0026amp;Config{ Queue: fifo, ListerWatcher: s.listerWatcher, ObjectType: s.objectType, FullResyncPeriod: s.resyncCheckPeriod, RetryOnError: false, ShouldResync: s.processor.shouldResync, Process: s.HandleDeltas, } func() { s.startedLock.Lock() defer s.startedLock.Unlock() s.controller = New(cfg) s.controller.(*controller).clock = s.clock s.started = true }() func New(c *Config) Controller { ctlr := \u0026amp;controller{ config: *c, clock: \u0026amp;clock.RealClock{}, } return ctlr } 启动processor func (p *sharedProcessor) run(stopCh \u0026lt;-chan struct{}) { func() { p.listenersLock.RLock() defer p.listenersLock.RUnlock() for _, listener := range p.listeners { p.wg.Start(listener.run) p.wg.Start(listener.pop) } p.listenersStarted = true }() \u0026lt;-stopCh p.listenersLock.RLock() defer p.listenersLock.RUnlock() for _, listener := range p.listeners { close(listener.addCh) // Tell .pop() to stop. .pop() will tell .run() to stop \t} p.wg.Wait() // Wait for all .pop() and .run() to stop } 可以看到, 主要是循环sharedProcessor里所有的listener, 然后调用了listener.run和listener.pop\nlistener.run func (p *processorListener) run() { // this call blocks until the channel is closed. When a panic happens during the notification \t// we will catch it, **the offending item will be skipped!**, and after a short delay (one second) \t// the next notification will be attempted. This is usually better than the alternative of never \t// delivering again. \tstopCh := make(chan struct{}) wait.Until(func() { // this gives us a few quick retries before a long pause and then a few more quick retries \terr := wait.ExponentialBackoff(retry.DefaultRetry, func() (bool, error) { for next := range p.nextCh { switch notification := next.(type) { case updateNotification: p.handler.OnUpdate(notification.oldObj, notification.newObj) case addNotification: p.handler.OnAdd(notification.newObj) case deleteNotification: p.handler.OnDelete(notification.oldObj) default: utilruntime.HandleError(fmt.Errorf(\u0026#34;unrecognized notification: %T\u0026#34;, next)) } } // the only way to get here is if the p.nextCh is empty and closed \treturn true, nil }) // the only way to get here is if the p.nextCh is empty and closed \tif err == nil { close(stopCh) } }, 1*time.Minute, stopCh) } listener 包含了 Controller 注册进来的 Handler 方法，因此 listener 最重要的职能就是当事件发生时来触发这些方法。\n可以看到，listener.run 不停的从 nextCh 这个 channel 中拿到事件，但是 nextCh 这个 channel 里的事件又是从哪来的呢？listener.pop 的职责便是将事件放入 nextCh 中。\nlistener.pop func (p *processorListener) pop() { defer utilruntime.HandleCrash() defer close(p.nextCh) // Tell .run() to stop  var nextCh chan\u0026lt;- interface{} var notification interface{} for { select { case nextCh \u0026lt;- notification: // Notification dispatched \tvar ok bool notification, ok = p.pendingNotifications.ReadOne() if !ok { // Nothing to pop \tnextCh = nil // Disable this select case \t} case notificationToAdd, ok := \u0026lt;-p.addCh: if !ok { return } if notification == nil { // No notification to pop (and pendingNotifications is empty) \t// Optimize the case - skip adding to pendingNotifications \tnotification = notificationToAdd nextCh = p.nextCh } else { // There is already a notification waiting to be dispatched \tp.pendingNotifications.WriteOne(notificationToAdd) } } } } listener 之所以包含了两个 channel：addCh 和 nextCh，是因为 Informer 无法预知 listener.handler 的事件消费的速度是否大于事件生产的速度，因此添加了一个名为 pendingNotifications 的缓冲队列来保存未来得及消费的事件\npop 方法一方面会不停的从 addCh 中获得最新事件，以保证不会让生产方阻塞。然后判断是否存在 buffer，如果存在则把事件添加到 buffer 中，如果不存在则尝试推给 nextCh。\n而另一方面，会判断 buffer 中是否还有事件，如果还有存量，则不停的传递给 nextCh。\npop 方法实现了一个带 buffer 的分发机制，使得事件可以源源不断的从 addCh 到 nextCh。\n运行controller func (c *controller) Run(stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() go func() { \u0026lt;-stopCh c.config.Queue.Close() }() r := NewReflector( c.config.ListerWatcher, c.config.ObjectType, c.config.Queue, c.config.FullResyncPeriod, ) r.ShouldResync = c.config.ShouldResync r.clock = c.clock c.reflectorMutex.Lock() c.reflector = r c.reflectorMutex.Unlock() var wg wait.Group defer wg.Wait() wg.StartWithChannel(stopCh, r.Run) wait.Until(c.processLoop, time.Second, stopCh) } 初始化Reflector并启动 Reflector通过 sharedIndexInformer 里定义的 listerWatcher 进行 List-Watch，并将获得的事件推入 DeltaFIFO 中, controller 启动之后会先将 Reflector 启动。\n执行c.processLoop func (c *controller) processLoop() { for { obj, err := c.config.Queue.Pop(PopProcessFunc(c.config.Process)) if err != nil { if err == FIFOClosedError { return } if c.config.RetryOnError { // This is the safe way to re-enqueue. \tc.config.Queue.AddIfNotPresent(obj) } } } } 通过一个死循环，不停的将从 DeltaFIFO 读出需要处理的资源事件, 然后交给c.config.Process函数处理, 在前面初始化controller时, c.config.Process被赋值为s.HandleDeltas。\nfunc (s *sharedIndexInformer) HandleDeltas(obj interface{}) error { s.blockDeltas.Lock() defer s.blockDeltas.Unlock() // from oldest to newest \tfor _, d := range obj.(Deltas) { switch d.Type { case Sync, Added, Updated: isSync := d.Type == Sync s.cacheMutationDetector.AddObject(d.Object) if old, exists, err := s.indexer.Get(d.Object); err == nil \u0026amp;\u0026amp; exists { if err := s.indexer.Update(d.Object); err != nil { return err } s.processor.distribute(updateNotification{oldObj: old, newObj: d.Object}, isSync) } else { if err := s.indexer.Add(d.Object); err != nil { return err } s.processor.distribute(addNotification{newObj: d.Object}, isSync) } case Deleted: if err := s.indexer.Delete(d.Object); err != nil { return err } s.processor.distribute(deleteNotification{oldObj: d.Object}, false) } } return nil } 这里调用了s.indexer.Add s.indexer.Update s.indexer.Delete以及s.processor.distribute。\ns.indexer.Add s.indexer.Update s.indexer.Delete最后都调用了queueActionLocked方法\nfunc (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { id, err := f.KeyOf(obj) if err != nil { return KeyError{obj, err} } newDeltas := append(f.items[id], Delta{actionType, obj}) newDeltas = dedupDeltas(newDeltas) if len(newDeltas) \u0026gt; 0 { if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas f.cond.Broadcast() } else { // We need to remove this from our map (extra items in the queue are \t// ignored if they are not in the map). \tdelete(f.items, id) } return nil } 而s.processor.distribute是把事件分发到listener\nfunc (p *sharedProcessor) distribute(obj interface{}, sync bool) { p.listenersLock.RLock() defer p.listenersLock.RUnlock() if sync { for _, listener := range p.syncingListeners { listener.add(obj) } } else { for _, listener := range p.listeners { listener.add(obj) } } } func (p *processorListener) add(notification interface{}) { p.addCh \u0026lt;- notification } 可以看到, distribute方法调用listener.add, listener.add会将事件发送到addCh。\n至此, 整个事件流就打通了，如下图。\n总结 Informer机制是kubernetes的核心, 了解清楚这个机制, 后续理解controller manager就容易多了, 而且也能更得心应手的编写自定义的controller。\n参考资料  client-go 源码  ","permalink":"https://cloudnative.to/blog/client-go-informer/","tags":["client-go","informer"],"title":"Kubernetes client-go informer原理"},{"categories":null,"contents":"百度云边缘计算部简介 百度云边缘计算部负责百度云在边缘计算领域的探索和创新，协同百度业内领头的 AI 技术，借势 5G 和新基建的时代浪潮，为客户提供业界领先的边缘场景的一站式解决方案。\n边缘计算资深研发工程师（北京 / 深圳） 工作职责  负责边缘计算产品的系统架构设计及开发，针对边缘计算的复杂场景进行解决方案设计与创新，并推动业务落地 负责边缘节点库存等资源的虚拟化管理及智能调度系统，最大化提升边缘资源的利用效率 负责边缘云基础框架的搭建以及边缘服务的标准化，打造边缘云生态 负责边缘计算相关开源事宜，参与 Kubernetes/Akraino 等开源项目的建设，提升百度在边缘计算领域的影响力  职位要求  2 年以上云计算行业经验，熟悉云计算平台技术体系，具备大型系统架构设计经验和能力，能独立负责技术架构规划和架构演进 深入理解 Cloud Native 思想，并对行业发展趋势有敏锐的嗅觉 精通 Go 或 C++ 开发语言，并至少精通一门脚本语言，具有丰富的开发、调试和性能优化等经验 具备较好的逻辑思考能力、沟通能力、学习能力，工作中积极主动、有责任心、抗压性强 满足以下多点的优先：  精通 Kubernetes，对 Kubernetes 设计理念及各模块源码比较熟悉，参与过源码贡献 精通 Docker 等容器引擎的使用，了解底层实现原理，并对容器网络、存储架构比较了解 熟悉 Linux 平台，掌握 Cgroup/CFS/CAT 等资源隔离和调度的原理和用法 熟悉 istio/service mesh/envoy，了解实现原理，参与过源码贡献 熟悉 ceph 等开源存储方案 熟悉各种 overlay 网络（flannel、calico 等）的构建模型及核心算法    投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/baidu-edge-computing/","tags":null,"title":"[社招] 百度云边缘计算部"},{"categories":null,"contents":"阿里云边缘计算团队简介 阿里云边缘计算团队负责阿里云边缘计算业务的总体规划、产品研发和技术创新，为客户提供行业领先的 IaaS、PaaS 及 SaaS 产品与服务。\n边缘计算作为云计算能力的延展和补充，与云计算共同形成一张覆盖全球的计算，存储，安全的大网络，打造全球最具竞争力的云服务生态。\n阿里云智能事业群-技术专家(边缘计算 / P7)-北京/杭州 岗位描述  主导各类业务及技术改造类项目的系统分析与设计工作，承担核心功能代码编写，开发与维护系统公用核心模块； 系统性能优化，主导技术难题攻关，持续提升系统在大规模分布式系统环境下高并发、海量请求数下的高处理性能，解决各类潜在系统技术风险，保证系统的安全、稳定、快速运行； 负责指导、培训普通开发工程师，审核开发工程师的设计与研发质量。  岗位要求  扎实的 Java、Golang 或 Rust 编程基础，熟练单元测试技术和 TDD 等相关技术；对各种开源的框架有深入的了解，对框架本身有过开发或重构者可优先考虑； 3 年以上大规模高并发访问系统设计和开发经验； 熟练掌握 Unix/Linux 操作系统，对常用命令运用娴熟，能够根据实际需要快速编写 Shell 脚本； 具备良好的识别和设计通用框架及模块的能力，熟悉 UML； 较强的表达和沟通能力，工作认真、严谨、敬业，对系统质量有近乎苛刻的要求意识。 有很强的分析问题和解决问题的能力，有强烈的责任心。  加分项：\n 熟悉分布式. 多线程及高性能系统设计、开发及性能调优者优先； 有 K8S、容器、Openstack 等云化技术相关开发经验者优先； 有边缘计算场景应用落地经验者优先。  阿里云智能事业群-高级技术专家(边缘计算 / P8)-北京/杭州 岗位描述  负责制定边缘计算技术方向和执行策略，设计整体技术架构和解决方案 负责针对边缘计算场景中的计算、存储、网络、安全等一项或多项领域进行架构和方案的把控及设计开发 负责针对边缘计算新场景、新方向和新技术进行研究，推动技术演进  岗位要求  在操作系统，安全，网络，存储，计算虚拟化，分布式调度，全球化架构，AI等关键技术方面有突出影响力，对边缘计算有认同感，并具有不断学习的能力和热情； 5 年以上行业内技术积累，精通云计算平台技术体系，具备大型系统架构设计经验和能力，能独立负责技术架构规划和架构演进； 熟悉 5G/MEC 的架构和标准，深入理解运营商骨干网和移动通信网，具有ICT融合网络下的应用开发实践经验； 深度参与或带领过边缘计算相关开源项目（Openstack，ODL，K8S，StarlingX，LF Edge，CORD，ONAP，OPNFV 等），并对其中关键技术具有把控力； 在过往从事的行业中有丰富的研究和工程成果，并与边缘技术有一定的相关性，对未来边缘计算的行业发展有深刻的认识； 精通 Go、Rust 或 Java 等开发语言，并至少精通一门脚本语言（Python 等），具有丰富的开发、调试和性能优化等经验； 有技术热情和探索精神，有较强的快速学习能力和自驱能力，有良好的全局意识和系统风险识别能力  投递简历 欢迎邮件简历，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/aliyun-edge-computing/","tags":null,"title":"[社招] 阿里云边缘计算团队"},{"categories":null,"contents":"招聘对象 本次社会招聘的要求为不限工作年限的同学。\n岗位类型 研发类：容器、kubernetes、service mesh等云原生方向，Go、C/C++、Java等语言。\n中信银行介绍 本行成立于1987年，是中国改革开放中最早成立的新兴商业银行之一，是中国最早参与国内外金融市场融资的商业银行，并以屡创中国现代金融史上多个第一而蜚声海内外，为中国经济建设做出了积极贡献。2007年4月，本行实现在上海证券交易所和香港联合交易所A+H股同步上市。\n本行以建设成为有担当、有温度、有特色、有尊严的最佳综合金融服务企业为发展愿景，充分发挥中信集团金融与实业并举的独特竞争优势，坚持“以客为尊”，秉承“平安中信、合规经营、科技立行、服务实体、市场导向、创造价值”的经营理念，向企业客户和机构客户提供公司银行业务、国际业务、金融市场业务、机构业务、投资银行业务、交易银行业务、托管业务等综合金融解决方案，向个人客户提供零售银行、信用卡、消费金融、财富管理、私人银行、出国金融、电子银行等多元化金融产品及服务，全方位满足企业、机构及个人客户的综合金融服务需求。\n截至2019年末，本行在国内151个大中城市设有1,401家营业网点，同时在境内外下设6家附属机构，包括中信国际金融控股有限公司、信银（香港）投资有限公司、中信金融租赁有限公司、浙江临安中信村镇银行股份有限公司、中信百信银行股份有限公司和哈萨克斯坦阿尔金银行。其中，中信国际金融控股有限公司子公司中信银行（国际）有限公司在香港、澳门、纽约、洛杉矶、新加坡和中国内地设有38家营业网点。信银（香港）投资有限公司在香港和境内设有3家子公司。中信百信银行股份有限公司为本行与百度公司发起设立的国内首家具有独立法人资格的直销银行。阿尔金银行在哈萨克斯坦设有7家营业网点和1个私人银行中心。\n本行坚持服务实体经济，稳健经营，与时俱进。经过30余年的发展，本行已成为一家总资产规模超6万亿元、员工人数近6万名，具有强大综合实力和品牌竞争力的金融集团。2019年，本行在英国《银行家》杂志“全球银行品牌500强排行榜”中排名第19位；本行一级资本在英国《银行家》杂志“世界1000家银行排名”中排名第26位。\n岗位描述 1、负责部分功能或非功能设计方案的编写、评审和落地。参与部署方案的制定和相关投产。\n2、负责对复杂关键技术问题进行技术攻关；负责新增组件的设计、开发、单元测试工作；负责对开源软件进行扩展、优化工作；参与代码评审工作。\n3、参与性能测试、高可用测试、混沌测试等。\n4、负责Service Mesh平台的推广，对应用设计、开发和部署提供技术支持，参与制定应用接入流程和技术规范。\n5、指导、支持初级工程师，培养新人。\n岗位要求 1、有超过3年的复杂软件系统的设计、开发经验。\n2、有较强的Go语言高并发编程经验或熟悉C++编程。\n3、熟悉Docker,Kubernates，了解Service Mesh。\n4、熟悉Java,Spring Cloud。\n5、有过对较为复杂的开源软件从代码级别掌控的经验。\n内推方式 欢迎邮件简历并说明对应的职位，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/social-citic-servicemesh/","tags":null,"title":"[社会招聘] 中信软开Service Mesh研发工程师（中级，高级）"},{"categories":null,"contents":"招聘对象 本次社会招聘的要求为不限工作年限的同学。\n中信银行介绍 本行成立于1987年，是中国改革开放中最早成立的新兴商业银行之一，是中国最早参与国内外金融市场融资的商业银行，并以屡创中国现代金融史上多个第一而蜚声海内外，为中国经济建设做出了积极贡献。2007年4月，本行实现在上海证券交易所和香港联合交易所A+H股同步上市。\n本行以建设成为有担当、有温度、有特色、有尊严的最佳综合金融服务企业为发展愿景，充分发挥中信集团金融与实业并举的独特竞争优势，坚持“以客为尊”，秉承“平安中信、合规经营、科技立行、服务实体、市场导向、创造价值”的经营理念，向企业客户和机构客户提供公司银行业务、国际业务、金融市场业务、机构业务、投资银行业务、交易银行业务、托管业务等综合金融解决方案，向个人客户提供零售银行、信用卡、消费金融、财富管理、私人银行、出国金融、电子银行等多元化金融产品及服务，全方位满足企业、机构及个人客户的综合金融服务需求。\n截至2019年末，本行在国内151个大中城市设有1,401家营业网点，同时在境内外下设6家附属机构，包括中信国际金融控股有限公司、信银（香港）投资有限公司、中信金融租赁有限公司、浙江临安中信村镇银行股份有限公司、中信百信银行股份有限公司和哈萨克斯坦阿尔金银行。其中，中信国际金融控股有限公司子公司中信银行（国际）有限公司在香港、澳门、纽约、洛杉矶、新加坡和中国内地设有38家营业网点。信银（香港）投资有限公司在香港和境内设有3家子公司。中信百信银行股份有限公司为本行与百度公司发起设立的国内首家具有独立法人资格的直销银行。阿尔金银行在哈萨克斯坦设有7家营业网点和1个私人银行中心。\n本行坚持服务实体经济，稳健经营，与时俱进。经过30余年的发展，本行已成为一家总资产规模超6万亿元、员工人数近6万名，具有强大综合实力和品牌竞争力的金融集团。2019年，本行在英国《银行家》杂志“全球银行品牌500强排行榜”中排名第19位；本行一级资本在英国《银行家》杂志“世界1000家银行排名”中排名第26位。\n岗位描述 1、参与新一代技术组件的设计和开发工作。\n2、使用并扩展优化相关开源软件。\n岗位要求 1、有较强的Java语言、Spring Boot,Spring Cloud编程能力。\n2、对缓存、多线程、高并发、性能优化、redis、netty、分布式事务有经验者优先。\n3、有过对较为复杂的开源软件从代码级别掌控的经验。\n内推方式 欢迎邮件简历并说明对应的职位，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/social-citic-component/","tags":null,"title":"[社会招聘] 中信软开技术组件研发工程师（初级、中级，高级）"},{"categories":["BPF"],"contents":"由范老师和我一起翻译的图书 《Linux内核观测技术BPF》 已经在 JD 上有现货，欢迎感兴趣 BPF 技术的同学选购。链接地址 https://item.jd.com/72110825905.html\n“eBPF 是我见过的 Linux 中最神奇的技术，没有之一，已成为 Linux 内核中顶级子模块，从 tcpdump 中用作网络包过滤的经典 cbpf，到成为通用 Linux 内核技术的 eBPF，已经完成华丽蜕变，为应用与神奇的内核打造了一座桥梁，在系统跟踪、观测、性能调优、安全和网络等领域发挥重要的角色。为 Service Mesh 打造了具备 API 感知和安全高效的容器网络方案 Cilium，其底层正是基于 eBPF 技术”\n1. BPF BPF（Berkeley Packet Filter ），中文翻译为伯克利包过滤器，是类 Unix 系统上数据链路层的一种原始接口，提供原始链路层封包的收发。1992 年，Steven McCanne 和 Van Jacobson 写了一篇名为《BSD数据包过滤：一种新的用户级包捕获架构》的论文。在文中，作者描述了他们如何在 Unix 内核实现网络数据包过滤，这种新的技术比当时最先进的数据包过滤技术快 20 倍。BPF 在数据包过滤上引入了两大革新：\n  一个新的虚拟机 (VM) 设计，可以有效地工作在基于寄存器结构的 CPU 之上；\n  应用程序使用缓存只复制与过滤数据包相关的数据，不会复制数据包的所有信息。这样可以最大程度地减少BPF 处理的数据；\n  由于这些巨大的改进，所有的 Unix 系统都选择采用 BPF 作为网络数据包过滤技术，直到今天，许多 Unix 内核的派生系统中（包括 Linux 内核）仍使用该实现。\ntcpdump 的底层采用 BPF 作为底层包过滤技术，我们可以在命令后面增加 ”-d“ 来查看 tcpdump 过滤条件的底层汇编指令。\n$ tcpdump -d \u0026#39;ip and tcp port 8080\u0026#39; (000) ldh [12] (001) jeq #0x800 jt 2\tjf 12 (002) ldb [23] (003) jeq #0x6 jt 4\tjf 12 (004) ldh [20] (005) jset #0x1fff jt 12\tjf 6 (006) ldxb 4*([14]\u0026amp;0xf) (007) ldh [x + 14] (008) jeq #0x1f90 jt 11\tjf 9 (009) ldh [x + 16] (010) jeq #0x1f90 jt 11\tjf 12 (011) ret #262144 (012) ret #0 图 1-1 tcpdump 底层汇编指令\nBPF 工作在内核层，BPF 的架构图如下 [来自于bpf-usenix93]：\n图 1-2 tcpdump 运行架构\n2. eBPF 2.1 eBPF 介绍 2014 年初，Alexei Starovoitov 实现了 eBPF（extended Berkeley Packet Filter）。经过重新设计，eBPF 演进为一个通用执行引擎，可基于此开发性能分析工具、软件定义网络等诸多场景。eBPF 最早出现在 3.18 内核中，此后原来的 BPF 就被称为经典 BPF，缩写 cBPF（classic BPF），cBPF 现在已经基本废弃。现在，Linux 内核只运行 eBPF，内核会将加载的 cBPF 字节码透明地转换成 eBPF 再执行。\neBPF 新的设计针对现代硬件进行了优化，所以 eBPF 生成的指令集比旧的 BPF 解释器生成的机器码执行得更快。扩展版本也增加了虚拟机中的寄存器数量，将原有的 2 个 32 位寄存器增加到 10 个 64 位寄存器。由于寄存器数量和宽度的增加，开发人员可以使用函数参数自由交换更多的信息，编写更复杂的程序。总之，这些改进使 eBPF 版本的速度比原来的 BPF 提高了 4 倍。\n   维度 cBPF eBPF     内核版本 Linux 2.1.75（1997年） Linux 3.18（2014年）[4.x for kprobe/uprobe/tracepoint/perf-event]   寄存器数目 2个：A, X 10个： R0–R9, 另外 R10 是一个只读的帧指针   寄存器宽度 32位 64位   存储 16 个内存位: M[0–15] 512 字节堆栈，无限制大小的 “map” 存储   限制的内核调用 非常有限，仅限于 JIT 特定 有限，通过 bpf_call 指令调用   目标事件 数据包、 seccomp-BPF 数据包、内核函数、用户函数、跟踪点 PMCs 等    表格 1-1 cBPF 与 eBPF 对比\n eBPF 在 Linux 3.18 版本以后引入，并不代表只能在内核 3.18+ 版本上运行，低版本的内核升级到最新也可以使用 eBPF 能力，只是可能部分功能受限，比如我就是在 Linux 发行版本 CentOS Linux release 7.7.1908 内核版本 3.10.0-1062.9.1.el7.x86_64 上运行 eBPF 在生产环境上搜集和排查网络问题。\n eBPF 实现的最初目标是优化处理网络过滤器的内部 BPF 指令集。当时，BPF 程序仍然限于内核空间使用，只有少数用户空间程序可以编写内核处理的 BPF 过滤器，例如：tcpdump和 seccomp。时至今日，这些程序仍基于旧的 BPF 解释器生成字节码，但内核中会将这些指令转换为高性能的表示。\n2014 年 6 月，eBPF 扩展到用户空间，这也成为了 BPF 技术的转折点。 正如 Alexei 在提交补丁的注释中写到：“这个补丁展示了 eBPF 的潜力”。当前，eBPF 不再局限于网络栈，已经成为内核顶级的子系统。eBPF 程序架构强调安全性和稳定性，看上去更像内核模块，但与内核模块不同，eBPF 程序不需要重新编译内核，并且可以确保 eBPF 程序运行完成，而不会造成系统的崩溃。\n图 2-1 BPF 架构图\n简述概括， eBPF 是一套通用执行引擎，提供了可基于系统或程序事件高效安全执行特定代码的通用能力，通用能力的使用者不再局限于内核开发者；eBPF 可由执行字节码指令、存储对象和 Helper 帮助函数组成，字节码指令在内核执行前必须通过 BPF 验证器 Verfier 的验证，同时在启用 BPF JIT 模式的内核中，会直接将字节码指令转成内核可执行的本地指令运行。\n同时，eBPF 也逐渐在观测（跟踪、性能调优等）、安全和网络等领域发挥重要的角色。Facebook、NetFlix 、CloudFlare 等知名互联网公司内部广泛采用基于 eBPF 技术的各种程序用于性能分析、排查问题、负载均衡、防范 DDoS 攻击，据相关信息显示在 Facebook 的机器上内置一系列 eBPF 的相关工具。\n相对于系统的性能分析和观测，eBPF 技术在网络技术中的表现，更是让人眼前一亮，BPF 技术与 XDP（eXpress Data Path） 和 TC（Traffic Control） 组合可以实现功能更加强大的网络功能，更可为 SDN 软件定义网络提供基础支撑。XDP 只作用与网络包的 Ingress 层面，BPF 钩子位于网络驱动中尽可能早的位置，无需进行原始包的复制就可以实现最佳的数据包处理性能，挂载的 BPF 程序是运行过滤的理想选择，可用于丢弃恶意或非预期的流量、进行 DDOS 攻击保护等场景；而 TC Ingress 比 XDP 技术处于更高层次的位置，BPF 程序在 L3 层之前运行，可以访问到与数据包相关的大部分元数据，是本地节点处理的理想的地方，可以用于流量监控或者 L3/L4 的端点策略控制，同时配合 TC egress 则可实现对于容器环境下更高维度和级别的网络结构。\n图 2-2 XDP 技术架构\neBPF 相关的知名的开源项目包括但不限于以下：\n Facebook 高性能 4 层负载均衡器 Katran； Cilium 为下一代微服务 ServiceMesh 打造了具备API感知和安全高效的容器网络方案；底层主要使用 XDP 和 TC 等相关技术； IO Visor 项目开源的 BCC、 BPFTrace 和 Kubectl-Trace： BCC 提供了更高阶的抽象，可以让用户采用 Python、C++ 和 Lua 等高级语言快速开发 BPF 程序；BPFTrace 采用类似于 awk 语言快速编写 eBPF 程序；Kubectl-Trace 则提供了在 kubernetes 集群中使用 BPF 程序调试的方便操作； CloudFlare 公司开源的 eBPF Exporter 和 bpf-tools：eBPF Exporter 将 eBPF 技术与监控 Prometheus 紧密结合起来；bpf-tools 可用于网络问题分析和排查；  越来越多的基于 eBPF 的项目如雨后脆笋一样开始蓬勃发展，而且逐步在社区中异军突起，成为一道风景线。比如 IO Visor 项目的 BCC 工具，为性能分析和观察提供了更加丰富的工具集：图片来源\n图 2-3 Linux bcc/BPF 观测工具\n同时，IO Visor 的 bpf-docs 包含了日常的文档，可以用于学习。\n 由于 eBPF 还在快速发展期，内核中的功能也日趋增强，一般推荐基于Linux 4.4+ (4.9 以上会更好) 内核的来使用 eBPF。部分 Linux Event 和 BPF 版本支持见下图：\n图 2-4 Linux 事件和 BPF 版本支持\n 2.2 eBPF 架构（观测） 基于 Linux 系统的观测工具中，eBPF 有着得天独厚的优势，高效、生产安全且内核中内置，特别的可以在内核中完成数据分析聚合比如直方图，与将数据发送到用户空间分析聚合相比，能够节省大量的数据复制传递带来的 CPU 消耗。\neBPF 整体结构图如下：\n图 2-5 eBPF 观测架构\neBPF 分为用户空间程序和内核程序两部分：\n 用户空间程序负责加载 BPF 字节码至内核，如需要也会负责读取内核回传的统计信息或者事件详情； 内核中的 BPF 字节码负责在内核中执行特定事件，如需要也会将执行的结果通过 maps 或者 perf-event 事件发送至用户空间；  其中用户空间程序与内核 BPF 字节码程序可以使用 map 结构实现双向通信，这为内核中运行的 BPF 字节码程序提供了更加灵活的控制。\n用户空间程序与内核中的 BPF 字节码交互的流程主要如下：\n 我们可以使用 LLVM 或者 GCC 工具将编写的 BPF 代码程序编译成 BPF 字节码； 然后使用加载程序 Loader 将字节码加载至内核；内核使用验证器（verfier） 组件保证执行字节码的安全性，以避免对内核造成灾难，在确认字节码安全后将其加载对应的内核模块执行；BPF 观测技术相关的程序程序类型可能是 kprobes/uprobes/tracepoint/perf_events 中的一个或多个，其中：  kprobes：实现内核中动态跟踪。 kprobes 可以跟踪到 Linux 内核中的导出函数入口或返回点，但是不是稳定 ABI 接口，可能会因为内核版本变化导致，导致跟踪失效。 uprobes：用户级别的动态跟踪。与 kprobes 类似，只是跟踪用户程序中的函数。 tracepoints：内核中静态跟踪。tracepoints 是内核开发人员维护的跟踪点，能够提供稳定的 ABI 接口，但是由于是研发人员维护，数量和场景可能受限。 perf_events：定时采样和 PMC。   内核中运行的 BPF 字节码程序可以使用两种方式将测量数据回传至用户空间  maps 方式可用于将内核中实现的统计摘要信息（比如测量延迟、堆栈信息）等回传至用户空间； perf-event 用于将内核采集的事件实时发送至用户空间，用户空间程序实时读取分析；     如无特殊说明，本文中所说的 BPF 都是泛指 BPF 技术。\n 2.3 eBPF 的限制 eBPF 技术虽然强大，但是为了保证内核的处理安全和及时响应，内核中的 eBPF 技术也给予了诸多限制，当然随着技术的发展和演进，限制也在逐步放宽或者提供了对应的解决方案。\n  eBPF 程序不能调用任意的内核参数，只限于内核模块中列出的 BPF Helper 函数，函数支持列表也随着内核的演进在不断增加。\n  eBPF 程序不允许包含无法到达的指令，防止加载无效代码，延迟程序的终止。\n  eBPF 程序中循环次数限制且必须在有限时间内结束，这主要是用来防止在 kprobes 中插入任意的循环，导致锁住整个系统；解决办法包括展开循环，并为需要循环的常见用途添加辅助函数。Linux 5.3 在 BPF 中包含了对有界循环的支持，它有一个可验证的运行时间上限。\n  eBPF 堆栈大小被限制在 MAX_BPF_STACK，截止到内核 Linux 5.8 版本，被设置为 512；参见 include/linux/filter.h，这个限制特别是在栈上存储多个字符串缓冲区时：一个char[256]缓冲区会消耗这个栈的一半。目前没有计划增加这个限制，解决方法是改用 bpf 映射存储，它实际上是无限的。\n/* BPF program can access up to 512 bytes of stack space. */ #define MAX_BPF_STACK\t512   eBPF 字节码大小最初被限制为 4096 条指令，截止到内核 Linux 5.8 版本， 当前已将放宽至 100 万指令（ BPF_COMPLEXITY_LIMIT_INSNS），参见：include/linux/bpf.h，对于无权限的BPF程序，仍然保留 4096 条限制 ( BPF_MAXINSNS )；新版本的 eBPF 也支持了多个 eBPF 程序级联调用，虽然传递信息存在某些限制，但是可以通过组合实现更加强大的功能。\n#define BPF_COMPLEXITY_LIMIT_INSNS 1000000 /* yes. 1M insns */  2.4 eBPF 与内核模块对比 在 Linux 观测方面，eBPF 总是会拿来与 kernel 模块方式进行对比，eBPF 在安全性、入门门槛上比内核模块都有优势，这两点在观测场景下对于用户来讲尤其重要。\n   维度 Linux 内核模块 eBPF     kprobes/tracepoints 支持 支持   安全性 可能引入安全漏洞或导致内核 Panic 通过验证器进行检查，可以保障内核安全   内核函数 可以调用内核函数 只能通过 BPF Helper 函数调用   编译性 需要编译内核 不需要编译内核，引入头文件即可   运行 基于相同内核运行 基于稳定 ABI 的 BPF 程序可以编译一次，各处运行   与应用程序交互 打印日志或文件 通过 perf_event 或 map 结构   数据结构丰富性 一般 丰富   入门门槛 高 低   升级 需要卸载和加载，可能导致处理流程中断 原子替换升级，不会造成处理流程中断   内核内置 视情况而定 内核内置支持    表格 2-1 eBPF 与 Linux 内核模块方式对比\n3. 应用案例 大名鼎鼎的性能分析大师 Brendan Gregg 等编写了诸多的 BCC 或 BPFTrace 的工具集可以拿来直接使用，完全可以满足我们日常问题分析和排查。\nBCC 在 CentOS 7 系统中可以通过 yum 快速安装\n# yum install bcc -y Resolving Dependencies --\u0026gt; Running transaction check ---\u0026gt; Package bcc.x86_64 0:0.8.0-1.el7 will be updated --\u0026gt; Processing Dependency: bcc(x86-64) = 0.8.0-1.el7 for package: python-bcc-0.8.0-1.el7.x86_64 ---\u0026gt; Package bcc.x86_64 0:0.10.0-1.el7 will be an update --\u0026gt; Processing Dependency: bcc-tools = 0.10.0-1.el7 for package: bcc-0.10.0-1.el7.x86_64 --\u0026gt; Running transaction check ---\u0026gt; Package bcc-tools.x86_64 0:0.8.0-1.el7 will be updated ---\u0026gt; Package bcc-tools.x86_64 0:0.10.0-1.el7 will be an update ---\u0026gt; Package python-bcc.x86_64 0:0.8.0-1.el7 will be updated ---\u0026gt; Package python-bcc.x86_64 0:0.10.0-1.el7 will be an update --\u0026gt; Finished Dependency Resolution ... 其他系统的安装方式参见：INSTALL.md\nBCC 中每一个工具都有一个对应的使用样例，比如 execsnoop.py 和 execsnoop_example.txt，在使用样例中有详细的使用说明，而且 BCC 中的工具使用的帮助文档格式基本类似，上手非常方便。\n BCC 的程序一般情况下都需要 root 用户来运行。\n 3.1 Linux 性能分析 60 秒 （BPF版本） 英文原文 Linux Performance Analysis in 60,000 Milliseconds，视频地址\nuptime dmesg | tail vmstat 1 mpstat -P ALL 1 pidstat 1 iostat -xz 1 free -m sar -n DEV 1 sar -n TCP,ETCP 1 top 60s 系列 BPF 版本如下：\n图 3-1 60s 排查之 BPF 版本\n对于在系统中运行的 \u0026ldquo;闪电侠\u0026rdquo; 程序，运行周期非常短，但是可能会带来系统的抖动延时，我们采用 top 命令查看一般情况下难以发现，我们可以使用 BCC 提供的工具 execsnoop  来进行排查：\n# Trace file opens with process and filename: opensnoop #/usr/share/bcc/tools/execsnoop PCOMM PID PPID RET ARGS sleep 3334 21029 0 /usr/bin/sleep 3 sleep 3339 21029 0 /usr/bin/sleep 3 conntrack 3341 1112 0 /usr/sbin/conntrack --stats conntrack 3342 1112 0 /usr/sbin/conntrack --count sleep 3344 21029 0 /usr/bin/sleep 3 iptables-save 3347 9211 0 /sbin/iptables-save -t filter iptables-save 3348 9211 0 /sbin/iptables-save -t nat 3.2 slab dentry 过大导致的网络抖动排查 现象\n网络 ping 的延时间歇性有规律出现抖动\n问题排查\n采用 execsnoop 分析发现，某个运行命令cat /proc/slabinfo的运行时间间隔与抖动的频率完全吻合，顺着这个的线索定位，我们发现云厂商提供的 Java 版本的云监控会定期调用 cat /proc/slabinfo 来获取内核缓存的信息；\n通过命令 slabtop 发现系统中的 dentry 项的内存占用非常大，系统内存 128G，dentry 占用 70G 以上，所以问题很快就定位到是系统在打开文件方面可能有相关问题；\n根因分析\n我们使用对于打开文件跟踪的 BCC 工具 opensnoop 很快就定位到是某个程序频繁创建和删除临时文件，最终定位为某个 PHP 程序设置的调用方式存在问题，导致每次请求会创建和删除临时文件；代码中将 http 调用中的 contentType 设置成了 Http::CONTENT_TYPE_UPLOAD，导致每次请求都会生成临时文件，修改成 application/x-www-form-urlencoded 问题解决。\n问题的原理可参考 记一次对网络抖动经典案例的分析 和 systemtap脚本分析系统中dentry SLAB占用过高问题\n3.3 生成火焰图 火焰图是帮助我们对系统耗时进行可视化的图表，能够对程序中那些代码经常被执行给出一个清晰的展现。Brendan Gregg 是火焰图的创建者，他在 GitHub 上维护了一组脚本可以轻松生成需要的可视化格式数据。使用 BCC 中的工具 profile 可很方面地收集道 CPU 路径的数据，基于数据采用工具可以轻松地生成火焰图，查找到程序的性能瓶颈。\n 使用 profile 搜集火焰图的程序没有任何限制和改造\n profile 工具可以让我们轻松对于系统或者程序的 CPU 性能路径进行可视化分析：\n/usr/share/bcc/tools/profile -h usage: profile [-h] [-p PID | -L TID] [-U | -K] [-F FREQUENCY | -c COUNT] [-d] [-a] [-I] [-f] [--stack-storage-size STACK_STORAGE_SIZE] [-C CPU] [duration] Profile CPU stack traces at a timed interval positional arguments: duration duration of trace, in seconds optional arguments: -h, --help show this help message and exit -p PID, --pid PID profile process with this PID only -L TID, --tid TID profile thread with this TID only -U, --user-stacks-only show stacks from user space only (no kernel space stacks) -K, --kernel-stacks-only show stacks from kernel space only (no user space stacks) -F FREQUENCY, --frequency FREQUENCY sample frequency, Hertz -c COUNT, --count COUNT sample period, number of events -d, --delimited insert delimiter between kernel/user stacks -a, --annotations add _[k] annotations to kernel frames -I, --include-idle include CPU idle stacks -f, --folded output folded format, one line per stack (for flame graphs) --stack-storage-size STACK_STORAGE_SIZE the number of unique stack traces that can be stored and displayed (default 16384) -C CPU, --cpu CPU cpu number to run profile on examples: ./profile # profile stack traces at 49 Hertz until Ctrl-C ./profile -F 99 # profile stack traces at 99 Hertz ./profile -c 1000000 # profile stack traces every 1 in a million events ./profile 5 # profile at 49 Hertz for 5 seconds only ./profile -f 5 # output in folded format for flame graphs ./profile -p 185 # only profile process with PID 185 ./profile -L 185 # only profile thread with TID 185 ./profile -U # only show user space stacks (no kernel) ./profile -K # only show kernel space stacks (no user) profile 配合 FlameGraph 可以轻松帮我们绘制出 CPU 使用的火焰图。\n$ profile -af 30 \u0026gt; out.stacks01 $ git clone https://github.com/brendangregg/FlameGraph $ cd FlameGraph $ ./flamegraph.pl --color=java \u0026lt; ../out.stacks01 \u0026gt; out.svg 图 3-2 火焰图\n3.3 排查网络调用来源 在生产场景下，会有些特定场景需要抓取连接到外网特定地址的程序，这时候我们可以采用 BCC 工具集中的 tcplife 来定位。\n/usr/share/bcc/tools/tcplife -h usage: tcplife [-h] [-T] [-t] [-w] [-s] [-p PID] [-L LOCALPORT] [-D REMOTEPORT] Trace the lifespan of TCP sessions and summarize optional arguments: -h, --help show this help message and exit -T, --time include time column on output (HH:MM:SS) -t, --timestamp include timestamp on output (seconds) -w, --wide wide column output (fits IPv6 addresses) -s, --csv comma separated values output -p PID, --pid PID trace this PID only -L LOCALPORT, --localport LOCALPORT comma-separated list of local ports to trace. -D REMOTEPORT, --remoteport REMOTEPORT comma-separated list of remote ports to trace. examples: ./tcplife # trace all TCP connect()s ./tcplife -t # include time column (HH:MM:SS) ./tcplife -w # wider colums (fit IPv6) ./tcplife -stT # csv output, with times \u0026amp; timestamps ./tcplife -p 181 # only trace PID 181 ./tcplife -L 80 # only trace local port 80 ./tcplife -L 80,81 # only trace local ports 80 and 81 ./tcplife -D 80 # only trace remote port 80 通过在机器上使用 tcplife 来获取的网络连接信息，我们可以看到包括了 PID、COMM、本地 IP 地址、本地端口、远程 IP 地址和远程端口，通过这些信息非常方便排查到连接到特定 IP 地址的程序，尤其是连接的过程非常短暂，通过 netstat 等其他工具不容易排查的场景。\n# /usr/share/bcc/tools/tcplife PID COMM IP LADDR LPORT RADDR RPORT TX_KB RX_KB MS 1776 blackbox_export 4 169.254.20.10 35830 169.254.20.10 53 0 0 0.36 27150 node-cache 4 169.254.20.10 53 169.254.20.10 35830 0 0 0.36 12511 coredns 4 127.0.0.1 58492 127.0.0.1 8080 0 0 0.32 ... 如果我们想知道更加详细的 TCP 状态情况，那么 tcptracer 可展示更加详细的 TCP 状态，其中 C 代表 Connect X 表示关闭， A 代表 Accept。\n# /usr/share/bcc/tools/tcptracer Tracing TCP established connections. Ctrl-C to end. T PID COMM IP SADDR DADDR SPORT DPORT C 21066 ilogtail 4 10.81.128.12 100.100.49.128 40906 80 X 21066 ilogtail 4 10.81.128.12 100.100.49.128 40906 80 C 21066 ilogtail 4 10.81.128.12 100.100.49.128 40908 80 X 21066 ilogtail 4 10.81.128.12 100.100.49.128 40908 80 tcpstates 还能够展示出来 TCP 状态机的流转情况：\n# /usr/share/bcc/tools/tcpstates SKADDR C-PID C-COMM LADDR LPORT RADDR RPORT OLDSTATE -\u0026gt; NEWSTATE MS ffff9fd7e8192000 22384 curl 100.66.100.185 0 52.33.159.26 80 CLOSE -\u0026gt; SYN_SENT 0.000 ffff9fd7e8192000 0 swapper/5 100.66.100.185 63446 52.33.159.26 80 SYN_SENT -\u0026gt; ESTABLISHED 1.373 ffff9fd7e8192000 22384 curl 100.66.100.185 63446 52.33.159.26 80 ESTABLISHED -\u0026gt; FIN_WAIT1 176.042 同样，我们也可以实时获取到 TCP 连接超时或者重连的网络连接；也可以通过抓取 UDP包相关的连接信息，用于定位诸如 DNS 请求超时或者 DNS 请求的发起进程。\n4. 编写 BPF 程序 对于大多数开发者而言，更多的是基于 BPF 技术之上编写解决我们日常遇到的各种问题，当前 BCC 和 BPFTrace 两个项目在观测和性能分析上已经有了诸多灵活且功能强大的工具箱，完全可以满足我们日常使用。\n BCC 提供了更高阶的抽象，可以让用户采用 Python、C++ 和 Lua 等高级语言快速开发 BPF 程序； BPFTrace 采用类似于 awk 语言快速编写 eBPF 程序；  更早期的工具则是使用 C 语言来编写 BPF 程序，使用 LLVM clang 编译成 BPF 代码，这对于普通使用者上手有不少门槛当前仅限于对于 eBPF 技术更加深入的学习场景。\n4.1 BCC 版本 HelloWorld 图 4-1 BCC 整体架构\n使用 BCC 前端绑定语言 Python 编写的 Hello World 版本：\n#!/usr/bin/python3 from bcc import BPF # This may not work for 4.17 on x64, you need replace kprobe__sys_clone with kprobe____x64_sys_clone prog = \u0026quot;\u0026quot;\u0026quot; int kprobe__sys_clone(void *ctx) { bpf_trace_printk(\u0026quot;Hello, World!\\\\n\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=prog, debug=0x04) b.trace_print() 运行程序前需要安装过 bcc 相关工具包，当运行正常的时候我们发现每当 sys_clone 系统调用时，运行的控制台上就会打印 “Hello, World!”，在打印文字前面还包含了调用程序的进程名称，进程 ID 等信息；\n 如果运行报错，可能是缺少头文件，一般安装 kernel-devel 包即可。\n # python ./hello.py kubelet-8349 [006] d... 33637334.829981: : Hello, World! kubelet-8349 [006] d... 33637334.838594: : Hello, World! kubelet-8349 [006] d... 33637334.843788: : Hello, World! 4.3 BPFTrace BPFTrace 是基于 BPF 和 BCC 的开源项目，与 BCC 不同的是其提供了更高层次的抽象，可以使用类似 AWK 脚本语言来编写基于 BPF 的跟踪或者性能排查工具，更加易于入门和编写，该工具的主要灵感来自于 Solaris 的 D 语言。BPFTrace 更方便与编写单行的程序。BPFTrace 与 BCC 一样也是 IO Visor 组织下的项目，仓库参见 bpftrace。更加深入的学习资料参见：Reference Guide 和 One-Liner Tutorial。\nBPFTrace 使用 LLVM 将脚本编译成 BPF 二进制码，后续使用 BCC 与 Linux 内核进行交互。从功能层面上讲，BPFTrace 的定制性和灵活性不如 BCC，但是比 BCC 工具更加易于理解和使用，降低了 BPF 技术的使用门槛。\n使用样例：\n# 统计进程调用 sys_enter 的次数 #bpftrace -e \u0026#39;tracepoint:raw_syscalls:sys_enter { @[comm] = count(); }\u0026#39; Attaching 1 probe... ^C @[bpftrace]: 6 @[systemd]: 24 @[snmp-pass]: 96 @[sshd]: 125 # 统计内核中函数堆栈的次数 # bpftrace -e \u0026#39;profile:hz:99 { @[kstack] = count(); }\u0026#39; Attaching 1 probe... ^C [...] @[ filemap_map_pages+181 __handle_mm_fault+2905 handle_mm_fault+250 __do_page_fault+599 async_page_fault+69 ]: 12 [...] @[ cpuidle_enter_state+164 do_idle+390 cpu_startup_entry+111 start_secondary+423 secondary_startup_64+165 ]: 22122 4.3 C 语言原生方式 采用 LLVM Clang 的方式编译会涉及到内核编译环境搭建，而且还需要自己编译 Makefile 等操作，属于高级用户使用：\nbpf_program.c\n#include \u0026lt;linux/bpf.h\u0026gt;#define SEC(NAME) __attribute__((section(NAME), used))  static int (*bpf_trace_printk)(const char *fmt, int fmt_size, ...) = (void *)BPF_FUNC_trace_printk; SEC(\u0026#34;tracepoint/syscalls/sys_enter_execve\u0026#34;) int bpf_prog(void *ctx) { char msg[] = \u0026#34;Hello, BPF World!\u0026#34;; bpf_trace_printk(msg, sizeof(msg)); return 0; } char _license[] SEC(\u0026#34;license\u0026#34;) = \u0026#34;GPL\u0026#34;; loader.c\n#include \u0026#34;bpf_load.h\u0026#34;#include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { if (load_bpf_file(\u0026#34;bpf_program.o\u0026#34;) != 0) { printf(\u0026#34;The kernel didn\u0026#39;t load the BPF program\\n\u0026#34;); return -1; } read_trace_pipe(); return 0; } Makefile 文件（部分）\nbuild: ${BPFCODE.c} ${BPFLOADER} $(CLANG) -O2 -target bpf -c $(BPFCODE:=.c) $(CCINCLUDE) -o ${BPFCODE:=.o} 其中 clang 编译中的选型 -target bpf 表明我们将代码编译成 bpf 的字节码。\n完整的程序参见：hello_world；更多的样例代码可以参见对应内核中 kernel-src/samples/bpf/ 下的样例代码。\n 后续会持续进行 BPF 相关的内容总结和分享，Github bpf_study 仓库，欢迎提交 PR 和 Star\n 5. 参考资料   The BSD Packet Filter: A New Architecture for User-level Packet Capture\n  [译] Cilium：BPF 和 XDP 参考指南（2019）  Cillum BPF and XDP Reference Guide\n  Cloudflare架构以及BPF如何占据世界\n  關於 BPF 和 eBPF 的筆記\n  Dive into BPF: a list of reading material 中文\n  eBPF 简史\n  https://www.youtube.com/watch?v=znBGt7oHJyQ\n  BPF Documentation HOWTO interact with BPF subsystem\n  Linux 内核 BPF 文档\n  Linux Extended BPF (eBPF) Tracing Tools Brendan Gregg\n  性能提升40%: 腾讯 TKE 用 eBPF绕过 conntrack 优化K8s Service\n  SDN handbook\n  Linux BPF 帮助文档 bpf(2) bpf-helpers(7) tc-bpf(8)\n  ","permalink":"https://cloudnative.to/blog/bpf-intro/","tags":["BPF"],"title":"eBPF 技术简介"},{"categories":["Kubernetes"],"contents":"目前在云原生社区的 Kubernetes 源码研习社中和广大学友们共同学习郑东旭大佬的 Kubernetes 源码剖析这本书。当前正在开展第一期学习活动，第五章节 client-go 的学习。之所以从这一章节开始学习，主要是考虑到 client-go 在源码中相对比较独立，可以单独阅读。更主要的是它是 Kubernetes 的核心处理框架，基本上运用在 Kubernetes 各个组件中，因此，如果你学好了这一章节，对于后面 Kubernetes 源码的阅读，将会有很大的帮助。此外随着 Operator 的盛行，一些开源的生成框架也受到广大 Operator 开发者们的青睐。例如 kubebuilder 和 operator-SDK 等。而精通了 client-go，将对你理解这些生成框架及编写 Operator 也是有很好的帮助。\n下面内容是在学习过程中总结的相关笔记及个人见解。\n概括 client-go 是用 Golang 语言编写的官方编程式交互客户端库，提供对 Kubernetes API server 服务的交互访问。\n其源码目录结构如下：\n discovery: 提供 DiscoveryClient 发现客户端。 dynamic: 提供 DynamicClient 动态客户端。 informers: 每种 K8S 资源的 Informer 实现。 kubernetes: 提供 ClientSet 客户端。 listers: 为每一个 K8S 资源提供 Lister 功能，该功能对 Get 和 List 请求提供只读的缓存数据。 plugin: 提供 OpenStack，GCP 和 Azure 等云服务商授权插件。 rest: 提供 RESTClient 客户端，对 K8S API Server 执行 RESTful 操作。 scale: 提供 ScaleClient 客户端，用于扩容或缩容 Deployment, Replicaset, Replication Controller 等资源对象。 tools: 提供常用工具，例如 SharedInformer, Reflector, DeltaFIFO 及 Indexers。 提供 Client 查询和缓存机制，以减少向 kube-apiserver 发起的请求数等。主要子目录为/tools/cache。 transport: 提供安全的 TCP 连接，支持 HTTP Stream，某些操作需要在客户端和容器之间传输二进制流，例如 exec，attach 等操作。该功能由内部的 SPDY 包提供支持。 util: 提供常用方法。例如 WorkQueue 工作队列，Certificate 证书管理等。  RESTClient 客户端 RESTful Client 是最基础的客户端，它主要是对 HTTP 请求进行了封装，并且支持 JSON 和 Protobuf 格式数据。\nDynamicClient 客户端 DynamicClient 是一种动态客户端，它可以动态的指定资源的组，版本和资源。因此它可以对任意 K8S 资源进行 RESTful 操作，包括 CRD 自定义资源。它封装了 RESTClient。所以同样提供 RESTClient 的各种方法。\n具体使用方法，可参考官方示例：dynamic-create-update-delete-deployment。\n注意: 该官方示例是基于集群外的环境，如果你需要在集群内部使用（例如你需要在 container 中访问），你将需要调用 rest.InClusterConfig() 生成一个 configuration。具体的示例请参考 in-cluster-client-configuration。\nClientSet 客户端 ClientSet 客户端在 RESTClient 的基础上封装了对资源和版本的管理方法。每个资源可以理解为一个客户端，而 ClientSet 则是多个客户端的集合，每一个资源和版本都以函数的方式暴露给开发者。\n具体使用方法，可参考官方示例：create-update-delete-deployment。\nDiscoveryClient 客户端 DiscoveryClient 是一个发现客户端，它主要用于发现 K8S API Server 支持的资源组，资源版本和资源信息。所以开发者可以通过使用 DiscoveryClient 客户端查看所支持的资源组，资源版本和资源信息。\nClientSet VS DynamicClient 类型化 ClientSets 使得使用预先生成的本地 API 对象与 API 服务器通信变得简单，从而获得类似 RPC 的编程体验。类型化客户端使用程序编译来强制执行数据安全性和一些验证。然而，在使用类型化客户端时，程序被迫与所使用的版本和类型紧密耦合。\n而 DynamicClient 则使用 unstructured.Unstructured 表示来自 API Server 的所有对象值。Unstructured 类型是一个嵌套的 map[string]inferface{} 值的集合来创建一个内部结构，该结构和服务端的 REST 负载非常相似。\nDynamicClient 将所有数据绑定推迟到运行时，这意味着程序运行之前，使用 DynamicClient 的的程序将不会获取到类型验证的任何好处。对于某些需要强数据类型检查和验证的应用程序来说，这可能是一个问题。\n然而，松耦合意味着当客户端 API 发生变化时，使用 DynamicClient 的程序不需要重新编译。客户端程序在处理 API 表面更新时具有更大的灵活性，而无需提前知道这些更改是什么。\nInformer 分析 这是一个官方图形表示，展示了client-go 库中的各种组件如何工作，以及它们与将要编写的自定义控制器代码的交互点。\n下面对图中每个组件进行简单介绍：\n  client-go 组件\n  Reflector: 定义在 /tools/cache 包内的 Reflector 类型 中的 reflector 监视 Kubernetes API 以获取指定的资源类型 (Kind)。完成此操作的函数是 ListAndWatch。监视可以用于内建资源，也可以用于自定义资源。当 reflector 通过监视 API 的收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。\n  Informer: 在 /tools/cache 包内的基础 controller 中定义的一个 informer 从 Delta FIFO 队列中弹出对象。完成此操作的函数是 processLoop。这个基础 controller 的任务是保存对象以供以后检索，并调用 controller 将对象传递给它。\n  Indexer: indexer 为对象提供索引功能。它定义在 /tools/cache 包内的 Indexer 类型。一个典型的索引用例是基于对象标签创建索引。Indexer 可以基于多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键值。在 /tools/cache 包内的 Store 类型 定义了一个名为MetaNamespaceKeyFunc的默认函数，该函数为该对象生成一个名为 \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; 组合的对象键值。\n    Custom Controller 组件\n  Informer reference: 这是一个知道如何使用自定义资源对象的 Informer 实例的引用。您的自定义控制器代码需要创建适当的 Informer。\n  Indexer reference: 这是一个知道如何使用自定义资源对象的 Indexer 实例的引用。您的自定义控制器代码需要创建这个。您将使用此引用检索对象，以便稍后处理。\n  Resource Event Handlers: 当 Informer 想要分发一个对象给你的控制器时，会调用这些回调函数。编写这些函数的典型模式是获取已分配对象的键值，并将该键值放入一个工作队列中进行进一步处理。\n  Work queue: 这是在控制器代码中创建的队列，用于将对象的分发与处理解耦。编写 Resource Event Handler 函数来提取所分发对象的键值并将其添加到工作队列中。\n  Process Item: 这是在代码中创建的处理 work queue 中的 items 的函数。可以有一个或多个其他函数来执行实际的处理。这些函数通常使用 Indexer 引用 或 Listing wrapper 来获取与键值对应的对象。\n    Informer 源码类图 该类图主要描述了 Informer 中主要的接口和类之前的调用关系。大家可以参考这个类图去阅读源码。其中每个类或接口具体功能，请参考 Kubernetes 源码剖析第五章节 client-go。\nIndexer 分析  Store : 是一个通用对象存储和处理接口。 Indexer : Indexer 扩展了多个索引的 Store，并限制每个累加器只保存当前对象（删除后为空）。 cache : 根据 ThreadSafeStore 和关联的 KeyFunc 实现的 Indexer。 ThreadSafeStore : 是一个允许对存储后端进行并发索引访问的接口。它类似于 Indexer，但不（必须）知道如何从给定对象中提取存储键。 threadSafeMap : 实现了 ThreadSafeStore。  下面为具体的类图展示：\nthreadSafeMap 分析 threadSafeMap 类中包含下面三个属性：\n items map[string]interface{} 保存所有数据的 map 结构。 indexers Indexers 通过一个名字映射一个 IndexFunc 索引处理函数。 indices Indices 通过一个名字映射一个 Index。  下面是 threadSafeMap 结构的源码定义：\n// threadSafeMap implements ThreadSafeStore type threadSafeMap struct { lock sync.RWMutex items map[string]interface{} // indexers maps a name to an IndexFunc  indexers Indexers // indices maps a name to an Index  indices Indices } 下面是 Indexers, Indices and Index 的源码定义：\n// IndexFunc knows how to compute the set of indexed values for an object. type IndexFunc func(obj interface{}) ([]string, error) // Index maps the indexed value to a set of keys in the store that match on that value type Index map[string]sets.String // Indexers maps a name to a IndexFunc type Indexers map[string]IndexFunc // Indices maps a name to an Index type Indices map[string]Index 这是一个 threadSafeMap 存储结构的示例图：\n最后以添加一个新的对象到 threadSafeMap 为例，分析具体需要哪些操作。\n首先列出源码以供参考：\nfunc (c *threadSafeMap) Add(key string, obj interface{}) { c.lock.Lock() defer c.lock.Unlock() oldObject := c.items[key] c.items[key] = obj c.updateIndices(oldObject, obj, key) } // updateIndices modifies the objects location in the managed indexes, if this is an update, you must provide an oldObj // updateIndices must be called from a function that already has a lock on the cache func (c *threadSafeMap) updateIndices(oldObj interface{}, newObj interface{}, key string) { // if we got an old object, we need to remove it before we add it again  if oldObj != nil { c.deleteFromIndices(oldObj, key) } for name, indexFunc := range c.indexers { indexValues, err := indexFunc(newObj) if err != nil { panic(fmt.Errorf(\u0026#34;unable to calculate an index entry for key %q on index %q: %v\u0026#34;, key, name, err)) } index := c.indices[name] if index == nil { index = Index{} c.indices[name] = index } for _, indexValue := range indexValues { set := index[indexValue] if set == nil { set = sets.String{} index[indexValue] = set } set.Insert(key) } } } 从上面代码可以总结出下面几个步骤：\n 从 items 中获取旧的对象值，并将新的对象添加到 items 中指定键值的位置。 将新加入对象的键值更新到索引中。  如果旧的对象存在，则将其从索引中删除，否则进行下一步。 迭代 indexers 进行新对象的索引处理。 通过 indexers 中的 indexFunc 处理新对象，找到相应的 indexValues。 使用 indexer 的 name 从 indices 中找到对应的 index。如果对应的 index 是空，则创建一个新的 index。 迭代 indexValues 进行 index 处理。 通过 indexValue 在 index 中找到对应的 set， 如果 set 不存在，则创建一个新的 set。并添加到 index 中。 添加新对象的键值到 set 中。 返回第 5 步，直到迭代完成。 返回第 2 步，直到迭代完成。    WorkQueue 分析 Interface : FIFO 队列接口，并支持去重处理。\nDelayingInterface: 延迟队列接口，基于 Interface 接口封装。\nRateLimitingInterface: 速率限制接口，基于 DelayingInterface 接口封装。\n下面是相关类图：\n示例参考   参考 K8S 官方示例 Kubernetes/sample-controller。\n  参考 client-go 官方示例 workqueue。这是一个典型的使用 client-go informer 的例子，它完全基于 client-go informer 的框架。几乎所有的 K8S 控制器都是基于这个框架实现的。所以个人认为 client-go 的 informer 机制是 k8S controller 实现的基石。\n  总结 可以说 Kubernetes 是当前云原生的基石。所以想要进军云原生领域，kubernetes 的学习必不可少。kubernetes 的设计理念就是通过各种控制器将系统的实际运行状态协调到声明 API 中的期待状态。而这种协调机制就是基于 client-go 实现的。同样，kubernetes 对于 ETCD 存储的缓存处理也使用到了 client-go 中的 Reflector 机制。所以学好 client-go，等于迈入了 Kubernetes 的大门。\n学习 Kubernetes 及更多云原生相关技术是一个漫长的过程。所以需要一个人有极强的意志力和学习动力。如果你觉得自己缺乏这些能力，可以加入我们 云原生社区。大家一起学习，相互督促，相互分享，相互学习，相互成长。\n最后送自己和正在学习及将要学习 Kubernetes 源码的同学们一句话：不积跬步，无以至千里；不积小流，无以成江海！\n参考文章  Source code Kubernetes client-go 库介绍和源码解析 Client-Go informer 机制 informer 之 store 和 index Kubernetes Client-Go Informer 实现源码剖析 client-go package Informer source code analysis kube-controller-manager 源码分析（三）之 Informer 机制 Sample-controller Indexer  ","permalink":"https://cloudnative.to/blog/client-go-study/","tags":["client-go"],"title":"client-go 源码学习总结"},{"categories":["BPF"],"contents":"TL;DR 声明：下文提到的bpf/BPF字样是泛指，包括cBPF和eBPF。\n通过文章，你能了解Linux内核代码中关于bpf程序的编译运行机制，并能学会如何基于Linux内核bpf示例环境编写你自己的bpf程序。文章涉及的实验环境和代码可以到这个git repo获取： https://github.com/nevermosby/linux-bpf-learning\n最近Kubecon 2020 China上已经有了3个关于bpf的中文分享（来自腾讯和PingCAP），也看到国内第一梯队公司越来越关心bpf这项新技术，欢迎大家都能加入bpf学习队伍。\n内核源码里的BPF示例代码概述 示例代码里基本是kern和user成对出现，也就是对于一个示例来说，分别提供了在内核空间运行的和用户空间运行的程序，绝对是良心之作了。\n下载Linux内核源代码 First thing first，第一步是下载内核代码。\n选择内核版本 目前社区维护的内核版本繁多，你需要确定下载哪个版本的代码。个人建议是下载与你的操作系统运行一致的内核版本，避免后续编译时出现不兼容问题。\n选择下载渠道 代码下载渠道也很多：\n  通过Linux社区官方仓库下载。以下几个网站都是官方维护的：\n https://github.com/torvalds/linux https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git 观察下来，只要有新的commit，基本是实时同步的，下载最新版本的内核代码肯定没问题。如果你跟我一样，需要相对较旧的版本，只要切换相关的目标tag即可。我的内核版本是v4.15.0，下载地址参考如下：  https://github.com/torvalds/linux/tree/v4.15 https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tag/?h=v4.15      通过Ubuntu apt仓库下载。Ubuntu官方自己维护了每个操作系统版本的背后的Linux内核代码，可以通过以下两种apt命令方式获取相关代码：\n# 第一种方式 # 先搜索 \u0026gt; apt-cache search linux-source linux-source - Linux kernel source with Ubuntu patches linux-source-4.15.0 - Linux kernel source for version 4.15.0 with Ubuntu patches linux-source-4.18.0 - Linux kernel source for version 4.18.0 with Ubuntu patches linux-source-5.0.0 - Linux kernel source for version 5.0.0 with Ubuntu patches linux-source-5.3.0 - Linux kernel source for version 5.3.0 with Ubuntu patches # 再安装 \u0026gt; apt install linux-source-4.15.0 # 第二种方式 \u0026gt; apt-get source linux Reading package lists... Done NOTICE: \u0026#39;linux\u0026#39; packaging is maintained in the \u0026#39;Git\u0026#39; version control system at: git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/bionic Please use: git clone git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/bionic to retrieve the latest (possibly unreleased) updates to the package. Need to get 167 MB of source archives. Get:2 https://mirrors.ustc.edu.cn/ubuntu bionic-updates/main linux 4.15.0-99.100 (tar) [158 MB] ...... # 以上两种方式，内核源代码均下载至/usr/src/目录下   下载完成后，BPF示例就在源码根目录/samples/bpf目录下，可以到这里看个在线版的，建议大家通读一遍这个目录下的README.rst，了解整体步骤。\n编译BPF示例代码 安装编译所依赖的工具 在真正开始编译工作之前，请确保你的实验环境已经安装clang和llvm：\n clang \u0026gt;= version 3.4.0 llvm \u0026gt;= version 3.7.1  正式编译示例代码 万事俱备了，可以正式开始编译工作。我们说的“编译”其本质就是利用内核目录下不同的Makefile，通过特定的make指令完成特定工作。来，先上命令：\n# 切换到内核源代码根目录 cd linux_sourcecode/ # 生成内核编译时需要的头文件 make headers_install # 可视化选择你想为内核添加的内核模块，最终生成保存了相关模块信息的.config文件，为执行后面的命令做准备 make menuconfig # 使用make命令编译samples/bpf/目录下所有bpf示例代码，注意需要加上最后的/符号 make samples/bpf/ # or make M=samples/bpf 如下截图看结果，生成了一大堆的文件，有.o后缀的目标文件，还有绿色高亮的可执行文件，挑两个执行下，效果符合期待。\n分析samples/bpf/Makefile文件 如果你是个喜欢打破砂锅问到底的同学，可以跟我一起看看最后的make命令到底用了什么魔法？当然你也可以跳过这个章节。本次分析的Makefile是基于内核版本v4.15.0，不同内核版本的Makefile内容会有差异，但总体逻辑是一致的。\n前提条件  如果你对make作为构建工具还不熟悉，可以看看这个教程。 Linux内核中大部分Makefile都是基于Kernel Build System，简称kbuild，它是对Makefile的扩展，使其在编译内核文件时更加高效、简洁。因此你需要对其有所了解，可以到这里看看官方介绍。 上文使用的另外两个make命令，利用的是根目录下的Makefile，完成“生成头文件”和“生成.config文件”，这两步是内核开发的必要步骤，感兴趣的同学移步看README.rst。  分段分析   第一段关于变量hostprogs-y\n# List of programs to build hostprogs-y := test_lru_dist hostprogs-y += sock_example hostprogs-y += fds_example hostprogs-y += sockex1 hostprogs-y += sockex2 hostprogs-y += sockex3 ... Makefile的第一段是初始化变量hostprogs-y，乍一看，好像是把所有示例程序名称都赋值给了hostprogs-y。官方的注释是List of programs to build，直译过来是，“准备构建的程序清单”、，大致能猜出这个变量的意义了，通过查询官方文档，发现一个概念叫Host Program support，意思是在编译阶段就构建出可以在本机直接运行的可执行文件，为了实现这个目的，需要经过两个步骤：\n  第一步告诉 kbuild 需要生成哪些可执行文件，这个就是通过变量hostprogs-y来指定。来看源码中的这一行：\nhostprogs-y := test_lru_dist 程序test_lru_dist就是一个被指定的可执行程序名称，kbuild默认会去同一个目录下查找名为test_lru_dist.c作为构建这个可执行文件的源文件。类似代码也是同样的意义，总计有41个可执行文件赋值给了变量hostprogs-y中。\n  第二步是将显式依赖关系添加到可执行文件中。这可以通过两种方式来完成，一种是为Makefile中某个target添加这个可执行文件，作为prerequisites，形成依赖关系，这样就可以触发这个可执行文件的构建任务，另一种是直接利用变量 always，即无需指定第一种方式中的依赖关系，只要Makefile被执行，变量always中包含的可执行文件都会被构建。来看源码中的相关片段：\n# Tell kbuild to always build the programs always := $(hostprogs-y) 可以看到它使用上文提到的第二种方式，保证这些可执行文件一定会被执行构建任务。\n    第二段关于变量\u0026lt;executeable\u0026gt;-objs\n# Libbpf dependencies LIBBPF := ../../tools/lib/bpf/bpf.o CGROUP_HELPERS := ../../tools/testing/selftests/bpf/cgroup_helpers.o test_lru_dist-objs := test_lru_dist.o $(LIBBPF) sock_example-objs := sock_example.o $(LIBBPF) fds_example-objs := bpf_load.o $(LIBBPF) fds_example.o sockex1-objs := bpf_load.o $(LIBBPF) sockex1_user.o sockex2-objs := bpf_load.o $(LIBBPF) sockex2_user.o sockex3-objs := bpf_load.o $(LIBBPF) sockex3_user.o ... 第一、二行是声明并初始化了两个变量LIBBPF和CGROUP_HELPERS，以便后续复用。后面的几行是有共性的，:=符号左边是个有规律的变量：\u0026lt;executeable\u0026gt;-objs，右边是多个.o文件，看上去的意义像是右边的多个文件会合并成一个指定文件。通过查询文档可知，可执行文件可以由多个其他文件复合组成，通过\u0026lt;executeable\u0026gt;-objs这样的语法，可以列出并指定所有用于生成最终可执行文件（命名为executeable）的文件清单。以如下代码为例，可执行文件sockex1是由bpf_load.o、bpf.o和sockex1_usr.o链接生成的。\nsockex1-objs := bpf_load.o $(LIBBPF) sockex1_user.o   第三段关于变量HOSTCFLAGS和HOSTLOADLIBES\nHOSTCFLAGS += -I$(objtree)/usr/include HOSTCFLAGS += -I$(srctree)/tools/lib/ HOSTCFLAGS += -I$(srctree)/tools/testing/selftests/bpf/ HOSTCFLAGS += -I$(srctree)/tools/lib/ -I$(srctree)/tools/include HOSTCFLAGS += -I$(srctree)/tools/perf HOSTCFLAGS_bpf_load.o += -I$(objtree)/usr/include -Wno-unused-variable HOSTLOADLIBES_fds_example += -lelf HOSTLOADLIBES_sockex1 += -lelf HOSTLOADLIBES_sockex2 += -lelf HOSTLOADLIBES_sockex3 += -lelf ... HOSTLOADLIBES_tracex4 += -lelf -lrt ... 上面的代码中有两个关键变量：\n 变量HOSTCFLAGS顾名思义，它是在编译host program（即可执行文件）时，为编译操作指定的特殊选项，如上面代码中使用-I参数指定依赖的头文件所在目录。默认情况下，这个变量的配置会作用到当前Makefile涉及的所有host program。如果你想为某个host program单独指定一个编译选项，可以像上文的这行代码： HOSTCFLAGS_bpf_load.o += -I$(objtree)/usr/include -Wno-unused-variable 只为bpf_load.o这个object文件指定特殊选项。\n 变量HOSTLOADLIBES是用于链接（link）操作时指定的特殊选项，如上面代码中使用两个library（因为代码中使用了相关的函数），通过选项-l加到最终生成的可执行文件中：  libelf，这个库用来管理elf格式的文件，bpf程序一般都会使用elf作为最终格式，因此需要加载这个library。 librt，这个库其实很常用，一般含有#include\u0026lt;time.h\u0026gt;头文件的代码，都需要加载这个library，用来支持real time相关功能。      第四段关于如何编译BPF程序源文件\n# Trick to allow make to be run from this directory all: $(MAKE) -C ../../ $(CURDIR)/ ... $(obj)/%.o: $(src)/%.c $(CLANG) $(NOSTDINC_FLAGS) $(LINUXINCLUDE) $(EXTRA_CFLAGS) -I$(obj) \\  -I$(srctree)/tools/testing/selftests/bpf/ \\  -D__KERNEL__ -Wno-unused-value -Wno-pointer-sign \\  -D__TARGET_ARCH_$(ARCH) -Wno-compare-distinct-pointer-types \\  -Wno-gnu-variable-sized-type-not-at-end \\  -Wno-address-of-packed-member -Wno-tautological-compare \\  -Wno-unknown-warning-option $(CLANG_ARCH_ARGS) \\  -O2 -emit-llvm -c $\u0026lt; -o -| $(LLC) -march=bpf -filetype=obj -o $@ 其中有两个系统变量：第一个$@代表的是target所指的文件名；第二个$\u0026lt;代表的是第一个prerequisite的文件名。看过本站关于BPF博文的同学可能已经看出如上代码的玄机了，我把它简化下：\nclang -I $(srctree)/tools/testing/selftests/bpf/ \\  -O2 -emit-llvm -c $\u0026lt; -o -| \\  llc -march=bpf -filetype=obj -o $@ 从上面的简化版命令，可以看出最后一行make命令的本质，就是把所有.c源代码文件，通过clang全部编译成.o目标文件。\n  小结 对samples/bpf/Makefile这个文件执行make命令的本质就是：\n 为运行在内核空间的示例源代码（一般文件名称后缀为kern.c），编译生成.o后缀的目标文件，以便加载到对应BPF提供的hook中去。 为运行在用户空间的示例源代码(一般文件文件后缀为user.c)，编译生成可以在本机直接运行的可执行文件，以便用户可以直接运行测试。  我在执行Make命令遇到的问题 我自己的实验环境是Ubuntu 18.04 with 4.15.0内核，在执行上面的make命令时，发生了以下的错误信息：\n... In file included from ./tools/perf/perf-sys.h:9:0, from samples/bpf/bpf_load.c:28: ./tools/perf/perf-sys.h: In function ‘sys_perf_event_open’: ./tools/perf/perf-sys.h:68:15: error: ‘test_attr__enabled’ undeclared (first use in this function) if (unlikely(test_attr__enabled)) ^ ./tools/include/linux/compiler.h:74:43: note: in definition of macro ‘unlikely’ # define unlikely(x) __builtin_expect(!!(x), 0) ^ ./tools/perf/perf-sys.h:68:15: note: each undeclared identifier is reported only once for each function it appears in if (unlikely(test_attr__enabled)) ^ ./tools/include/linux/compiler.h:74:43: note: in definition of macro ‘unlikely’ # define unlikely(x) __builtin_expect(!!(x), 0) ^ In file included from samples/bpf/bpf_load.c:28:0: ./tools/perf/perf-sys.h:69:3: warning: implicit declaration of function ‘test_attr__open’ [-Wimplicit-function-declaration] test_attr__open(attr, pid, cpu, fd, group_fd, flags); ^~~~~~~~~~~~~~~ scripts/Makefile.host:107: recipe for target \u0026#39;samples/bpf/bpf_load.o\u0026#39; failed make[1]: *** [samples/bpf/bpf_load.o] Error 1 Makefile:1823: recipe for target \u0026#39;samples/bpf/\u0026#39; failed make: *** [samples/bpf/] Error 2 根据错误信息，查看发生错误的文件为**./tools/perf/perf-sys.h**，报错的那一行是test开头的。通过Google发现了内核大佬们的邮件来往：https://www.spinics.net/lists/netdev/msg608676.html。大佬们建议由于是测试相关的代码，所以可以skip掉。修改完的文件在这里，请斟酌参考。重新运行make命令，错误不再发生了。\nmake samples/bpf/ # and it works 编译运行自己的BPF程序 如果你想利用Linux内核环境来编译自己的BPF程序，是非常方便的。只要对samples/bpf/目录下的Makefile进行一点点自定义改造即可，如果你仔细阅读了上面的分析，那么改造的原理就显而易见了：\n# 假设你自己BPF程序如下所示： # 内核空间代码：my_bpf_101_kern.c # 用户空间代码：my_bpf_101_user.c # 从上之下，添加新的代码行 # 1. 追加新的一行至hostprogs-y开头的代码块最后，保证自己的BPF程序能够生成可执行文件 hostprogs-y += my_bpf_101 # 2. 一般BPF程序使用以下命令即可，具体取决于你的程序是否依赖其他特殊头文件 my_bpf_101-objs := bpf_load.o $(LIBBPF) my_bpf_101_user.o # 3. 追加新的一行至always开头的代码块最后，保证触发生成可执行文件的任务 always += my_bpf_101_kern.o 一般的BPF程序只需要通过如上3处更新加入到Makefile中，就可以使用make samples/bpf/命令，生成你自己程序的可执行文件了。\n","permalink":"https://cloudnative.to/blog/compile-bpf-examples/","tags":["源码分析","Linux内核"],"title":"编译运行Linux内核源码中的eBPF示例代码"},{"categories":["Kubernetes"],"contents":"Kubernetes 诞生至今已经 5 年了，火爆整个社区，大家对 Kubernetes 越来越熟悉，越来越了解。但现阶段很多人都是熟练使用 Kubernetes，甚至我们会自嘲为 “YAML 工程师”。\n可是随着各类云原生应用的出现、Operator 理念的推广、深入维护 Kubernetes 的需求下，仅仅做一个 \u0026ldquo;YAML 工程师\u0026rdquo; 已经不能满足老板的要求了。需要我们进一步了解 Kubernetes 是如何实现的，该怎么扩展 Kubernetes。\n我在这样的场景下，开始学习 Kubernetes 编程，在这里总结了我学习到的 Kubernetes 编程的基础知识，让大家对 Kubernetes 编程有个大致的了解。\n基于 Kubernetes 编程 什么叫做基于 Kubernetes 编程呢？回想一下，我们以前听过基于 Linux 编程，基于 Windows 编程，可以放在‘基于’后面的都是通用标准的平台。基于 Kubernetes 编程有着相同的概念，Kubernetes 经过 5 年的高速发展，已经成为了容器编排调度框架的标准，直接将之定义为 “云原生操作系统” 也不为过。\n基于 Kubernetes 编程可以定义为，开发一个 Kubernetes-native 应用，它直接与 K8S API Server（K8S 的一个核心组件，后面会介绍）交互，查询资源的状态或更新状态。\n为什么要基于 Kubernetes 编程呢？大多数基于 Kubernetes 编程的服务都属于 PaaS 层的能力，PaaS 将服务抽象成应用进行分发部署管理，并且对应用屏蔽下层 IaaS 的复杂度。PaaS 层是在 Kubernetes 诞生之前就存在的，在 Kubernetes 环境下以前很多 PaaS 层的应用都需要进行改造迁移，或者被云原生时代的新应用代替，随之诞生了服务网格、Operator 等云原生产物。\n这些需求都是要基于 Kubernetes 编程来实现的，因此掌握 Kubernetes 编程是做云原生开发，PaaS 平台的必备基础。\n学习 Kubernetes 编程后会对 Kubernetes 的各个组件有更加深刻的认知。比如你了解了 controller 架构模式  后就会知道（以下说法并不严谨，只列出组件中的部分功能）:\n kube-proxy 是 Service 资源和服务发现负载之间的协调控制器。 kubelet 是 Pod 资源和容器运行时之间的协调控制器。  了解 API Server 的架构后就知道， kubectl 其实是高级定制版的 curl 工具。\n扩展模式 Kubernetes 是一个强大的并且内聚的可扩展系统。 常用的有如下扩展点：\n 二进制 kubelet 插件，如 网络 (CNI)、设备、存储 (CSI)、容器运行时 (CRI) 二进制 kubectl 插件 API server 中的访问扩展，例如 webhooks 的动态准入控制 自定义资源（CRD）和自定义 controller 自定义 API servers 调度器扩展，例如使用 webhook 来实现自己的调度决策 通过 webhook 进行 身份验证  Kubernetes 提供了很强的扩展能力，其本身的很多组件也是使用了这种扩展能力来实现的。controller 模式是 Kubernetes 编程中通用性最强，使用最多的扩展能力。\nController 实现控制循环，通过 API Server 监听集群的共享状态，根据资源的当前状态做出反应更改真实世界，使将资源更接近期望状态。\n控制循环 The Control Loop 所有的控制器都按照以下逻辑运行:\n 由事件驱动来读取资源 (resources) 的状态 (state)。 更改集群内或集群外对象的状态 (state)。比如，启动一个 Pod，创建 Endpoint。 通过 API server 更新步骤 1 中的资源状态（status），存储到 etcd 中。 重复循环，返回步骤 1。  引用自《Programming Kubernetes》\n控制器组件 从架构的角度来看，Controller 通常使用以下数据结构:\n引用自 “深入剖析 Kubernetes”\n Informers 从 Kubernetes API Server 里监听它所关心的对象状态，Informer 与 API 对象是一一对应的。 Reflector 连接 APIServer，使用 ListAndWatch 方法，获取并监听 API 对象实例的变化。 变化事件及对应的 API 对象，被称为增量，放进 Delta FIFO Queue。 Delta FIFO Queue 存放事件数据 Store 对象在本地的缓存 Indexer 查询与索引本地缓存的数据结构 ResourceEventHandler 在初始化时将事件类型对应的处理函数注册到 Informer，当事件触发时，由 Informer 调用 Handler Work queues 在执行周期里 (processNextWorkItem)，从工作队列 (workqueue) 中获取一个对象来处理。 event handler 可以通过它来排队或重试状态变化处理任务。 资源在处理中遇到错误时可以被重新入队 (requeued)。  事件 Event Kubernetes 控制平面大量使用事件和松散耦合的组件。 其他分布式系统常使用远程调用（RPC）来触发行为。 但 Kubernetes 并没有这么做。Kubernetes controller 监听 API server 中 Kubernetes 对象的操作：添加，更新和删除。 当发生此类事件时，controller 将执行其业务逻辑。\n例如，为了通过 deployment 来启动 pod，就涉及到许多 controller 和其他控制平面组件协同工作：\n Deployment controller（在 kube-controller-manager 内部）感知到（通过 deployment informer）用户创建了一个 deployment。根据其业务逻辑，它将创建一个 replica set。 Replica set controller（同样在 kube-controller-manager 内部）感知到（通过 replica set informer）新的 replica set 被创建了。并随后运行其业务逻辑，它将创建一个 pod 对象。 Scheduler（在 kube-scheduler 二进制文件内部）——同样是一个 controller，感知到（通过 pod informer）pod 设置了一个空的 spec.nodeName 字段。根据其业务逻辑，它将该 pod 放入其调度队列中。 与此同时，另一个 controller kubelet（通过其 pod informer）感知到有新的 pod 出现，但是新 pod 的 spec.nodeName 字段为空，因此与 kubelet 的 node name 不匹配。它会忽视该 pod 并返回休眠状态（直到下一个事件）。 Scheduler 更新 pod 中的 spec.nodeName 字段，并将该字段写入 API server，由此将 pod 从工作队列中移出，并调度到具有足够可用资源的 node 上。 由于 pod 的更新事件，kubelet 将被再次唤醒，这次再将 pod 的 spec.nodeName 与自己的 node name 进行比较，会发现是匹配的，接着 kubelet 将启动 pod 中的容器，并将容器已启动的信息写入 pod status 中， 由此上报给 API server。 Replica set controller 会感知到已更新的 pod，但并不会做什么。 如果 pod 终止，kubelet 将感知到该事件，进而从 API server 获取 pod 对象，并把 pod status 设置为 “terminated”，然后将其写回到 API server。 Replica set controller 会感知到终止的 pod，并决定必须更换此 pod。它将在 API server 上删除终止了的 pod，然后创建一个新的 pod。 依此类推。  许多独立的控制循环只通过 API server 上对象的变化进行通信，这些变化通过 informer 触发事件。\n书中第一章后面还介绍了事件驱动对应 I/O 模型选择，如何处理并发，Operator 等话题，参考后面给出的 [推荐阅读](# 推荐阅读) 继续阅读。\nI/O 模型的相关知识可以额外阅读《Linux/UNIX 系统编程手册》第 63 章。\nThe API Server Kubernetes 由一堆不同角色的节点（集群中机器）组成，如下图所示：主节点的控制面由 API Server，controller manager 和 scheduler 组成。API Server 是系统的中央管理实体（central management entity），它是系统中唯一个与分布式存储组件 etcd 进行直接交互的组件。\n主要完成以下任务：\n  为 Kubernetes API 提供服务\n 读取状态 (state) 操作状态 (state)    代理转发集群组件\n Kubernetes dashboard 代理 kubectl exec 会话    引用自《Programming Kubernetes》\nAPI Server HTTP 协议接口  API server 使用 RESTful HTTP API 外部请求正常使用 json 格式 内部调用使用 protocol buffer ，为了更高的性能 使用 API 路径参数，如 GET /api/v1/namespaces/{namespace}/pods  使用 kubectl 指令列出当前命名空间下的 pods，kubectl -n *THENAMESPACE* get pods。实际上会发出 GET /api/v1/namespaces/THENAMESPACE/pods 的 HTTP 请求，通过 -v 6 参数能看到 HTTP 请求的 log。\nI0804 10:55:47.463928 23997 loader.go:375] Config loaded from file: /root/.kube/config ... ... I0804 10:55:51.689482 23997 round_trippers.go:443] GET https://172.24.28.3:6443/api/v1/namespaces/default/pods?limit=500 200 OK in 36 milliseconds NAME READY STATUS RESTARTS AGE busybox 1/1 Running 119 4d23h redis-cli 1/1 Running 303 12d API 术语 弄清楚什么是 RESTful 架构 就很容易理解和区分 Kubernetes API Server 里面这些概念。 如果一个架构符合 REST 原则，就称它为 RESTful 架构，REST 是 Representational State Transfer 的缩写，可以翻译为 \u0026ldquo;表现层状态转化\u0026rdquo;，这里省略了主语 “资源”（Resources)。 核心在于 “资源”，它是一种信息实体，可以有很多种外在表现形式，我们把 “资源” 具体呈现出来的形式，叫做它的 “表现层”（Representation）。\nRESTful API 是基于 HTTP 协议且符合 REST 原则的软件架构，controller 架构也符合 REST 原则。在 Kubernetes 中同时使用了这两种架构，所以弄出来了一些术语来区分指代实体，其实都是 “资源” 这一信息实体在不同上下文中的不同表示形态。\n    RESTful API controller 架构     实体类型 Resource Kind   实现方式 http controller   资源定位 URL Path GroupVersionKind    Kind 表示实体的类型。每个对象都有一个字段 Kind（JSON 中的小写 kind，Golang 中的首字母大写 Kind），该字段告诉如 kubectl 之类的客户端它表示什么类型。\nAPI group 在逻辑上相关的一组 Kind 集合。 如 Job 和 ScheduledJob 都在 batch API group 里。\nVersion 标示 API group 的版本更新， API group 会有多个版本 (version)。\n v1alpha1: 初次引入 v1beta1: 升级改进 v1: 开发完成毕业  在持续开发中，对象会发生变化，便用 Version 来标示版本变化。 对象会存储所有版本的对象属性的并集。但是在取出时指定版本，即只会取出这个版本所需要的对象定义。\nResource 通常是小写的复数词（例如，pod），用于标识一组 HTTP 端点（路径），来对外暴露 CURD 操作。\nGVR Resource 和 API group、Version 一起称为 GroupVersionResource（GVR），来唯一标示一个 HTTP 路径。\n引用自《Programming Kubernetes》\n声明式状态管理 controller 模式能运作的另一大原因是声明式状态管理，它规定资源必须要有在 spec 中定义的期望状态（desired state）, 和由 controller 补充的当前状态（current status），填写在 status 中。\nspec 定义的期望状态提供了实现 \u0026ldquo;infrastructure-as-code\u0026rdquo; 的基础，让 controller 可以在 event 触发、水平获取、定时同步的时候都可以获取到资源的期望状态。另一方面 status 的设计让 controller 了解到资源当前状态，进而作出操作来调协资源的当前状态与期望状态，再将调协后的当前状态写入 status。这种设计完全可以仍受因网络分区等原因造成的数据短暂不一致问题。\n举个例子，在一个 deployment 里你可能指定想要 20 个应用程序的副本（replicas）持续运行。deployment controller 作为控制面中 controller manager 的一部分，将读取你提供的 deployment spec，并创建一个 replica set 用于管理这些副本，再由 replicat set 来负责创建对应数量的 pods，最终结果是在工作节点上启动容器。如果任何的副本挂了，deployment controller 让你通过 status 可以感知到。这就是我们说的声明式状态管理（declarative state management），简而言之，就是声明期望的状态，剩下的交给 Kubernetes。\n推荐阅读 Programming Kubernetes 本文是阅读《Programming Kubernetes》书籍前两章时做的笔记与总结。\n这本书是由来自 AWS 和 Red Hat 的两位高级工程师写作的，他们自 2015 年以来就一直致力于 Kubernetes 的开发，写作，教学。\n书中主要围绕着 “Kubernetes 扩展编程 “ 主题讲了 Kubernetes 编程基础，client-go，自定义资源（CRD），Operator，API Servers 扩展等内容。\n对于接触过云原生但不想仅仅停留在使用阶段的朋友，这本书值得一读，通过学习如何在 Kubernetes 基础上做开发，能让你更加了解 Kubernetes，后续可以深入阅读 Kubernetes 源码。\n这本书目前国内还未出版，可以去购买 ACM 会员，在 Oreilly 官网 上阅读。 或者加入 云原生社区，社区内分享了 Programming Kubernetes 中文版（腾讯内部翻译）。在 社区 Github 仓库 Issue 下回复即可。\nKubernetes 源码剖析 对 Kubernetes 编程有了基础的了解后，推荐大家阅读 《Kubernetes 源码剖析》，由来自百度 BFE 团队的郑东旭大佬写的。 前文说了，Kubernetes 本身的很多组件是通过 controller 模式来写的，对于我们编写 Kubernetes 扩展应用来说，是极好的样例代码。 书中第 3 章分析了 Kubernetes 核心数据结构，第 5 章详细的分析了在扩展编程时必不可少的依赖库 client-go，有需求的同学还可以根据第 2 章的说明自己构建 Kubernetes 组件。\n目前（2020-08）云原生社区正在组织 Kubernetes 源码剖析精读活动，有兴趣的同学可以加入一起学习，具体信息查看 社区 Issue。\n深入剖析 Kubernetes 这是极客时间的课程，其中的第 23、24、25 节简短的过了一下 Kubernetes 编程。\n参考  理解 RESTful 架构 Kubernetes ApiServer 并发安全机制 深入剖析 Kubernetes  ","permalink":"https://cloudnative.to/blog/kubernetes-programming-base/","tags":["Kubernetes"],"title":"Kubernetes 编程基础知识"},{"categories":["开源社区"],"contents":"IT 技术日新月异，想必每个 IT 人都会有类似的焦虑：我该学习什么？哪些知识学到就是赚到？怎样学习才能最有效提升编程能力？\n阅读优秀的代码是提高编程能力万无一失的办法。诚然，提高编程能力的显著方法是写更多代码，但也需要静下心来品味优秀的代码，大侠行走江湖也需要武功秘籍，而当今优秀的开源项目代码便是程序员的武林秘籍。\n优秀的开源项目浩如烟海，应该如何选择适合自己的项目呢？\n选择方式有很多，比如项目使用到什么开源项目就学习该项目的源码，比如基于 Apache Dubbo 构建微服务，则可以学习 Dubbo 框架源码，理解其底层机制以及原理（比如服务治理），学以致用；阅读那些让你印象深刻或者自己可以掌握的源码，比如从一个小项目或者一个插件开始，也是不错的选择；最重要的是，大多数人时间有限但选择又太多，一定要选择适合自己的，能够融入自己的知识体系。如果你是云原生爱好者，那么阅读 Kubernetes 核心源码就是一个非常好的选择。\n找到一个合适的开源项目后，但在具体实践的时候常常因为一些不正确的看法而误入歧途，中途折戟：\n 缺乏自信，我并未参与该项目开发，因此我很难深入理解其源码 数据结构和算法很重要，所以只需要研究开源项目的数据结构和算法就够了 “Talk is cheap, show me the code”，一头扎进源码，只见树木不见森林  这些看法要么会让人半途而废又或者徒劳无功，那该如何更高效的学习开源项目的源码呢？\n简而言之，纵览全局，按需学习，由上及下，自下而上，避免一开始陷入细节。\n 纵览全局，运筹帷幄。在开始之前需要宏观上了解要学习的项目，了解其背景、功能、业务价值等等，学习方式非常多，比如项目网站、入门教程、官方文档目录等，方便我们快速纵览全局，了解项目主要组成部分。 按需学习，有所取舍。工作后时间有限精力有限，需要在纵览全局后辨别出哪三个功能是对自己最有益处的，摒弃其他模块，全力攻克对自己有价值的功能以及源码。 由上及下，先理解功能、原理以及关键设计后再剖析源码。 自下而上，从一个个实践问题剖析源码。 拓展联系，触类旁通。深度探索（比如 5W2H），横向拓展（比如多种 pod 调度算法横向对比），纵向类比（比如 Kubernetes 与数据库概念上的异同）。  读源码如读书，积累的越多，越熟练，读得越快。\n读书活动介绍 云原生是未来 10 年 IT 发展最重要的趋势，而 Kubernetes 正是云原生的基石。另一方面，《Kubernetes 源码剖析》深入浅出的讲解了 kubernetes 的架构以及核心源码，是进阶 Kubernetes 的不二之选。\n云原生社区 Kubernetes 源码研习社招募志同道合的热爱学习的小伙伴，共同研读《Kubernetes 源码剖析》。\n加入研习社方式 加入知识星球，扫码置顶二维码即可加入云原生社区的 Kubernetes 源码研习社\n欢迎加入 云原生社区\n你能收获什么？  对 Kubernetes 核心源码有更深刻的理解 一群热爱云原生的志同道合的朋友  ","permalink":"https://cloudnative.to/blog/study-groups/","tags":["学习小组"],"title":"如何学习开源项目源码"},{"categories":["GoLang"],"contents":" 本文主要分享火焰图使用技巧，介绍 systemtap 的原理机制，如何使用火焰图快速定位性能问题原因，同时加深对 systemtap 的理解。\n 让我们回想一下，曾经作为编程新手的我们是如何调优程序的？通常是在没有数据的情况下依靠主观臆断来瞎蒙，稍微有些经验的同学则会对差异代码进行二分或者逐段调试。这种定位问题的方式不仅耗时耗力，而且还不具有通用性，当遇到其他类似的性能问题时，需要重复踩坑、填坑，那么如何避免这种情况呢？\n俗语有云：“工欲善其事，必先利其器。”个人认为，程序员定位性能问题也需要一件“利器”。 如同医生给病人看病，需要依靠专业的医学工具（比如 X 光片、听诊器等）进行诊断，最后依据医学工具的检验结果快速精准地定位出病因所在。性能调优工具（比如 perf / gprof 等）之于性能调优就像 X 光之于病人一样，它可以一针见血地指出程序的性能瓶颈。\n但是常用的性能调优工具 perf 等，在呈现内容上只能单一地列出调用栈或者非层次化的时间分布，不够直观。这里我推荐大家配合使用火焰图，它将 perf 等工具采集的数据呈现得更为直观。\n初识火焰图 火焰图（Flame Graph）是由 Linux 性能优化大师 Brendan Gregg 发明的，和所有其他的 profiling 方法不同的是，火焰图以一个全局的视野来看待时间分布，它从底部往顶部，列出所有可能导致性能瓶颈的调用栈。\n火焰图整个图形看起来就像一个跳动的火焰，这就是它名字的由来。\n火焰图有以下特征（这里以 on-cpu 火焰图为例）：\n 每一列代表一个调用栈，每一个格子代表一个函数； 纵轴展示了栈的深度，按照调用关系从下到上排列，最顶上格子代表采样时，正在占用 cpu 的函数； 横轴的意义是指：火焰图将采集的多个调用栈信息，通过按字母横向排序的方式将众多信息聚合在一起。需要注意的是它并不代表时间； 横轴格子的宽度代表其在采样中出现频率，所以一个格子的宽度越大，说明它是瓶颈原因的可能性就越大； 火焰图格子的颜色是随机的暖色调，方便区分各个调用信息； 其他的采样方式也可以使用火焰图， on-cpu 火焰图横轴是指 cpu 占用时间，off-cpu 火焰图横轴则代表阻塞时间； 采样可以是单线程、多线程、多进程甚至是多 host，进阶用法可以参考附录进阶阅读；  火焰图类型 常见的火焰图类型有 On-CPU，Off-CPU，还有 Memory，Hot/Cold，Differential 等等。他们分别适合处理什么样的问题呢？\n这里笔者主要使用到的是 On-CPU、Off-CPU 以及 Memory 火焰图，所以这里仅仅对这三种火焰图作比较，也欢迎大家补充和斧正。\n火焰图分析技巧  纵轴代表调用栈的深度（栈桢数），用于表示函数间调用关系：下面的函数是上面函数的父函数； 横轴代表调用频次，一个格子的宽度越大，越说明其可能是瓶颈原因； 不同类型火焰图适合优化的场景不同，比如 on-cpu 火焰图适合分析 cpu 占用高的问题函数，off-cpu 火焰图适合解决阻塞和锁抢占问题； 无意义的事情：横向先后顺序是为了聚合，跟函数间依赖或调用关系无关；火焰图各种颜色是为方便区分，本身不具有特殊含义； 多练习：进行性能优化有意识的使用火焰图的方式进行性能调优（如果时间充裕）；  如何绘制火焰图？ 要生成火焰图，必须要有一个顺手的动态追踪工具，如果操作系统是 Linux 的话，那么通常通常是 perf 或者 systemtap 中的一种。其中 perf 相对更常用，多数 Linux 都包含了 perf 这个工具，可以直接使用；SystemTap 则功能更为强大，监控也更为灵活。网上关于如何使用 perf 绘制火焰图的文章非常多而且丰富，所以本文将以 SystemTap 为例。\nSystemTap 是动态追踪工具，它通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。SystemTap 定义了一种类似的 DSL 脚本语言，方便用户根据需要自由扩展。不过，不同于动态追踪的鼻祖 DTrace ，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。\n使用 SystemTap 绘制火焰图的主要流程如下：\n 安装 SystemTap 以及 操作系统符号调试表 根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 生成内核模块 运行 SystemTap 或者运行生成的内核模块统计数据 将统计数据转换成火焰图  本文演示步骤将会基于操作系统 Tlinux 2.2 ( Linux 内核版本3.10.107)\n安装 SystemTap 以及 操作系统符号调试表 使用 yum 工具安装 systemtap:\nyum install systemtap systemtap-runtime 由于 systemtap 工具依赖于完整的调试符号表，而且生产环境不同机器的内核版本不同（虽然都是Tlinux 2.2版本，但是内核版本后面的小版本不一样，可以通过 uname -a 命令查看）所以我们还需要安装 kernel-debuginfo 包、 kernel-devel 包 我这里是安装了这两个依赖包\nkernel-devel-3.10.107-1-tlinux2-0046.x86_64 kernel-debuginfo-3.10.107-1-tlinux2-0046.x86_64 根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 使用 SystemTap 统计相关数据往往需要自己依照它的语法，编写脚本，具有一定门槛。幸运的是，github 上春哥（agentzh）开源了两组他常用的 SystemTap 脚本：openresty-systemtap-toolkit 和 stapxx，这两个工具集能够覆盖大部分 C 进程、nginx 进程以及 Openresty 进程的性能问题场景。\n我们这里需要绘制 off-cpu 火焰图，所以使用 sample-bt-off-cpu 脚本即可\n生成内核模块 现在我们有了统计脚本，也安装好了 systemtap，正常来说就可以使用了，但由于 systemtap 是通过生成内核模块的方式统计相关探针的统计数据，而 tlinux 要求所有运行的内核模块需要先到 tlinux 平台签名才可以运行，所以：\n故需要先修改 off-cpu 脚本，让其先生成内核模块；之后对该内核模块作签名；最后使用 systemtap 命令手工运行该脚本，统计监控数据。\nSystemtap 执行流程如下：\n parse：分析脚本语法 elaborate：展开脚本 中定义的探针和连接预定义脚本库，分析内核和内核模块的调试信息 translate：.将脚本编译成c语言内核模块文件放 在$HOME/xxx.c 缓存起来，避免同一脚本多次编译 build：将c语言模块文件编译成.ko的内核模块，也缓存起来。 把模块交给staprun，staprun加载内核模块到内核空间,stapio连接内核模块和用户空间，提供交互IO通道,采集数据。  所以我们这里修改下 off-cpu 的 stap 脚本，让其只运行完第四阶段，只生成一个内核模块\n// 在 stap 命令后增加 -p4 参数，告诉systemtap，当前只需要执行到第四阶段 open my $in, \u0026#34;|stap -p4 --skip-badvars --all-modules -x $pid -d \u0026#39;$exec_path\u0026#39; --ldd $d_so_args $stap_args -\u0026#34; or die \u0026#34;Cannot run stap: $!\\n\u0026#34;; 修改好之后运行脚本，会生成一个内核模块\n// -p 8682 是需要监控的进程的进程号 // -t 30 是指会采样30秒 ./sample-bt-off-cpu -p 8692 -t 30 生成的内核模块名称形如 stap_xxxxx.ko模块名称 由于读者并不需要关心内核模块签名，故章节略过\n运行内核模块统计数据 内核模块签名完成后，便可以使用 staprun 命令手工运行相关内核模块了\n命令：\n// 注意：签名脚本会将生产的内核模块重命名，需要将名字改回去……（脚本bug） staprun -x {进程号} {内核模块名} \u0026gt; demo.bt 值得注意的是，监控的进程要有一定负载 systemtap 才可以采集到相关数据，即在采集时，同时需要要有一定请求量（通常是自己构造请求，压测进程）\n将统计数据转换成火焰图 获得了统计数据 demo.bt 后，便可以使用火焰图工具绘制火焰图了\n下载 FlameGraph，链接：https://github.com/brendangregg/FlameGraph\n命令：\n./stackcollapse-stap.pl demo.bt \u0026gt; demo.folded ./flamegraph.pl demo.folded \u0026gt; demo.svg 这样便获得了 off-cpu 火焰图：\n看图说话 趁热打铁，通过几张火焰图熟悉下如何使用火焰图\n图片源于春哥微博或者本人近期绘制的性能火焰图\non-cpu 火焰图 Apache APISIX QPS急剧下降问题 Apache APISIX 是一个开源国产的高性能 API 网关，之前在进行选型压测时，发现当 Route 匹配不中场景下， QPS 急剧下降，在其 CPU （四十八核）占用率几乎达到100%的情况下只有几千 QPS，通过绘制火焰图发现，其主要耗时在一个 table 插入阶段(lj_cf_table_insert)，分析代码发现是该 table 一直没有释放，每次匹配不中时，路由会向一张用于统计的表中插入一条数据，导致该表越来越大，后续插入耗时过长导致 QPS 下降。\noff-cpu 火焰图 nginx 互斥锁问题 这是一张 nginx 的 off-cpu 火焰图，我们可以很快锁定到 ngx_common_set_cache_fs_size -\u0026gt; ngx_shmtx_lock -\u0026gt; sem_wait 这段逻辑使用到了互斥锁，它让 nginx 进程绝大部分阻塞等待时间花费在获取该锁。\nagent 监控上报断点问题 这是一张 agent 的 off-cpu 火焰图，它是一个多线程异步事件模型，主线程处理各个消息，多个线程分别负责配置下发或者监控上报。当前问题出现在监控上报性能差，无法在周期（一分钟）内完成监控数据上报，导致监控断点，通过 off-cpu 火焰图我们可以分析出，该上报线程花费了大量的时间使用 curl_easy_perform 接口收发 http 监控数据消息。\n依据火焰图将发送 http 消息的逻辑改为异步非阻塞后，该问题解决。\n附录 进阶阅读  谷歌搜索演讲：Blazing Performance with Flame Graphs 演讲 ppt：https://www.slideshare.net/brendangregg/blazing-performance-with-flame-graphs 《SystemTap新手指南》：https://spacewander.gitbooks.io/systemtapbeginnersguide_zh/content/index.html 极客时间《Linux性能优化实战》\u0026ndash;倪朋飞  FAQ 使用 perf 或者 systemtap 的方式采集数据，会对后台服务有性能影响吗？\n有，但是很小，可以基本忽略不计。\n它们使用系统的探针或者使用一些自定义的动态探针进行数据采集，第一对代码无侵入性，它既不需要停止服务，也不需要修改应用程序的代码；第二，它们是以内核模块/内核原生的方式跟踪用户态和内核态的所有事件，并通过一系列优化措施，进行采样统计，对目标服务性能影响极小，大概在5%左右或者更低的性能损耗。相较于将进程运行在沙箱的 valgrind 工具或静态调试工具 gdb 来说，动态追踪 perf 或者 systemtap 或者 ebpf 的性能损耗基本可以忽略不计。\n目标进程重启后，systemtap 是否需要重新生成内核模块？\n不需要。甚至同一个 linux 内核版本下的同一个二进制进程（md5值一致），在安装 kernel 调试符号表后，便可以在生成采集指标的内核模块，并且可以多次使用。\n当 linux 内核版本不一致，符号表有变化，需要重新生成内核模块；当目标进程二进制文件重新编译后，也需要重新生成统计用的 systemtap 内核模块。\n","permalink":"https://cloudnative.to/blog/flame-graph/","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图"},{"categories":["Envoy"],"contents":"背景 Istio 从发布开始就使用 Envoy 作为自己的数据平面，充分利用了 Envoy 提供的服务发现、路由、熔断、负载均衡等功能。与此同时，Istio 项目也一直致力于提供一个便于灵活扩展的平台，以满足用户多样化的需求。在过去的一年半中， Google 的团队一直在努力用 WebAssembly 技术为 Envoy 代理添加动态扩展，并推出了针对 Envoy 代理的 WebAssembly (以下简称为WASM) 扩展机制，包括标准化的 ABI，SDK，以及该扩展机制的第一个重点实现：全新的、低延迟的 Istio 遥测系统。\n本文主要对 Envoy 和 WebAssembly 技术进行介绍，并使用 solo.io 团队推出的 wasme 工具完成 WASM filter 的构建、发布和部署，方便读者了解 Envoy WASM Filter 的扩展方式及其实现原理。\nEnvoy 的过滤器机制 Envoy 是 Istio 中的 Sidecar 官方标配，是一个面向服务架构的高性能网络代理，由 C++ 语言实现，拥有强大的定制化能力。Envoy 提供了进程外架构、支持L3/L4 filter、HTTP L7 filter、服务发现和动态配置、健康检查等高级功能。这里我们重点介绍一下 Envoy 流量处理过程中的 filter 机制。\n过滤器机制 Envoy 是面向服务架构设计的L7代理和通信总线，核心是一个 L3/L4 网络代理。可插入 filter 链机制允许开发人员编写 filter 来执行不同的 TCP 代理任务并将其插入到主体服务中。Envoy 还支持额外的 HTTP L7 filter 层。可以将 HTTP filter 插入执行不同任务的 HTTP 连接管理子系统。\n目前，Envoy 提供的过滤器包括侦听器过滤器（Listener Filters）、网络过滤器（Network Filters）、HTTP过滤器（HTTP Filters）三种类型，它们共同组成了一个层次化的过滤器链。\n1、侦听器过滤器\n侦听器过滤器在初始连接阶段访问原始数据并操作 L4 连接的元数据。例如，TLS 检查器过滤器（TLS Inspector Filter）标识连接是否经过 TLS 加密，并解析与该连接关联的 TLS 元数据（SNI或ALPN协商的协议类型）；HTTP Inspector Filter 检测应用协议是否是 HTTP，如果是的话，再进一步检测 HTTP 协议类型 (HTTP/1.x or HTTP/2) ，这两种过滤器解析到的元数据都可以和 FilterChainMatch 结合使用。\n2、网络过滤器\n网络过滤器访问和操作 L4 连接上的原始数据，即TCP数据包。例如，TCP代理过滤器（TCP Proxy Filter）将客户端连接数据路由到上游主机，它还可以生成连接统计数据。此外，MySQL proxy、Redis proxy、Dubbo proxy、Thrift proxy等都属于网络过滤器。\n3、HTTP过滤器\nHTTP 过滤器在 L7 上运行，由网络过滤器（即 HTTP 连接管理器，HTTP Connection Manager）创建。这些过滤器用于访问、操作 HTTP 请求和响应，例如，gRPC-JSON 转码器过滤器（gRPC-JSON Transcoder Filter）可以为 gRPC 后端提供一个 REST API，并将请求和响应转换为相应的格式。此外，还包括 JWT、Router、RBAC 等多种过滤器。\n整体来看，Envoy 的过滤器机制为用户提供了很多好处，比如：用户可以创建一个中间层，以便在与不兼容的服务器通信时优雅地处理客户端请求；代理可以执行协议转换，允许不同的协议互操作；代理可以通过过滤器做出智能路由决策等。\n扩展方式 现有的 Filter 可能无法满足用户的使用需求，这时候就需要对 Envoy 进行功能扩展，通过在现有的过滤链基础上自定义新的 filter，实现定制化需求。用户可以通过以下三种方式对 Envoy 进行扩展。\n1、编写 C++ 代码扩展 Envoy\n这种方式直接在 Envoy 基础上编写 C++ 代码进行功能增强，实现自定义的 filter 之后，重新编译新的二进制可执行文件，完成现有业务的升级替换。这种方式有以下两方面问题：\n受语言限制，只能使用 C++ 进行扩展，不利于生态发展； 提高了部署、运维、升级的复杂性，Envoy将会变得越来越重，并且每次更改都需要重新编译二进制文件，不利于技术迭代和管理。\n2、使用 lua 脚本扩展 filter\nLua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。HTTP Lua Filter 允许在请求和响应流程中运行 Lua 脚本，在运行时使用 LuaJIT。该过滤器仅支持在配置中直接加载 Lua 代码。\n目前支持的主要功能包括：对传输的请求或响应流，提供头部、正文和尾部的检查；对头部和尾部进行修改；对上游主机执行异步HTTP调用；直接执行响应并跳过后续的过滤器等。\n然而，HTTP Lua Filter 是实验性的，在生产中使用需要自担风险。若存在非常复杂或更高性能的场景，建议使用本地 C++ 过滤器。\n3、使用 WASM 扩展 envoy\n为了提供更加方便、更加灵活的扩展方式，Google 团队计划用 WebAssembly 为 Envoy 代理添加动态扩展。用户可以使用自己擅长的编程语言编写 filter，并使用工具编译成 wasm 格式，嵌入到 Envoy 中运行即可。目前，Google 也与社区紧密合作，以确保为用户提供良好的开发者体验，帮助用户快速上手。Google 团队也一直与 Solo.io 团队紧密合作，Solo 团队已经建立了 WebAssembly Hub 服务，用于构建，共享，发现和部署 WASM 扩展。有了 WebAssembly Hub，WASM 扩展就会像容器一样易于管理，安装和运行。\nWASM 概述 介绍 WebAssembly（WASM）是一种由多种语言编写的，可移植的字节码格式，它能以接近本机的速度执行。作为一种可移植、体积小、加载快并且兼容 Web 的全新格式，wasm具有以下特点：\n 高效：WASM 有一套完整的语义，实际上 WASM 是体积小且加载快的二进制格式， 其目标就是充分发挥硬件能力以达到原生执行效率。 安全：WASM 运行在一个沙箱化的执行环境中，甚至可以在现有的 JavaScript 虚拟机中实现。 开放：WASM 设计了一个非常规整的文本格式，用于调试、测试、实验、优化、学习、教学或者编写程序。 标准：WASM 在 web 中被设计成无版本、特性可测试、向后兼容的特点。WASM 不仅可以运行在浏览器上，也可以运行在非web环境下。  需要注意的是，WASM 是一个编译目标，不是一种编程语言。WebAssembly 是经过编译器编译之后的目标格式，体积小、起步快。在语法上完全脱离 JavaScript，同时具有沙盒化的执行环境。\n尽管 WASM 最初是作为客户端技术诞生的，但它应用于服务器端时也有很多优势。比如运行时是内存安全的，并且以沙盒方式运行以确保其安全性。\n工具链 这里简单介绍一下 WASM 编译相关的工具链。传统的编译器设计都是三步式的：Frontend(前端)，Optimizer（优化器），Backend(后端)。\n Frontend ：源代码解析，错误检查，然后构建一个语言相关的抽象语法树(AST)来表示输入的代码。 Optimizer：优化器会做很多的转换来减少代码的运行时间，比如说减少冗余的计算。 Backend：将优化后的代码映射到目标指令集，也可以被称为代码生成器。  而在一个基于 LLVM 的编译器中，一个 Frontend 的任务是对源代码进行解析、错误诊断，然后将解析后的的代码转换为 LLVM IR（Intermediate Representation），IR 会经过一系列的分析和优化以便提高代码性能，最后基于优化后的代码生成相应的机器代码。这种方式十分灵活，当扩展编程语言或硬件类型时，添加对应的前端或后端即可，优化阶段则成为了一个通用的阶段。\nEmscripten 的底层就是 LLVM 编译器，可以将 LLVM 字节码编译成 JavaScript，还支持 WebAssembly 这一更加先进的 Web 技术，可以生成 WASM 字节码文件。\nWASM与Envoy和Istio Istio 引入 WebAssembly 该特性在 Istio 1.5 自带的 Envoy 中以 Alpha 版本推出，其源代码在 envoy-wasm 开发分支中，并且正在努力将其合并到 Envoy 主干上。该实现使用了 Google 高性能 V8 引擎 中内置的 WebAssembly 运行时。\n除了构建底层的运行时，Google 团队还开展了以下关键工作：\n 制定 Wasm 嵌入代理的通用应用程序二进制接口（ABI），这意味着编译后的扩展将可以在不同版本的 Envoy 中工作，甚至其它代理也可以，前提是其它代理实现了 ABI 用 C++, Rust 和 AssemblyScript 可以方便进行扩展开发的 SDK，后续还会支持更多类型的编程语言 全面的示例和说明，介绍如何在 Istio 和独立的 Envoy 中部署 允许使用其它 WASM 运行时的抽象，包括把扩展直接编译进 Envoy 中 “null” 运行时，这对于测试和调试非常有用  使用 WASM 扩展 Envoy 带来了很多好处：\n 敏捷性：可以用 Istio 控制平面在运行时下发和重载扩展，这就可以快速的进行开发、测试、发布，而无需重启 Envoy。 可靠性和隔离性：扩展模块部署在具有资源限制的沙箱中，这意味着虽然该模块可能崩溃或泄漏内存，但不会让整个 Envoy 挂掉。 灵活性：可以将多种编程语言编译为 WASM，让各种技术背景的开发人员都可以选择自己的语言来编写 Envoy 扩展，比如：C++，Go，Rust，Java，TypeScript 等。  WASME 实践 Solo.io 团队发布了 WebAssembly Hub，这是一套为 Envoy 和 Istio 准备的，用于构建、部署、共享和发现 Envoy Proxy WASM 扩展的工具和仓库。\nWebAssembly Hub 将开发和部署 Wasm 扩展所需的许多步骤都自动化了。使用 WebAssembly Hub 提供的工具，用户可以轻松地把任何受支持语言开发的代码编译为 WASM 扩展，并将这些扩展上传到 Hub 仓库，使用单个命令就将其在 Istio 中部署和删除。\nWebAssembly Hub 工具提供了功能强大的 CLI 和优雅且易于使用的图形用户界面，该产品的一个重要目标是简化构建 WASM 模块的体验。下面介绍一下使用 wasme 工具开发、构建和部署 filter 的整体流程。\n1、安装 wasme cli\nwasme 命令行工具用于构建、管理 wasm filter，作用和流程有点像 docker 构建和管理容器。\n# 安装wasme curl -sL https://run.solo.io/wasme/install | sh export PATH=$HOME/.wasme/bin:$PATH # 查看版本号 wasme --version 2、初始化filter项目\n创建一个新的filter项目：\nwasme init ./new-filter 根据命令行的提示可以知道，现在只支持cpp、assemblyscript两种语言；可以选择部署到 Istio 或 Gloo 平台。这里我们选择cpp、istio选项，完成项目创建。\n我们可以看一下生成的项目包括哪些文件：\n# tree . |-- bazel | `-- external | |-- BUILD | |-- emscripten-toolchain.BUILD | `-- envoy-wasm-api.BUILD |-- BUILD |-- filter.cc |-- filter.proto |-- README.md |-- runtime-config.json |-- toolchain | |-- BUILD | |-- cc_toolchain_config.bzl | |-- common.sh | |-- emar.sh | `-- emcc.sh `-- WORKSPACE 3 directories, 14 files 这些文件的作用分别为：\n BUILD：用于编译 filter 的 bazel 编译文件 WORKSPACE：用于编译 filter 的 bazel WORKSPACE 文件 bazel/：bazel 外部依赖 toolchain/：编译 WASM 模块的 bazel 工具链 filter.cc：filter 源代码，这里是C++语言 filter.proto：filter配置的 protobuf schema runtime-config.json：和 filter 镜像共同存储的 config 文件，用于在运行时加载 filter  这里重点关注 filter.cc 文件即可，里面定义了一组接口和实现，只需要对相关的方法进行修改，就可以实现自定义的filter。其他文件主要用于编译，可以看到这里也引入了 emscripten 工具链，用于编译成 wasm 字节码格式。\n3、修改和编译\n这里我们在响应头添加一组 header 信息，以验证 filter 功能是否符合预期。\nFilterHeadersStatus AddHeaderContext::onResponseHeaders(uint32_t) { LOG_DEBUG(std::string(\u0026#34;onResponseHeaders \u0026#34;) + std::to_string(id())); addResponseHeader(root_-\u0026gt;header_name_, root_-\u0026gt;header_value_); replaceResponseHeader(\u0026#34;location\u0026#34;, \u0026#34;envoy-wasm\u0026#34;); addResponseHeader(\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;); return FilterHeadersStatus::Continue; } 接下来使用 wasme 命令编译 filter，这里会自动拉取quay.io/solo-io/ee-builder镜像完成编译过程，构建完成的filter镜像将会存储在本地的 registry中。\nwasme build cpp -t webassemblyhub.io/sunboy0213/add-header:v0.1 . 查看本地编译完成的filter镜像：\nwasme list NAME TAG SIZE SHA UPDATED webassemblyhub.io/sunboy0213/add-header v0.1 1.0 MB 72ad74e2 15 Apr 20 11:03 CST 这里可以看一下我们最终编译生成的文件如下，目标文件 filter.wasm 只有 1021K，可以很方便的集成到 envoy 中。\nls store/41aabc92e1f91207d4b4e12385fd5bca/ -alh total 1.1M drwxr-xr-x 2 root root 4.0K Apr 15 12:19 . drwxr-xr-x 4 root root 4.0K Apr 15 12:19 .. -rw-r--r-- 1 root root 226 Apr 15 20:58 descriptor.json -rw-r--r-- 1 root root 1021K Apr 15 20:58 filter.wasm -rw-r--r-- 1 root root 44 Apr 15 20:58 image_ref -rw-r--r-- 1 root root 128 Apr 15 20:58 runtime-config.json 4、推送到 WebAssembly hub\n这里需要首先注册https://webassemblyhub.io账号，然后将本地编译完成的镜像推送到远程仓库。\n# 登录账号 wasme login -u $YOUR_USERNAME -p $YOUR_PASSWORD # 推送镜像 wasme push webassemblyhub.io/sunboy0213/add-header:v0.1 # 查找我的远程镜像 wasme list --search $YOUR_USERNAME 5、部署到istio集群\n这一步的前提是已经搭建了 Istio 运行环境，并部署好了 bookinfo 示例应用。测试服务间的访问连通性如下：\n# kubectl exec -ti deploy/productpage-v1 -c istio-proxy -- curl -v http://details:9080/details/123 * Trying 172.18.233.86... * TCP_NODELAY set * Connected to details (172.18.233.86) port 9080 (#0) \u0026gt; GET /details/123 HTTP/1.1 \u0026gt; Host: details:9080 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; content-type: application/json \u0026lt; server: istio-envoy \u0026lt; date: Thu, 23 Apr 2020 09:16:53 GMT \u0026lt; content-length: 180 \u0026lt; x-envoy-upstream-service-time: 1 \u0026lt; x-envoy-peer-metadata: Ch4KDElOU1RBTkNFX0lQUxIOGgwxNzIuMTYuMC4yMDYK1QEKBkxBQkVMUxLKASrHAQoQCgNhcHASCRoHZGV0YWlscwohChFwb2QtdGVtcGxhdGUtaGFzaBIMGgo3NWQ5NGM0OGY1CiQKGXNlY3VyaXR5LmlzdGlvLmlvL3Rsc01vZGUSBxoFaXN0aW8KLAofc2VydmljZS5pc3Rpby5pby9jYW5vbmljYWwtbmFtZRIJGgdkZXRhaWxzCisKI3NlcnZpY2UuaXN0aW8uaW8vY2Fub25pY2FsLXJldmlzaW9uEgQaAnYxCg8KB3ZlcnNpb24SBBoCdjEKGgoHTUVTSF9JRBIPGg1jbHVzdGVyLmxvY2FsCiUKBE5BTUUSHRobZGV0YWlscy12MS03NWQ5NGM0OGY1LTdibHhtChYKCU5BTUVTUEFDRRIJGgdkZWZhdWx0Ck4KBU9XTkVSEkUaQ2t1YmVybmV0ZXM6Ly9hcGlzL2FwcHMvdjEvbmFtZXNwYWNlcy9kZWZhdWx0L2RlcGxveW1lbnRzL2RldGFpbHMtdjEKJQoPU0VSVklDRV9BQ0NPVU5UEhIaEGJvb2tpbmZvLWRldGFpbHMKHQoNV09SS0xPQURfTkFNRRIMGgpkZXRhaWxzLXYx \u0026lt; x-envoy-peer-metadata-id: sidecar~172.16.0.206~details-v1-75d94c48f5-7blxm.default~default.svc.cluster.local \u0026lt; x-envoy-decorator-operation: details.default.svc.cluster.local:9080/* \u0026lt; * Connection #0 to host details left intact {\u0026#34;id\u0026#34;:123,\u0026#34;author\u0026#34;:\u0026#34;William Shakespeare\u0026#34;,\u0026#34;year\u0026#34;:1595,\u0026#34;type\u0026#34;:\u0026#34;paperback\u0026#34;,\u0026#34;pages\u0026#34;:200,\u0026#34;publisher\u0026#34;:\u0026#34;PublisherA\u0026#34;,\u0026#34;language\u0026#34;:\u0026#34;English\u0026#34;,\u0026#34;ISBN-10\u0026#34;:\u0026#34;1234567890\u0026#34;,\u0026#34;ISBN-13\u0026#34;:\u0026#34;123-1234567890\u0026#34;} 部署我们刚才定制开发的filter：\nwasme deploy istio webassemblyhub.io/sunboy0213/add-header:v0.1 --id=myfilter 再次访问，可以发现响应头已经增加了 \u0026ldquo;hello: world!\u0026rdquo; 键值对。注意：该部署过程会触发pod重建操作。\nkubectl exec -ti deploy/productpage-v1 -c istio-proxy -- curl -v http://details:9080/details/123 * Trying 172.18.233.86... * TCP_NODELAY set * Connected to details (172.18.233.86) port 9080 (#0) \u0026gt; GET /details/123 HTTP/1.1 \u0026gt; Host: details:9080 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; content-type: application/json \u0026lt; server: istio-envoy \u0026lt; date: Thu, 23 Apr 2020 09:20:12 GMT \u0026lt; content-length: 180 \u0026lt; x-envoy-upstream-service-time: 2 \u0026lt; : \u0026lt; location: envoy-wasm \u0026lt; hello: world! \u0026lt; x-envoy-peer-metadata: Ch4KDElOU1RBTkNFX0lQUxIOGgwxNzIuMTYuMC4yMDgK1QEKBkxBQkVMUxLKASrHAQoQCgNhcHASCRoHZGV0YWlscwohChFwb2QtdGVtcGxhdGUtaGFzaBIMGgo3NzdkOGY1NDc1CiQKGXNlY3VyaXR5LmlzdGlvLmlvL3Rsc01vZGUSBxoFaXN0aW8KLAofc2VydmljZS5pc3Rpby5pby9jYW5vbmljYWwtbmFtZRIJGgdkZXRhaWxzCisKI3NlcnZpY2UuaXN0aW8uaW8vY2Fub25pY2FsLXJldmlzaW9uEgQaAnYxCg8KB3ZlcnNpb24SBBoCdjEKGgoHTUVTSF9JRBIPGg1jbHVzdGVyLmxvY2FsCiUKBE5BTUUSHRobZGV0YWlscy12MS03NzdkOGY1NDc1LWY0Z3c0ChYKCU5BTUVTUEFDRRIJGgdkZWZhdWx0Ck4KBU9XTkVSEkUaQ2t1YmVybmV0ZXM6Ly9hcGlzL2FwcHMvdjEvbmFtZXNwYWNlcy9kZWZhdWx0L2RlcGxveW1lbnRzL2RldGFpbHMtdjEKJQoPU0VSVklDRV9BQ0NPVU5UEhIaEGJvb2tpbmZvLWRldGFpbHMKHQoNV09SS0xPQURfTkFNRRIMGgpkZXRhaWxzLXYx \u0026lt; x-envoy-peer-metadata-id: sidecar~172.16.0.208~details-v1-777d8f5475-f4gw4.default~default.svc.cluster.local \u0026lt; x-envoy-decorator-operation: details.default.svc.cluster.local:9080/* \u0026lt; * Connection #0 to host details left intact {\u0026#34;id\u0026#34;:123,\u0026#34;author\u0026#34;:\u0026#34;William Shakespeare\u0026#34;,\u0026#34;year\u0026#34;:1595,\u0026#34;type\u0026#34;:\u0026#34;paperback\u0026#34;,\u0026#34;pages\u0026#34;:200,\u0026#34;publisher\u0026#34;:\u0026#34;PublisherA\u0026#34;,\u0026#34;language\u0026#34;:\u0026#34;English\u0026#34;,\u0026#34;ISBN-10\u0026#34;:\u0026#34;1234567890\u0026#34;,\u0026#34;ISBN-13\u0026#34;:\u0026#34;123-1234567890\u0026#34;} 6、生产环境的部署\n前面我们使用的 wasme 命令行提供了一种编译、部署 wasm filter 的简单方式，可以方便的在开发和测试环境中使用，但该方式显然无法用于声明式、无状态的k8s生产环境中。\n为此，官方推荐使用 Wasme Operator 管理 Service Mesh 集群中的 wasm filter。主要包括两个组件：\n 镜像缓存：从 filter registry 拉取 filter 镜像，并缓存到本地，该组件以 DaemonSet 的形式进行部署； operator：安装、配置 wasm filter 到数据面代理，以 Kubernetes Deployment 的形式部署。  用户提交的 FilterDeployment 示例如下：\napiVersion: wasme.io/v1 kind: FilterDeployment metadata: name: bookinfo-custom-filter namespace: bookinfo spec: deployment: istio: kind: Deployment filter: config: \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;world\u0026#34;}\u0026#39; image: webassemblyhub.io/ilackarms/istio-test:1.5.0-0 工作原理分析 刚才我们使用 wasme 命令行工具完成了 wasm filter 的构建、部署过程，其背后的工作原理简单描述如下：\n 由 Wasme Operator 设置 wasm filter 的本地缓存信息，同时生成 EnvoyFilter 资源提交给k8s； 镜像缓存模块拉取需要的 wasm filter 到本地缓存中，该模块以 DaemonSet 的形式部署在集群节点中； 缓存模块拉取完成后，将 wasm 文件挂载到目标的workload中； 同时，Istiod 监测到 EnvoyFilter 变更，通过 xDS API 将 wasm 文件的信息下发到 envoy 代理。  目前，WASM 扩展是通过 mount 机制来分发给对应的 workload，这种方式显然不够灵活，理想的方案是通过网络拉取 WASM 文件，完成实时加载。针对该问题，社区也正在积极优化。\n结合前面的实践内容和原理分析，这里我们可以查看已经添加的 EnvoyFilter 资源。\n[root@c-wfodwhfz-aaxyxwyz ~]# kubectl get envoyfilters.networking.istio.io NAME AGE details-v1-myfilter 50m productpage-v1-myfilter 50m ratings-v1-myfilter 50m reviews-v1-myfilter 50m reviews-v2-myfilter 50m reviews-v3-myfilter 50m 这里的 EnvoyFilter 是 Istio 提供的一种资源对象，用来更新配置 Envoy 中的 filter，为服务网格控制面提供了强大的扩展能力。可以详细看一下 productpage-v1-myfilter 的具体描述。\napiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: creationTimestamp: \u0026#34;2020-04-23T09:19:34Z\u0026#34; generation: 1 name: productpage-v1-myfilter namespace: default resourceVersion: \u0026#34;9071122\u0026#34; selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/envoyfilters/productpage-v1-myfilter uid: b528b175-5e08-4b08-85ed-a324a2418a64 spec: configPatches: - applyTo: HTTP_FILTER match: context: SIDECAR_INBOUND listener: filterChain: filter: name: envoy.http_connection_manager subFilter: name: envoy.router patch: operation: INSERT_BEFORE value: config: config: name: myfilter rootId: add_header_root_id vmConfig: code: local: filename: /var/local/lib/wasme-cache/72ad74e260c99fd77bbfd62f5dfab16af666dbdee8bacca39d97eafe60c69584 runtime: envoy.wasm.runtime.v8 vmId: myfilter name: envoy.filters.http.wasm workloadSelector: labels: app: productpage version: v1 该配置内容通过 xDS API 下发到 Envoy 代理之后，envoy 的运行时配置就会出现如下类型的 http filter，可以看到该 filter 指定了wasm文件的位置，并将wasm的运行时设置为v8引擎，从而实现了 wasm filter 的加载和运行。\n{ \u0026#34;name\u0026#34;: \u0026#34;envoy.filters.http.wasm\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;config\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;myfilter\u0026#34;, \u0026#34;rootId\u0026#34;: \u0026#34;add_header_root_id\u0026#34;, \u0026#34;vmConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;local\u0026#34;: { \u0026#34;filename\u0026#34;: \u0026#34;/var/local/lib/wasme-cache/72ad74e260c99fd77bbfd62f5dfab16af666dbdee8bacca39d97eafe60c69584\u0026#34; } }, \u0026#34;runtime\u0026#34;: \u0026#34;envoy.wasm.runtime.v8\u0026#34;, \u0026#34;vmId\u0026#34;: \u0026#34;myfilter\u0026#34; } } } }, 小结 本文首先介绍了 Envoy 的过滤器模型和 WASM 扩展技术，并结合 Solo 团队提供的 wasme 工具完成了 WASM 扩展的构建、部署过程，最后对背后的工作原理进行了分析。可以看到，使用 WASM 可以很方便的将自定义 filter 集成到 Envoy 中，实现 Envoy 代理的功能增强，同时我们也发现 envoy-wasm 仍然处于初步阶段，在支持的语言类型、运行性能、部署运维等方面仍然有待完善，相信在社区的不断努力下，WASM 技术能够走向成熟并应用于更多的使用场景中。\n参考 重新定义代理的扩展性：Envoy 和 Istio 引入 WebAssembly\n如何高效地编写Envoy过滤器！第1部分\nWebAssembly for Proxies (ABI specification)\nDeclarative WebAssembly deployment for Istio\n","permalink":"https://cloudnative.to/blog/envoy-wasm/","tags":["Istio","Envoy","WASM"],"title":"Istio 进阶学习系列 - 基于 WebAssembly 实现 Envoy 与 Istio 的功能扩展"},{"categories":["Etcd"],"contents":" 作者介绍：aoho，一线码农，对云原生、微服务、Go 语言、容器化感兴趣，并做了深入研究。闲暇时间会分享一些技术思考和实践，与大家讨论交流，共同进步。\n 0 专辑概述 etcd 是云原生架构中重要的基础组件，由 CNCF 孵化托管。etcd 在微服务和 Kubernates 集群中不仅可以作为服务注册于发现，还可以作为 key-value 存储的中间件。\n《彻底搞懂 etcd 系列文章》将会从 etcd 的基本功能实践、API 接口、实现原理、源码分析，以及实现中的踩坑经验等几方面具体展开介绍 etcd。预计会有 20 篇左右的文章，笔者将会每周持续更新，欢迎关注。\n1 etcd 介绍 etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值(key-value)数据库。具有以下特点：\n 简单：安装配置简单，而且提供了 HTTP API 进行交互，使用也很简单 键值对存储：将数据存储在分层组织的目录中，如同在标准文件系统中 监测变更：监测特定的键或目录以进行更改，并对值的更改做出反应 安全：支持 SSL 证书验证 快速：根据官方提供的 benchmark 数据，单实例支持每秒 2k+ 读操作 可靠：采用 raft 算法，实现分布式系统数据的可用性和一致性  etcd 采用 Go 语言编写，它具有出色的跨平台支持，很小的二进制文件和强大的社区。 etcd 机器之间的通信通过 Raft 算法处理。\netcd 是一个高度一致的分布式键值存储，它提供了一种可靠的方式来存储需要由分布式系统或机器集群访问的数据。它可以优雅地处理网络分区期间的 leader 选举，以应对机器的故障，即使是在 leader 节点发生故障时。\n从简单的 Web 应用程序到 Kubernetes 集群，任何复杂的应用程序都可以从 etcd 中读取数据或将数据写入 etcd。\netcd 于 2018 年 12 月正式加入云原生计算基金会(CNCF，全称 Cloud Native Computing Foundation)，并由 CNCF 支持。CNCF 是一个厂商中立的基金会、云原生技术推广和普及的领导者。\n2 使用场景 etcd 比较多的应用场景是用于服务注册与发现，除此之外，也可以用于键值对存储，应用程序可以读取和写入 etcd 中的数据。\n一个简单的用例是将数据库连接详细信息或功能标志存储在 etcd 中作为键值对。 可以观察这些值，使我们的应用在更改时可以重新配置自己。高级用法是利用 etcd 的一致性保证来实施数据库 leader 选举或在一组 follower 之间执行分布式锁定。\n2.1 键值对存储  A highly-available key value store for shared configuration and service discovery.\n一个用于配置共享和服务发现的键值存储系统。\n 归根结底，etcd 是一个键值存储的组件，其他的应用都是基于其键值存储的功能展开。etcd 的存储有如下特点：\n 采用kv型数据存储，一般情况下比关系型数据库快。 支持动态存储(内存)以及静态存储(磁盘)。 分布式存储，可集成为多节点集群。 存储方式，采用类似目录结构。  只有叶子节点才能真正存储数据，相当于文件。 叶子节点的父节点一定是目录，目录不能存储数据。    etcd leader 的延迟是要跟踪的最重要的指标，并且内置仪表板具有专用于此的视图。在我们的测试中，严重的延迟会在群集内造成不稳定，因为 Raft 的速度仅与大多数机器中最慢的机器一样快。我们可以通过适当地调整群集来缓解此问题。etcd 已在具有高度可变网络的云提供商上进行了预调。\n2.2 服务注册与发现 服务注册与发现(Service Discovery)要解决的是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务如何才能找到对方并建立连接。从本质上说，服务发现就是要了解集群中是否有进程在监听 UDP 或者 TCP 端口，并且通过名字就可以进行查找和链接。\n要解决服务发现的问题，需要下面三大支柱，缺一不可。\n  强一致性、高可用的服务存储目录。 基于 Raft 算法的 etcd 天生就是这样一个强一致性、高可用的服务存储目录。\n  一种注册服务和服务健康状况的机制。 用户可以在 etcd 中注册服务，并且对注册的服务配置 key TTL，定时保持服务的心跳以达到监控健康状态的效果。\n  一种查找和连接服务的机制。通过在 etcd 指定的主题下注册的服务业能在对应的主题下查找到。为了确保连接，我们可以在每个服务机器上都部署一个 Proxy 模式的 etcd，这样就可以确保访问 etcd 集群的服务都能够互相连接。\n  etcd2 中引入的 etcd/raft 库，是目前最稳定、功能丰富的开源一致性协议之一。作为 etcd、TiKV、CockcorachDB、Dgraph 等知名分布式数据库的核心数据复制引擎，etcd/raft 驱动了超过十万个集群，是被最为广泛采用一致性协议实现之一。etcd3 中引入的多版本控制、事务等功能，大大的简化了分布式应用的开发流程，提高了效率和稳定性。经过 5 年的演进，etcd 也已经成为了各种容器编排系统的默认存储选项。Kubernetes 是流行的容器平台，运行在任何环境的 Kubernetes 集群都依赖 etcd 来提供稳定而可靠的存储服务。\n2.3 消息发布与订阅 在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。\n应用中用到的一些配置信息放到 etcd 上进行集中管理。这类场景的使用方式通常是这样：应用在启动的时候主动从 etcd 获取一次配置信息，同时，在 etcd 节点上注册一个Watcher并等待，以后每次配置有更新的时候，etcd 都会实时通知订阅者，以此达到获取最新配置信息的目的。\n分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在etcd中，供各个客户端订阅使用。使用etcd的key TTL功能可以确保机器状态是实时更新的。\n分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用（或主题）来分配收集任务单元，因此可以在 etcd 上创建一个以应用（主题）命名的目录P，并将这个应用（主题相关）的所有机器ip，以子目录的形式存储到目录P上，然后设置一个 etcd 递归的Watcher，递归式的监控应用（主题）目录下所有信息的变动。这样就实现了机器IP（消息）变动的时候，能够实时通知到收集器调整任务分配。\n系统中信息需要动态自动获取与人工干预修改信息请求内容的情况。通常是暴露出接口，例如 JMX 接口，来获取一些运行时的信息。引入 etcd 之后，就不用自己实现一套方案了，只要将这些信息存放到指定的 etcd 目录中即可，etcd 的这些目录就可以通过 HTTP 的接口在外部访问。\n2.4 分布式通知与协调 这里说到的分布式通知与协调，与消息发布和订阅有些相似。在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。\n这里用到了 etcd 中的 Watcher 机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。实现方式通常是这样：不同系统都在 etcd 上对同一个目录进行注册，同时设置 Watcher 观测该目录的变化（如果对子目录的变化也有需要，可以设置递归模式），当某个系统更新了 etcd 的目录，那么设置了 Watcher 的系统就会收到通知，并作出相应处理。\n通过 etcd 进行低耦合的心跳检测。检测系统和被检测系统通过 etcd 上某个目录关联而非直接关联起来，这样可以大大减少系统的耦合性。\n通过 etcd 完成系统调度。某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了 etcd 上某些目录节点的状态，而 etcd 就把这些变化通知给注册了Watcher的推送系统客户端，推送系统再作出相应的推送任务。\n通过 etcd 完成工作汇报。大部分类似的任务分发系统，子任务启动后，到 etcd 来注册一个临时工作目录，并且定时将自己的进度进行汇报（将进度写入到这个临时目录），这样任务管理者就能够实时知道任务进度。\n2.5 分布式锁 当在分布式系统中，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。与单机模式下的锁不仅需要保证进程可见，分布式环境下还需要考虑进程与锁之间的网络问题。\n分布式锁可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。\n因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。\n保持独占即所有获取锁的用户最终只有一个可以得到。etcd 为此提供了一套实现分布式锁原子操作 CAS （CompareAndSwap）的 API。通过设置 prevExist 值，可以保证在多个节点同时去创建某个目录时，只有一个成功。而创建成功的用户就可以认为是获得了锁。\n控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录建值时指定为 POST 动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用API按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。\n3. 小结 本章主要介绍了 etcd 的相关概念，以及 etcd 主要的使用场景。etcd 在分布式环境中是一个利器，在一致性存储方面有广泛的应用。下一篇将会具体介绍 etcd 的安装以及使用的实践。\n参考  etcd 官方文档  ","permalink":"https://cloudnative.to/blog/etcd-1/","tags":["etcd"],"title":"彻底搞懂 etcd 系列文章（一）：初识 etcd"},{"categories":["Kubernetes"],"contents":"导言 2018年 kubecon 大会上，阿里的陈俊大佬分享 Node-operator 的主题让我印象深刻，回来之后开始着手研究 Operator。正好当时老板希望能够将公司正在使用的 Nosql 组件容器化，顺势给老板安利一波 Operator 的思想。随后以 opentsdb 的容器为开端，后续完成一系列组件容器化，一路走来不断学习和借鉴其他 operator 的先进经验。Zookeeper作为最新完成 operator 化的组件，除了可以快速部署以外，还实现了 Operator 对 scale up/down 的进度干预，控制 rolling 的重启顺序，感知组件实际运行状态等，具体实现请阅读对于相关章节。\n功能需求 目前 operator 主要实现如下功能：\n 快速部署 安全伸缩容 自动化监控 故障自愈 可视化操作  CRD Operator 设计第一步是定义声明式接口的 Item，spec 主要包含节点资源、监控组件、副本数、持久化存储。\napiVersion: database.ymm-inc.com/v1beta1 kind: ZooKeeper metadata: name: zookeeper-sample spec: version: v3.5.6 cluster: name: test resources: requests: cpu: 1000m memory: 2Gi limits: cpu: 2000m memory: 2Gi exporter: exporter: true exporterImage: harbor.ymmoa.com/monitoring/zookeeper_exporter exporterVersion: v3.5.6 disableExporterProbes: false nodeCount: 3 storage: size: 100Gi 架构图 Operator 主要包含：Deploy、Monitor、Scale 三个大模块。\n Deploy：主要用于生成和创建 Statefulset、Service、ConfigMap、PV 等原生资源，用于快速部署 zookeeper 集群。 Monitor：主要用于生成和创建 ServiceMonitor、PrometheusRule 资源，用于自动化注册 target、添加告警策略，实现对集群的监控和告警。 Scale：主要用于把控扩缩容以及滚动升级的进度，确保以最少的主从切换完成重启。  具体方案 快速部署 基本知识   Kubernetes Labels\n Labels：是一对 key/value，被关联到特定对象上，标签一般用来表示同一类资源，用来划分特定的对象，一个对象可以有多个标签，但是，key 值必须是唯一的。这里我们将在 list-watch 的时候用这个 labels 进行过滤，从所有的 Kubernetes event 中过滤出符合特定 label 的 event，用来触发 operator 的主流程。    Kubernetes Informer\n  watch：可以是 Kubernetes 内建的资源或者是自定义的资源。当 reflector 通过 watch API 接收到有关新资源实例存在的通知时，它使用相应的列表 API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。\n  Informer：informer 从 Delta Fifo 队列中弹出对象。执行此操作的功能是 processLoop。Base controller 的作用是保存对象以供以后检索，并调用我们的控制器将对象传递给它。\n  Indexer：索引器提供对象的索引功能。典型的索引用例是基于对象标签创建索引。 Indexer 可以根据多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键。 在 Store 中定义了一个名为 MetaNamespaceKeyFunc 的默认函数，该函数生成对象的键作为该对象的 / 组合。\n    Labels labels: app: zookeeper app.kubernetes.io/instance: zookeeper-sample app.kubernetes.io/managed-by: zookeeper-operator app.kubernetes.io/name: zookeeper app.kubernetes.io/part-of: zookeeper component: zookeeper zookeeper: zookeeper-sample 节点部署 容器分类  InitContainer  配置文件初始化容器，主要用于 zk config 文件复制到工作区域。   Container  主进程容器 监控容器 Agent    初始化容器  zoo.cfg.dynamic，这个文件同样以 configmap 方式挂入主容器，主要用于zk节点发现和注册，下面将详细介绍下这个zk 3.5之后的特性。\n  具体可以参考 ZooKeeper 动态重新配置  server.1=zookeeper-sample-0.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.2=zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.3=zookeeper-sample-2.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.4=zookeeper-sample-3.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.5=zookeeper-sample-4.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181  更新目录权限   设置 data 和 logs 目录的权限，确保 zk 能够正常启动。\n echo \u0026#34;chowning /data to zookeeper:zookeeper\u0026#34; chown -v zookeeper:zookeeper /data echo \u0026#34;chowning /logs to zookeeper:zookeeper\u0026#34; chown -v zookeeper:zookeeper /logs 主进程容器  环境变量   POD_IP、POD_NAME，主要将 node 的 pod ip 和名称传到 pod 内部，方便容器内部调用。\nZK_SERVER_HEAP，这变量为限制 zk 启动 heapsize 大小，由 operator 根据 request 内部大小设置，zk启动会读取这个变量。\n - name: POD_IP valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: ZK_SERVER_HEAP value: \u0026#34;2048\u0026#34; - name: ZK_CLIENT_HEAP value: \u0026#34;512\u0026#34;  Readiness探针   主要通过 zk 客户端端口传入 ruok 命令，检查返回码，返回 imok 认为 zk node 已经准备完毕，zk node 将会被更新到上面说到的 zoo.cfg.dynamic 文件，zk cluster 将会自动发现该节点。\n ZK_CLIENT_PORT=${ZK_CLIENT_PORT:-2181} OK=$(echo ruok | nc 127.0.0.1 $ZK_CLIENT_PORT) if [ \u0026#34;$OK\u0026#34; == \u0026#34;imok\u0026#34; ]; then exit 0 else exit 1 fi 监控容器  github 项目（https://github.com/dabealu/zookeeper-exporter） exporter 跟随主进程一同启动，后续会介绍如何注册到 prometheus target 以及告警策略。\n 访问控制  暴露端口   9114：该端口为 exporter 服务端口，通过 servicemonitor 注册 prometheus target 时将通过 labels 匹配该端口。\n1988：该端口为 zk-agent 服务端口，通过该接口 operator 可以查询到当前节点运行状态，后面会详解介绍。\n2181：该端口为 zk 客户端端口，该端口创建 Kubernetes headless 模式 svc，方便客户端一次获取所有节点 ip。\n3888：选举 leader 使用\n2888：集群内机器通讯使用（ Leader 监听此端口）\n ports: - name: client port: 2181 protocol: TCP targetPort: 2181 - name: server port: 2888 protocol: TCP targetPort: 2888 - name: leader-election port: 3888 protocol: TCP targetPort: 3888 - name: http-metrics port: 9114 protocol: TCP targetPort: 9114 - name: http-agent port: 1988 protocol: TCP targetPort: 1988  暴露方式   这里主要 kubernetes service 的两种模式：Headless 和 Cluster\n Headless Services：简单而言就是，每次访问 headless service，kube-dns 将返回后端一组 ip，在我们这种场景下，即会返回 es 所有节点 ip 给客户端，再由客户端自己判断通过哪个 ip 访问 es 集群。\nCluster：这种模式是默认配置，创建此类 service 之后，将分配一个 cluster ip，这个 ip 类似 vip，每次访问这个 service name，kube-dns 将会随机返回一个节点 ip。\n operator 在创建 service 的时候，上面两种都会创建，headless 类型主要给 kubernetes 内部应用访问，cluster 类型主要通过 NodePort 暴露给外部应用访问。\n 配置信息  配置文件  autopurge.purgeInterval=24 autopurge.snapRetainCount=20 initLimit=10 syncLimit=5 skipACL=yes maxClientCnxns=300 4lw.commands.whitelist=cons, envi, conf, crst, srvr, stat, mntr, ruok tickTime=2000 dataDir=/data dataLogDir=/logs reconfigEnabled=true standaloneEnabled=false dynamicConfigFile=/conf/zoo.cfg.dynamic.c00000002 数据存储  PersistentVolume   StorageClass PROVISIONER: diskplugin.csi.alibabacloud.com，阿里云CSI插件实现了 Kubernetes 平台使用阿里云云存储卷的生命周期管理，支持动态创建、挂载、使用云数据卷。 当前的 CSI 实现基于kubernetes 1.14以上的版本。\n云盘 CSI 插件支持动态创建云盘数据卷、挂载数据卷。云盘是一种块存储类型，只能同时被一个负载使用(ReadWriteOnce)。\noperator 会将 CRD 中配置的 pvc 信息，透传到 sts 中去，并挂载到 zk data 目录下 。\n 自动化监控 监控注册 ServiceMonitor selector.matchLabels：这里通过 zookeeper: zookeeper-sample 来匹配 service。\nport: http-metrics：这里通过匹配 service 中到 port name 来注册到 prometheus target。\noperator 调用 prometheus-operator client 完成 ServiceMonitor 资源的创建，实现新建zk集群自动注册到prometheus的功能。\napiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: labels: app: zookeeper app.kubernetes.io/instance: zookeeper-sample app.kubernetes.io/managed-by: zookeeper-operator app.kubernetes.io/name: zookeeper app.kubernetes.io/part-of: zookeeper component: zookeeper zookeeper: zookeeper-sample name: zookeeper-sample namespace: default spec: endpoints: - interval: 30s port: http-metrics namespaceSelector: {} selector: matchLabels: zookeeper: zookeeper-sample PrometheusRule operator 调用 prometheus-operator client 完成 PrometheusRule 资源的创建，实现将告警策略自动注册到 prometheus。\n告警策略中的 dingtalkRobot 标签，主要用来重定向告警信息到指定钉钉群中，这里可以添加多个钉钉群机器人。\n安全伸缩容 扩缩节点   更新 Zookeeper CR 中 spec.cluster.nodeCount 配置。\n  触发 operator 主流程，判断期望副本数大于实际副本数继续流程，否则退出主流程。\n  更新 zk 集群 records，提交两种 record：\n  Zookeeper upscale from 3 to 4.\n  Zookeeper Statefulset %s already update.\n    更新 zk 集群 StatefulSet 资源，StatefulSet 控制器将会新建节点，zk 将新建节点加入集群中，数据将会自动做同步。\n  Reconfig 模块将从集群中添加或者剔除节点\n  扩资源   更新 Zookeeper CR 中 spec.node.resources 配置。\n  如果zk节点数与期望节点数不一致，退出主流程，直到节点数一致，所有 pod 全部 ready。\n  通过节点数量检查之后，更新 StatefulSet 资源，由于我们这边 StatefulSet 设置的 RollingUpdate 策略为 OnDelete，即更新 StatefulSet 配置之后，StatefulSet 将不会主动重启节点以完成升级，需要我们自己手动去重启节点。\n  获取当前集群中节点角色，将 leader 节点放到最后重启，尽量减少集群不可用时间。\n  operator 比对 StatefulSet 和 pod resourceVersion值，如果不一致将节点加入到需要重启节点列表中。\n  operator 执行对节点如下检查项：\n  当前重启中对节点是否超过 MaxUnavailable 值，目前 MaxUnavailable 值默认为1.\n  跳过节点状态为 Terminating 的节点。\n    从重启节点中取一个节点，调用 kubernetes 接口，执行重启操作。\n  第一个节点重启完成之后，将 requeue 主流程，继续其他节点重启。\n  所有节点全部重启完成，滚动升级成功。\n  故障自愈 Observer   operator 会为每一个创建的 zk 集群启动一个 observer，每个 observer 将会启动两个 goroutine：\n  GetClusterStatus，获取 zk-agent /status 接口数据。\n  GetClusterUp，获取 /runok 接口数据。\n    operator 将每10秒获取集群最新状态，包括集群状态、node 节点数、leader 节点等。\n  operator 获取到最新集群状态之后，将更新CR的 status 中，达到实时更新 CR 中 zk 集群状态的功能，效果如下图。\n  status: availableNodes: 3 leaderNode: zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local  如果zk集群被销毁, operator 将调用 finalizers 方法停止 observer 协程。  触发主流程   operator 控制器在初始化的时候，将 watch 一个自定义的 event channel，等待 event 通过 channel 传递过来，触发主控流程执行。\n  observer 初始化的时候，创建一个 listeners 函数数组，用于 observer 状态刷新时候调用，每新建一个 zk 集群将加入一个 listener。\n  observer 执行一次，listeners 数组中的函数将会执行一次，获取最新各个 zk 集群的 health 状态。\n  listeners 数组的函数将判断，集群新状态与老状态是否一致，一致则返回 nil，否则进一步处理。\n  如果状态不一致将传值到 event channel，由 watch 消费以触发 operator 主控流程执行。\n  可视化操作 可视化操作，主要实现一下功能：\n zk 集群的查询、创建、伸缩、资源调整 支持多 kubernetes 环境 支持集群监控展示  多kubernetes环境 对于多 kubernetes 环境的支持，主要通过在每个环境部署 agent 组件，组件通过 rbac 进行授权，确保agent组件只能操作指定资源。将 agent 注册到管理平台，管理平台按照环境请求不同环境接口即可。\n接口列表    模式 接口 说明 备注     GET /zookeeper/list 查询所有zookeeper集群信息    POST /zookeeper/info 查询单个zookeeper集群信息    POST /zookeeper/create 创建单个zookeeper集群    POST /zookeeper/update 更新单个zookeeper集群    POST /zookeeper/delete 销毁单个zookeeper集群     参数校验 Admission Webhooks  ValidatingWebhook：主要实现验证检测，即检查通过 kubernetes API client 提交到CR参数是否合法，如果不符合要求直接拒绝资源创建。检查项如下：  检查节点资源，request CPU/mem 是否小于 limit CPU/mem   MutatingWebhook：主要实现注入默认参数，即检查到提交参数缺少一些关键性参数，将由 webhook 补齐并注入到创建资源中。补全项如下：  节点资源限制，比如request cpu/mem和limit cpu/mem。 exporter配置，默认开启exporter，    Exporter: true, ExporterImage: \u0026#34;harbor.ymmoa.com/monitoring/zookeeper_exporter\u0026#34;, ExporterVersion: \u0026#34;1.1.0\u0026#34;, DisableExporterProbes: false, 升级策略 StatefulSets 提供了多种升级策略：OnDelete，RollingUpdate，RollingUpdate with partition。\nOnDelete的一般方法 使用 OnDelete，除非 Pod 的数量高于预期的副本数，否则 StatefulSet 控制器不会从 StatefulSet 中删除 Pod。\nOperator 决定何时要删除 Pod。一旦删除，便会由 StatefulSet 控制器自动重新创建一个 Pod，该 Pod 具有相同的名称，但是最新的规范。\n我们的操作员永远不会创建 Pod，但是当我们决定准备删除 Pod 时，它将负责 Pod 的删除。\n当对 StatefulSet 进行修改时（例如，更改 Pod 资源限制），我们最终得到一个新的 revision（基于模板规范的哈希值）。\n查看 StatefulSet 状态，我们可以获得当前的修订版（currentRevision: zookeeper-sample-7b889dd5b4），使用该修订版的容器的数量以及仍在使用旧修订版的容器的数量（updateRevision: zookeeper-sample-74597f9b9d）。\n通过列出该 StatefulSet 中的 Pod，我们可以检查每个 Pod（metadata.labels[\u0026ldquo;controller-revision-hash\u0026rdquo;]: \u0026ldquo;zookeeper-sample-7b889dd5b4\u0026rdquo;）的当前版本。\nRollingUpdate.Partition 方法 使用此策略，我们定义了一个 partition 索引：这允许使用 StatefulSet 控制器替换序数高于此索引的 Pod。\n例如，如果我们有一个带有5个副本的 StatefulSet：\n zookeeper-sample-0 zookeeper-sample-1 zookeeper-sample-2 zookeeper-sample-3 zookeeper-sample-4  如果分区索引为3，则允许 StatefulSet 控制器自动删除然后重新创建 Pod zookeeper-sample-3 和 zookeeper-sample-4。\n在此模式下，操作员永远不会删除 Pod。它所做的就是：\n 当应添加新容器或应除去容器时，更新 StatefulSets 副本 当应更换某些 Pod 时更新分区索引  要对上面的 StatefulSet 进行滚动升级，我们将从索引开始5，确保4可以安全地替换 Pod ，然后将索引更新为4。这将触发更换 Pod。\nOnDelete 除了不显式删除 Pod 而是管理索引外，其他逻辑与适用相同。\nAgent zk agent 作为 sidecar 伴随主容器一并启动，提供如下接口：\n status：返回宿主 zk 节点当前运行状态，参考 zk srvr 命令。 runok：返回宿主 zk 节点是否正常运行且无错误，参考 zk ruok 命令。 health：返回 agent 运行状态，用于 agent 的心跳检测。 get：返回 zk 集群节点列表，查询 /zookeeper/config 文件。 add：增加节点到 zk 集群中，主要依赖 zk reconfigure 特性，集群扩容时使用。 del：从现有 zk 集群中删除某个节点，如果删除节点是主节点，会先做主节点切换，之后才会移除节点，集群缩容时使用。  接口列表    模式 接口 说明 备注     GET /status getZkStatus    GET /runok getZkRunok    GET /health Health    GET /get getMember    POST /add addMember    POST /del delMember     GET /status, 获取当前 zk 节点运行状态，字段含义对照 mntr 查看信息，包括如下字段：\n{ \u0026#34;Sent\u0026#34;: 1617, \u0026#34;Received\u0026#34;: 1618, \u0026#34;NodeCount\u0026#34;: 5, \u0026#34;MinLatency\u0026#34;: 0, \u0026#34;AvgLatency\u0026#34;: 2, \u0026#34;MaxLatency\u0026#34;: 5, \u0026#34;Connections\u0026#34;: 1, \u0026#34;Outstanding\u0026#34;: 0, \u0026#34;Epoch\u0026#34;: 14, \u0026#34;Counter\u0026#34;: 82, \u0026#34;BuildTime\u0026#34;: \u0026#34;2019-10-08T20:18:00Z\u0026#34;, \u0026#34;Mode\u0026#34;: 2, //0表示Unknown，1代表Leader，2代表follower \u0026#34;Version\u0026#34;: \u0026#34;3.5.6-c11b7e26bc554b8523dc929761dd28808913f091\u0026#34;, \u0026#34;Error\u0026#34;: null } /runok，获取当前节点是否正常启动。\n/health，获取 zk-agent 是否正常启动。\n/get，获取当前 Reconfig 动态配置节点信息。\n{ \u0026#34;record\u0026#34;: \u0026#34;server.1=zookeeper-sample-0.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nserver.2=zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nserver.3=zookeeper-sample-2.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nversion=c00000002\u0026#34; } POST /add，获取客户端传入需要新增的节点信息，并更新到动态节点配置中。\n/del，获取客户端传入需要删除到节点信息，并更新到动态节点配置中。传入值参考 add 接口格式。\nOAM对接  OAM 是一个专注于描述应用的标准规范。有了这个规范，应用描述就可以彻底与基础设施部署和管理应用的细节分开。这种关注点分离（Seperation of Conerns）的设计好处是非常明显的。\n 应用组件（Components）  组件（Components）：概念让平台架构师等能够将应用分解成成一个个可被复用的模块，这种模块化封装应用组成部分的思想，代表了一种构建安全、高可扩展性应用的最佳实践：通过一个完全分布式的架构模型，实现了应用组件描述和实现的解耦。\n 按照应用组件的定义，对应到目前zk operator的快速部署模块上，部署模块主要生成和创建原生资源，完成容器化zk集群搭建，并持续维持声明式定义的集群终态。部署模块可以单独定义CRD, 比如 workload.zookeeper.example.com。\n应用运维特征（Traits）  运维特征（Traits）：它们描述了应用在具体部署环境中的运维特征，比如应用的水平扩展的策略和 Ingress 规则，这些特征对于应用的运维来说非常重要，但它们在不同的部署环境里却往往有着截然不同的实现方式。\n Traits则对应 zk operator 模块中的 伸缩、滚动升级两个模块，这两个模块可以抽出来定义为单独CRD，比如 scale.zookeeper.example.com 和 rolling.zookeeper.example.com。\n小结 目前 zk operator 的实现能力也仅仅实现 部署、伸缩、滚动升级、监控等能力，还有很多模块可以做，比如：备份、重置、迁移、调度策略、暂停等等。\n参考文档   阿里云携手微软与 Crossplane 社区发布 OAM Kubernetes 标准实现与核心依赖库 OAM 正式开源：全球首个云原生应用标准定义与架构模型  ","permalink":"https://cloudnative.to/blog/zookeeper-operator/","tags":["zookeeper","operator","OAM"],"title":"Zookeeper operator 实战"},{"categories":["开源社区"],"contents":"前言 开源已经无处不在，当下已经很难找到一款软件是完全和开源没有任何关系的了。开源软件，正在成为现代社会的基础设施。\n“Open up your phone. Your social media, your news, your medical records, your bank: they are all using free and public code.” - Nadia Eghbal 《Roads and Bridges: The Unseen Labor Behind Our Digital Infrastructure》\n开源，并非与你不相关，并非离你很遥远，开源就在你身边！\n而谈到开源软件的开发模式，不得不提及 Eric S.Raymond 在其著名的论文《大教堂与集市》中论证了开源的软件工程理论。如他所定义的 Linus 定律：众目睽睽之下，Bug 将无处藏身，模块化、去中心化、快速发布快速反馈等等是可行的，Kernel 就是成功的案例。\n随着 Linux、Apache、Perl/Python/PHP、MySQL/PostgreSQL 等开源技术的崛起，以及技术的更新迭代，开源已经不再是稀缺，而是一种过剩，架构师在最初构建业务系统的时候，面临的不是创造，而是选择。于是开源项目又有了新的优势：\n可以让业务快速的搭建原型 几乎以零成本的方式来进行 让产品迅速进入市场，获得及时反馈\n开源社区 开源的理论知识或许太过深奥、晦涩。接下来我就接地气地讨论下面几个实际问题：\n 为什么要加入开源社区？ 加入社区的门槛有哪些？ 加入社区你能做什么？ 加入社区如何正确互动提问？ 加入社区有哪些收益？  为什么要加入开源社区？ 本文开篇说到过，开源已经无处不在，不管你是从事架构、开发、运维、算法还是产品、运营，只要你从事计算机与互联网相关工作，总有“一款”开源社区适合你，你可以从该社区中获益。\n加入社区的门槛有哪些？ 最近在邀请身边的朋友加入社区时，偶尔发现有人这样回答：我现在水平还不够，等以后知识水平提升了再加入吧。如果这位是在诚实地回答，我想告诉你的是，加入开源社区原则上并没有门槛。不限于其经验水平、性别、性别认同和表达、性取向、残疾、个人外貌、体型、人种、种族、年龄、宗教或国籍等。如果一定要在加上一个门槛的话，我希望你能有参与社区建设的热情、你懂得社交的基本礼仪、你有一定责任心与荣辱感，你能遵守社区的行为准则与国家地区的法律法规！\n加入社区你能做什么？ 很重要的一点，加入社区的个体可以做什么，可以在其中扮演怎样的角色！这个可能需要看社区本身的性质。如果是开源项目官方社区，加入社区后，你可以参与讨论如何贡献代码，参与技术方案的决策，当然也可以参与“疑难杂症”的讨论或者提问。如果社区的性质是终端用户社区，比如某个技术领域或者某个开源项目在中国的本地社区，那么加入社区你有很多事可以做，包括但不限于：\n 参与技术话题讨论与交流 参与官方文档汉化活动（翻译） 参与或协办线上线下活动 技术文章（原创/翻译）投稿 在社区内进行技术分享 参与社区组织的电子书的写作 参与社区网站的构建和维护 宣传自己热爱的开源项目 其它  正如第二点所说，加入社区本身没有门槛，但是加入社区后具体能做些什么取决于个体本身的水平和能力。社区是由个体组成，社区伴随个体共同成长。\n值得一提的是，很多人加入社区长期处于潜水状态，我这里强烈建议这部分群体浮出水面。被动接受地知识不易于真正吸纳，参与讨论，最终将知识产出反馈给社区，这样才能形成良性循环。另外有一部分人加入社区后，只有工作中遇到问题时才活跃起来，在社区中提问，其它社区活动也不参与，也没有任何反馈，这样单方面索取的行为不利于社区的发展，久而久之，社区就不再有知识产出了，自己也很难从社区中获得提升。\n加入社区如何正确互动提问？ 紧接上面的话题，大部分参与开源社区主要的活动就是参与互动或者提问。\n参与社区互动其实也是一个社交活动，需要个人把握社交分寸，遵守基本的社交礼仪。不可接受的参与者行为包括但不限于：讨论问题上升到人身攻击，挑衅、侮辱或贬低性评论、公开或私下骚扰、未经允许发布他人私人信息、未经允许发布广告或者其它不良信息、无故刷屏刷帖从而占用公共资源等。\n另外，在社区里提问或者发起相关技术话题讨论是被鼓励的，但是提问也是一门艺术，需要提问着好好把握。有一个知名 Github 项目 How-To-Ask-Questions-The-Smart-Way对提问的智慧进行完整的整理，我这里简单整理几点如下：\n 提问之前先尝试自己通过各种手段搜索答案，包括但不限于百度、谷歌、相关技术论坛、技术手册等。当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并不是一个不劳而获且浪费别人的时间的提问者。 提问时，使用清晰、正确、精准的语句描述问题，话不在多而在精。无效的问题，往往浪费大家的时间去阅读和理解，并且可能没有人去给你解答，因此清楚明确地表达你的问题以及需求至关重要。 提问时要有一定的礼貌，尤其通过社区向个人提问时至关重要。虽然同为社区成员，但往往素不相识，别人没有义务一定要给你解决问题，尤其当该问题需要花费不少时间去梳理和解答。向个人提问时，一般需要首先做个自我介绍，然后礼貌地请教问题，不管问题最终是否得到解答，都能够表示感谢。尤其当你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。  加入社区有哪些收益？ 简单来说，加入社区，肯定是有利可图的，你能够收获知识与成长、收获人脉、以及其它长期收益。\n 收获知识与成长。长期参与社区技术话题讨论，阅读社区提供的学习资源，参与社区活动，甚至直接给开源项目提交 PR，久而久之，在该领域的知识水平与解决问题的能力就会得到提升。以社区里面的技术达人为目标或者榜样，往往能督促个人朝着正确的方向快速前进。 收获人脉。有一句俗话，参与开源社区就是混技术圈子的。在这个圈子里，你能找到志同道合的人，结交更多的朋友。三人行，必有我师焉。圈子里面技术大牛如云，结交和认识社区里面的技术达人，除了向强者学习之外，还有利于扩展自己的人脉资源，人脉多了，路就越走越宽了。 收获影响力与认同感。一旦积极参与了社区活动，包括技术博客投稿，参与社区技术文档撰写，个人的技术影响力也会逐步提升，同时也会有更多人对你表示赞同与尊敬。替人解疑答惑，不仅自己的知识得到巩固和传播，也能收获别人的感激之情。 其它长期收益。加入社区的收益往往很难在短期之内显现，而且即使你投入很多，也很难获得物质上的回报。如果你把目光放长远，你会发现，加入社区的长期收益有很多，包括个人技术影响力的提升、自身技术视野的提升、社交水平的提升，对于一些公司和部门来说，长期活跃在开源社区也能有助于职业的晋升。 更多的收益取决于你愿意贡献多少精力在开源上。  写在最后 对于广大中国开发者而言，终端用户开源社区是最容易接触的，也是最容易从中受益的。终端用户，这里指开源项目的最终收益者/使用者。而终端用户社区即由一群终端用户成立的社区。对于这样的社区，一般的宗旨为：拥抱开源、反馈开源。终端用户开源社区不仅仅是对开源项目与技术的传播、布道、交流，也会引导社区成员在力所能及的前提之下对开源项目进行反馈，包括提 bug，提交 PR，参与项目重要决策或设计等等。\n在开发者真正拥抱开源的同时，一个开放、多样且极具成长空间的开源社区不该被错过，它将为开发者回馈更大的价值。无论是社区本身，还是参与其中的众多开发者，相信都能在良性的互动中，相互促进，获得快速且长足的发展。\n","permalink":"https://cloudnative.to/blog/opensource-and-community/","tags":["开源","社区"],"title":"解秘开源与社区"},{"categories":["云原生"],"contents":"今天我们不讲行业和商业，讲讲2019年最热的概念——云原生（Cloud Native）。\n我认为云原生是未来10年IT发展最重要的趋势，但是它涵盖的概念非常多，需要花很多时间研究，同时浩如烟海的资料分散在网络上各个地方，缺乏系统性的梳理。今年2月我在基金内部做过一个分享，今日成文，希望让更多的人有所了解。\n本文试图解答：\n 为什么云原生概念具有革命性？ 什么是微服务？ 微服务和中台的关系 容器和微服务为什么是最佳搭档？ 容器化与虚拟化的区别 API管理与API集成的区别 Kubernetes是做什么用的？ 开源软件商业化遇到的典型问题是什么？  涉及到的概念包括云原生、DevOps、持续集成、持续交付、持续部署、微服务、API管理、iPaaS、Service Mesh、Serverless、容器、Docker、Kubernetes等等，我争取用比较形象和通俗的方式把这些技术概念讲清楚。\n本文内容较多，共分为六个章节。\n 第一部分：云原生及CNCF基金会 第二部分：DevOps与CI/CD 第三部分：微服务、API管理与集成 第四部分：容器与Docker 第五部分：Kubernetes与容器编排之战 第六部分：思考与机会  第一部分：云原生及CNCF基金会 从集装箱革命说起\n有一本非常有名的书，叫《集装箱改变世界》，说的是看起来平淡无奇的铁箱子，如何从二十世纪起永久性的改变了这个世界，并促进了全球化和全球分工。集装箱的出现和发展是实体货物包装、运输、交付方式的一次革命。\n《经济学家》杂志曾经评价说“没有集装箱，不可能有全球化”。集装箱为什么具有革命性？\n经济全球化的基础就是现代运输体系,而一个高度自动化、低成本和低复杂性的货物运输系统的核心就是集装箱。集装箱最大的成功在于其产品的标准化及由此建立的一整套运输体系。能够让一个载重几十吨的庞然大物实现标准化，并且以此为基础逐步实现全球范围内的船舶、港口、航线、公路、中转站、桥梁、隧道、多试联运相配套的物流系统，这的确堪称人类有史以来创造的伟大奇迹之一，而撬动这个系统的理念就是标准化和系统化。\n改变世界的不仅仅是集装箱本身，还有一整套货物处理的新方法，包括港口、货船、起重机、卡车，还有发货人的自身操作方式等。\n云原生在IT领域的意义非常类似于集装箱，只是里面装载的不再是实体货物，而是虚拟世界的二进制代码和软件。我们将在介绍完众多概念之后再来对应解释。\n云原生的诞生\n随着虚拟化技术的成熟和分布式框架的普及，在容器技术、可持续交付、编排系统等开源社区的推动下，以及微服务等开发理念的带动下，应用上云已经是不可逆转的趋势。\n云原生的发展史，来自CNCF基金会执行董事Dan Kohn\n云计算的3层划分，即基础设施即服务(IaaS)、平台即服务(PaaS)、软件即服务(SaaS)为云原生提供了技术基础和方向指引，真正的云化不仅仅是基础设施和平台的变化，应用也需要做出改变，摈弃传统的土方法，在架构设计、开发方式、部署维护等各个阶段和方面都基于云的特点，重新设计，从而建设全新的云化的应用，即云原生应用。\n云原生（Cloud Native）这个概念，是由Pivotal的Matt Stine于2013年首次提出，他还在2015年出版了《Migrating to Cloud-Native Application Architectures（迁移到云原生应用架构）》一书。\nGartner提到云原生的定义尚不明确，但含义丰富。云原生对于不同的人和组织来讲，有着不同的理解。众多顶级技术的铸造者、Matt Stine的东家Pivotal如此定义云原生。\n“Cloud native is an approach to building and running applications that fully exploit the advantages of the cloud computing model.”——云原生是一种构建和运行充分利用云计算模型优势的应用程序的方法。\nCNCF云原生计算基金会如此定义云原生：\n“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格（Service Mesh）、微服务、不可变基础设施和声明式API。这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。”\n其中服务网格和声明式API是新加入的内容，而不可变基础设施指的是应用的基础设施应是不可变的，是一个自包含、自描述可以完全在不同环境中迁移的东西，容器技术正是这一理念实现的基石。\n而CNCF同时把云原生计算定义为：\n“Cloud native computing uses an open source software stack to be:\nContainerized. Each part (applications, processes, etc) is packaged in its own container. This facilitates reproducibility, transparency, and resource isolation.\nDynamically orchestrated. Containers are actively scheduled and managed to optimize resource utilization.\nMicroservices-oriented. Applications are segmented into microservices. This significantly increases the overall agility and maintainability of applications.”\n——云原生计算使用的开源技术栈包括：\n 容器化。每个部分（应用、流程等等）都打包在自己的容器中，这有助于提升复用性、透明度以及改善资源隔离。 动态编排。容器受到有效的调度和管理，以便优化资源利用。 以微服务为导向。应用被分割到不同的微服务中，这种分割可以显著的提高应用的整体敏捷性和可维护性。  我个人理解，云原生是指从云的原生应用角度出发，一整套设计、开发、部署、运行、维护的流程、技术栈以及背后文化理念的统称。\n下表列举了云原生应用和传统应用的有哪些主要区别。\n要转向云原生应用需要以新的云原生方法开展工作，云原生有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。\n云原生的发展脉络\n云原生背后的价值主张有哪些？\n 隔离性：把应用程序打包在容器中加快了代码和组件的重用，并且简化了操作； 无锁定：开源软件栈支持在任何公共或私有云上或以组合方式进行部署； 无限扩展：为能够扩展到数万个自修复多租户节点的现代分布式系统环境而优化； 灵活性和可维护性：将应用程序拆分为具有明确描述的依赖关系的微服务； 提高效率和资源利用率：动态管理和调度微服务的中央编排流程降低了与维护和操作相关的成本； 应用的弹性：以应对单个容器甚至数据中心的故障，以及不同级别的需求  2019年，Gartner曾经发布报告表示云原生时代已经到来，在未来三年中将有75%的全球化企业将在生产中使用容器化的应用。\n请注意，云原生相关技术不仅仅能用于云计算，即便是和云计算即对立又协同的边缘计算，微服务、容器、Kubernetes依然是事实上的杀手应用和标准。如由著名的Kubernetes管理平台创业公司Rancher所贡献的K3s项目，就是Kubernetes（K8s）的最轻量级版本，以满足边缘计算和IOT环境中，在x86、ARM64和ARMv7处理器上运行小型、易于管理的Kubernetes集群日益增长的需求。\n云原生计算基金会CNCF\n提到云原生，就不能不介绍云原生计算基金会CNCF（Cloud Native Computing Foundation）（https://www.cncf.io）。CNCF于2015 年7月由Google 牵头成立，隶属于 Linux 基金会，初衷是围绕云原生服务云计算，致力于培育和维护一个厂商中立的开源生态系统，维护和集成开源技术，支持编排容器化微服务架构应用，通过将最前沿的模式民主化，让这些创新为大众所用。\nCNCF的使命包括以下三点：\n 容器化包装 通过中心编排系统的动态资源管理 面向微服务  全球主流的科技企业和云计算厂商绝大部分都是CNCF会员，其中不乏多家来自中国的科技巨头。\nCNCF黄金、白金会员\n截止2020年4月，CNCF 基金会共托管49个云原生项目，每个CNCF项目都对应一个成熟度等级，申请成为CNCF项目的时候需要确定项目的成熟度级别，Kubernetes和 Envoy等项目基于生产可用和高稳定性首先成为毕业项目（9个），其他项目则根据其成熟度分别位于孵化（17个）和沙箱（23个）阶段。CNCF目前托管的项目共同构成了云原生生态的基石。\n值得注意的是其中有三个来自中国的项目：VMware中国团队为企业用户设计的 Registry Server开源项目Harbor，PingCap贡献的分布式事务键值数据库TiKV以及阿里自研的P2P文件分发系统Dragonfly。\nCNCF项目成熟度等级划分\n对于企业在复杂的基础架构之上如何推动云原生应用的更好落地，从而更好地适应环境与业务的发展，CNCF给出了路线图（Trail Map）用于对用户在整体上给出指导建议，共分成十个步骤（容器化；CI/CD；应用定义及编排；监控及分析；服务代理、发现和网格；网络、策略及安全；分布式数据库及存储；流与消息；镜像库与运行时；软件分发）进行实施，而在不同的步骤都可以结合CNCF全景图（Landscape）中列出的产品或服务进行选择。\nCNCF全景图则列举了和云原生相关的产品及服务的完整名单，这1381个项目共同构成了恢弘庞大的云原生世界。整个全景图按照功能分为29个模块，分别归属于9种大的类别（应用定义与开发、编排与管理、运行时、配置、平台、可观察性与分析、Serverless、会员和其它）。值得注意的是其中专门有一种分类是Cards from China，列举了来自中国的145个项目，其中不乏许多大家耳熟能详的知名项目，可惜的是数据并不完整。感兴趣的朋友可以自行研究。\n从CNCF的理念及野心来看，基于云原生的基础设施正在壮大和蚕食非云的市场，未来极有可能成为整个IT生态事实上的意见领袖和领导者。\n云原生涵盖的主要概念\n上面提到云原生的代表技术包括容器、服务网格（Service Mesh）、微服务、不可变基础设施和声明式API。另外一种比较主流的说法是云原生=微服务+DevOps+持续交付+容器化，广泛的见诸于各种文章和资料。\n在接下来的《云原生时代》系列报告中，我们将依照这些概念，分成DevOps与CI/CD；微服务、API管理与集成；容器与Docker；Kubernetes与容器编排之战四个部分全面介绍云原生各个组成部分。\n第二部分：DevOps与CI/CD DevOps\nDevOps（Development \u0026amp; Operations，开发和运维）是09年提出来的概念，但一直没有太火。直到14年，容器与微服务架构的提出，DevOps才得到了快速的发展。DevOps不单是一个实现自动化的工具链，而是组织、流程与技术的结合。组织上强调全栈团队、团队特性专一、团队自治；技术上打通开发与运维；流程上强调端到端、可视化、灰度升级、A/B测试等。\n对于DevOps，微服务不是必须的，但微服务为DevOps提供了最好的架构支撑，对于组织和流程的要求也是一致的。所以，也有人称微服务是DevOps架构。\nDevOps流程示意图\nDevOps与下面提到的CI、CD不同，DevOps更偏向于一种对于文化氛围的构建。DevOps也即是促使开发人员与运维人员之间相互协作的文化。DevOps的概念似乎与持续交付的概念有些类似，两者均旨在促进开发与运维之间的协作，但是实际上两者差别很大：DevOps 更偏向于一种文化的构建，在DevOps文化指导下，团队中将包含了具有不同技能的人员（开发、测试等），并通过自动化测试与发布的手段，更快、更高质量的生产软件。\n持续集成\n持续集成（CONTINUOUS INTEGRATION，CI）指的是开发人员频繁的（一天多次的）将所有开发者的工作合并到主干上。这些新提交在最终合并到主线之前，都需要通过编译和自动化测试流进行验证，以保障所有的提交在合并主干之后的质量问题，对可能出现的一些问题进行预警。持续集成的核心在于确保新增的代码能够与原先代码正确的集成。\n持续集成流程示意图\n持续集成带来的好处是：\n 易于定位错误 易于控制开发流程 易于Code Review 易于减少不必要的工作  持续交付\n与持续集成相比，持续交付（CONTINUOUS DELIVERY，CD）的侧重点在于交付，其核心对象不在于代码，而在于可交付的产物。由于持续集成仅仅针对于新旧代码的集成过程执行了一定的测试，其变动到持续交付后还需要一些额外的流程。与持续集成相比较，持续交付添加了测试Test-\u0026gt;模拟Staging-\u0026gt;生产Production的流程，也就是为新增的代码添加了一个保证：确保新增的代码在生产环境中是可用的。\n持续交付流程示意图\n持续交付带来的好处是：\n 繁琐的部署工作没有了。团队不再需要花费几天的时间去准备一个发布 可以更快的进行交付，这样就加快了与客户之间的反馈环 轻松应对小变更，加速迭代  持续部署\n持续部署（CONTINUOUS DEPLOYMENT）指的是通过自动化部署的手段将软件功能频繁的进行交付。与持续交付以及持续集成相比，持续部署强调了通过自动部署的手段，对新的软件功能进行集成。同持续交付相比持续集成的区别体现在对生产的自动化。从开发人员提交代码到编译、测试、部署的全流程不需要人工的干预，完全通过自动化的方式执行。这一策略加快了代码提交到功能上线的速度，保证新的功能能够第一时间部署到生产环境并被使用。\n持续部署流程示意图\n持续部署带来的好处是：\n 发布频率更快，因为不需要停下来等待发布。每一处提交都会自动触发发布流 在小批量发布的时候，风险降低了，发现问题可以很轻松的修复 客户每天都可以看到持续改进和提升，而不是每个月或者每季度，或者每年  自动实时的部署上线，是最优的解决办法，但持续部署的要求是团队非常成熟，并且上线前是需要经过QA测试的，所以实际情况下很难实现，一般的团队也很难接受，挑战和风险都很大。\n我们总结下，DevOps、持续集成、持续交付、持续部署并不是某种技术栈或者框架，而是开发文化、流程、理念和操作方式。下一部分，我们将介绍云原生最重要的概念之一：微服务。\n第三部分：微服务、API管理与集成 什么是微服务\n微服务（Microservice）概念最早出现于2012年，2015年以后受到越来越多的关注，并且逐渐开始流行开来。其中著名技术大神Martin Fowler功不可没，他于2014年发表的一篇博客《Microservices: a definition of this new architectural term》（微服务：新技术架构的定义）清晰的定义和阐述了微服务概念。\n“要开始解释什么是微服务之前，先了解单体（Monolithic）应用是很有用的：作为一整个单元构建的应用程序。企业应用由三个重要部分组成：客户端界面（由HTML、Javascript组成，使用浏览器访问）、数据库、服务端程序。服务端程序处理HTTP请求、执行业务逻辑、检索并更新数据库中的数据、选择和填充HTML视图发送给客户端。这个服务端程序是一个单一结构也即一个整体，系统中的任何修改都将导致服务端重新编译和布署一个新版本。\n这样一个单体应用很自然的被构建成为一个系统，虽然可以使用开发语言的基本特性把应用封装成类、函数、命名空间，但是业务中所有请求都要在单一的进程中处理完成，在某些场景中，你可以在开发人员的笔记本电脑中运行和测试，并且通过布署通道将测试通过的程序布署到生产环境中，你还可以水平扩展，利用负载均衡将实例布署到多台服务器中。\n的确，单体应用也非常成功，但是越来越多的人感觉到了不妥，特别是应用程序被发布到云的时候，变更周期被捆绑在一起-对应用程序一小部分所做的变更，都需要重新编译和部署整个应用。随着时间的推移，软件开发者很难保持一个好的模块架构，使得单个模块的变更不会影响到其它模块，而且扩展时也只能进行整体扩展，而不能根据需求进行部分扩展。”\u0026ndash; Martin Fowler\n下图是传统单体应用的技术及对应的组织架构，Martin Fowler称之为大家已熟知的Siloed Architectures-烟囱式（也称为谷仓）架构。\n传统单体应用的架构及对应的职能型组织架构\n综上，传统的单体应用有很大的局限性，应用程序随着业务需求的迭代、功能的追加扩展，最终成为一个庞然大物。单体应用的局限性大体包括以下几方面：\n 复杂性高：业务规模和团队规模发展的一定阶段，模块耦合严重，代码难以理解，质量变差 交付效率低：构建和部署耗时长，难以定位问题，开发效率低，全量部署耗时长、影响范围广、风险大，发布频次低 伸缩性差：单体只能按整体横向扩展，无法分模块垂直扩展 可靠性差：一个bug有可能引起整个应用的崩溃 阻碍技术创新：受技术栈限制，团队成员使用同一框架和语言  解决这一问题的银弹就是微服务。\n“微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间相互协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务和服务之间采用轻量级的通信机制相互沟通（通常是基于HTTP的Restful API)。这些服务要基于业务场景，并使用自动化布署工具进行独立的发布。可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。”\u0026ndash; Martin Fowler\n微服务架构将单体应用，按照业务领域拆分为多个高内聚低耦合的小型服务，每个服务运行在独立进程，由不同的团队开发和维护，服务间采用轻量级通信机制，如HTTP RESTful API，独立自动部署，可以采用不同的语言及存储方式。微服务体现去中心化、天然分布式，是中台战略落地到IT系统的具体实现方式的技术架构，用来解决企业业务快速发展与创新时面临的系统弹性可扩展、敏捷迭代、技术驱动业务创新等难题。\n下图左边是传统的单体应用，右边是微服务模式，图中每种颜色代表一种可拆分的微服务应用。\n单体应用和微服务\n一个比较形象的例子是装配式建筑。传统建筑（单体应用）的施工周期（开发时间）很长，往往依赖于建筑公司（开发团队）的能力和水平，修建完成后难以搬迁和复用，而装配式建筑（微服务）的梁、板、柱、墙等构件（单个服务）可以事先批量化的在工厂（容器）生产，而在建造过程中，我们可以把构件想象成一块块乐高积木，在施工现场只需把它们拼合在一起，大大提升了施工进度和建筑质量。\n装配式建筑：乐高积木\n微服务的特征包括：\n 小：粒度小，专注于一件事 独：单独的进程。微服务不等于组件，服务是可以直接使用的商品，组件是待加工的原材料 轻：轻量级通信机制，通常是HTTP Restful的接口。此处区别于传统的SOA（面向服务的架构） 松：松耦合，可以独立部署。每个微服务可以独立编译、独立部署、独立运行  微服务采用独立的数据库服务，数据去中心化\n微服务运行在独立的进程中，部署去中心化\n微服务架构的好处是：\n 易于开发与维护：微服务相对小，易于理解 独立部署：一个微服务的修改不需要协调其它服务 伸缩性强：每个服务都可按硬件资源的需求进行独立扩容 与组织结构相匹配：微服务架构可以更好将架构和组织相匹配，每个团队独立负责某些服务，获得更高的生产力 技术异构性：使用最适合该服务的技术，降低尝试新技术的成本 企业环境下的特殊要求：去中心化和集中管控/治理的平衡，分布式数据库和企业闭环数据模型的平衡  微服务的实践有两个重要问题：什么时候选择微服务架构，以及颗粒度如何拆分，与经验和实际情况息息相关。\n上图来自Martin Fowler另一篇叫《微服务进阶》的文章，揭示了生产率和复杂度的一个关系。在复杂度较小时采用单体应用的生产率更高，复杂度到了一定规模时，单体应用的生产率开始急剧下降，这时对其进行微服务化的拆分才是合算的。\n我个人建议是除非在可见的将来，复杂度都不会显著提高的情况下，才选择单体应用，否则其它时候都应提前为微服务架构做好设计和准备。\n微服务基础设施及案例\n下图是一个典型的微服务技术架构图。\n微服务架构最常见、最广泛使用的框架是基于Java的Spring Cloud（集成了上图里的Netflix OSS技术栈），提供了服务发现、负载均衡、故障转移、动态扩展和数据分区等功能，已经成为微服务的最佳实践。\n但是Spring Cloud构建在Java虚拟机之上，不能满足高并发下的性能要求，所以许多开源产品层出不穷，其中也包括中国互联网企业所贡献的微服务框架，例如华为的ServiceComb、阿里的Dubbo等等。\n下面我们举一个例子。传统的电商的技术架构如下图所示，这是一个单体应用。\n所带来的常见问题包括：\n 不同客户端产品之间，例如小程序、App、网站端有许多相同业务逻辑的重复代码，每个产品都要各自维护一份代码，修改的时候所有地方要一起修改。 单个应用经常需要给其他应用提供接口，渐渐地越来越复杂，包含了很多本来不属于它的逻辑，代码变得臃肿，功能边界模糊。 系统代码耦合性高，相互之间逻辑复杂，一旦出现开发离职的情况，继任者需要花很长时间review代码，才有可能搞清楚整体架构和逻辑关系。 多个应用使用一个数据库，依赖性严重，很难重构和优化。所有应用都在一个数据库上操作，数据库很容易出现性能瓶颈。同时数据库成为单点，出现意外整个系统都会受到影响。 即使只改动一个小功能，也需要整个应用一起发布，发布流程繁琐、上线时间长。并且很容易出现一个小bug影响整个系统，每次发布都是胆战心惊，很容易出现开发、运维和测试之间的矛盾。  下面我们用微服务重构整个系统：\n改造之后，去除了大量冗余代码，系统复用性得到提升；不同的团队专注于不同的微服务，代码和工程质量得到保证；数据库不再存在单点问题，系统健壮性得以提升；前后端分离，业务逻辑更加清晰；降低了系统耦合性，不同的微服务可以分开部署上线，相互之间并不影响。\n组织挑战、康威定律与蜂群理论\n请注意，微服务理念不仅反映了技术架构的变化，也反映了组织内部沟通结构为了应对更加灵活、快速、碎片化的需求和环境而变化的结果。例如液态组织就是组织形态应对当前市场环境快速变化的一种输出形式，但实际应该如何构建？\n曾经有一张非常有名的组织架构图，如下图所示。\n对一家企业来说，能一步步不断发展壮大，进入一个领域就能迅速突破，这其中的根本核心必然是组织模式。在粗放发展的年代，很少有企业强调内部效率，组织模式绝大部分都类似单体应用，按照职能划分的方式进行管理，从而创造了无数的烟囱/谷仓。\n单体架构和职能型组织模式相似\n一张著名的图：技术组织造就了难以逾越的谷仓\n我在我的知识星球里提出过企业级产品设计所面临的重要挑战，其中一个问题是：\n 版本。企业级产品现在经常涉及多个平台和不同的版本，例如Web、PC、App、钉钉、企业微信、微信小程序、飞书的版本等等，第一会面临重复开发的问题，第二业务逻辑非常复杂，很容易造成产品逻辑和体验的不统一，以及不同版本产品之间逻辑的缺失。例如登录和注册微信小程序可能用的是手机号，而通过邮件注册需要使用的却是邮箱。如何设计一套比较好的产品流程和组织架构，来保证统一完善的产品逻辑及用户体验？  是的，这不仅仅是产品和技术问题，还是组织问题。现在越来越多的企业意识到了最大的挑战在于组织内部，无论是增长黑客还是MVP的理念都需要快速灵活的机制来配合。为什么有的组织效率高、能力强，能及时响应客户的需求和环境变化？\n新的组织设计理念认为传统的烟囱形式会成为创建有效增长和盈利途径的障碍，需要解构组织孤岛，采用跨职能组织的形式以支持增长。企业组织设计是非常专业的领域，有许多文章讨论，例如《战胜组织孤岛的战略之路》，本文不延伸讨论。\n职能组织与跨职能组织\n我们可以看到单体应用和职能组织，微服务与跨职能组织，在形式上是高度相似的，这引申出微服务背后的理论基础。\n“当希望把一个大型应用拆分成多个部分时，管理层通常将重点放在技术层面。而如果组织架构还按UI团队、服务端逻辑团队和数据库团队的标准设立，甚至一个非常简单的变更都将导致跨团队间的项目协作，从而耗费时间和预算审批。一个高效的团队会针对这种情况进行优化，关注它们所涉及的应用逻辑，并从中做出更好的选择。换句话说，逻辑无处不在。这是康威定律的一个实例。”\u0026ndash; Martin Fowler\n 设计系统的架构受制于产生这些设计的组织的沟通结构（Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations）\u0026ndash; Melvyn Conway, 1967\n 康威定律可谓软件架构设计中的第一定律，本质是对商业世界的规律总结，但是因为投稿到编程相关的杂志，后经过《人月神话》这本软件界圣经的引用，并命名为康威定律（Conway\u0026rsquo;s law），因此得以推广。\n只通过简单的描述可能无法理解康威定律的精髓所在，原文中康威定律可总结为四项：\n 第一定律 组织沟通方式会通过系统设计表达出来（Communication dictates design） 第二定律 时间再多一件事情也不可能做的完美，但总有时间做完一件事情（There is never enough time to do something right, but there is always enough time to do it over） 第三定律 线型系统和线型组织架构间有潜在的异质同态特性（There is a homomorphism from the linear graph of a system to the linear graph of its design organization） 第四定律 大的系统组织总是比小系统更倾向于分解（The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems）  例如微服务的团队间应该是inter-operate，not integrate（互操作、不集成）。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合变弱，跨系统的沟通成本也就能减低。\n康威定律可以上升到哲学的高度进行讨论，但是过于复杂。简言之，微服务架构与组织模式互相决定和影响，协同才能发挥出最大价值。\n跨职能组织-微服务架构/团队边界强化服务边界\n凯文·凯利在《失控》中提出了著名的“蜂群理论”，利用蜂巢思维比喻人类的协作带来的群体智慧：依靠成千上万个发条一起驱动一个并行的系统，进行生产，进行自维持。蜂巢思维就是“群体思维”（Collective consciousness）。作为“超级有机体”的蜂群，被称为“分布式系统”，是以生物逻辑建立起来的群集模型。由此形成的蜂巢思维这四个理念至关重要：\n 去中心化。几乎所有的团队都直接接触用户与市场，因此所有的团队都将围绕市场格局而变，充分重视第一线的敏感度与直觉，从而做到真正的应时而动； 分布式。与垂直型集团组织不同，这个形态打破单一的行业垂直细分格局。在这种多维度矩阵式结构中，拥有更加专注的功能型团队，可建立起一个紧密围绕具体客户与市场的服务体系； 强化合作。从控制权、所有权的角度来说，这些组织单元是分离的，因而要建立起一种横向合作的文化，打破物理团队，提倡交流、合作，整体核心竞争力的提升； 适应变化。市场在不断变化，但因所有的团队都直接接触用户与市场，因此无论个人还是团队，都将不断的学习和进化。  微服务理念对应的组织模式包括蜂巢型组织，它具有突出的稳定性和抗弯曲能力，特点是：\n 跨组织：它不一定是一个独立的法人实体，而是为了特定目标或项目形成的联盟 相对统一：蜂巢组织不是一成不变的，当市场需求或组织目标发生变化时立即变化 分享性：它改变了传统的等级分明的金字塔结构，允许信息横向传递与交流，使信息利用更为充分及时  在这样一个以蜂巢为理念搭建的企业圈层里面，各个独立团队能够得到更好的协助与支撑，不断扩大视野，提高眼界，掌握话语权，团队成员也会更有归属感。这样的团队乃至蜂巢本身，也一定会更有活力和变革力，更加能适应市场的变化。蜂巢型组织有四个突出特点，所谓活系统的特质也正是由此而来：没有强制性的中心控制；次级单位具有自治的特质；次级单位之间彼此高度连接；点对点间的影响通过网络形成了非线性因果关系。\n微服务：筑巢\n蜂巢型组织的典型案例之一是华为。除了组织架构去中心化的管理模式之外，华为的著名的轮值CEO制度正是由此而来，华为有三位轮值CEO，每六个月轮换一次，这体现了依靠集体民主决策而非一人独裁的理念。\n再例如国美蜂巢式组织变革的实践是将由四个大区管辖54个分公司，调整为七个大区直接管辖200家分公司的结构，即将原来二级市场里的146家分公司独立出来，直接划归大区管辖，而原来四个大区变成七个大区。实践证明，组织扁平化是国美提升供应链效率，提升消费者消费体验的重要战略。\n国外著名的代表案例是微服务先驱Netflix。Netflix是一家技术强大的互联网公司，但是它却没有CTO职位，产品团队和技术团队(包括UI前端工程团队、Discovery搜索工程团队和Platform平台团队等)全部汇报首席产品CPO，产品驱动是该公司的核心文化要素之一，Netflix称其为BusDevOps组织架构。\nNetflix：BusDevOps组织\n在整个系列第二部分中，我们介绍了DevOps，现在我们可以理解，DevOps是配合微服务的理念组织构建团队协作的方式，各团队可以独立开发，测试、发布和迭代各自的微服务，互不干扰，沟通协调成本小。全部业务、研发和运维围绕产品开展工作，统一目标，大家都是产品驱动，分别服务于内外不同客户，避免技术驱动 vs 业务驱动的陷阱。\n传统水平组织 vs DevOps驱动的垂直组织\n在某些文章中，认为微服务的切割应该按照组织架构来划分，我反而觉得应该按微服务的分割方式来划分组织架构，因为归根结底，组织架构应该为业务服务，而不是业务为组织服务，组织需要贯彻执行微服务的理念，就必须由微服务驱动组织业务的不断迭代演进。\n微服务与中台\n可能有人会问，中台的目标不也是为了解决企业内部业务系统烟囱林立，数据孤岛严重，各自为战，缺乏复用性，所以要充分提取业务共性，从而及时应对需求变化，听起来和微服务的目标和理念非常相似，那它们之间有什么异同呢？\n阿里巴巴中台战略架构图\n来自阿里官方的定义，“企业中台就是，将企业的核心能力随着业务不断发展以数字化形式沉淀到平台，形成以服务为中心，由业务中台和数据中台构建起数据闭环运转的运营体系，供企业更高效的进行业务探索和创新，实现以数字化资产的形态构建企业核心差异化竞争力。”\n中台架构，简单地说，就是企业级能力的复用，一种方法论，企业治理思想。\n微服务，是可独立开发、维护、部署的小型业务单元，是一种技术架构方式。\n所以中台并不是微服务，中台是一种企业治理思想和方法论，偏向于宏观，微服务是技术架构方式，偏向于微观。而中台化的落地，离不开使用微服务架构。\n中台强调核心基础能力的建设，基础能力以原子服务的形式来建设，并通过将原子服务产品化，支撑业务端各种场景的快速迭代和创新；原子服务和微服务所倡导的服务自闭环思想不谋而合，使得微服务成为实现原子服务的合适架构。\n支撑业务场景的应用也是通过服务来实现，其生命周期随业务变化需要非常灵活的调整，这也和微服务强调的快速迭代高度一致，所以业务应用服务也适合通过微服务来实现。\nAPI管理与API集成\n下面我们讲讲微服务相关的两个具体领域，API管理与API集成。\n1、全生命周期API管理\n上文提到微服务各个服务对外都是以Restful API形式提供服务。再加上企业越来越多地使用云服务，各种云服务也提供了众多API。\n这就导致企业拥有的API越来越多，那就当然需要有一个系统把这些API统一管理起来。同时，如果能够顺便把这些API的权限认证、安全审计等等机制也一并统一了，那就更好了，这样其它系统调用起来就方便多了。能管了以后，当然又会冒出来更多的想法。比如，能不能改一下原有API的格式内容？能不能把两个API合成一个API？能不能让一个API直接调用另一个API？能不能把这些API的调用自动化串起来？\n简单来说，API管理就是解决以上这些问题的。我们来看看Gartner全生命周期API管理领域魔力象限，许多巨头都在里面。值得注意的是，Google之所以排名第一，是因为它在2016年用6.5亿美元收购了刚上市一年左右的Apigee。\n2019年全生命周期API管理魔力象限\n2、API网关：微服务基础设施\n全生命周期API管理里一个细分的领域是API网关（API Gateway），它是微服务1.0时代最重要的基础设施。\nAPI网关顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界，主要起到隔离外部访问与内部系统的作用，并处理常见的南北向流量。在微服务概念的流行之前，API网关的实体就已经诞生了，例如银行、证券等领域常见的前置机系统，它也是解决访问认证、报文转换、访问统计等问题的。\nAPI网关的流行，源于近几年来，移动应用与企业间互联需求的兴起。移动应用、企业互联，使得后台服务支持的对象，从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的要求都不尽相同。这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构概念的提出，API网关成为了微服务架构的标配组件。\nAPI网关作为企业能力开放的一个门户，除了具备基本的请求转发、协议转换、路由等功能，以及高性能和高稳定性外，还需具备良好的扩展性，已便于网关能力的不断增强。在网关实施过程中，要规划好网关层与服务层的交互方式，尽量使得网关层与服务层解耦，便于各个团队工作的独立性。另外，在API的管理上，需要提供API全生命周期的发布、配置、鉴权、流控、监控等配套的管理功能。\nAPI网关：微服务基础设施\n例如Uber，在传统的单体架构遇到越来越大挑战的时候，决定改变自己的架构，效仿亚马逊、Netflix、Twitter等其他超级增长公司，将其整体架构拆分为多个代码库，以形成一个微服务架构。其主要变化是引入了API网关，所有的司机和乘客都是通过这个网关连接的。从API网关，所有的内部点都连接在一起，如乘客管理、司机管理、行程管理等。每个单元是单独的可部署单元，执行单独的功能。例如：如果你想在账单微服务中更改任何内容，那么只需部署账单微服务，而不必部署其他服务。所有的功能都是单独扩展的，即每个特征之间的相互依赖被移除。\nUber的微服务架构\nAPI网关带来的的好处包括：\n 网关层对外部和内部进行了隔离，保障了后台服务的安全性 对外访问控制由网络层面转换成了运维层面，减少变更的流程和错误成本 减少客户端与服务的耦合，服务可以独立发展。通过网关层来做映射 通过网关层聚合，减少外部访问的频次，提升访问效率 节约后端服务开发成本，减少上线风险 为服务熔断，灰度发布，线上测试提供简单方案。 便于扩展  API网关常见的解决方案包括Spring Cloud Gateway、Zuul、Tyk以及下文要介绍的Kong。\nCNCF Landscape：API Gateway\n3、Kong：API网关独角兽\nKong是我去年起就在关注的一家公司，它的创业历程非常有意思。“Kong的创始人Augusto Marietti（简称Aghi）出生在罗马，因为意大利创业环境很弱，在2009年飞来了旧金山。Aghi刚来就参加了一个早期创业者的小聚会，聚会上参加的人不多，但现在都是如雷贯耳的名字：Uber的创始人Travis，Airbnb的CEO Brian，Dropbox的CEO Drew和Box的CEO Aaron。Aghi当时为了省钱，借住在Uber创始人Travis家，每天睡沙发。\n后来Travis搬了家，Aghi又去了当时只有十多个人的Airbnb办公室里借住，当时的Airbnb虽然Bug很多，但订单量一天天疯涨。在Travis的帮助下拿到天使投资后，Aghi做了一个把云端的组件连接起来的PaaS公司，一做就是五六年。由于时机不对，公司濒临破产，Aghi告诉团队，这么多年公司写了很多小功能，现在可以把代码开放出去，放在网上看看有没有人用，给社区做点贡献。没想到这看似濒死的挣扎，却给公司带来了巨大的转机。\n后来，公司关于API管理的代码模块，在GitHub上被疯狂下载，Kong也接到客户要求，希望购买相应的付费企业版。Kong敏锐地发现了这个大机会，迅速转型成了一个开源软件公司。”如果在CSDN博客上搜索，关于Kong开源版本的教程比比皆是。这是一个成功的开源软件商业化的案例，听起来经历和Docker非常相似。\nKong开源版本Github主页\nKong成长的大背景是软件开发技术正在经历革命性变化，全球5000强公司都在转向新的分布式软件架构，因为现代应用程序需要有高度可扩展性、跨平台支持以及处理实时数据流的能力。IDC预计，到2022年90%的应用程序将采用微服务架构和第三方代码，35%的生产应用程序将诞生于云端。由于容器和敏捷方法的采用，预计2018-2023年间将诞生5亿个新应用程序。\n同时开源软件初期具有的优势也在逐渐显现。Kong本身基于开源的Openresty（Nginx+lua），但比Nginx提供了更简单的配置方式，数据采用了Apache Cassandra/PostgreSQL存储，由于底层使用Nginx，所以性能比基于Java的Spring Cloud Gateway及Zuul更为出色。Kong另外一个非常诱人的地方就是提供了大量的插件来扩展应用，通过设置不同的插件可以为服务提供各种增强的功能。Kong默认插件包括：身份认证、安全、流量控制、分析监控、转换等等。\nKong的插件功能\nKong提供开源的Kong Gateway和商业版Kong Enterprise两个产品。例如在插件功能上，商业版本提供更多的选择。\nKong的部分插件功能\nKong通过云原生、混合和本地部署无缝连接API和微服务，便于程序员开发可扩展的微服务应用，推动业务增长。凭借高性能的开源内核和AI技术以及机器学习，Kong将实现全方位的服务生命周期管理，覆盖前期到后期全过程，帮助客户搭建和管理创新产品及服务。它服务于全球5000强企业，帮助程序员更方便地开发和管理高性能、可扩展的微服务应用，推动业务增长。\n从业务和融资上来讲，2018年，Kong订单大幅增加，公司员工数翻倍，已服务超过100家企业客户，包括雅虎日本、法拉利、SoulCycle、WeWork等，开源软件下载量超过5400万次，收入为500万美元。2019年，Kong完成了Index Ventures领投，GGV纪源资本、World InnovationLab跟投，老股东Andreessen Horowitz、Charles Rivers Ventures追加的4300万美元C轮融资，至此Kong累计融资共计7100万美元。\n4、RapidAPI：全球最大API市场\n和Kong紧密相关的另外一家企业是RapidAPI，2017年，Kong的母公司Mashape将其API市场业务与RapidAPI合并，从而组成了世界上最大的API市场。\n市场研究机构Ovum Research曾经表示，API经济在迅迅猛发展，到2018年将成为产值高达2.2万亿美元的市场。合并后，RapidAPI成为了这个市场的主要提供商之一。\nRapidAPI的首席执行官吉纳在宣布合并的博文中表示，“软件相互连接起来后，其功效就要大得多。不妨想一想。你使用Facebook登录到某个游戏应用程序，就能看到玩游戏的所有朋友。当亚马逊的购买门户网站与仓库存货连接起来后，你就能实时获得发货估计日期。如果你在订购机票呢？已经在你的谷歌日历中预定了航班。”吉诺补充道，API正是让那些连接成为可能的秘诀。“它们让不同的软件得以彼此联系，共享信息，并且简化我们的生活。”\n吉纳在博文中表示这只是开了个头。API正在迅速发展，打开之前紧闭的许多大门。使用API，开发人员就有可能从任何地方来访问服务，比如IBM公司的超级计算机和谷歌的机器学习模型，这就意味着他们能够充分利用比以前处理的任何资源丰富得多的资源。\n吉纳说：“我们想要让广大开发人员更容易寻找、测试和连接API。我们的计划始终未变，那就是将世界上的所有API统统集中到一个地方。将Mashape API市场合并到RapidAPI让我们离实现这个目标比以往更近了一步。现在我们每月总共有370000名开发人员在调用3000亿次API。也就是说，每秒的API调用超过100000次。”\nRapidAPI的市场里包括各种各样类型的API，例如天气、体育、科技、通讯、图像处理等等，例如获取新闻信息、实时体育比赛比分、天气信息，甚至还包括新冠病毒API分类。\n开发商可以自由的为自己的API接口定价，下图是Twilio SMS接口的报价方案。\n2019年，RapidAPI完成了由微软领投、A16Z等跟投的2500万美元B轮融资，历史累计融资达到3750万美元。RapidAPI表示，它将利用这笔新筹集的资金扩大其API市场规模，并推动其新发布的RapidAPI for Teams产品。它是一个自助服务平台，使开发人员能够发布，管理和协调API和微服务，这些是用于构建现代应用程序的常用组件。\n5、Mulesoft：API集成/iPaaS/API管理领头羊\n1）从SOA讲起\n讲API管理之前，我们得先来说说前文提到过的SOA（Service-Oriented Architecture，面向服务的架构）。\n简单地说，一个企业建设了许多业务系统，每个系统都拥有自己的数据，那么如何将这些分散各处的数据打通，从而可以进一步加以利用呢？\n这就涉及到企业应用集成（EAI，Enterprise Application Integration）这个领域了。\n传统上，企业应用集成很多是利用ETL（Extract-Transform-Load，抽取转换加载）工具，把不同系统里的数据经过抽取、过滤、转换，最终导入到一个集中的数据仓库里，然后再做整合应用。但是这种做法也存在很多问题。\n一是只认数据，没有脑子。在数据汇集的过程中，只能针对数据格式本身进行一些处理，很难利用业务系统原有的业务逻辑。\n二是随着各个系统数据体量越来越大，把所有系统的数据都汇到一个数据仓库里就变得越来越困难。\n为了解决这样的问题，SOA应运而生，就是企业中每个系统都对外发布自己的服务，那么系统之间的集成，就可以通过调用对应系统的服务来解决了。\n但是，随着企业拥有的系统越来越多，这种系统之间相互调用服务接口的集成方式又遇到了新麻烦。\n可能每两个系统之间都需要相互调用服务，这最终就会演变成一个复杂的蜘蛛网结构，使得整个集成变得越来越脆弱，难以维护。\n为了解决这个新问题，ESB（Enterprise Service Bus，企业服务总线）的概念被提出来了，就是把每个系统的服务接口都对接到ESB上，这样在系统集成的时候，只需要跟总线打交道，而不再需要直接跟所有其它系统打交道了，从而大大简化了集成的复杂度。\n使用ESB前后\n2）Mulesoft\n2018年3月，美国SaaS巨头Salesforce花费65亿美元收购iPaaS代表企业Mulesoft，Mulesoft于2017年在纽交所上市，市值约30亿美元。Mulesoft的核心产品是企业软件集成平台Anypoint Platform（旧称Mule ESB），客户可以在Anypoint上集成所有业务系统的服务，实现本地系统与云、以及云与云服务的集成。Anypoint Platform/Mule ESB是世界上使用最广泛的开源ESB产品，已拥有超过数百万的下载量，以及来自世界各地数十万个开发人员，财富500强中35%的企业、全球10大银行中的5家均使用了该平台。\nMule ESB\n尽管只有一个产品，但从Gartner的划分标准来看，Mulesoft同时踩在了两个领域里：全生命周期API管理和企业集成平台即服务（iPaaS，Enterprise Integration Platform as a Service）。\nGartner魔力象限：全生命周期API管理\nGartner魔力象限：企业集成平台即服务\nMule ESB同时包括开源和商业版本，在各个技术论坛上遍布其技术教程。\nMule开源版讨论文章\nMulesoft的成长历程非常具有参考意义，他们瞄准了一个有7000亿美元空间的市场，目标是解决一个十分困难的IT问题-集成。在摸索过程中Mulesoft不断优化其产品形态和销售方式，例如针对大客户需要的不仅是平台提供的通用功能，还需要更复杂的综合服务。于是MuleSoft把他们的销售方式从出售可靠的集成功能，变成了向高级管理人员出售提升企业连接能力的愿景和相应的解决方案，客单价也从10-30000美元提升到了500万美元。\n3）应用场景与案例\nMule ESB的常见应用场景例如：\n 旧系统改造，开放系统的服务能力。举个例子，企业有一个电商系统，需要调用SAP ERP的订单接口来创建订单，这个时候需要将SAP的订单服务暴露成流行的Restful API，以方便电商系统调用。使用Mule ESB可以轻松实现。 系统集成。企业之间的数据交换，竟然有一半以上是文件的形态进行的，这在互联网思维普及的今天，是不容易想象的。在10年前，企业间交换数据采用文件形态的比重占60%，当时普遍认为这个比重会迅速下降，最终以接口服务形态进行交换的比重会占绝大多数。然而10年后直至今天，采用文件形态的依然占51%的比重。其实仔细想想，也不无合理。两个对等企业之间，行业上下游多个企业之间，不同系统之间的进行数据交换，采用文件的形式，可能是最简单便捷的方式。举个例子，很多系统之间数据交互可能还是用FTP目录。尤其是企业跟企业之间的数据交互，比如，A企业丢一个EDI文件到B企业的FTP目录，然后B企业会从FTP目录下载解析并放置到数据库。这个场景用Mule ESB实现也很方便。  4）Salesforce为什么收购Mulesoft\nSalesforce最初为中小企业提供SaaS的CRM，而随着大客户越来越多，定制化、个性化的需求也越来强烈，所以就需要提供PaaS平台解决个性化、定制化的问题。\n而这个定制化，最开始只是以Salesforce为核心的功能延伸及简单扩展，而随着个性化需求的不断深入，这种定制已经逐步演变为更大规模的多个骨干数据源之间的数据集成与交换，Salesforce可能只是多个数据源之一。\n所以也可以说，数据集成是PaaS平台的上层建筑，Salesforce需要帮助客户解决整合不同数据源所带来的挑战。\n收购之后，Salesforce会将MuleSoft植入进Salesforce Integration Cloud，从而帮助客户连接多个数据源，并计划在之后推出集成云。\n所以，可以看出Salesforce其实更在乎的是集成（Integration）这个词。\n5）iPaaS、API管理与API集成\niPaaS的集成不光是针对云服务，也包括本地系统，这样就解决了混合云模式下的集成问题。iPaaS集成的范畴，除了API接口之外，一般还会包括更多种类的协议（比如FTP、数据库），也包括对于文件数据的集成。\n从这个角度来理解，API管理更关注API的治理与整合，iPaaS关注更大范畴的集成，包含API集成的概念。\n6）SOA、ESB与微服务的关系\n微服务架构和SOA架构非常类似，微服务是SOA的升华，只不过微服务架构强调的是“业务需要彻底的组件化及服务化”，原单个业务系统会被拆分为多个可以独立开发、设计、部署运行的小应用，这些小应用间通过服务化完成交互和集成。\nESB是一种集中式服务治理的架构，看上去微服务中不需要ESB，Martin Fowler也不赞同在微服务架构中继续用ESB。\n我们下面要介绍到的下一代微服务架构核心-服务网格*，则可以视为分布式的ESB。*\n微服务2.0：服务网格与Serverless\n1、服务网格\n微服务当前遇到的挑战包括：\n 技术门槛高：开发团队在实施微服务的过程中，除了基础的服务发现、配置中心和鉴权管理之外，团队在服务治理层面面临了诸多的挑战，包括负载均衡、熔断降级、灰度发布、故障切换、分布式跟踪等，这对开发团队提出了非常高的技术要求。 代码侵入性强：Spring Cloud、Dubbo等主流的微服务框架都对业务代码有一定的侵入性，技术升级替换成本高，导致开发团队配合意愿低，微服务落地困难。  为了解决上述问题，号称微服务2.0的服务网格（Service Mesh）应运而生。服务网格这个词最早由著名开源服务网格项目Linkerd所在的Buoyant公司CEO William Morgan所提出。按照他的定义，服务网格是一个软件基础设施层，用于控制和监视微服务应用程序中的内部、服务到服务的流量。\n服务网格架构\nSidecar是服务网格中的核心组成部分，可以看到，上图中每一个微服务都配备了一个Sidecar。此时用户只需要关心业务逻辑，而不用关心服务治理等非业务功能，非业务功能都由Sidecar负责，接管对应服务的入流量和出流量，并将微服务架构中的服务订阅、服务发现、熔断、限流等功能从服务中抽离到Sidecar中。\n服务网格和API网关是两个联系非常紧密的概念，它们的用途既不同，但是在某些方面又相互重叠。在某种程度上，我们可以认为服务网格是一个分布式的、微观层面的API网关，解决微服务服务发现、负债均衡、流量控制等需求。在具体用途上，API网关处理的是所谓南北向流量即内外部请求；而服务网格处理的是东西向流量即内部服务相互间的访问。想深入了解两者区别的读者可以仔细阅读《Service Mesh和API Gateway关系深度探讨》这篇文章。\n南北向流量 vs 东西向流量\n服务网格相关的著名项目包括Linkerd、Envoy和最受欢迎的服务网格框架Istio。Kong也于2019年发布了基于Envoy的开源服务网格产品Kuma。\nKong的服务网格产品：Kuma\n下图是CNCF Landscape里服务网格分类所罗列的项目，其中Linkerd正由CNCF进行孵化。\n2、Serverless\nServerless（无服务器架构）这个概念在2012年时便已经存在，比微服务和服务网格的概念出现都要早，但是直到微服务概念大红大紫之后，Serverless才重新又被人们所关注。\nServerless是一种构建和管理基于微服务架构的完整流程，它与传统架构的不同之处在于，完全由第三方管理，由事件触发，存在于无状态、暂存的计算容器内。Serverless相关的重要概念包括FaaS（Functions as a Service，函数即服务）。开发者把函数上传到云厂商的FaaS平台，函数只在被请求时才实例化运行，然后被销毁，其它时候不占用任何服务器资源，完全实现按需使用，大幅度降低了服务器占用和成本。\nServerless通常适用于实时性要求不高、无状态的场景，例如突发事件处理、数据统计分析、视频解码、离线批量计算等等，像AWS FaaS平台Lambda限制用户功能必须在15分钟内完成。\n相较服务网格，Serverless概念更为超前，虽然AWS Lambda、阿里云等许多平台都已经提供对其的支持，但是目前仍处于发展早期，无论是成熟项目数量和企业应用程度都相对有限。\nFaaS Landscape\nCNCF Serverless Landscape\n微服务 vs 宏服务：新的抉择\n最近，Uber支付体验平台的工程经理Gergely Orosz发布推文表示他们的架构方向已经发生了变化。\n “声明一下，在Uber，我们正将许多微服务转移到@copyconstruct所称的Macroservices宏服务（大小适中的服务）。 确切地说，B/C测试和维护成千上万的微服务不仅很难——它可能会带来更多的长期麻烦，而不是解决短期问题。 微服务确实可以帮助团队在早期快速推进。 等你意识到服务越少越好时，已为时已晚。你需要解决很多服务的“困难”部分。 我们在不断增加更多的服务，但也在停止使用服务，并且会更慎重的思考新的服务。“\n 全部的上下文可以在这里阅读。有一篇英文文献中这样描述Macroservices宏服务：宏服务应该定义为运行2-20个单独服务的应用程序体系结构，每个服务代表一个中等大小的代码库，可处理业务中定义明确的部分。宏服务的关键是拆分服务，最大程度地从拆分中获得收益，同时最大程度地降低运行多个服务的开销。通俗点讲，宏服务介于单体服务到微服务之间，关注的不再是某一个细节点，而是一个业务点。\n实际上，宏服务目前的定义并不清晰，影响和实践相当有限，也并非比微服务更优的解决方案，本质还是不同企业和团队在架构演进中对于系统复杂性的不同度量。\n总结\n微服务的理念不同的团队有不同的实践，例如微服务如何拆分、组织架构如何搭建、技术栈如何选择。\n我们理解，微服务是云原生的核心，后面要介绍到的容器（及Docker）和Kubernetes是实现的技术方法和手段，DevOps是配合的文化和研发流程，但是微服务带来的启发，更多是思维方式上的转变。\n第四部分：容器和Docker 虚拟化与容器\n在容器技术之前，业界的网红是虚拟机。虚拟机技术的代表是VMware和OpenStack，我在虚拟化与超融合系列里做过介绍。很多人都用过虚拟机，就是在操作系统里安装一个软件，然后通过这个软件，再模拟一台甚至多台“子电脑”出来。在“子电脑”里，可以和正常电脑一样运行程序，例如微信、Word。“子电脑”和“子电脑”之间，相互隔离互不影响。\n虚拟机虽然可以隔离出很多“子电脑”，但占用空间大，启动慢，虚拟机软件可能还要花钱（例如VMware）。而容器技术恰好没有这些缺点，它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境（类似“沙箱”），启动时间很快，几秒钟就能完成。而且，它对资源的利用率很高（一台主机可以同时运行几千个Docker容器）。此外它占的空间很小，虚拟机一般要几GB到几十GB的空间，而容器只需要MB级甚至KB级。虚拟机和以Docker为代表的容器都是虚拟化技术，不过容器属于轻量级的虚拟化。下面是两者的主要对比。\nDocker的源起\n我们再来看看Docker，Docker本身并不是容器，它是创建容器的工具，是应用容器引擎。虽然Docker 把容器技术推向了巅峰，但容器技术却不是Docker发明的。实际上，容器技术连新技术都算不上，因为它的诞生和使用有些年头了，像最早的容器LXC发布于2008年。\nDocker本来是做PaaS的公司，原来叫做DotCloud，成立于2010年。但比起Pivotal、Red Hat等著名企业，DotCloud运营并不成功。眼看就要失败的时候，2013年DotCloud决定开源自己的容器项目Docker。但是短短几个月，Docker迅速崛起，吸引大量的开发者使用。随着Docker在开发者中越来越流行，2013年10月，DotCloud公司正式更名为Docker，2014年8月，Docker 宣布把PaaS业务出售，开始专心致志做Docker。\nDocker一词意为码头工人，而它的logo则是一个托着许多集装箱的鲸鱼，非常形象：Docker是鲸鱼，而集装箱则是一个个的容器。在Docker的官网上，对于容器有一个一句话的解释“A standardized unit of software”，即“软件的一个标准化单元”。\n下面的图片比较了Docker和传统虚拟化的不同之处，容器是在操作系统层面上实现虚拟化，而传统方式是在硬件层面实现，所以导致两者的特性有很大区别，Docker更小更轻。\nDocker vs 虚拟化\n而Docker与传统的Linux容器也并不完全一致。Docker技术最初是建立在LXC技术之上的，大多数人都把LXC技术与传统的Linux容器联系在一起，尽管后来它已经摆脱了这种依赖性。LXC作为轻量级虚拟化很有用，但它没有很好的开发人员或用户体验。Docker技术带来的不仅仅是运行容器的能力，它还简化了创建和构建容器、加载镜像和镜像版本控制等过程。传统的Linux容器使用可以管理多个进程的init系统，这意味着整个应用可以作为一个整体运行。Docker鼓励将应用程序分解为它们各自的进程，并提供了实现这一点的工具，这种粒度有不少优点。\n传统Linux容器 vs Docker\nDocker解决的问题\n众所周知，Linux上我们不愉快的经历之一就是安装软件。因为系统硬件、操作系统环境不一样，软件包有不同的依赖性，所以必须要安装完软件依赖路径上的所有包，这个链条之长，往往要耗费几小时甚至几天的时间。例如下面的案例，我要安装Docker，系统提示我必须要先安装selinux-policy、selinux-policy-base、selinux-policy-targeted三个相关模块。而我安装selinux-policy的时候，又提示要先安装python；安装python的时候，又提示我要先安装_bz2、_curses、_curses_panel等等模块…\n这就是由于环境不统一带来的巨大问题，每天在世界各地的数千万台机器上都会重复上演无数次。那么，如果服务器环境能够标准化，那我们安装任何软件只需要一个版本就可以解决问题。\n同时，如果所有服务器环境统一、标准化，还能保留上面的配置、安装的软件和应用，对于我们来讲就更加有用。Docker正是在操作系统之上实现了这个标准化、统一化的运行环境，并且把各种不同的配置和应用存储成镜像，供未来使用。这有点类似于我们熟悉的Ghost或者虚拟光驱，把需要的环境和状态保留为镜像，随时恢复、随时使用。不过Ghost基于操作系统，镜像是一个大文件，管理起来并不方便，恢复速度也很慢，同时不支持跨平台的镜像恢复；而虚拟光驱则是基于软件层面，使用范围有限；而Docker正处于两者之间，能完成更多功能的同时，还实现了镜像的快速加载和运行。\nGhost软件\n虚拟光驱软件\n我们在上一部分讲微服务的时候，将其比喻成装配式建筑。把这个比喻用在Docker上的话，我们只要提前设计好模板（配置环境、部署软件或服务），就能在工厂（Docker）里批量化生产（说复制可能更加合适）出楼板、墙板、楼梯、阳台等构件和配件（容器所装载的、不同的微服务），这些构件在建筑施工现场经过组装拼合（API访问），就能成为各种各样的建筑（各种类型的产品和应用）。\n装配式建筑由各种构件组成\nDocker与各种概念的关系\n所以，Docker曾经有一句Slogan叫做“Build once，Run anywhere（搭建一次，随处可用）”。\nDocker的核心概念\nDocker技术的三大核心概念，分别是：\n 镜像（Image） 容器（Container） 仓库（Repository）  上面的例子里，设计出来的模板就是Docker镜像，生产（复制）出来的构件就是Docker容器，而Docker仓库则是集中放置管理Docker镜像的地方。\nDocker镜像是一个特殊的文件系统。它除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的配置参数（例如环境变量）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n每一种模板（镜像）能够创建出一种构件，但是模板可以由不同的设计师来设计，提供不同用途、不同风格，例如斜顶式阳台、嵌入式阳台、包豪斯风格、蒙德里安风格等等，所有人相互之间可以共享，这就形成了大的公共仓库。\nDocker官方提供了Docker Hub来维护管理所有的镜像，只是对于免费用户而言,只能创建一个私有仓库。Docker Hub里提供了大量高质量的官方镜像，例如Oracle、MySQL、redis、Ubuntu、Nginx、python、Docker（Docker in Docker！）等等，开发人员需要一个环境的时候，可以直接到Docker镜像仓库去查找，减少了大量无谓的环境安装工作。\nDocker Hub\nDocker创始人曾经公布过一个相关数据，Docker Hub里镜像的下载数量从2014年的100万次，3年内猛增到了120亿次。\n下面是我从Docker Hub上拉取一个hello world演示镜像，并且运行的示例。\nDocker的好处\nDocker给我们带来的好处非常多，下面简单列举几点：\n 更高效的利用系统资源  有了Docker，我们可以在一台服务器上运行很多应用，充分利用硬件资源。例如现在我们有一台Linux服务器，可以构建不同版本的Ubuntu镜像启动，并且为不同的用户分配不同的容器。这样用一台服务器就能虚拟出许多运行不同操作系统的虚拟服务器，而对于用户来说，这些都是透明的。许多公有云采用了容器技术为用户提供服务，所以虚拟化与容器共同成为了现代云计算的基石。\n 更快速的启动时间  传统的虚拟机技术启动应用服务往往需要数分钟，而Docker容器应用，由于直接运行于宿主内核，无须启动完整的操作系统，因此可以做到秒级甚至毫秒级的启动时间，大大的节约了开发、测试、部署的时间。\n 保证环境一致性  开发过程中常见的问题之一是环境一致性问题，由于开发环境、测试环境、生产环境不一致，导致有些bug并未在开发过程中被发现，而Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，再也不会有在线下开发环境中运行正常，而部署到线上有各种错误的情况了。\n 持续交付和部署  对于开发和运维人员来说，最希望的是一次创建或配置，可以在任意地方正常运行。开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码，无论在多少台服务器中部署都是如此。Docker可以快速创建容器，快速迭代应用程序，并让整个过程全程可见。\n 更轻松的迁移  由于Docker确保了执行环境的一致性，使得应用的迁移更加容易，Docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，其运行结果是一致的，因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。\n 提升复用性，降低耦合性，维护和扩展更轻松  Docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。安装Docker后，我们可以从Docker Hub上获取各种各样的操作系统镜像，这个操作很简单，只需要拉取相应的镜像到本地然后运行即可。另外我们可以将数据库、Web服务器、缓存服务器运行在不同的容器中，降低了各个服务之间的耦合性、便于扩展，Docker Hub上有各种各样的优秀镜像，我们可以直接拿来使用，不需要自己搭建，应用的部署就像搭积木一样简单。\n 实现沙盒机制，提高了安全性  由于应用运行在容器中，与操作系统隔离开，从而使操作系统基本不可能受到破坏。另外如果应用因为攻击而瘫痪，并不需要重启服务器，直接重启容器或者再启动一个镜像就可以了。\n容器与微服务\n容器是微服务和云原生架构的最佳实现载体。微服务与容器几乎是完美的搭配。单体式架构（Monolithic）变成微服务架构（Microservices），相当于一个全能型变成N个专能型，每个专能型分配一个隔离的容器，赋予了最大程度的灵活。\n服务器势必会走上虚拟化的道路，因为虚拟化有太多的优势，例如前文所说的低成本、高利用率、充分灵活、动态调度等等。而采用容器之后，只需要一台服务器，创建十几个容器，用不同的容器，来分别运行不同用途的服务程序。这些容器，随时可以创建，也可以随时销毁。还能够在不停机的情况下，随意变大，随意变小，随意变强，随意变弱，在性能和功耗之间动态平衡。所以容器化是云计算的终极形态。\n如果把传统IT架构比作传统工厂，容器化比作现代化工厂，那么下一部分我们要讲到的Kubernetes则会将现代化工厂进一步提升为智能化无人工厂。那么当Docker遇到Kubernetes之后将会发生什么有趣的事情？让我们拭目以待。\n第五部分：Kubernetes与容器编排之战 容器编排与Kubernetes\n在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。所以企业需要一套管理系统，对Docker及容器进行更高级更灵活的管理，按照用户的意愿和整个系统的规则，完全自动化的处理好容器之间的各种关系，这叫做编排（Orchestration）。\nOrchestration这个词来自于音乐领域，是指一种将不同乐器、音色加以合理的编排等手法营造出一个听感交融、平衡的艺术，它完美地描述了容器编排的含义：为单个应用程序（乐队中的每种乐器）提供协同工作的模式。\n在IT领域编排可以理解为一种工作流，它能把整个IT系统都串接起来，然后自动化运作。在云原生时代，整体式的应用早已成为过去时，应用一般由单独容器化的组件即微服务组成，而这些组件需要通过相互间的协同合作，才能使既定的应用按照设计运作。\n2014年6月，IT基础设施领域的领先者Google发布了Kubernetes（简写为K8S）。编排概念并不是由Kubernetes第一个提出的，Kubernetes这个单词来自于希腊语，含义是舵手或领航员。\nKubernetes是基于Docker的开源容器集群管理系统，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，因为容器本身可移植，所以Kubernetes容器集群能跑在私有云、公有云或者混合云上。\nKubernetes属于主从的分布式集群架构，包含Master和Nodes。Master作为控制节点，调度管理整个系统；Nodes是运行节点，负责运行应用。Pod是Kubernetes创建或部署的最小单位。一个Pod封装一个或多个容器（Container）、存储资源（Volume）、一个独立的网络IP以及管理控制容器运行方式的策略选项。\nKubernetes的主要功能包括：\n 资源调度：资源调度是一套分布式系统最基本的核心指标 资源管理：控制Pod对计算资源、网络资源、存储资源的使用 服务发现：管理外在的程序或者内部的程序如何访问Kubernetes里面的某个Pod 健康检查：监控检测服务是否正常运行非常重要 自动伸缩：因为涉及到环境的快速迁移和复制，虚拟机时代之前都非常难实现。容器化时代很自然的解决了这个问题，Kubernetes保证了资源的按需扩容 更新升级：Kubernetes为服务的滚动和平滑升级提供了很好的机制  Kubernetes使用案例：滚动发布\n下面我们举一个Kubernetes的应用场景，帮助大家更好的理解Kubernetes的用途。\n应用程序升级面临最大挑战是新旧业务切换，将软件从测试的最后阶段带到生产环境，同时要保证系统不间断提供服务。长期以来，业务升级渐渐形成了几个发布策略：蓝绿发布、灰度发布（金丝雀发布）和滚动发布，目的是尽可能避免因发布导致的流量丢失或服务不可用问题。\n在微服务架构盛行的时代，用户希望应用程序时时刻刻可用，为了满足不断变化的新业务，需要不断升级更新应用程序，有时可能需要频繁的发布版本。实现\u0026quot;零停机\u0026rdquo;、“零感知”的持续集成和持续交付/部署应用程序，一直都是软件升级换代必须面对的难题和追求的理想方式，也是DevOps诞生的目的。\n滚动发布/滚动更新（Rolling Update Deployment）是指每次只升级一个或多个服务，升级完成后加入生产环境，不断执行这个过程，直到集群中的全部旧版本升级成为新版本。在整个滚动发布期间，保证始终有可用的副本在运行，从而平滑的发布新版本，实现零停机、用户零感知，是云原生时代非常主流的发布方式。\n下图是滚动发布的流程示意图，Load Balance是前端的负载均衡器，橙色是正在运行旧版本服务的节点，紫色是正在更新及更新完毕新版本服务的节点。\n滚动发布流程示意图\n可以看到，滚动发布开始后（Step 2），负载均衡器将服务器A从集群里摘除，服务器A进行新版本的发布，由服务器B和服务器C对外提供版本1.0的服务；Step 3，服务器A更新完毕，部署验证成功，负载均衡器将其加入集群，开始和服务器C一起对外提供不同版本的服务，同时服务器B开始发布；直至服务器ABC全部发布完成（Step 5），服务都更新到最新的2.0版本。\n滚动发布的优点是用户无感知，平滑过渡，同时不需要冗余服务器，节省资源。不足是部署时间慢，取决于每阶段的更新时间；发布策略较复杂；同时涉及自动化的更新策略、部署验证、回滚机制等等，自动化程度比较高，通常需要复杂的发布工具支撑，而Kubernetes正好可以完美的支持这个任务。\nKubernetes通用的编排模式是控制循环，用伪代码表示如下：\n解释一下，Kubernetes集群本身状态就是实际状态，而期望状态来自于用户提交的配置文件。滚动发布的时候，Kubernetes将会根据这个控制循环，使用一个叫做Deployment的控制器，通过创建新的集群（下图中的v2版本ReplicaSet复制集）将其控制的Pod副本从0个逐渐变成3个，与此同时旧的集群（下图中v1版本的ReplicaSet）管理的Pod副本数则从3个逐渐变成0个，以此将一个集群中正在运行的多个Pod交替的逐一升级，实现滚动发布的效果。\n如果在发布刚开始的时候，集群里只有1个新版本的Pod，这个Pod有问题启动不起来，那么滚动发布就会停止，开发和运维可以及时介入解决问题。而应用本身还有旧版本的集群和Pod在线，所以服务不会受到任何影响。关于滚动发布的详细介绍和互动教程可以阅读这里。\n下面这张图展示了使用Kubernetes，配合代码仓库GitLab、Docker镜像仓库Harbor、构建工具Jenkins，实现自动化的CI/CD流程。\n上一部分结束时我们提到，传统IT架构好比传统工厂，容器化好比现代化工厂，而Kubernetes则是智能化的无人工厂，让容器和应用能够高效自动、井然有序的被控制和管理；Kubernetes还实现了服务的抽象、解耦、高扩展、统一调度与集中化管理，例如用户可以专注用同样的方式在不同硬件上的应用，比如GPU节点池和低优先级的CPU节点池。Kubernetes不仅解决了容器的编排问题，让容器应用进入大规模工业生产，更进一步对云原生应用提供了定义规范，CNCF整个技术栈都是围绕Kubernetes建立，所以Kubernetes是云原生生态最重要的基石，可以说“Kubernetes是云原生时代的Linux”，即云原生应用的操作系统。\n高扩展的Kubernetes：兼容不同的硬件节点\nKubernetes：云原生应用的大规模工业生产\n回到本文第一部分，我们曾经用集装箱革命比喻云原生。现在大家已经理解，货船可以类比操作系统，集装箱类比容器，里面装的货物则是一个个的微服务，吊臂、吊桥、起重机等自动化操作设备是Kubernetes，而一整套集装箱的操作方法和流程则是DevOps。所有这些加起来构成了现代PaaS所具备的能力：操作系统、集群管理、应用编排、应用发布、持续集成等等。\n容器编排之战\n意识到容器编排的重要性，Docker在2014年发布了Docker Swarm（Swarm是蜂群的意思），以一个整体来对外提供集群管理功能，最大的亮点就是全部使用Docker项目原来的容器管理API来完成集群管理。\n同时从2014年底开始，Docker收购了最先提出容器编排概念的Fig项目，并改名为Compose（Compose是作曲的意思），它可以用来组装多容器的应用，并在Swarm集群中部署分布式应用。\n2014年Kubernetes发布之后，为了与Swarm竞争，在容器编排地位取得绝对的优势，Google、RedHat等开源基础设施公司共同发起了CNCF基金会，希望以Kubernetes为基础，建立一个由开源基础设施领域厂商主导、按照独立基金会方式运营的平台社区，来对抗以Docker公司为核心的容器商业生态。\n一方面Kubernetes脱胎于Google内部久负盛名的大规模集群管理系统Borg，是Google在容器化基础设施领域十余年实践经验的沉淀和升华，Google利用Kubernetes的架构和设计思想成功将其所有应用（搜索、地图、视频、金融、社交、人工智能）运行在超过100万台服务器、超过80个数据中心，每周的20亿个容器上，所以Kubernetes是唯一具有超过10年以上大规模容器生产使用的技术经验和积淀的开源项目。并且Kubernetes采用了非常优雅的软件工程设计和开源开放的态度，使得用户可以根据自己的使用场景、通过灵活插拔的方式，采用自定义的网络、存储、调度、监控、日志等模块，所以在Github上的各项指标一路飙升，将较为简单、并且生态自闭的Swarm项目远远地甩在了后边。CNCF社区也迅速增加了一系列容器生态的知名工具和项目，大量的公司和初创团队将注意力投向CNCF社区而不再是Docker，CNCF本质上成为了以Kubernetes为核心的生态系统。\n企业服务大厂也纷纷加入Kubernetes平台战局，在公有云或者私有PaaS平台上来发展自己的Kubernetes产品。像微软直接找来Kubernetes联合创始人Brendan Burns负责领导Azure容器服务团队，自身的混合云产品Azure Stack也大力支持Kubernetes。IBM同样也靠以Kubernetes为核心的PaaS软件IBM Cloud Private来抢占企业私有云容器平台市场，尤其是微服务的管理需求。很早就支持Kubernetes的Redhat，在2015年推出的OpenShift 3.0版中，不惜放弃自己的容器调度工具，开始支持Kubernetes，现在更成为了支持跨多云、混合云架构，以及裸机、容器和虚拟机的企业级通用应用管理平台。而虚拟化龙头VMware也改为力推主打通吃多家IaaS和Kubernetes集群管理的容器服务软件，甲骨文也在旗下云端服务支持Kubernetes。\n在用户、社区和大厂的支持中，Kubernetes逐步成为企业基础架构的部署标准和新一代的应用服务层。\n2016年，面对CNCF的竞争优势，Docker公司宣布放弃现有的Swarm项目，将容器编排和集群管理功能转到Docker项目当中。然而这种改变带来的技术复杂度和维护难度，给Docker项目造成了非常不利的局面。不同于Docker，Kubernetes推进的民主化架构从API到容器运行的每一层，都给开发者暴露出了可扩展的插件机制，鼓励用户通过代码的方式介入每一个阶段。Kubernetes的变革非常有效，很快在整个容器社区中催生出了大量的、基于Kubernetes API和扩展接口的二次创新产品，例如前文提到的Istio等等。Docker公司在Kubernetes社区崛起和壮大后，败下阵来。\n2017年，Docker公司将容器运行时部分Containerd捐献给CNCF社区，并在自己主打产品Docker企业版中内置Kubernetes项目，持续了两年的容器编排之争终于落下帷幕，Kubernetes成为了最后的胜利者，而Docker输掉了最关键的一仗，失去了成为云原生时代操作系统的机会。\nDocker在最重要的容器编排之战中失败，带给我们的教训包括：\n 开源不等于免费，开源是一种商业模式，一个开源组织和开源项目要想生存下去，最重要的基础就是普遍被使用，不然很快就会被竞争者替代 开源技术终将走向商业，包括Docker，必然面临企业市场的挑战 Docker进入企业级市场，有优势也有劣势，优势是挟Docker的大量开发者，劣势是没有做过企业级市场，开发者市场和企业级市场的做法完全不同 Docker在竞争中失利，看起来是时机和生态构建的问题，但归根结底是基因和能力问题  此系列文章的前五部分，我们详细介绍了云原生的各种理念和技术。在最后一部分，我们将展开总结和思考，分析云原生时代的机遇与挑战。\n第六部分：机会与思考 上文主要介绍了Kubernetes与容器编排之战，本文的最后一部分将系统性的总结云原生能带给我们什么样的未来，相关的创业和投资机会在哪里。\n每一次IT产业架构的变革都会带来巨大的机遇和行业洗牌的挑战。过去的三四十年间，IT业经历了多次重大的变革，包括20世纪七八十年代从大型机向小型机的转移、九十年代C/S架构的普及，以及21世纪初互联网的兴起，先后造就了IBM、思科、惠普、Oracle、EMC、SAP等巨头企业。\n历次IT技术革命还有个共同特点：无论原有的基础软硬件公司此前有多么牢不可破的垄断地位，一旦不能符合新的IT技术变革的趋势，洗牌在所难免。\n现代云计算的浪潮开始于2000年以后，已经造就了VMware、ServiceNow、Salesforce、Shopify等数百亿美金的明星企业，以及无数的独角兽公司。\n云计算是通过互联网的方式按需交付基础设施（硬件/服务器）、存储、数据库和各种应用服务，通常这些服务是由AWS、Azure等公有云或者私有云平台提供的。\n而云原生是一种理念和架构，用于以针对云环境优化的方式组装上述所有基于云的组件。因此云原生也是一个目的地：对于那些希望实现基础设施和流程现代化，甚至组织文化现代化的企业来说，最终的目标是仔细选择最适合其具体情况的云技术。\n要从云计算中获得最佳效果，需要使用云原生架构；云原生的普及又会促进云计算的加速发展。\n从统计数据和发展趋势来看，云原生被接受的程度和普及速度正在大大加快，例如下图显示，自从2016年以来容器的使用量每年都在快速上升。IDC预计，到2022年90%的应用程序将采用微服务架构和第三方代码，35%的生产应用程序将诞生于云端。由于容器和敏捷方法的采用，预计2018-2023年间将诞生5亿个新应用程序。由数字化转型，以及接受和采用新技术的需求驱动，云原生将更深入地渗透到大型企业组织中。这意味着云原生技术和方法可能会遵循敏捷和DevOps的模式，越来越多地吸引更多的利益相关者，包括管理者和业务线领导人，在未来几年内覆盖一半或更多的组织。\n各种场景容器使用量都在逐步上升\n但目前不是所有的云计算技术和产品都能很好的满足云原生架构分布式、自动化、轻量化的要求，传统的IT基础设施正在受到越来越大的冲击，例如传统集中式数据库正在逐渐被分布式数据库所取代，虚拟机技术受到了容器的巨大冲击，分布式监控系统完全替代了传统的监控产品，而传统的安全产品也远远无法满足云原生安全性的要求。\n还需要注意的是，云原生的概念不仅仅只意味着容器、Kubernetes或Serverless，也为下一项技术留下了足够的空间。\n云原生投资的分层\n对于大多数软件开发组织来说，仍然处于采用微服务和容器的早期阶段。新机遇一方面源自于云原生在各行各业的应用，一方面则是云原生相关新的基础设施。\nCNCF全景图呈现了比较完整的云原生项目和分类，我们可以将其简化成如下图所示的几种大的分类：\n一共分为AppDev \u0026amp; DevOps；Management；Runtimes；Infrastructure and Services；Serverless；Observability；Security八个大的模块。\n从广义的角度来讲，云原生应用的设计、开发、管理、运维、分析与传统应用有非常大的不同，生态的每个环节、技术的每个领域都会有许多机会，例如云原生应用的设计、咨询、开发、培训，需要有方案商、供应商、实施商；在基础设施层面，数据库、开发工具、核心中间件、安全产品等等都会有巨大市场需求，例如Service Mesh+安全、Serverless+安全、容器+安全、多云+安全，例如云原生数据的分析处理，例如云原生架构的灾备管理。\n我个人将云原生的生态分为三层：\n 技术层  技术层包括云原生技术相关的基础设施，主要分为两种类型：\n 原有技术的替代品：例如ETCD取代传统的数据库 全新基础设施：新技术相关产品，例如Istio和OpenFaaS   应用层  应用层主要是云原生在各行业的具体应用。\n 服务层  包括云原生相关的培训、咨询、认证等相关服务。\n下面我重点讲讲技术层和应用层。\n云原生技术层\n下面的表格里代表性的列举了云原生技术层的几个领域及相关项目。\n下图展示了当前这些项目的市场占有率情况。\n可以看到技术层涉及的范围非常广，机会非常多，本文仅展开介绍其中我比较看好的一个领域-云原生安全。\n据CNCF统计，采用容器技术的挑战中，开发团队面临的文化挑战、安全性、复杂性、就绪性和监控分别排在前五位。\n使用容器的挑战\n在云原生架构中，安全问题显得尤其突出的原因有以下几点：\n 快速迁移到云原生架构对企业安全状况和运营产生了深远的影响。在容器、微服务和编排框架的世界中，以持久“状态”运行在“服务器”上的“应用程序”的概念已经过时。现在，该应用程序或服务是一个分布式系统，由多个组件组成，这些组件运行在数量可变的节点上，处于几乎恒定的变化状态。依赖于机器隔离和可预测的系统状态的传统安全控制是无效的。对服务到服务的通信视而不见的安全策略以及缺乏水平可扩展的控件，根本无法跟上当今微服务应用程序的步伐。 随着企业将工作负载从数据中心转移到AWS、Google Cloud Platform和Microsoft Azure，它们已经改变了购买安全性的方式。他们需要独立于平台的安全工具，这样就不会被绑定到特定的云平台中。 复杂系统可以创建大量的警报和事件日志，这会是一项惊人的任务。安全项目被堆积如山的繁忙工作所淹没，分析师们疲惫不堪。随着分析师对惊人的数据量变得不敏感，真正的问题就从他们的手指间溜走了。 DevOps是一种协作方法，它将开发人员和IT操作统一起来，以加快应用程序的构建、测试和部署，它也影响了IT安全。当开发人员可以直接将他们的应用程序部署到生产服务器上，因为业务敏捷性需要它时，他们就不能停下来找出安全问题。DevOps提供了一种完全不同的安全方式，安全自动化有很多机会。  为了在云本机环境中保护业务资产，组织必须将安全实践和技术与它们要保护的系统纳入体系结构中。正如DevOps支持持续开发和部署一样，“DevSecOps”也必须支持持续的安全管道。这意味着要建立全新的方法、功能和工具，以确保旨在保护云原生系统的解决方案呈现以下基本特征：\n 全局的实时可见性：局部的或事后的可见性是不够的。无论位于何处，基础架构层和应用程序都必须可见。 快速、迭代的反馈循环：反馈循环允许安全措施不断适应快速变化的环境。 解决安全问题的工程方法：自动化、连续测量和受控实验将是解决整个企业安全问题的主要方法，取代手动分析和控制更新。  因此，像Netflix、Lyft和Square等组织已经开始将云原生安全作为工程问题来处理，使用自动化来避免这些陷阱，并使安全团队更加有效。他们还规避了将检测、响应和开发团队分开的烟囱式结构，在构建安全检测机制并将它们与响应编排集成时遵循DevOps的思想。\n来自Netflix的安全检测组件示例\nKubernetes官网\n云原生的安全分为4C，即代码、容器、集群、云四个层级。\nCNCF全景图中安全与合规子分类里包含的项目如下图所示。\n像在我多篇文章里曾经提及的新一代云安全公司，市值189亿美金的CrowdStrike，直接将自己定义为云原生的端点保护平台（Cloud-Native Endpoint Protection Platform），以此同传统的端点保护产品区分开来。\n下面我介绍几家和云原生安全相关的初创企业。\n1、Capsule8（B轮）\nCapsule8是一家由经验丰富的黑客和安全企业家创建的高新科技初创型企业，总部位于纽约布鲁克林，成立于2016年秋季，在2018年8月获得1500万美元的B轮融资。\nCapsule8开发了业界第一个也是唯一一个针对Linux的实时0day攻击检测平台，可主动保护用户的Linux基础设施免受攻击。Capsule8实时0day攻击检测平台可显著改善和简化当今基础架构的安全性，同时为未来的容器化环境提供弹性的支持。\n混合云架构已经成为企业IT基础设施的重要架构，但其复杂性也使企业面临多种攻击的风险，根据Capsule8与ESG Research赞助的一项新研究表明，仅2017一年就有42%的企业报告了混合云环境受到攻击，28%的企业表示0day攻击是这些攻击的起源。\n混合云环境由于存在多云服务商，缺乏中心控制和完整的合规性规划，存在边界模糊，访问策略不一致等问题，加上公有云的暴露面增大，攻击者容易通过攻击薄弱点进入，这也是近年来如软件定义边界SDP、移动目标防护MTD等新方案兴起的原因。\n无论是传统环境，还是混合环境，防护利用0day漏洞的高级威胁需要企业安全团队全方位持续防护资产、获得环境的可视性，检测恶意行为。\nCapsules8平台整体架构图如下所示：\n假设客户生产环境是一个混合云环境，服务器部署于客户侧数据中心、公有云AWS和Azure中。Capsule8的整个工作流程主要分为感知、检测、阻断、调查四步。\n2、Aqua Security（C轮）\nAqua Security成立于2015年，它为基于容器、Serverless和云原生应用提供保护解决方案。2019年，Aqua Security完成了6200万美金的C轮融资，累计融资超过1亿美元。它的客户包括能源、航空航天、互联网、媒体、旅游、零售、制药和酒店业的100多家知名企业。\nAqua Security的云原生安全平台使用现代化的零接触方法来检测和预防威胁，在整个应用程序生命周期内提供全面的可见性和安全自动化。例如在漏洞管理方面，Aqua可以实现：\n扫描镜像和功能：Aqua几乎与所有CI/CD工具集成在一起，可在构建镜像和功能时主动扫描，及早发现问题并允许快速修复。\n关注应用风险：下一个挑战是大规模提供安全性。这种情况是指可能要扫描成千上万个镜像的漏洞。但是，其中许多镜像实际上并未在生产中部署，因此即使处于脆弱状态风险也不高。Aqua提供了对正在运行的工作负载中易受攻击组件的实例化的可见性，这使安全团队可以集中精力修复最容易遭受利用风险的那些组件。\n提供可行建议：Aqua提供了有关漏洞的具体可行建议，通常是建议升级到特定的版本或者改变配置和环境变量。\n3、Twistlock（被收购）\n位于CNCF全景图里的Twistlock创立于2015年。曾经在以色列著名的网安黄埔8200部队服役，并在微软企业安全部门工作的Ben Bernstein以不到30万美元的种子轮开始起家，定位容器安全。Twistlock自己贴的标签除了容器安全，就是云原生安全。Twistlock的融资节奏很好，2015年5月天使轮280万美元，2016年7月A轮1000万美元，2017年4月B轮1700万美元，2018年8月C轮3300万美元，2019年就被Palo Alto Networks以4.1亿美金的价格收购。\nTwistlock产品界面\n现在，Twistlock已经能为Amazon ECS、Azure、Docker、GCP、Pivotal、OpenShift、Istio等多个平台提供安全方案。Twistlock的自己一句话介绍是“领先的全栈，全生命周期容器安全解决方案，保护容器环境及其中运行的应用程序，具有轻量级，可扩展和自动化特性，自动化的策略构建和全开发生命周期内的无缝集成”。\n截至目前，Twistlock总结了6方面的核心能力，分别是漏洞管理、合规、运行时防护、持续集成和持续交付、云原生防火墙和访问控制。像运行时防护包括网络和应用程序防火墙，支持Docker和AWS Fargate运行安全以及主机防护，可以通过机器学习为每个应用程序进行自动建模，保护网络，文件系统，进程和系统调用。云原生防火墙方面，Twistlock包括3层防火墙和7层防火墙，它可以自动学习应用程序的网络拓扑，并为所有微服务提供应用程序的微分段，可以检测和阻止XSS攻击、SQL注入等威胁，还可以自动模拟所有微服务之间的所有流量，并允许安全团队集中查看和实施安全流量，同时自动阻止异常，无需手动创建和管理规则。\n除了云原生安全领域，以及前文介绍过的Kong、RapidAPI之外，我再介绍三家知名的云原生技术层创业企业。\n1、Rancher（D轮）\n在本文第一部分我们提过Rancher（中文意思是放牧人）这家公司，它的创始人梁胜职业生涯贯穿软件开发与云计算的发展历史。作为耶鲁大学计算机博士、Java语言J2SE平台核心组件JNI的作者、JVM的领导设计与开发者，梁胜2000年离开Sun创办了应用防火墙软件公司Teros Networks并担任CTO，2001年公司被Citrix收购。2008年梁胜第二次创业创建了Cloud.com，并推出了著名的云计算管理软件CloudStack，他也因此被誉为“CloudStack之父”，2011年Cloud.com被Citrix又以2亿美金收购，他成为Citrix首位华人CTO。随后2014年梁胜创立了容器管理公司Rancher Labs。这是他创建公司的初衷。\nRancher是一个容器管理平台，通过Rancher可以实现Docker和Kubernetes的轻松部署。Rancher由基础设施编排、容器编排与调度、应用商店、企业级权限管理组成。下图展示了Rancher的主要组件和功能。\n今年3月份，Rancher对外公布了4000万美元的D轮融资，由此Rancher累计融资高达9500万美元。\n2、HashiCorp（E轮）\nHashiCorp（简称为Hashi，日语“桥梁”的含义）是我一直非常看好的一家云原生技术企业，不过最近因为禁止中国企业使用其商业产品而被刷屏。它成立于2012年，主要开发DevOps和云管理基础设施相关产品，日裔创始人及CTO Mitchell Hashimoto从12岁就开始创业，目前年仅30岁，公司主要产品都出自于他的手笔。\nHashiCorp旗下包含多款知名的云原生相关开源产品，我们自上而下的来看：\n Nomad：程序自动化，集群管理器和调度器，专为微服务和批量处理工作流设计。与Kubernetes相比，Nomad通用性更强。 Vault：安全自动化，企业级私密信息管理工具。 Terraform：基础架构自动化，安全有效地构建、更改和版本控制基础设施的工具。 Packer：镜像工具，旨在通过简易的方式自动化构建镜像。 Vagrant：用于创建和部署虚拟化开发环境的工具，由Mitchell Hashimoto在23岁时开发，并成为其创建HashiCorp的基石。 Consul：网络自动化、服务网格解决方案，它提供了一个功能齐全的控制平面，主要功能包括服务发现、健康检查、键值存储、安全服务通信、多数据中心等等。  今年3月HashiCorp对外公布了1.75亿美元的E轮融资，投后估值为51亿美元。\n3、Snowflake（G轮）\nSnowflake成立于2012年，创始人Bob Muglia曾在微软工作23年，拥有丰富的数据库经验。Bob Muglia认为，NoSQL型数据库并不能完全适应业务要求，基于云端的数据仓库省去了相关软硬件的设置需要，降低了使用门槛。Snowflake包括数据引擎在内的几乎所有技术都是自己研发的，在数据库和数据处理方面拥有非常多的专利，它是一个云原生的SQL数据仓库，完全针对云计算特点设计，部署在AWS等云端平台上，可以将用户所有的数据集中在一个地方，用户只需加载数据然后运行查询就可以查找到各种结构化或半结构化的数据。\n为什么要使用云原生数据仓库？\n作为一个类别，云原生的数据仓库提供了许多好处。首先，它们使公司摆脱了对设备和机器的担忧：在过去的物理服务器时代，公司需要操心服务器机房，或者至少是运行软件或存储数据的特定机器。构建这个物理基础设施是启动或扩展软件公司的一个巨大障碍。现在，服务器成本要低得多，只需点击几下鼠标就可以创建云端数据仓库。公司只需要按需处理和存储数据，并为他们使用的东西付费。云的使用还可以为公司提供更多的冗余和支持，因为他们不再需要担心单个服务器的故障和整个操作的崩溃。大型云服务提供商拥有多个备份系统，可以在全球数据中心之间自动扩展，以保持一切正常运行。这对客户公司来说是双赢的。\n作为一个基于云的数据仓库，Snowflake具有很强的灵活性和可伸缩性。Snowflake基于订阅的模型将存储和计算服务分离，允许它们独立运行。当用户构建插入Snowflake的新解决方案时，他们只支付存储数据或根据需要分析数据的费用。此外，该系统还构建了一个相互连接的云服务器阵列，将数据分散，允许组织内的单个用户或组访问他们需要的特定数据，而无需复杂的数据传输，简化了连接和分析。\n对于云原生数据仓库来说，能够在不影响底层的情况下快速查询数据并使用实时数据执行分析是一个强大的功能。由于数据不断地被各种各样的系统所创建，其中许多系统最初都是云端固有的，因此实时分析这些数据的能力对现代公司至关重要。实时分析会根据需要，只对特定实例和项目收费而不产生更高的成本。\nSnowflake在今年2月份完成了4.79亿美元的G轮融资，估值高达124亿美元，投资机构包括Salesforce Ventures，Snowflake还由此宣布了与Salesforce的战略合作伙伴关系。Snowflake在《福布斯》最新的“云100强”榜单中位列第二，仅次于Stripe。\n云原生技术层的机会我还在《信天研报 | 虚拟化与超融合（一）》系列里提到过，由于容器技术对于传统虚拟机的冲击，众多创业公司正在解构VMware，这将在该系列详细讨论。\n云原生应用层\n云原生能广泛应用在所有的行业，并发挥其快速、灵活、弹性、扩展性强、迁移能力强等多种优势。在这里我仅抛砖引玉，分析下云原生游戏的优点。\n围绕云游戏的许多讨论都集中在其“杀死控制台”的潜力上，从而消除了本地硬件玩游戏的需求。但是，对硬件的持续关注未能抓住云游戏的真正潜力。云游戏的真正创新不仅仅在于我们怎么玩游戏方式，还在于我们玩什么游戏：“云原生”游戏将完全颠覆游戏体验本身，以及这些游戏的销售和销售方式。\n云原生游戏是专门为云开发的游戏，其中客户端和服务器托管在同一架构中，有可能产生全新的游戏体验和商业模式。\n病毒式传播\n大多数MMO（Massively Multiplayer Online，大型多人在线）游戏具有固有的网络效应，这意味着与更多玩家一起玩游戏会更加有趣。然而，MMO通常会遇到冷启动问题：一开始，没有足够的参与者来创造积极的体验，从而导致新用户的流失。与朋友合作玩耍是最好的招募和留住新用户的方式，但是在此过程中可能会遇到很多障碍。例如，用户可以在不同时间或在不同平台上玩。由于不透明的配对规则和服务器限制，在游戏中寻找朋友可能很麻烦。\n利用云原生开发的MMO游戏本质上是跨平台的，因此可以从任何设备上访问。没有下载、安装，或者加载时间，用户不用再为了补丁或者一个游戏的副本需要等待三个小时。\n为了简化入门过程，云原生游戏可以使用深层链接来无缝地允许新玩家加入朋友的游戏会话。同时，想要获得更轻松体验的用户可以实时选择确切的时点来参加比赛或作为旁观者。\n这些支持云的功能共同加速了多人游戏固有的网络效果。如果成功的话，第一个云原生MMO游戏可能会完全通过玩家主导的招募而快速发展，其病毒增长曲线比传统的MMO更类似于Facebook。\n创造视频营销机会\n除了更强大的病毒性之外，云原生游戏还将为AAA（3A大作，高成本、高体量、高质量）游戏提供新的营销形式。传统上AAA游戏依赖于广告牌和展示广告等营销方式。在没有安装时间的情况下，潜在玩家将能够单击链接立即尝试一款游戏—这是一个巨大的进步。\n随着云游戏的普及，视频和有影响力的营销将变得越来越重要。销售佣金和“点击加入”可能会成为云游戏经济中网络大V收入的最大来源。\n实现AI驱动的实时内容生成\n由于客户端和服务器在同一个网络中，云原生游戏可以方便的跟踪和收集用户旅程中几乎所有的数据，这使得我们可以以开创性的方式在游戏中增强人工智能和机器学习能力。\n例如，游戏长期以来通过出售改变玩家外观或周围世界的化妆品来赚钱。由于云提供无限的数据、处理能力和最小的客户端-服务器延迟，人工智能可以实时生成完全动态的环境。以下是基于Nvidia深度学习系统的剪辑，显示用户在AI的帮助下修改了一个逼真的虚拟环境：\n将来，实时内容生成可能会催生新的、沉浸式的故事讲述方法。下一代的“选择你自己的冒险”可能是一个虚拟世界，实时适应你的选择。为了使这些虚拟世界货币化、个性化，自发性的广告可能会出现，类似于《少数派报告》中的生物识别广告。\n更远的未来，AI驱动、程序生成的世界可以为用户提供一个无尽的游乐场，那时距离《头号玩家》里的绿洲世界或者著名的网络世界-元界（Metaverse）已经不远。\n预计我们将在两三年内看到第一款云原生游戏上市，在谷歌、微软、亚马逊和其他许多公司的投资推动下，下一代云原生游戏将有潜力重塑我们所知道的游戏体验。\n在上述认知的推动下，A16Z、腾讯、淡马锡投资了免费沙盒MMO游戏Roblox的1.5亿美金的G轮，相应估值高达40亿美元，他们认为未来游戏将不再只是游戏，甚至将比电影和音乐加在一起的规模还大。游戏的发展也将推动技术革新，而Roblox作为世界上最大的社交平台和多人游戏平台之一，接下来将有望成为未来的Metaverse。\n写在最后\n至此，这篇接近4万字的《云原生时代》已接近尾声。\n我们再来梳理下本文的核心观点：\n 云原生、中台、微服务、CI/CD、Devops、SaaS背后的理念是一致的 即更快速、更灵活、更轻量、更自动，从开发开始，不断实现企业的产品目标和业务目标 类似理念涉及的维度包括开发、产品、运维、销售，从产品、服务到组织结构  如何判断云原生技术层的项目？\n 是否拥有核心技术是关键 单点产品的价值和延展性要足够强。参照Rancher、HashiCorp、Kong 面向客户提供一整套产品化的解决方案具有更大价值 在云原生体系里，开源项目比普通商业项目更占优势。开源项目更容易被其它产品支持和集成；云原生架构早期使用者以开发者为主，开源项目更容易快速建立口碑和影响力；在社区支持下，开源项目质量更容易得到保证 尽量选择成熟和被市场验证的技术和产品  国内的创业机会是否已经到来？\n国内已经出现了像PingCap、Kylin、SkyWalking、Dubbo、ServiceComb等优秀的开源项目，在云原生技术不断成熟和普及、国内开源文化和社区逐渐兴起、去IOE和自主可控的时代背景下，国内对标海外的创业机会将会不断涌现。不过由于国内企业IT水平参差不齐，像API集成、API管理等领域的创业时机尚早，所以选择合适的产品切入点和行业将成为成败的关键，另外团队对软件本质的理解、销售和客户服务能力也是相当重要的因素。\n最后，我真心希望未来3到5年中国新一代的基础软件企业能够高举国产化的大旗，灯火辉煌。\n参考  绿盟科技解读2019创新沙盒 被Palo Alto 4.1亿美元收购的Twistlock是一家什么公司？ DETECTION ENGINEERING FOR CLOUD-NATIVE SECURITY 一文搞懂蓝绿发布、灰度发布和滚动发布 深入剖析Kubernetes学习笔记：“控制器”模型（16） 技术专栏 | 云原生应用之路 极简Docker和Kubernetes发展史 Docker生态到底会不会重蹈Hadoop的覆辙 金丝雀发布、滚动发布、蓝绿发布到底有什么差别？关键点是什么？ 15 Most Interesting Cloud Native Trends From The CNCF Survey 10分钟看懂Docker和K8S 极简Docker和Kubernetes发展史 “中台不就是微服务吗？有啥区别？” 火热的云原生到底是什么？一文了解云原生四要素！ 大神告诉你如何理解微服务框架 Service Mesh 和 API Gateway 关系深度探讨 一文详解微服务架构 Martin Fowler关于微服务的原文翻译（一） 微服务架构的理论基础 - 康威定律 A text interpretation of the cloud native (rpm) 走访了十几家美国企业服务公司，我们写下了这篇万字文章 | GGV投资笔记第一期 从Uber微服务看最佳实践如何炼成？ Mashape 和 RapidAPI 合并，组成全球最大的应用编程接口（API）集市！ 放弃微服务，改用宏服务，Uber 这波什么操作？ 腾讯大牛深入浅出详解云原生 【零壹视界】从Salesforce收购Mulesoft说起，白话讲讲企业数据交换  EnjoyingSoft之Mule ESB开发教程第一篇：初识Mule ESB 微服务架构 持续集成、持续交付、持续部署 为什么你必须了解云原生？！  What is Cloud-Native? Is It Hype or The Future of Software Development?   本文转载自：蒋宇捷的企业服务投资洞察。\n 云原生时代（一）云原生及CNCF基金会 云原生时代（二）：DevOps与CI/CD 云原生时代（三）：微服务、API管理与集成 云原生时代（四）：容器和Docker 云原生时代（五）：Kubernetes与容器编排之战 云原生时代（六）：机会与思考  ","permalink":"https://cloudnative.to/blog/cloud-native-era/","tags":["Cloud Native"],"title":"云原生时代——投资人视角下的云原生趋势思考"},{"categories":["Kubernetes"],"contents":"前言 这个问题 flannel 和 calico 的 VXLAN 模式下都会发生，部分人的集群的A记录 UDP 下查询可能有问题。原因是 v1.17+ 的 kubernetes 某部分会引起内核的某个 UDP 相关的 BUG 而不是 CNI 的软件层面， WEAVE 没有这个问题，原因后面会说到。写这篇文章的日期是05/28，最开始发现是上周五也就是05/23号，文章从时间线写起，因为很多时候想发文章但是没空。\n由来 上周五我经过同事的工位看到同事的桌面是 kubectl get po 的输出，问他咋开始学 Kubernetes 了，他说跟着视频学下。看了下用的 kubeadm 部署了一套1.18.2的集群。1.18的 kube-proxy 的 ipvs 包的 parseIP 有 bug ，我推荐他换v1.17.5。他当时在部署一个入门的 SVC 实验，无法解析域名。使用dig命令排查了下，下面是对照:\n dig @\u0026lt;podIP\u0026gt; +short kubernetes.default.svc.cluster.local 能解析 dig @10.96.0.10 +short kubernetes.default.svc.cluster.local 超时  很多市面上的kubeadm部署教程都是直接命令 kubeadm init 的，所以我推荐同事去按照我文章的 kubeadm部署 一套后再试试，叫他用v1.17的最新版本v1.17.5，结果还是上面一样。 coredns 实际上还有 metrics 的 http 接口，从 http 层测了下：\n curl -I 10.96.0.10:9153/metrics 超时，很久之后才有返回 curl -I \u0026lt;podIP\u0026gt;:9153/metrics 能直接返回  涉及到本次排查的信息为：\n$ kubectl get node -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME master Ready master 7d8h v1.18.2 10.0.100.3 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 node1 Ready \u0026lt;none\u0026gt; 7d7h v1.18.2 10.0.100.4 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 node2 Ready \u0026lt;none\u0026gt; 7d7h v1.18.2 10.0.100.15 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 $ kubectl get po -o wide -n kube-system -l k8s-app=kube-dns NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-546565776c-v5wwg 1/1 Running 2 25h 10.244.2.73 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 多次尝试发现很久的时间都是一样，用 time 命令观察了下一直是63秒返回。包括其他任何 SVC 都是这样。\n$ time curl -I 10.96.0.10:9153/metrics HTTP/1.1 200 OK Content-Type: text/plain; version=0.0.4; charset=utf-8 Date: Wed, 25 May 2020 08:39:35 GMT real\t1m3.091s user\t0m0.002s sys\t0m0.007s proxyMode 是 ipvs ，用 ipvsadm 看下超时的时候的状态，一直是SYN_RECV，也就是发送了 SYN ，没收到回包。\n$ ipvsadm -lnc |\u0026amp; grep 9153 TCP 00:59 SYN_RECV 10.96.0.10:41282 10.96.0.10:9153 10.244.2.73:9153 抓包 因为 CNI 使用的 flannel ，用的 VXLAN 模式。master 上抓9153和flannel.1的 8472 端口，coredns 的 POD 所在 node 上抓 flannel 的 VXLAN 包，下面三个是对应的:\n[root@master /root]# tcpdump -nn -i flannel.1 port 9153 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes 16:30:56.705696 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17148909 ecr 0,nop,wscale 7], length 0 16:30:57.708489 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17149912 ecr 0,nop,wscale 7], length 0 16:30:59.712458 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17151916 ecr 0,nop,wscale 7], length 0 16:31:03.716441 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17155920 ecr 0,nop,wscale 7], length 0 16:31:11.732562 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17163936 ecr 0,nop,wscale 7], length 0 16:31:27.764498 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17179968 ecr 0,nop,wscale 7], length 0 16:31:59.828493 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.829565 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.829611 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.829714 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.829897 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.831300 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.831322 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.831435 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.831633 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.831660 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 [root@master /root]# tcpdump -nn -i eth0 port 8472 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 16:30:56.705718 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17148909 ecr 0,nop,wscale 7], length 0 16:30:57.708523 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17149912 ecr 0,nop,wscale 7], length 0 16:30:59.712478 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17151916 ecr 0,nop,wscale 7], length 0 16:31:03.716452 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17155920 ecr 0,nop,wscale 7], length 0 16:31:11.732590 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17163936 ecr 0,nop,wscale 7], length 0 16:31:27.764513 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17179968 ecr 0,nop,wscale 7], length 0 16:31:59.828541 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.829521 IP 10.0.100.15.56771 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.829617 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.829729 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.829883 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.831292 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.831327 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.831448 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.831612 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.831665 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 [root@node2 /root]# tcpdump -nn -i eth0 port 8472 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 16:31:59.836137 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.836328 IP 10.0.100.15.56771 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.836811 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.836910 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.836951 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.838385 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.838522 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.838621 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.838703 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.838836 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 先看上面的第一部分，搜了下资料，得知 TCP 默认 SYN 报文最大 retry 5次，每次超时了翻倍，1s -\u0026gt; 3s -\u0026gt; 7s -\u0026gt; 15s -\u0026gt; 31s -\u0026gt; 63s。只有63秒的时候 node 的机器上才收到了 VXLAN 的报文。说明 POD 所在 node 压根没收到63秒之前的。\n一般 LVS 的 dr 模式下 TCP 的时间戳混乱或者其他几个 ARP 的内核参数不对下 SYN 是一直收不到的而不是63秒后有结果，所以和内核相关参数无关。于是同样上面的步骤 tcpdump 抓包，加上-w filename.pcap选项把抓的包导出下来导入到 wireshark 里准备看看。\n报文分析 9153的包 wireshark 里看63秒前面都是 TCP 的 SYN 重传，看到了 master 上向外发送的 VXLAN 报文的时候有了发现。\n可以看到 UDP 的 checksum 是0xffff，我对 UDP 报文不太熟悉， UDP 的 header 的 Checksum 没记错的话CRC32校验的，不可能是这种两个字节都置1的 0xffff ，明显就是 UDP 的 header 的校验出错了。后面几个正常包的 Checksum 都是 missing 的。\nwireshark 的编辑-\u0026gt;首选项-\u0026gt;Protocols-\u0026gt;UDP-\u0026gt;Validate the UDP checksum if possible 勾上更直观看。\n不是根本的解决方法 搜了下wireshark linux udp checksum incorrect，都是推荐把 Checksum Offload disable 掉就行了，例如我这里是 flannel ，则是：\n$ /sbin/ethtool -K flannel.1 tx-checksum-ip-generic off Actual changes: tx-checksumming: off tx-checksum-ip-generic: off tcp-segmentation-offload: off tx-tcp-segmentation: off [requested on] tx-tcp-ecn-segmentation: off [requested on] tx-tcp6-segmentation: off [requested on] tx-tcp-mangleid-segmentation: off [requested on] udp-fragmentation-offload: off [requested on] 再测下正常，而 WEAVE 他们也用的 VXLAN 模式，但是他们在创建网卡的时候把这个已经 off 掉了，所以 WEAVE 的 VXLAN 模式在v1.17+集群没出现这个问题。\n$ time curl -I 10.96.0.10:9153 HTTP/1.1 404 Not Found Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff Date: Wed, 27 May 2020 02:14:04 GMT Content-Length: 19 real\t0m0.009s user\t0m0.005s sys\t0m0.003s 你以为这样就完了？其实并没有，因为我自己维护了一套 ansible 部署 kubernetes 的方案，每次新版本发布我都会实际测下。并且同事反映了他同样云主机开出来用我 ansible 部署v1.17.5没有这个问题。这就很奇怪了，原因后面说，请接着继续看。\n什么是checksum offload Checksum Offload 是网卡的一个功能选项。如果该选项开启，则网卡层面会计算需要发送或者接收到的消息的校验和，从而节省 CPU 的计算开销。此时，在需要发送的消息到达网卡前，系统会在报头的校验和字段填充一个随机值。但是，尽管校验和卸载能够降低 CPU 的计算开销，但受到计算能力的限制，某些环境下的一些网络卡计算速度不如主频超过 400MHz 的 CPU 快。\n正文 对照组 很奇怪的就是为啥就是我的 ansible 部署的二进制就正常没这个问题，而 kubeadm 部署的就不正常，后面我花时间整了以下几个对照组(期间同事也帮我做了几个条件下的测试，但是不是系统用错了就是版本整错了。。。)，终于找到了问题的范围，下面是我自己统计的对照组信息， kubeadm 和 ansible 版本均为1.17.5测试。os 不重要，因为最终排查出和 os 无关：\n   os type(kubeadm or ansible) flannel version flannel is running in pod? will 63 sec delay?     7.6 kubeadm v0.11.0 yes yes   7.6 kubeadm v0.12.0 yes yes   7.6 kubeadm v0.11.0 no yes   7.6 kubeadm v0.12.0 no yes   7.6 ansible v0.11.0 yes no   7.6 ansible v0.12.0 yes no   7.6 ansible v0.11.0 no no   7.6 ansible v0.12.0 no no    这就看起来很迷了。但是排查出和 flannel 无关，感觉 kube-proxy 有关系，然后今天05/28针对 kube-proxy 做了个对照组：\n   os type(kubeadm or ansible) kube-proxy version kube-proxy is running in pod? will 63 sec delay?     7.6 kubeadm v1.17.5 yes yes   7.6 kubeadm v1.17.5 no no   7.6 kubeadm v1.16.9 yes no   7.6 kubeadm v1.16.9 no no   7.6 ansible v1.17.5 yes yes   7.6 ansible v1.17.5 no no    可以看出就是1.17以上的 kube-proxy 如果使用 POD 则会有这个问题，而非 POD 则不会， 在github 上 compare 了下v1.17.0和v1.16.3。\n发现了 Dockerfile的改动 ， 1.17.0里的 Dockerfile 的BASEIMAGE是用 指定了一个源安装了最新的iptables，然后利用update-alternatives把脚本/usr/sbin/iptables-wrapper去替代iptables 来检测应该使用nft还是legacy， hack 下镜像回自带源里的 iptables 验证下。\nFROMregistry.aliyuncs.com/google_containers/kube-proxy:v1.17.5RUN rm -f /usr/sbin/iptables \u0026amp;\u0026amp;  clean-install iptables构建的镜像推送到了 dockerhub 上zhangguanzhang/hack-kube-proxy:v1.17.5，更改下集群 kube-proxy ds 的镜像。\n$ kubectl -n kube-system get ds kube-proxy -o yaml | grep image: image: zhangguanzhang/hack-kube-proxy:v1.17.5 测试访问成功。\n$ time curl -I 10.96.0.10:9153 HTTP/1.1 404 Not Found Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff Date: Thu, 28 May 2020 04:47:21 GMT Content-Length: 19 real\t0m0.008s user\t0m0.003s sys\t0m0.003s 对于这个问题我在 flannel 的 pr 下面也参与了回复，同时在官方 github 上提了一个 issue。\n这个问题的触发是由于v1.17+的 kube-proxy 的 docker 镜像里安装了最新的 iptables ， --random-fully选项会触发内核vxlan的bug。\n总结 目前解决问题三种办法:\n 关闭 CNI 的 VXLAN 网卡的 checksum offload 更改 Docker 镜像 升级到新内核，具体版本就不知道了，只要在这个 内核pr 合并后出的内核版本都行，有人说这些可以 Stable kernels 5.6.13, 5.4.41, 4.19.123, 4.14.181 and later have the checksum patch included.  参考链接  TCP超时重传定时器梳理 wireshark文档 offloading  ","permalink":"https://cloudnative.to/blog/kubernetes-1-17-vxlan-63s-delay/","tags":["tcpdump","vxlan","wireshark"],"title":"Kubernetes v1.17+ 集群下 CNI 使用 VXLAN 模式 SVC 有 63 秒延迟的触发原因定位"},{"categories":["OAM"],"contents":" OAM和Crossplane社区共同致力于建设一个聚焦在标准化的应用和基础设施上的开放社区。\n 前言 在2020年三月份，在来自Crossplane社区的协作和巨大贡献下，开放应用模型（即OAM）项目发布了其v1alpha2规范，旨在为OAM本身和任何采用OAM的Kubernetes应用平台带来绝佳的可扩展性。在2020年5月份，随着Crossplane最新的v0.11版本发布，Crossplane现在具备了OAM规范的标准实现。我们十分激动看到两个社区间的合作，合作将标准的应用和基础设施定义与实施一起带入了云原生社区。\n旅程的开始 从Kubernetes工程师的角度来说，我们很接受现在的Kubernetes抽象层级：容器和基础设施API资源。但是对于平台的终端用户而言还是太过底层。\n为了在一定程度上提高终端用户的体验，一些团队试图通过引入PaaS或者GUI来向终端用户隐藏Kubernetes API。初看上去，这似乎是一个好主意。但事实上，这极大的限制了平台的能力。Kubernetes资源模型强调系统的所有能力都要能够可以表达成\u0026quot;数据\u0026rdquo;，例如API对象。向终端用户隐藏这些对象本质上会使得你的PaaS缺乏可扩展性，因而无法利用在生态圈中数不胜数的插件的能力。\n带着我们必须使平台构建者能够定义应用级别的抽象而不引入对平台可扩展性限制的理念，我们开始探索这个领域。\n建模你的应用，而不仅仅是描述 因为我们要定义应用级别的抽象，那么第一个问题就是：什么是应用？ 一个现代应用通常是若干部分的组合(如上图所示)。这样的模式广泛存在于现实世界：多层应用，机器学习训练应用（参数服务器和工作节点），更不用提微服务架构。但是经常被遗忘的是，这些应用的组件经常需要绑定一系列的运行策略。另外，分组策略也是一个特殊类型的运行策略。例如，我们需要在一个组内设置多个组件的安全组。\n因此直观的方法是使用CRD作为描述应用的高级抽象。并且这样可以与应用运行所需的所有其他部分（如运行策略、基础设施）一起合并成一个YAML文件，如下：\n上面的这个例子其实就是阿里巴巴“应用”定义的1.0版本。可以想象，开发人员会抱怨这样的“应用”太过于复杂，尽管它的初衷是使他们的生活更加简单。同样的，我们发现维护这个对象十分的混乱，并且基本上不可能扩展。更糟糕的是，越来越多的能力被安装到我们的Kubernetes集群中，这些都需要加进这个对象——Kubernetes社区发展的十分迅速！\n事实上，如果你仔细检查上述YAML文件，会发现开发者真正关心的只是运行他们应用的定义里的一些较小片段，如\u0026quot;commands\u0026quot;和\u0026quot;package\u0026rdquo;。\n因此为何我们不把这个YAML分解成多个片段呢？开发人员只需要根据他们自己掌握的部分定义\u0026quot;运行什么(what to run)\u0026quot;，运维人员（或者系统管理员）定义运行策略，基础设施运维人员处理基础设施部分。\n在接触了社区中的各个公司之后，我们发现“关注点分离”的想法与微软的团队非常契合。在与微软经过了数周的合作之后，我们定义了如下的顶层草图：\n看到了吗？与all-in-one式的CRD把所有东西揉在一起不同的是，OAM的核心思想本质上是一个\u0026quot;框架（frame）\u0026quot;。因此，开发人员和运维人员可以在整个应用表单的“空格”里填充他们自己片段的数据。这种灵活性保证了任何平台都可以采用这个定义而不会受限于特定的工作负载和能力类型，并且这个系统可以支持任何工作负载（容器、函数、甚至虚拟机）与运行能力（例如autoscaling、ingress、security policy)。\n我们称这种方法为“应用模型”，因为当一个用户需要组合多个片段为一个应用时需要遵循这个规范，他们需要去思考哪些空白需要去填充，例如是否是描述“运行什么”？或者是否是运行策略？这个过程和数学建模十分类似，数学建模使用数学概念和语言来描述系统。我们现在使用OAM概念来描述应用的不同部分。好处是现在平台可以理解这些不同片段的类别，这样可以保证片段的拓扑，或是检查运行策略的兼容性——可发现性和可管理性是现代产品级应用平台的核心。\n我们最终将这个理念发布为OAM spec v1alpha1\nCrossplane + OAM：构建Kubernetes之上的现代应用 OAM spec v1alpha1在阿里云的企业级分布式应用服务（EDAS）以及内部平台上得到了快速采用。然而，我们同样发现了一个在\u0026quot;运行什么\u0026quot;片段中的问题(之前称之为ComponentSchematic)，我们需要发布新版本的ComponentSchematic来进行YAML中的任何修改。这是因为它被设计成了一个模式（schematic）对象，因此开发者可以定义他们需要部署的任何工作负载并与他人分享。一个类似的问题同样存在于运行策略部分（我们称之为\u0026quot;traits\u0026rdquo;）——它的模式同样将schematic暴露给了终端用户。\n在12月份举行的KubeCon北美大会上，我们会见了来自Upbound.io的Crossplane维护者。我们讨论了OAM，以及如何通过利用CRD作为模式(CRD as schemas)的方法将OAM规范与Crossplane无缝集成。我们都认为这个方向是有希望的，在经过了数月的头脑风暴，提案以及无数次的激烈讨论之后，这个想法最终演进成为了如下的OAM spec v1alpha2:\nOAM spec v1alpha2采用了Kubernetes资源模型，因此Kubernetes中的任何数据片段都可以通过简单的定义一个WorkloadDefinition或者TraitDefinition来无缝引用为一个OAM中的工作负载或者特征(trait)。一个关于OAM spec v1alpha2的更深入的博客即将发布，这里可以先看看一个详细的说明。\n在实现方面，我们开发了一个基于Go的实现版本，称之为oam-kubernetes-runtime，作为Crossplane的一部分。现在我们有一个用于OAM的标准Kubernetes运行时。\n组合：完成整个图景 就像你可能看到的，我们仍然缺乏关于OAM的一个部分：我们如何定义组件依赖的基础设施片段，例如，一个来自阿里云MySQL数据库实例（RDS）？如何使这个定义适用于不同的云，就像OAM组件那样。\n在Kubernetes中定义这样应用中心的和可移植的基础设施绝非易事，社区中有一些operator和产品来做这个事情，但是没有像Crossplane中的Composition那样好。Composition组合多个基础设施片段，然后将其发布到与平台无关的CRD中，例如组合CRD来将VPC与RDS描述为一个新的数据库CRD。这个CRD，可以在之后引用为一个OAM的WorkloadDefinition并且成为一个应用的一部分。搞定！\n组合的结果十分的有力，以团队为中心的平台，可以让基础设施运维人员为应用定义和组合供应商无关的基础设施，并且可以使应用开发人员和应用运维人员以OAM的方式定义，运行和管理可移植的应用，不用再关心基础设施的复杂性。基础设施运维人员现在可以管理运行这些应用的基础设施。OAM和Crossplane一起提供了面向应用开发者和基础设施运维人员的优雅的解决方案。\n下一步？ OAM的核心理念是让开发人员描述自己的应用，使应用可以运行在一个无服务器平台，或者在一个本地的Kubernetes集群而无需修改应用的描述。这是阿里巴巴和微软一直在努力的云边协同（cloud/edge consistency）故事的一部分。很明显，与Crossplane的合作弥补了这个故事真正实现所缺失的重要部分，那就是在一个系统中同时涵盖统一的应用定义和基础设施定义。我们将继续努力使Crossplane成为OAM的标准Kubernetes实现，并且具有更好的工作负载/特征可移植性，互操作性，丰富的运行能力；构建一个聚焦于标准应用和基础设施的开放社区。\n（原文地址：OAM and Crossplane: The Next Stage for Building Modern Application）\n","permalink":"https://cloudnative.to/blog/oam-crossplane/","tags":["OAM","Microservices","Crossplane"],"title":"OAM和Crossplane: 构建现代应用的下一个阶段"},{"categories":["Istio"],"contents":"在上一篇文章一文带你彻底厘清 Kubernetes 中的证书工作机制中，我们介绍了 Kubernetes 中证书的工作机制。在这篇文章中，我们继续探讨 Istio 是如何使用证书来实现网格中服务的身份认证和安全通信的。\n本文是对 Istio 认证工作机制的深度分析，假设读者已经了解 Service Mesh 以及 Istio 的相关基础概念，因此在本文对此类基础概念不再解释。对于 Istio 不熟悉的读者，建议先阅读 Istio 官方网站上的的这篇基础介绍 What is Istio?。\nIstio 安全架构 Istio 为微服务提供了无侵入，可插拔的安全框架。应用不需要修改代码，就可以利用 Istio 提供的双向 TLS 认证实现服务身份认证，并基于服务身份信息提供细粒度的访问控制。Istio 安全的高层架构如下图所示：\n图1. Istio Security Architecture，图片来源istio.io\n图中展示了 Istio 中的服务认证和授权两部分内容。让我们暂时忽略掉授权部分，先关注认证部分。服务认证是通过控制面和数据面一起实现的：\n 控制面：Istiod 中实现了一个 CA （Certificate Authority，证书机构） 服务器。该 CA 服务器负责为网格中的各个服务签发证书，并将证书分发给数据面的各个服务的sidecar代理。 数据面：在网格中的服务相互之间发起 plain HTTP/TCP 通信时，和服务同一个 pod 中的sidecar代理会拦截服务请求，采用证书和对端服务的sidecar代理进行双向 TLS 认证并建立一个 TLS 连接，使用该 TLS 连接来在网络中传输数据。  控制面证书签发流程 图1是对 Istio 安全架构的一个高度概括的描述，让我们把图1中控制面的交互展开，看一下其中的细节。\n图2. Istio 证书分发流程\n我们先暂时忽略图中右边蓝色虚线的部分（稍后会在 控制面身份认证 部分讲到），图中左半部分描述了 Istio 控制面向 Envoy 签发证书的流程：\n Envoy 向 pilot-agent 发起一个 SDS (Secret Discovery Service) 请求，要求获取自己的证书和私钥。 Pilot-agent 生成私钥和 CSR （Certificates Signing Request，证书签名请求），向 Istiod 发送证书签发请求，请求中包含 CSR 和该 pod 中服务的身份信息。 Istiod 根据请求中服务的身份信息（Service Account）为其签发证书，将证书返回给 Pilot-agent。 Pilot-agent 将证书和私钥通过 SDS 接口返回给 Envoy。  为什么要通过 Pilot-agent 中转？ 从图2可以看到，Istio 证书签发的过程中涉及到了三个组件： Istiod (Istio CA) \u0026mdash;\u0026gt; Pilot-agent \u0026mdash;\u0026gt; Enovy。为什么其他 xDS 接口都是由 Istiod 直接向 Envoy 提供，但 SDS 却要通过 Pilot-agent 进行一次中转，而不是直接由 Envoy 通过 SDS 接口从 Istiod 获取证书呢？这样做主要有两个原因。\n首先，在 Istio 的证书签发流程中，由 Pilot-agent 生成私钥和 CSR，再通过 CSR 向 Istiod 中的 CA 申请证书。在整个过程中，私钥只存在于本地的 Istio-proxy 容器中。如果去掉中间 Pilot-agent 这一步，直接由 Envoy 向 Isitod 申请证书，则需要由 Istiod 生成私钥，并将私钥和证书一起通过网络返回给 Envoy，这将大大增加私钥泄露的风险。\n另一方面，通过 Pilot-agent 来提供 SDS 服务，由 Pilot-agent 生成标准的 CSR 证书签名请求，可以很容易地对接不同的 CA 服务器，方便 Istio 和其他证书机构进行集成。\n控制面身份认证 要通过服务证书来实现网格中服务的身份认证，必须首先确保服务从控制面获取自身证书的流程是安全的。Istio 通过 Istiod 和 Pilog-agent 之间的 gRPC 通道传递 CSR 和证书，因此在这两个组件进行通信时，双方需要先验证对方的身份，以避免恶意第三方伪造 CSR 请求或者假冒 Istiod CA 服务器。在目前的版本中(Istio1.6)，Pilot-agent 和 Istiod 分布采用了不同的认证方式。\n Istiod 身份认证  Istiod 采用其内置的 CA 服务器为自身签发一个服务器证书（图2中的 Istiod certificate），并采用该服务器证书对外提供基于 TLS 的 gPRC 服务。 Istiod 调用 Kube-apiserver 生成一个 ConfigMap， 在该 ConfigMap 中放入了 Istiod 的 CA 根证书(图2中的 istio-ca-root-cert)。 该 ConfigMap 被 Mount 到 Istio-proxy 容器中，被 Pilot-agent 用于验证 Istiod 的服务器证书。 在 Pilot-agent 和 Istiod 建立 gRPC 连接时，Pilot-agent 采用标准的 TLS 服务器认证流程对 Istiod 的服务器证书进行认证。   Pilot-agent 身份认证  在 Kubernetes 中可以为每一个 pod 关联一个 Service Account，以表明该 pod 中运行的服务的身份信息。例如 bookinfo 中 reviews 服务的 service accout 是 “bookinfo-reviews” 。 Kubernetes 会为该 service account 生成一个 jwt token，并将该 token 通过 secret 加载到 pod 中的一个文件。 Pilot-agent 在向 Istiod 发送 CSR 时，将其所在 pod 的 service account token 也随请求发送给 Istiod。 Istiod 调用 Kube-apiserver 接口验证请求中附带的 service account token，以确认请求证书的服务身份是否合法。    备注：除了 Kubernetes 之外， Istio 也支持虚机部署，在虚机部署的场景下，由于没有 service account，Pilot-agent 和 Pilotd 之间的身份认证方式有所不同。由于 Istio 的主要使用场景还是 Kubernetes，本文只分析 Kubernetes 部署场景。\nSDS 工作原理 和其他 xDS 接口一样，SDS 也是 Envoy 支持的一种动态配置服务接口。Envoy 可以通过 SDS（secret discovery service） 接口从 SDS 服务器自动获取证书。和之前的方式相比，SDS 最大的好处就是简化了证书管理。在没有使用 SDS 前，Istio 中的服务证书被创建为 Kubernetes secret，并挂载到代理容器中。如果证书过期了，则需要更新 secret 并重启 Envoy 容器，以启用新的证书。使用SDS后，SDS 服务器（Pilot-agent充当了 SDS 服务器的角色）将向 Envoy 实例主动推送证书。如果证书过期，SDS 服务器只需将新的证书推送到 Envoy 例中，Envoy 会使用新的证书来创建链接，无需重新启动。\n图3. Envoy SDS 服务\n可以看到，Istio 采用 SDS 后，避免了在证书更新后重启 Envoy，大大减少了证书更新对业务的影响。同时，由于 Pilot-agent 和 Envoy 处于同一容器中，私钥只存在于本地容器，避免了在网络中传递私钥，也降低了私钥泄露的安全风险。\nSDS 服务向 Envoy 下发的数据结构为extensions.transport_sockets.tls.v3.Secret,其结构如下：\n{\r\u0026#34;name\u0026#34;: \u0026#34;...\u0026#34;, // Secret 名称\r\u0026#34;tls_certificate\u0026#34;: \u0026#34;{...}\u0026#34;, // 数字证书\r\u0026#34;session_ticket_keys\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;validation_context\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书验证信息\r\u0026#34;generic_secret\u0026#34;: \u0026#34;{...}\u0026#34;\r}\r其中在 Istio 中用到的主要是 tls_certificate 和 validation_context。 分别用于传递数字证书和验证对方证书使用到的根证书。下面是这两个字段的结构，结构中标注了我们主要需要关注的内容。\ntls_certificate\n{\r\u0026#34;certificate_chain\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书内容\r\u0026#34;private_key\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书的私钥\r\u0026#34;private_key_provider\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;{...}\u0026#34;\r}\rvalidation_context\n{\r\u0026#34;trusted_ca\u0026#34;: \u0026#34;{...}\u0026#34;, // CA 根证书\r\u0026#34;verify_certificate_spki\u0026#34;: [],\r\u0026#34;verify_certificate_hash\u0026#34;: [],\r\u0026#34;match_subject_alt_names\u0026#34;: [], // 需要验证的 subject alt name\r\u0026#34;crl\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;allow_expired_certificate\u0026#34;: \u0026#34;...\u0026#34;,\r\u0026#34;trust_chain_verification\u0026#34;: \u0026#34;...\u0026#34;\r}\r网格 Sidecar 证书配置 在 Istio 的 Enovy sidecar 配置中，有两处需要通过 SDS 来配置证书：\n Inbound Listener：由于Enovy 通过 Listener 对外提供服务，需要通过 SDS 配置服务器证书，服务器证书私钥，以及验证下游客户端证书的 CA 根证书。 Outbound Cluster：对于上游的 Cluster 而言，Envoy 是客户端的角色，因此需要在 Cluster 中通过 SDS 配置客户端证书，客户端证书私钥，以及验证上游服务器的 CA 根证书。  下面我们来看一下 bookinfo 示例中 Envoy sidecar代理上 reviews 微服务相关的证书配置，以对 Istio 中 SDS 的运作机制有一个更清晰的认识。为了简略起见，本文只显示了部分关键的配置。你也可以查看 Github 上的完整配置。\n通过 Envoy 的管理端口，可以导出 Envoy 中的当前配置，导出命令如下：\nkubectl exec reviews-v1-6d8bc58dd7-ts8kw -c istio-proxy curl http://127.0.0.1:15000/config_dump \u0026gt; config_dump\r配置文件中 SDS 服务器的定义如下，Pilot-agent 在 /etc/istio/proxy/SDS 这路径上通过 unix domain socket 提供了一个 SDS 服务器。\n{\r\u0026#34;name\u0026#34;: \u0026#34;sds-grpc\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;STATIC\u0026#34;,\r\u0026#34;connect_timeout\u0026#34;: \u0026#34;10s\u0026#34;,\r\u0026#34;hidden_envoy_deprecated_hosts\u0026#34;: [\r{\r\u0026#34;pipe\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/etc/istio/proxy/SDS\u0026#34;\r}\r}\r],\r\u0026#34;http2_protocol_options\u0026#34;: {}\r}\rDetails Pod 在 9080 端口对外提供服务，因此需要通过 SDS 配置 9080 端口上的服务端证书和验证客户端证书的 CA 根证书。\n{\r\u0026#34;name\u0026#34;: \u0026#34;virtualInbound\u0026#34;, // 15006端口上的虚拟入向监听器\r\u0026#34;active_state\u0026#34;: {\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14T03:59:54Z/25\u0026#34;,\r\u0026#34;listener\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Listener\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;virtualInbound\u0026#34;,\r\u0026#34;address\u0026#34;: {\r\u0026#34;socket_address\u0026#34;: {\r\u0026#34;address\u0026#34;: \u0026#34;0.0.0.0\u0026#34;,\r\u0026#34;port_value\u0026#34;: 15006\r}\r},\r\u0026#34;filter_chains\u0026#34;: [\r{\r\u0026#34;filter_chain_match\u0026#34;: {\r\u0026#34;prefix_ranges\u0026#34;: [\r{\r\u0026#34;address_prefix\u0026#34;: \u0026#34;10.44.0.8\u0026#34;,\r\u0026#34;prefix_len\u0026#34;: 32\r}\r],\r\u0026#34;destination_port\u0026#34;: 9080 // 用于处理发向reviews服务9080端口的业务请求的filter chain\r},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;h2\u0026#34;,\r\u0026#34;http/1.1\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [ // 配置服务器端证书\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, // 服务器证书 Secret 名称\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取服务器端证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r],\r\u0026#34;combined_validation_context\u0026#34;: {\r\u0026#34;default_validation_context\u0026#34;: {},\r\u0026#34;validation_context_sds_secret_config\u0026#34;: { // 配置验证客户端证书的 CA 根证书\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;, // CA 根证书 Secret 名称\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取 CA 根证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r}\r},\r\u0026#34;require_client_certificate\u0026#34;: true\r}\r}\r}\r],\r}\r}\r客户端 Pod 上的 Enovy 通过 reviews outbound cluster 访问上游 reviews 服务，因此需要在该 cluster 上配置客户端证书以及验证服务器端证书的 CA 根证书。在这里我们需要注意的是，Envoy 在验证服务器端证书时会同时验证证书中的 subject alternative name 字段。该字段中设置的是 reviews 服务 Pod 关联的 Service Account 名称。 由于 Service Account 是 Istio 中认可的一种用户账户，因此通过为 Service Account 设置不同的资源访问权限，可以进一步实现细粒度的权限控制，例如按照 URL 进行授权。\n{\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14T03:15:47Z/18\u0026#34;,\r\u0026#34;cluster\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Cluster\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;EDS\u0026#34;,\r\u0026#34;eds_cluster_config\u0026#34;: {\r\u0026#34;eds_config\u0026#34;: {\r\u0026#34;ads\u0026#34;: {}\r},\r\u0026#34;service_name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;\r},\r\u0026#34;service_name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;\r},\r\u0026#34;circuit_breakers\u0026#34;: {...},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket_matches\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;tlsMode-istio\u0026#34;,\r\u0026#34;match\u0026#34;: {\r\u0026#34;tlsMode\u0026#34;: \u0026#34;istio\u0026#34;\r},\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.UpstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;istio-peer-exchange\u0026#34;,\r\u0026#34;istio\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, // 配置用于访问 reviews 服务的客户端证书\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取客户端证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r],\r\u0026#34;combined_validation_context\u0026#34;: {\r\u0026#34;default_validation_context\u0026#34;: {\r\u0026#34;verify_subject_alt_name\u0026#34;: [\r\u0026#34;spiffe://cluster.local/ns/default/sa/bookinfo-reviews\u0026#34; // 验证服务器证书时需要验证 SAN 中的 service account 名称\r]\r},\r\u0026#34;validation_context_sds_secret_config\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;, // 配置验证 reviews 服务器证书的 CA 根证书\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取 CA 根证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r}\r},\r\u0026#34;sni\u0026#34;: \u0026#34;outbound_.9080_._.reviews.default.svc.cluster.local\u0026#34;\r}\r}\r},\r]\r},\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:33.061Z\u0026#34;\r}\r上面配置中 SAN 中的 service account 名称来自于 reviews pod 中的 service account 配置。\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: reviews-v1\rlabels:\rapp: reviews\rversion: v1\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: reviews\rversion: v1\rtemplate:\rmetadata:\rlabels:\rapp: reviews\rversion: v1\rspec:\rserviceAccountName: bookinfo-reviews // 设置 reviews pod 的 service account\rcontainers:\r- name: reviews\rimage: docker.io/istio/examples-bookinfo-reviews-v1:1.15.0\rimagePullPolicy: IfNotPresent\renv:\r- name: LOG_DIR\rvalue: \u0026#34;/tmp/logs\u0026#34;\rports:\r- containerPort: 9080\r...\r在导出的配置中可以看到 Envoy 通过 SDS 服务器获取到的证书（为了简略起见，省略了证书中间的部分内容）。\n{\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.admin.v3.SecretsConfigDump\u0026#34;,\r\u0026#34;dynamic_active_secrets\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;version_info\u0026#34;: \u0026#34;05-14 03:16:30.900\u0026#34;,\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:31.125Z\u0026#34;,\r\u0026#34;secret\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;tls_certificate\u0026#34;: {\r\u0026#34;certificate_chain\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FUXXXXXXXXXXXXXXUZJQ0FURS0tLS0tCg==\u0026#34; // details 服务的证书，该证书被同时用作了服务器证书和客户端证书\r},\r\u0026#34;private_key\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;W3JlZGFjdGVkXQ==\u0026#34; // detatils 服务证书对应的私钥\r}\r}\r}\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;,\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14 03:16:31.300416193 +0000 UTC m=+1.537483882\u0026#34;,\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:31.343Z\u0026#34;,\r\u0026#34;secret\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;,\r\u0026#34;validation_context\u0026#34;: {\r\u0026#34;trusted_ca\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0XXXXXXXXXXXXXXXXXXXXJQ0FURS0tLS0tCg==\u0026#34; // 用于验证通信对方证书的 CA 根证书\r}\r}\r}\r}\r]\r}\r通过上面的配置，我们可以看到，虽然需要在 Enovy sidecar配置文件中不同的位置为 Envoy 配置服务器、客户端证书以及验证对方的 CA 根证书，但 Istio 中实际上只采用了一个服务证书和 CA 根证书。Isito 将名称为 default 的证书被同时用于 Inbound Listener 的服务器证书和 Outbound Cluster 的客户端证书，并将名称为 ROOTCA 的证书被用于验证下游客户端证书和上游服务器证书的根证书。\nGateway 证书配置 除了需要和网格内部的服务进行通信之外，Ingress Gateway 和 Egress Gateway 还需要连接到网格外部的系统。如果这些外部连接也需要采用 TLS，则 Gateway 中也要配置这些外部系统的相关证书。\nIngress Gateway 中需要如下证书相关的配置：\n 作为客户端和网格内部其他服务进行通信的客户端证书和私钥，和其他服务使用的证书类似，该证书也是由 Istio CA 颁发的。 验证网格内其他服务证书的 CA 根证书，该根证书是 Istio CA 的根证书。 作为网关向网格外部提供服务使用的服务器端证书和私钥，该证书一般是由一个权威 CA 或者第三方 CA 签发的。如果有多个 host，需要为每一个 host 分别配置配置不同的证书。 如果对外提供的服务需要双向 TLS 认证，还需要配置用于验证客户端证书的 CA 根证书。  Egress Gateway 中需要如下证书相关的配置：\n 作为服务器接受网格内部其他服务访问的服务器证书和私钥，和其他服务使用的证书类似，该证书也是由 Istio CA 颁发的。 验证网格内其他服务证书的 CA 根证书，该根证书是 Istio CA 的根证书。 作为出口网关访问外部服务时，如果该外部服务采用了 TLS，则需要配置一个验证该服务器证书的 CA 根证书来验证该服务器。该根证书一般是一个权威 CA 或者第三方 CA。 如果访问的外部服务要求双向 TLS 认证，则还需要网关配置一个该外部服务认可的客户端证书。该证书一般是由一个权威 CA 或者第三方 CA 签发的。  由于 Gateway 中配置的和外部系统相关的证书不是通过 SDS 从 Istio CA 获取的，而是采用第三方 CA 颁发的，因此到期后并不能自动更新，而需要手动进行更新。因此需要注意这些证书的有效期，在证书过期前及时重新申请证书并更新到 Gateway 配置中，以避免影响业务。\n在 Gateway 上配置第三方证书的方法是采用 Kubernetes Secret 和 Istio Gateway CRD。例如我们可以采用下面的步骤在 Ingress Gateway 上配置对外提供服务使用的服务器证书。\n首先创建一个 secret，该 secret 中包含了服务器证书和私钥：\nkubectl create -n istio-system secret tls bookinfo-credential --key=bookinfo.example.com.key --cert=bookinfo.example.com.crt\r然后通过 Gateway CRD 定义一个对外提供服务的虚拟主机，并指定使用刚才定义的 secret。\napiVersion: networking.istio.io/v1alpha3\rkind: Gateway\rmetadata:\rname: mygateway\rspec:\rselector:\ristio: ingressgateway\rservers:\r- port:\rnumber: 443\rname: https\rprotocol: HTTPS\rtls:\rmode: SIMPLE\rcredentialName: httpbin-credential # 在此处设置包含了服务器证书和私钥的 secret\r hosts:\r- bookinfo.example.com\rIstio 将此配置通过 xDS 接口下发到 Ingress Gateway Pod 中的 Envoy 上，可以在该 Envoy 的配置导出中看到 Ingress 网关对外提供的 443 端口上的证书配置（配置文件中的端口是8443，这是因为 Pod 内使用了8443端口，但对外暴露的 LoadBalancer 上的端口是443）。\n{\r\u0026#34;name\u0026#34;: \u0026#34;0.0.0.0_8443\u0026#34;,\r\u0026#34;active_state\u0026#34;: {\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-27T07:43:51Z/21\u0026#34;,\r\u0026#34;listener\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Listener\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;0.0.0.0_8443\u0026#34;,\r\u0026#34;address\u0026#34;: {\r\u0026#34;socket_address\u0026#34;: {\r\u0026#34;address\u0026#34;: \u0026#34;0.0.0.0\u0026#34;,\r\u0026#34;port_value\u0026#34;: 8443\r}\r},\r\u0026#34;filter_chains\u0026#34;: [\r{\r\u0026#34;filter_chain_match\u0026#34;: {\r\u0026#34;server_names\u0026#34;: [\r\u0026#34;bookinfo.example.com\u0026#34;\r]\r},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;h2\u0026#34;,\r\u0026#34;http/1.1\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;bookinfo-credential\u0026#34;, // Ingress Gateway 中配置的 Kubernetes secret\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;google_grpc\u0026#34;: {\r\u0026#34;target_uri\u0026#34;: \u0026#34;unix:/var/run/ingress_gateway/sds\u0026#34;, // 从本地 unix domain socket 上的 SDS 服务器获取服务器证书\r\u0026#34;stat_prefix\u0026#34;: \u0026#34;sdsstat\u0026#34;\r}\r}\r]\r}\r}\r}\r]\r},\r\u0026#34;require_client_certificate\u0026#34;: false\r}\r}\r}\r],\r},\r}\r}\r从配置中可以看出，Ingress Gateway 使用的服务器证书也是通过 SDS 服务获取的。Pilot-agent 在路径unix:/var/run/ingress_gateway/sds 上为 Ingress Gateway 提供了一个基于 unix domain socket 的 SDS 服务。Ingress Gateway 中的 Envoy 向该 SDS 服务器请求上述配置文件中的 secret，Pilot-agent 从 Kubernetes 中查到该 同名 secret，然后转换为 SDS 消息返回给 Envoy。\n备注：\n Ingress Gateway 用于和网格内其他服务通信的服务身份证书还是由 Istio CA 颁发的，其证书获取的流程同图2。 Egress Gateway 未使用 SDS 获取用于访问外部服务的客户端证书（1.6 现状，后续也许会修改）。  图4. Ingress Gateway 证书获取流程\n数据面使用的所有证书 下图中以 bookinfo 来举例说明 Istio 在数据面使用到的所有证书。为了方便说明 Gateway 的证书配置，我们假设在 Ingress Gateway 上以 bookinfo.example.com 的主机名对外提供服务，并且 ratings 服务通过 Egress Gateway 访问了一个网格外部的第三方 TLS 服务。\n图中不同颜色边框的图标代表了不同的证书。该示例中一共使用了七个不同的证书，分别为3个服务的证书（同时用作服务器和客户端证书），Ingress Gateway 自身的客户端证书，Ingress Gateway 对外部提供服务的服务器证书，Egress Gateway 自身的服务器证书，Egress Gateway 访问外部服务使用的客户端证书。\n除了 Ingress Gateway 对外提供服务的服务器证书和 Egress Gateway 访问第三方服务的客户端证书之外，其他证书都是 Envoy 通过 SDS 服务从 Istio CA 获取的，因此都使用 Istio Root CA 证书进行验证。这两个第三方证书则需要采用第三方 CA 根证书进行验证。\n图5. Istio 数据面使用到的所有证书\n小结 微服务应用本质上是一个分布式的网络程序，在微服务应用内存在大量的服务间网络通信。在云化部署环境中，服务间的身份认证和安全通信是微服务面临的一大挑战。Istio 建立了一套以数字证书为基础的服务认证安全框架，在不修改应用的前提下提供了服务之间的身份认证和安全通信，并以身份认证为基础提供了强大的授权机制。\n参考文档  Istio Secure Gateways Istio Egress Gateways with TLS Origination  ","permalink":"https://cloudnative.to/blog/istio-certificate/","tags":["Istio"],"title":"一文带你彻底厘清 Isito 中的证书工作机制"},{"categories":["Tekton"],"contents":"这篇文章是基于 Tekton Pipeline 的最新版本v0.12.1版本。\n快速入门请参考：云原生 CICD: Tekton Pipeline 实战 ，实战是基于版本 v0.10.x。\nPipeline CRD 与核心资源的关系 $ k api-resources --api-group=tekton.dev NAME SHORTNAMES APIGROUP NAMESPACED KIND clustertasks tekton.dev false ClusterTask conditions tekton.dev true Condition pipelineresources tekton.dev true PipelineResource pipelineruns pr,prs tekton.dev true PipelineRun pipelines tekton.dev true Pipeline taskruns tr,trs tekton.dev true TaskRun tasks tekton.dev true Task Tekton Pipelines提供了上面的CRD，其中部分CRD与Kubernetes core中资源相对应\n Task =\u0026gt; Pod Task.Step =\u0026gt; Container  工作原理 (图片来自tekton.dev)\nTekton Pipeline 是基于 Knative 的实现，pod tekton-pipelines-controller 中有两个 Knative Controller的实现：PipelineRun 和 TaskRun。\nTask的执行顺序 PipelineRun Controller 的 #reconcile()方法，监控到有PipelineRun被创建。然后从PipelineSpec的 tasks 列表，构建出一个图（graph），用于描述Pipeline中 Task 间的依赖关系。依赖关系是通过runAfter和from，进而控制Task的执行顺序。与此同时，准备PipelineRun中定义的PipelineResources。\n// Node represents a Task in a pipeline. type Node struct { // Task represent the PipelineTask in Pipeline \tTask Task // Prev represent all the Previous task Nodes for the current Task \tPrev []*Node // Next represent all the Next task Nodes for the current Task \tNext []*Node } // Graph represents the Pipeline Graph type Graph struct { //Nodes represent map of PipelineTask name to Node in Pipeline Graph \tNodes map[string]*Node } func Build(tasks Tasks) (*Graph, error) { ... } PipelineRun中定义的参数（parameters）也会注入到PipelineSpec中：\npipelineSpec = resources.ApplyParameters(pipelineSpec, pr) 接下来就是调用dag#GetSchedulable()方法，获取未完成（通过Task状态判断）的 Task 列表；\nfunc GetSchedulable(g *Graph, doneTasks ...string) (map[string]struct{}, error) { ... } 为 Task A 创建TaskRun，假如Task配置了Condition。会先为 condition创建一个TaskRun，只有在 condition 的TaskRun运行成功，才会运行 A 的TaskRun；否则就跳过。\nStep的执行顺序 这一部分篇幅较长，之前的文章 控制 Pod 内容器的启动顺序 中提到过。\n这里补充一下Kubernetes Downward API的使用，Kubernetes Downward API的引入，控制着 Task 的第一个 Step 在何时执行。\nTaskRun Controller 在 reconciling 的过程中，在相应的 Pod 状态变为Running时，会将tekton.dev/ready=READY写入到 Pod 的 annotation 中，来通知第一个Step的执行。\nPod的部分内容：\nspec: containers: - args: - -wait_file - /tekton/downward/ready - -wait_file_content - -post_file - /tekton/tools/0 - -termination_path - /tekton/termination - -entrypoint - /ko-app/git-init - -- - -url - ssh://git@gitlab.nip.io:8022/addozhang/logan-pulse.git - -revision - develop - -path - /workspace/git-source command: - /tekton/tools/entrypoint volumeMounts: - mountPath: /tekton/downward name: tekton-internal-downward volumes: - downwardAPI: defaultMode: 420 items: - fieldRef: apiVersion: v1 fieldPath: metadata.annotations[\u0026#39;tekton.dev/ready\u0026#39;] path: ready name: tekton-internal-downward 对原生的排序step container进一步处理：启动命令使用entrypoint提供，并设置执行参数：\nentrypoint.go\nfunc orderContainers(entrypointImage string, steps []corev1.Container, results []v1alpha1.TaskResult) (corev1.Container, []corev1.Container, error) { initContainer := corev1.Container{ Name: \u0026#34;place-tools\u0026#34;, Image: entrypointImage, Command: []string{\u0026#34;cp\u0026#34;, \u0026#34;/ko-app/entrypoint\u0026#34;, entrypointBinary}, VolumeMounts: []corev1.VolumeMount{toolsMount}, } if len(steps) == 0 { return corev1.Container{}, nil, errors.New(\u0026#34;No steps specified\u0026#34;) } for i, s := range steps { var argsForEntrypoint []string switch i { case 0: argsForEntrypoint = []string{ // First step waits for the Downward volume file. \t\u0026#34;-wait_file\u0026#34;, filepath.Join(downwardMountPoint, downwardMountReadyFile), \u0026#34;-wait_file_content\u0026#34;, // Wait for file contents, not just an empty file. \t// Start next step. \t\u0026#34;-post_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i)), \u0026#34;-termination_path\u0026#34;, terminationPath, } default: // All other steps wait for previous file, write next file. \targsForEntrypoint = []string{ \u0026#34;-wait_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i-1)), \u0026#34;-post_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i)), \u0026#34;-termination_path\u0026#34;, terminationPath, } } ... } 自动运行的容器 这些自动运行的容器作为 pod 的initContainer会在 step 容器运行之前运行\ncredential-initializer 用于将 ServiceAccount 的相关secrets持久化到容器的文件系统中。比如 ssh 相关秘钥、config文件以及know_hosts文件；docker registry 相关的凭证则会被写入到 docker 的配置文件中。\nworking-dir-initializer 收集Task内的各个Step的workingDir配置，初始化目录结构\nplace-scripts 假如Step使用的是script配置（与command+args相对），这个容器会将脚本代码（script字段的内容）持久化到/tekton/scripts目录中。\n注：所有的脚本会自动加上#!/bin/sh\\nset -xe\\n，所以script字段里就不必写了。\nplace-tools 将entrypoint的二进制文件，复制到/tekton/tools/entrypoint.\nTask/Step间的数据传递 针对不同的数据，有多种不同的选择。比如Workspace、Result、PipelineResource。对于由于Task的执行是通过Pod来完成的，而Pod会调度到不同的节点上。因此Task间的数据传递，需要用到持久化的卷。\n而Step作为Pod中的容器来运行，\nWorkspace 工作区，可以理解为一个挂在到容器上的卷，用于文件的传递。\npersistentVolumeClaim 引用已存在persistentVolumeClaim卷（volume）。这种工作空间，可多次使用，需要先进行创建。比如 Java 项目的 maven，编译需要本地依赖库，这样可以节省每次编译都要下载依赖包的成本。\nworkspaces: - name: m2 persistentVolumeClaim: claimName: m2-pv-claim apiVersion: v1 kind: PersistentVolume metadata: name: m2-pv labels: type: local spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteMany hostPath: path: \u0026#34;/data/.m2\u0026#34; --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: m2-pv-claim spec: storageClassName: manual # volumeName: m2-pv accessModes: - ReadWriteMany resources: requests: storage: 10Gi volumeClaimTemplate 为每个PipelineRun或者TaskRun创建PersistentVolumeClaim卷（volume）的模板。比如一次构建需要从 git 仓库克隆代码，而针对不同的流水线代码仓库是不同的。这里就会用到volumeClaimTemplate，为每次构建创建一个PersistentVolumeClaim卷。（从0.12.0开始）\n生命周期同PipelineRun或者TaskRun，运行之后释放。\nworkspaces: - name: git-source volumeClaimTemplate: spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi 相较于persistantVolumeClain类型的workspace，volumeClaimTemplate不需要在每次在PipelineRun完成后清理工作区；并发情况下可能会出现问题。\nemptyDir 引用emptyDir卷，跟随Task生命周期的临时目录。适合在Task的Step间共享数据，无法在多个Task间共享。\nworkspaces: - name: temp emptyDir: {} configMap 引用一个configMap卷，将configMap卷作为工作区，有如下限制：\n 挂载的卷是只读的 需要提前创建configMap configMap的大小限制为1MB（Kubernetes的限制）  使用场景，比如使用maven编译Java项目，配置文件settings.xml可以使用configMap作为工作区\nworkspaces: - name: maven-settings configmap: name: maven-settings secret 用于引用secret卷，同configMap工作区一样，也有限制：\n 挂载的卷是只读的 需要提前创建secret secret的大小限制为1MB（Kubernetes的限制）  results results字段可以用来配置多个文件用来存储Tasks的执行结果，这些文件保存在/tekton/results目录中。\n在Pipeline中，可以通过tasks.[task-nanme].results.[result-name]注入到其他Task的参数中。\napiVersion: tekton.dev/v1beta1 kind: Task metadata: name: print-date annotations: description: | A simple task that prints the date spec: results: - name: current-date-unix-timestamp description: The current date in unix timestamp format - name: current-date-human-readable description: The current date in human readable format steps: - name: print-date-unix-timestamp image: bash:latest script: | #!/usr/bin/env bash date +%s | tee $(results.current-date-unix-timestamp.path) - name: print-date-humman-readable image: bash:latest script: | #!/usr/bin/env bash date | tee $(results.current-date-human-readable.path) --- apiVersion: tekton.dev/v1beta1 kind: PipelineRun metadata: name: pass-date spec: pipelineSpec: tasks: - name: print-date taskRef: name: print-date - name: read-date runAfter: #配置执行顺序 - print-date taskSpec: params: - name: current-date-unix-timestamp type: string - name: current-date-human-readable type: string steps: - name: read image: busybox script: | echo $(params.current-date-unix-timestamp) echo $(params.current-date-human-readable) params: - name: current-date-unix-timestamp value: $(tasks.print-date.results.current-date-unix-timestamp) # 注入参数 - name: current-date-human-readable value: $(tasks.print-date.results.current-date-human-readable) # 注入参数  执行结果：\n┌──────Logs(tekton-pipelines/pass-date-read-date-rhlf2-pod-9b2sk)[all] ────────── │ │ place-scripts stream closed ││ step-read 1590242170 │ │ step-read Sat May 23 13:56:10 UTC 2020 ││ step-read + echo 1590242170 │ │ step-read + echo Sat May 23 13:56:10 UTC 2020 │ │ place-tools stream closed │ │ step-read stream closed │ │ PipelineResource PipelineResource在最后提，因为目前只是alpha版本，何时会进入beta或者弃用目前还是未知数。有兴趣的可以看下这里：Why Aren’t PipelineResources in Beta?\n简单来说，PipelineResource可以通过其他的方式实现，而其本身也存在弊端：比如实现不透明，debug有难度；功能不够强；降低了Task的重用性等。\n比如git类型的PipelineResource，可以通过workspace和git-clone Task来实现；存储类型的，也可以通过workspace来实现。\n这也就是为什么上面介绍workspace的篇幅比较大。个人也偏向于使用workspace，灵活度高；使用workspace的Task重用性强。\n参考  云原生 CICD: Tekton Pipeline 实战 控制 Pod 内容器的启动顺序 Knative Controller Why Aren’t PipelineResources in Beta?  ","permalink":"https://cloudnative.to/blog/how-tekton-works/","tags":["Tekton","CICD"],"title":"Tekton 的工作原理"},{"categories":["Kubernetes"],"contents":"接触 Kubernetes 以来，我经常看到 Kubernetes 在不同的地方使用了证书（Certificate），在 Kubernetes 安装和组件启动参数中也需要配置大量证书相关的参数。但是 Kubernetes 的文档在解释这些证书的工作机制方面做得并不是太好。经过大量的相关阅读和分析工作后，我基本弄清楚了 Kubernetes 中证书的使用方式。在本文中，我将试图以一种比官方文档更容易理解的方式来说明 Kubernetes 证书相关的工作机制，如果你也存在这方面的疑惑，希望这篇文章对你有所帮助。\nKubernetes 组件的认证方式 首先让我们来看一下 Kubernetes 中的组件：在 Kubernetes 中包含多个以独立进程形式运行的组件，这些组件之间通过 HTTP/gRPC 相互通信，以协同完成集群中应用的部署和管理工作。\nkubernetes 组件，图片来源kubernetes.io\n从图中可以看到，Kubernetes 控制平面中包含了 etcd，kube-api-server，kube-scheduler，kube-controller-manager 等组件，这些组件会相互进行远程调用，例如 kube-api-server 会调用 etcd 接口存储数据，kube-controller-manager 会调用 kube-api-server 接口查询集群中的对象状态；同时，kube-api-server 也会和在工作节点上的 kubelet 和 kube-proxy 进行通信，以在工作节点上部署和管理应用。\n以上这些组件之间的相互调用都是通过网络进行的。在进行网络通信时，通信双方需要验证对方的身份，以避免恶意第三方伪造身份窃取信息或者对系统进行攻击。为了相互验证对方的身份，通信双方中的任何一方都需要做下面两件事情：\n 向对方提供标明自己身份的一个证书 验证对方提供的身份证书是否合法，是否伪造的？  在 Kubernetes 中使用了数字证书来提供身份证明，我们可以把数字证书简单理解为我们在日常生活中使用的“身份证”，上面标注了证书拥有者的身份信息，例如名称，所属组织机构等。为了保证证书的权威性，会采用一个通信双方都信任的 CA（证书机构，Certificate Authority）来颁发证书。这就类似于现实生活中颁发“身份证”的政府机构。数字证书中最重要的内容实际上是证书拥有者的公钥，该公钥代表了用户的身份。本文假设读者已经了解数字证书和 CA 的基本原理，如果你对此不太清楚，或者希望重新温习一下相关知识，可以先阅读一下这篇文章《数字证书原理》。\nCA （证书机构），图片来源www.trustauth.cn\n在 Kubernetes 的组件之间进行通信时，数字证书的验证是在协议层面通过 TLS 完成的，除了需要在建立通信时提供相关的证书和密钥外，在应用层面并不需要进行特殊处理。采用 TLS 进行验证有两种方式：\n 服务器单向认证：只需要服务器端提供证书，客户端通过服务器端证书验证服务的身份，但服务器并不验证客户端的身份。这种情况一般适用于对 Internet 开放的服务，例如搜索引擎网站，任何客户端都可以连接到服务器上进行访问，但客户端需要验证服务器的身份，以避免连接到伪造的恶意服务器。 双向 TLS 认证：除了客户端需要验证服务器的证书，服务器也要通过客户端证书验证客户端的身份。这种情况下服务器提供的是敏感信息，只允许特定身份的客户端访问。  在 Kubernetes 中，各个组件提供的接口中包含了集群的内部信息。如果这些接口被非法访问，将影响集群的安全，因此组件之间的通信需要采用双向 TLS 认证。即客户端和服务器端都需要验证对方的身份信息。在两个组件进行双向认证时，会涉及到下面这些证书相关的文件：\n 服务器端证书：服务器用于证明自身身份的数字证书，里面主要包含了服务器端的公钥以及服务器的身份信息。 服务器端私钥：服务器端证书中包含的公钥所对应的私钥。公钥和私钥是成对使用的，在进行 TLS 验证时，服务器使用该私钥来向客户端证明自己是服务器端证书的拥有者。 客户端证书：客户端用于证明自身身份的数字证书，里面主要包含了客户端的公钥以及客户端的身份信息。 客户端私钥：客户端证书中包含的公钥所对应的私钥，同理，客户端使用该私钥来向服务器端证明自己是客户端证书的拥有者。 服务器端 CA 根证书：签发服务器端证书的 CA 根证书，客户端使用该 CA 根证书来验证服务器端证书的合法性。 客户端 CA 根证书：签发客户端证书的 CA 根证书，服务器端使用该 CA 根证书来验证客户端证书的合法性。  下面这张来自The magic of TLS, X509 and mutual authentication explained 文章中的图形象地解释了双向 TLS 认证的原理。如果你需要了解更多关于 TLS 认证的原理，可以阅读一下 medium 上的原文。\n图片来源The magic of TLS, X509 and mutual authentication explained\nKubernetes 中使用到的CA和证书 Kubernetes 中使用了大量的证书，本文不会试图覆盖到所有可能使用到的证书，但会讨论到主要的证书。理解了这些证书的使用方法和原理后，也能很快理解其他可能遇到的证书文件。下图标识出了在 kubernetes 中主要使用到的证书和其使用的位置：\nKubernetes 中使用到的主要证书\n上图中使用序号对证书进行了标注。图中的箭头表明了组件的调用方向，箭头所指方向为服务提供方，另一头为服务调用方。为了实现 TLS 双向认证，服务提供方需要使用一个服务器证书，服务调用方则需要提供一个客户端证书，并且双方都需要使用一个 CA 证书来验证对方提供的证书。为了简明起见，上图中只标注了证书使用方提供的证书，并没有标注证书的验证方验证使用的 CA 证书。图中标注的这些证书的作用分别如下：\n  etcd 集群中各个节点之间相互通信使用的证书。由于一个 etcd 节点既为其他节点提供服务，又需要作为客户端访问其他节点，因此该证书同时用作服务器证书和客户端证书。\n  etcd 集群向外提供服务使用的证书。该证书是服务器证书。\n  kube-apiserver 作为客户端访问 etcd 使用的证书。该证书是客户端证书。\n  kube-apiserver 对外提供服务使用的证书。该证书是服务器证书。\n  kube-controller-manager 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kube-scheduler 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kube-proxy 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kubelet 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  管理员用户通过 kubectl 访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kubelet 对外提供服务使用的证书。该证书是服务器证书。\n  kube-apiserver 作为客户端访问 kubelet 采用的证书。该证书是客户端证书。\n  kube-controller-manager 用于生成和验证 service-account token 的证书。该证书并不会像其他证书一样用于身份认证，而是将证书中的公钥/私钥对用于 service account token 的生成和验证。kube-controller-manager 会用该证书的私钥来生成 service account token，然后以 secret 的方式加载到 pod 中。pod 中的应用可以使用该 token 来访问 kube-apiserver， kube-apiserver 会使用该证书中的公钥来验证请求中的 token。我们将在文中稍后部分详细介绍该证书的使用方法。\n  通过这张图，对证书机制比较了解的读者可能已经看出，我们其实可以使用多个不同的 CA 来颁发这些证书。只要在通信的组件中正确配置用于验证对方证书的 CA 根证书，就可以使用不同的 CA 来颁发不同用途的证书。但我们一般建议采用统一的 CA 来颁发 kubernetes 集群中的所有证书，这是因为采用一个集群根 CA 的方式比采用多个 CA 的方式更容易管理，可以避免多个CA 导致的复杂的证书配置、更新等问题，减少由于证书配置错误导致的集群故障。\nKubernetes 中的证书配置 前面我们介绍了 Kubernetes 集群中主要使用到的证书。下面我们分别看一下如何将这些证书及其对应的私钥和 CA 根证书需要配置到 Kubernetes 中各个组件中，以供各个组件进行使用。这里假设使用一个集群根 CA 来颁发所有相关证书，因此涉及到 CA 的配置对应的证书文件名都是相同的。\netcd 证书配置 需要在 etcd 的启动命令行中配置以下证书相关参数：\n etcd 对外提供服务的服务器证书及私钥。 etcd 节点之间相互进行认证的 peer 证书、私钥以及验证 peer 的 CA。 etcd 验证访问其服务的客户端的 CA。  /usr/local/bin/etcd \\\\\r--cert-file=/etc/etcd/kube-etcd.pem \\\\ # 对外提供服务的服务器证书\r--key-file=/etc/etcd/kube-etcd-key.pem \\\\ # 服务器证书对应的私钥\r--peer-cert-file=/etc/etcd/kube-etcd-peer.pem \\\\ # peer 证书，用于 etcd 节点之间的相互访问\r--peer-key-file=/etc/etcd/kube-etcd-peer-key.pem \\\\ # peer 证书对应的私钥\r--trusted-ca-file=/etc/etcd/cluster-root-ca.pem \\\\ # 用于验证访问 etcd 服务器的客户端证书的 CA 根证书\r--peer-trusted-ca-file=/etc/etcd/cluster-root-ca.pem\\\\ # 用于验证 peer 证书的 CA 根证书\r...\rkube-apiserver 证书配置 需要在 kube-apiserver 中配置以下证书相关参数：\n kube-apiserver 对外提供服务的服务器证书及私钥。 kube-apiserver 访问 etcd 所需的客户端证书及私钥。 kube-apiserver 访问 kubelet 所需的客户端证书及私钥。 验证访问其服务的客户端的 CA。 验证 etcd 服务器证书的 CA 根证书。 验证 service account token 的公钥。  /usr/local/bin/kube-apiserver \\\\ --tls-cert-file=/var/lib/kubernetes/kube-apiserver.pem \\\\ # 用于对外提供服务的服务器证书\r--tls-private-key-file=/var/lib/kubernetes/kube-apiserver-key.pem \\\\ # 服务器证书对应的私钥\r--etcd-certfile=/var/lib/kubernetes/kube-apiserver-etcd-client.pem \\\\ # 用于访问 etcd 的客户端证书\r--etcd-keyfile=/var/lib/kubernetes/kube-apiserver-etcd-client-key.pem \\\\ # 用于访问 etcd 的客户端证书的私钥\r--kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver-kubelet-client.pem \\\\ # 用于访问 kubelet 的客户端证书\r--kubelet-client-key=/var/lib/kubernetes/kube-apiserver-kubelet-client-key.pem \\\\ # 用于访问 kubelet 的客户端证书的私钥\r--client-ca-file=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证访问 kube-apiserver 的客户端的证书的 CA 根证书\r--etcd-cafile=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证 etcd 服务器证书的 CA 根证书 --kubelet-certificate-authority=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证 kubelet 服务器证书的 CA 根证书\r--service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ # 用于验证 service account token 的公钥\r...\r采用 kubeconfig 访问 kube-apiserver Kubernetes 中的各个组件，包括kube-controller-mananger、kube-scheduler、kube-proxy、kubelet等，采用一个kubeconfig 文件中配置的信息来访问 kube-apiserver。该文件中包含了 kube-apiserver 的地址，验证 kube-apiserver 服务器证书的 CA 证书，自己的客户端证书和私钥等访问信息。\n在一个使用 minikube 安装的集群中，生成的 kubeconfig 配置文件如下所示，这四个文件分别为 admin 用户， kube-controller-mananger、kubelet 和 kube-scheduler 的kubeconfig配置文件。\n$ ls /etc/kubernetes/\radmin.conf controller-manager.conf kubelet.conf scheduler.conf\r我们打开 controller-manager.conf 来看一下，为了节约篇幅，这里没有写出证书和私钥的完整内容。\napiVersion: v1\rclusters:\r- cluster: # 用于验证 kube-apiserver 服务器证书的 CA 根证书  certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX0tLS0tCg==\rserver: https://localhost:8443\rname: kubernetes\rcontexts:\r- context:\rcluster: kubernetes\ruser: system:kube-controller-manager\rname: system:kube-controller-manager@kubernetes\rcurrent-context: system:kube-controller-manager@kubernetes\rkind: Config\rpreferences: {}\rusers:\r- name: system:kube-controller-manager\ruser:\r# 用于访问 kube-apiserver 的客户端证书\r client-certificate-data: LS0tLS1CRUdJTiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXQ0FURS0tLS0tCg==\r# 客户端证书对应的私钥\r client-key-data: LS0tLS1CRUdXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXtFWS0tLS0tCg==\r可以看到，访问 kube-apiserver 所需要的相关证书内容已经被采用 base64 编码写入了文件中。其他几个文件中的内容也是类似的，只是配置的用户名和客户端证书有所不同。\n在启动这些组件时，需要在参数中指出 kubeconfig 文件的路径，例如 kube-controller-manager 的启动命令如下。\n/usr/local/bin/kube-controller-manager \\\\\r--kubeconfig=/etc/kubernetes/controller-manager.conf # 下面几个证书和访问 kube-apiserver 无关，我们会在后面介绍到\r--cluster-signing-cert-file=/var/lib/kubernetes/cluster-root-ca.pem # 用于签发证书的 CA 根证书\r--cluster-signing-key-file=/var/lib/kubernetes/cluster-root-ca-key.pem # 用于签发证书的 CA 根证书的私钥 --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem # 用于对 service account token 进行签名的私钥\r... Service Account 证书 Kubernetes 中有两类用户，一类为 user account，一类为 service account。 service account 主要被 pod 用于访问 kube-apiserver。 在为一个 pod 指定了 service account 后，kubernetes 会为该 service account 生成一个 JWT token，并使用 secret 将该 service account token 加载到 pod 上。pod 中的应用可以使用 service account token 来访问 api server。service account 证书被用于生成和验证 service account token。该证书的用法和前面介绍的其他证书不同，因为实际上使用的是其公钥和私钥，而并不需要对证书进行验证。\n我们可以看到 service account 证书的公钥和私钥分别被配置到了 kube-apiserver 和 kube-controller-manager 的命令行参数中，如下所示：\n/usr/local/bin/kube-apiserver \\\\ --service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ # 用于验证 service account token 的公钥\r...\r/usr/local/bin/kube-controller-manager \\\\\r--service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem # 用于对 service account token 进行签名的私钥\r... 下图展示了 kubernetes 中生成、使用和验证 service account token 的过程。\n认证方法：客户端证书还是 token ？ 我们可以看到，Kubernetes 提供了两种客户端认证的方法，控制面组件采用的是客户端数字证书;而在集群中部署的应用则采用了 service account token 的方式。为什么 Kubernetes 不为 service account 也生成一个证书，并采用该证书进行身份认证呢？ 实际上 Istio 就是这样做的，Istio 会自动为每个 service account 生成一个证书，并使用该证书来在 pod 中的应用之间建立双向 tls 认证。我没有找到 Kubernetes 这个设计决策的相关说明，如果你知道原因或对此有自己的见解，欢迎联系我进行探讨。\nKubernetes 证书签发 Kubernetes 提供了一个 certificates.k8s.io API，可以使用配置的 CA 根证书来签发用户证书。该 API 由 kube-controller-manager 实现，其签发证书使用的根证书在下面的命令行中进行配置。我们希望 Kubernetes 采用集群根 CA 来签发用户证书，因此在 kube-controller-manager 的命令行参数中将相关参数配置为了集群根 CA。\n/usr/local/bin/kube-controller-manager \\\\\r--cluster-signing-cert-file=/var/lib/kubernetes/cluster-root-ca.pem # 用于签发证书的 CA 根证书\r--cluster-signing-key-file=/var/lib/kubernetes/cluster-root-ca-key.pem # 用于签发证书的 CA 根证书的私钥 ... 关于更多 Kubernetes 证书签发 API 的内容，可以参见 管理集群中的 TLS 认证。\n使用 TLS bootstrapping 简化 Kubelet 证书制作 在安装 Kubernetes 时，我们需要为每一个工作节点上的 Kubelet 分别生成一个证书。由于工作节点可能很多，手动生成 Kubelet 证书的过程会比较繁琐。为了解决这个问题，Kubernetes 提供了 TLS bootstrapping  的方式来简化 Kubelet 证书的生成过程。其原理是预先提供一个 bootstrapping token，kubelet 通过该 kubelet 调用 kube-apiserver 的证书签发 API 来生成 自己需要的证书。要启用该功能，需要在 kube-apiserver 中启用 --enable-bootstrap-token-auth ，并创建一个 kubelet 访问 kube-apiserver 使用的 bootstrap token secret。如果使用 kubeadmin 安装，可以使用 kubeadm token create命令来创建 token。\n采用TLS bootstrapping 生成证书的流程如下：\n 调用 kube-apiserver 生成一个 bootstrap token。 将该 bootstrap token 写入到一个 kubeconfig 文件中，作为 kubelet 调用 kube-apiserver 的客户端验证方式。 通过 --bootstrap-kubeconfig 启动参数将 bootstrap token 传递给 kubelet 进程。 Kubelet 采用bootstrap token 调用 kube-apiserver API，生成自己所需的服务器和客户端证书。 证书生成后，Kubelet 采用生成的证书和 kube-apiserver 进行通信，并删除本地的 kubeconfig 文件，以避免 bootstrap token 泄漏风险。  小结 Kubernetes 中使用了大量的证书来确保集群的安全，弄清楚这些证书的用途和配置方法将有助于我们深入理解 kubernetes 的安装过程和组件的配置。本文是笔者在学习 过程中整理的 Kubernetes 集群中主要使用到的证书，由于笔者对 Kubernetes 的理解有限，文章中难免存在部分错误，欢迎指正。\n参考文档  Kubernetes PKI 证书和要求 kubernetes the hard way Kubernetes 之 二进制安装(二) 证书详解 TLS bootstrapping 数字证书原理  ","permalink":"https://cloudnative.to/blog/k8s-certificate/","tags":["Kubernetes"],"title":"一文带你彻底厘清 Kubernetes 中的证书工作机制"},{"categories":["Service Mesh"],"contents":"前言 Service Mesh 在企业落地中有诸多挑战，当与传统微服务应用共同部署治理时可用性挑战更为严峻。本文将以 Service Mesh 与 Spring Cloud 应用互联互通共同治理为前提，着重介绍基于 Consul 的注册中心高可用方案，通过各种限流、熔断策略保证后端服务的高可用，以及通过智能路由策略（负载均衡、实例容错等）实现服务间调用的高可用。\nService Mesh 与 Spring Cloud 应用的互通、互联 微服务是时下技术热点，大量互联网公司都在做微服务架构的推广和落地。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。而在这个技术转型中，国内有一个现象，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。近年来， 新兴的 Service Mesh 技术也越来越火热，受到越来越多开发者的关注，大有后来居上的趋势。\n在听到社区里很多人谈到微服务技术选型时，注意到他们讨论一个非此即彼的问题：采用 Spring Cloud 还是以 Istio 为代表的 Service Mesh 技术？然而这个答案并非非黑即白、非你即我，一部分应用采用 Spring Cloud，另一部分采用 Service Mesh（Istio）是完全可能的。今天我就和大家一起来讨论这个问题。\n首先，我们来看一下 Spring Cloud 这个传统侵入式微服务框架。它包含以下优点：\n 集大成者，Spring Cloud 包含了微服务架构的方方面面；选用目前各家公司开发的比较成熟的、经得住实践考验的服务框架； 轻量级组件，Spring Cloud 整合的组件大多比较轻量级，且都是各自领域的佼佼者； 开发简便，Spring Cloud 对各个组件进行了大量的封装，从而简化了开发； 开发灵活，Spring Cloud 的组件都是解耦的，开发人员可以灵活按需选择组件。  特别感谢 Netflix ，这家很早就成功实践微服务的公司，几年前把自家几乎整个微服务框架栈贡献给了社区，早期的 Spring Cloud 主要是对 Netflix 开源组件的进一步封装。不过近两年，Spring Cloud 社区开始自研了很多新的组件，也接入了其他一些互联网公司的优秀实践。\n接下来，我们简单看一下 Service Mesh 框架。它带来了两大变革：微服务治理与业务逻辑的解耦，异构系统的统一治理。此外，服务网格相对于传统微服务框架，还拥有三大技术优势：可观察性、流量控制、安全。服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。\n然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。这些局限性包括：增加了链路与运维的复杂度、需要更专业的运维技能、带来了一定的延迟以及对平台的适配。\n更多关于 Spring Cloud 与 Service Mesh 的优缺点与比较，请阅读 Istio-Handbook [Service Mesh 概述]。\n前面提到过，对于传统微服务框架 Spring Cloud 与新兴微服务框架 Service Mesh，并非是个非黑即白，非你即我，延伸到微服务与单体架构，它们也是可以共存的。\n也可以将其与混合云相类比，混合云中包含了公有云、私有云，可能还有其它的自有基础设施。目前来看，混合云是一种流行的实践方式；实际上，可能很难找到一个完全单一云模式的组织。对多数组织来说，将一个单体应用完全重构为微服务的过程中，对开发资源的调动是一个很严峻的问题；采用混合微服务策略是一个较好的方式，对开发团队来说，这种方式让微服务架构触手可及；否则的话，开发团队可能会因为时间、经验等方面的欠缺，无法接受对单体应用的重构工作。\n构建混合微服务架构的最佳实践：\n 最大化收益的部分优先重构； 非 Java 应用优先采用 Service Mesh 框架。  混合微服务出现的原因是为了更好的支持平滑迁移，最大限度的提升服务治理水平，降低运维通信成本等，并且可能会在一个较长的周期存在着。而实现这一架构的前提，就是各服务的“互联互通”。\n要想实现上述“混合微服务架构”，运行时支撑服务必不可少，它主要包括服务注册中心、服务网关和集中式配置中心三个产品。\n传统微服务和 Service Mesh 双剑合璧（双模微服务），即“基于 SDK 的传统微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标：\n 互联互通：两个体系中的应用可以相互访问； 平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知； 灵活演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进。  这里还包括对应用运行平台的要求，即两个体系下的应用，既可以运行在虚拟机之上，也可以运行在容器 /K8s 之上。我们不希望把用户绑定在 K8s 上，因此 Service Mesh 没有采用 K8s 的 Service 机制来做服务注册与发现，这里就突出了注册中心的重要性。\n百度智能云 CNAP 团队实现了上述混合微服务架构，即实现了两个微服务体系的应用互联互通、平滑迁移、灵活演进。上述混合微服务架构图包括以下几个组件：\n API Server：前后端解耦，接口权限控制、请求转发、异常本地化处理等等； 微服务控制中心：微服务治理的主要逻辑，包括服务注册的多租户处理、治理规则（路由、限流、熔断）的创建和转换、微服务配置的管理； 监控数据存储、消息队列：主要是基于 Trace 的监控方案使用的组件； 配置中心：微服务配置中心，最主要的功能是支持配置管理，包括治理规则、用户配置等所有微服务配置的存储和下发，微服务配置中心的特色是借助 SDK 可以实现配置/规则热更新。  接下来主要看一下注册中心的服务注册和发现机制：\n Spring Cloud 应用通过 SDK、Service Mesh 应用实现 Sidecar 分别向注册中心注册，注册的请求先通过微服务控制中心进行认证处理与多租户隔离； Mesh 控制面直接对接注册中心获取服务实例、Spring Cloud 应用通过 SDK 获取服务实例； 双模异构，支持容器与虚机两种模型。  注册中心与高可用方案 前面提到过，要想实现实现混合微服务架构，注册中心很关键。谈到注册中心，目前主流的开源注册中心包括：\n Zookeeper：Yahoo 公司开发的分布式协调系统，可用于注册中心，目前仍有很多公司使用其作为注册中心； Eureka：Netflix 开源组件，可用于服务注册发现组件，被广大 Spring Cloud 开发者熟知，遗憾的是目前已经不再维护，也不再被 Spring Cloud 生态推荐使用； Consul： HashiCorp 公司推出的产品，其可作为实现注册中心，也是本文介绍的重点； Etcd：Etcd 官方将其定义为可靠的分布式 KV 存储。  我们注册中心选择了 Consul，Consul 包含了以下几个重要的功能：\n 服务发现：可以注册服务，也可以通过 Http 或 DNS 的方式发现已经注册的服务； 丰富的健康检查机制； 服务网格能力，最新版本已经支持 Envoy 作为数据面； KV 存储：可以基于 Consul KV 存储实现一个分布式配置中心； 多数据中心：借助多数据中心，无需使用额外的抽象层，即可构建多地域的场景，支持多 DC 数据同步、异地容灾。  上图是 Consul 官网提供的架构图。Consul 架构中几个核心的概念如下：\n Agent: Agent 是运行在 Consul 集群的每个节点上的 Daemon 进程，通过 Consul Agent 命令将其启动，Agent 可以运行在 Client 或者 Server 模式下； Client：Client 是一种 Agent，其将会重定向所有的 RPC 请求到 Server，Client 是无状态的，其主要参与 LAN Gossip 协议池，其占用很少的资源，并且消耗很少的网络带宽； Server：Server 是一种 Agent，其包含了一系列的责任包括：参与 Raft 协议写半数（Raft Quorum）、维护集群状态、响应 RPC 响应、和其他 Datacenter 通过 WAN gossip 交换信息和重定向查询请求至 Leader 或者远端 Datacenter； Datacenter: Datacenter 其是私有的、低延迟、高带宽的网络环境，去除了在公共网络上的网络交互。  注册中心作为基础组件，其自身的可用性显得尤为重要，高可用的设计需要对其进行分布式部署，同时因在分布式环境下的复杂性，节点因各种原因都有可能发生故障，因此在分布式集群部署中，希望在部分节点故障时，集群依然能够正常对外服务。注册中心作为微服务基础设施，因此对其容灾和其健壮性有一定的要求，主要体现在：\n 注册中心作为微服务基础设施，因此要求出现某些故障（如节点挂掉、网络分区）后注册中心仍然能够正常运行； 当注册中心的发生故障时，不能影响服务间的正常调用。  Consul 使用 Raft 协议作为其分布式一致性协议，本身对故障节点有一定的容忍性，在单个 DataCenter中 Consul 集群中节点的数量控制在 2*n + 1 个节点，其中 n 为可容忍的宕机个数。Quorum size: Raft 协议选举需要半数以上节点写入成功。\nQ1: 节点的个数是否可以为偶数个？\nA2：答案是可以的，但是不建议部署偶数个节点。一方面如上表中偶数节点4和奇数节点3可容忍的故障数是一样的，另一方面，偶数个节点在选主节点的时候可能会出现瓜分选票的情形（虽然 Consul 通过重置 election timeout 来重新选举），所以还是建议选取奇数个节点。\nQ2: 是不是 Server 节点个数越多越好？\nA2：答案是否定的，虽然上表中显示 Server 数量越多可容忍的故障数越多，熟悉 Raft 协议的读者肯定熟悉 Log Replication（ 如上文介绍，日志复制时过半写成功才返回写成功），随着 Server 的数量越来越多，性能就会越低，所以结合实际场景一般建议 Server 部署3个节点。\n推荐采用三节点或五节点，最为有效，且能容错。\n注册中心设计的一个重要前提是：注册中心不能因为自身的原因或故障影响服务之间的相互调用。因此在实践过程中，如果注册中心本身发生了宕机故障/不可用，绝对不能影响服务之间的调用。这要求对接注册中心的 SDK 针对这种特殊情况进行客户端容灾设计，『客户端缓存』就是一种行之有效的手段。当注册中心发生故障无法提供服务时，服务本身并不会更新本地客户端缓存，利用其已经缓存的服务列表信息，正常完成服务间调用。\n我们在设计时采用同 Datacenter 集群内部部署3个 Server 节点，来保障高可用性，当集群中1个节点发生故障后，集群仍然能够正常运行，同时这3个节点部署在不同的机房，达到机房容灾的能力。\n在云上环境，涉及多 region 环境，因此在架构设计设计时，我们首先将 Consul 的一个 Datacenter 对应云上一个 region，这样更符合 Consul 对于 Datecenter 的定义（DataCenter 数据中心是私有性、低延迟、高带宽的网络环境）。中间代理层实现了服务鉴权、多租户隔离等功能；还可以通过中间代理层，对接多注册中心。\n云上环境存在多租户隔离的需求，即：A租户的服务只能发现A租户服务的实例。针对此场景，需要在 『中间代理层』完成对多租户隔离功能的实现，其主要实践思路为使用 Consul Api Feature 具备 Filtering 功能：\n 利用 Filtering 功能实现租户隔离需求； 减少查询注册中心接口时网络负载。  通过治理策略保证服务高可用 什么是高可用？维基百科这么定义：系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。我们通常用 N 个9来定义系统的可用性，如果能达到4个9，则说明系统具备自动恢复能力；如果能达到5个9，则说明系统极其健壮，具有极高可用性，而能达到这个指标则是非常难的。\n常见的系统不可用因素包括：程序和配置出 bug、机器故障、机房故障、容量不足、依赖服务出现响应超时等。高可用的抓手包括：研发质量、测试质量、变更管理、监控告警、故障预案、容量规划、放火盲测、值班巡检等。这里，将主要介绍通过借助治理策略采用高可用设计手段来保障高可用。\n高可用是一个比较复杂的命题，所以设计高可用方案也涉及到了方方面面。这中间将会出现的细节是多种多样的，所以我们需要对这样一个微服务高可用方案进行一个顶层的设计。\n比如服务冗余：\n 冗余策略：每个机器每个服务都可能出现问题，所以第一个考虑到的就是每个服务必须不止一份，而是多份。所谓多份一致的服务就是服务的冗余，这里说的服务泛指了机器的服务、容器的服务、还有微服务本身的服务。在机器服务层面需要考虑，各个机器间的冗余是否有在物理空间进行隔离冗余。 无状态化：我们可以随时对服务进行扩容或者缩容，想要对服务进行随时随地的扩缩容，就要求我们的服务是一个无状态化，所谓无状态化就是每个服务的服务内容和数据都是一致的。  比如柔性化/异步化：\n 所谓的柔性化，就是在我们业务允许的情况下，做不到给予用户百分百可用的，通过降级的手段给到用户尽可能多的服务，而不是非得每次都交出去要么 100 分或 0 分的答卷。柔性化更多是一种思维，需要对业务场景有深入的了解。 异步化：在每一次调用，时间越长存在超时的风险就越大，逻辑越复杂执行的步骤越多，存在失败的风险也就越大。如果在业务允许的情况下，用户调用只给用户必须要的结果，不是需要同步的结果可以放在另外的地方异步去操作，这就减少了超时的风险也把复杂业务进行拆分减低复杂度。  上面讲到的几种提高服务高可用的手段，大多需要从业务以及部署运维的角度实现。而接下来会重点介绍，可以通过 SDK/Sidecar 手段提供服务高可用的治理策略，这些策略往往对业务是非侵入或者弱侵入的，能够让绝大多数服务轻松实现服务高可用。\n微服务之间一旦建立起路由，就意味着会有数据在服务之间流通。由于不同服务可以提供的资源和对数据流量的承载能力不尽相同，为了防止单个 Consumer 占用 Provider 过多的资源，或者突发的大流量冲击导致 Provider 故障，需要服务限流来保证服务的高可用。\n在服务治理中，虽然我们可以通过限流规则尽量避免服务承受过高的流量，但是在实际生产中服务故障依然难以完全避免。当整个系统中某些服务产生故障时，如果不及时采取措施，这种故障就有可能因为服务之间的互相访问而被传播开来，最终导致故障规模的扩大，甚至导致整个系统奔溃，这种现象我们称之为“雪崩”。熔断降级其实不只是服务治理中，在金融行业也有很广泛的应用。比如当股指的波动幅度超过规定的熔断点时，交易所为了控制风险采取的暂停交易措施。\n负载均衡是高可用架构的一个关键组件，主要用来提高性能和可用性，通过负载均衡将流量分发到多个服务器，同时多服务器能够消除这部分的单点故障。\n以上治理规则在某种程度上可以在 Spring Cloud 与 Service Mesh 两个框架上进行对齐，即同一套治理配置，可以通过转换分发到 Spring Cloud 应用的 SDK 上以及 Service Mesh 的 Sidecar 上。可以由 Config-server 负责规则下发，也可以由 Service Mesh 的控制面负责下发，取决于具体的架构方案。\n服务限流 对于一个应用系统来说一定会有极限并发/请求数，即总有一个 TPS/QPS 阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务或进行流量整形。\n常用的微服务限流架构包括：\n 接入层（api-gateway）限流：  单实例； 多实例：分布式限流算法；   调用外部限流服务限流：  微服务收到请求后，通过限流服务暴露的 RPC 接口查询是否超过阈值； 需单独部署限流服务；   切面层限流（SDK）：  限流功能集成在微服务系统切面层，与业务解耦； 可结合远程配置中心使用；    常用的限流策略包括：\n 拒绝策略：  超过阈值直接返回错误； 调用方可做熔断降级处理。   延迟处理：  前端设置一个流量缓冲池，将所有的请求全部缓冲进这个池子，不立即处理。然后后端真正的业务处理程序从这个池子中取出请求依次处理，常见的可以用队列模式来实现（MQ：削峰填谷）； 用异步的方式去减少了后端的处理压力。   特权处理：  这个模式需要将用户进行分类，通过预设的分类，让系统优先处理需要高保障的用户群体，其它用户群的请求就会延迟处理或者直接不处理。    常用的限流算法包括：\n  固定时间窗口限流：\n 首先需要选定一个时间起点，之后每次接口请求到来都累加计数器，如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次接口请求），累加访问次数超过限流值，则限流熔断拒绝接口请求。当进入下一个时间窗口之后，计数器清零重新计数； 缺点在于：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。    滑动时间窗口算法：\n 流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题，是对固定时间窗口算法的一种改进； 缺点在于：需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。    令牌桶算法：\n 接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中； 桶中最多可以存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 会被丢弃； 接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 就阻塞或者拒绝服务。    漏桶算法：\n 对于取令牌的频率也有限制，要按照 t/n 固定的速度来取令牌； 实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃； 令牌桶和漏桶算法的算法思想大体类似，漏桶算法作为令牌桶限流算法的改进版本。    令牌桶算法和漏桶算法，在某些场景下（内存消耗、应对突发流量），这两种算法会优于时间窗口算法成为首选。\n熔断 断路器模式是微服务架构中广泛采用的模式之一，旨在将故障的影响降到最低，防止级联故障和雪崩，并确保端到端性能。我们将比较使用两种不同方法实现它的优缺点: Hystrix 和 Istio。\n在电路领域中，断路器是为保护电路而设计的一种自动操作的电气开关。它的基本功能是在检测到故障后中断电流，然后可以重置(手动或自动)，以在故障解决后恢复正常操作。这看起来与我们的问题非常相似：为了保护应用程序不受过多请求的影响，最好在后端检测到重复出现的错误时立即中断前端和后端之间的通信。Michael Nygard 在他的《Release It》一书中使用了这个类比，并为应用于上述超时问题的设计模式提供了一个典型案例，可以用上图来总结。\nIstio 通过 DestinationRule 实现断路器模式，或者更具体的路径 TrafficPolicy (原断路器) -\u0026gt; OutlierDetection，根据上图模型：\n consecutiveErrors 断路器打开前的出错次数； interval 断路器检查分析的时间间隔； baseEjectionTime 最小的开放时间，该电路将保持一段时间等于最小弹射持续时间和电路已打开的次数的乘积； maxEjectionPercent 可以弹出的上游服务的负载平衡池中主机的最大百分比，如果驱逐的主机数量超过阈值，则主机不会被驱逐。  与上述公称断路器相比，有两个主要偏差:\n 没有半开放的状态。然而，断路器持续打开的时间取决于被调用服务之前失败的次数，持续的故障服务将导致断路器的开路时间越来越长。 在基本模式中，只有一个被调用的应用程序(后端)。在更实际的生产环境中，负载均衡器后面可能部署同一个应用程序的多个实例。某些情况下有些实例可能会失败，而有些实例可能会工作。因为 Istio 也有负载均衡器的功能，能够追踪失败的实例，并把它们从负载均衡池中移除，在一定程度上: ‘maxEjectionPercent’ 属性的作用是保持一小部分的实例池。  Hystrix 提供了一个断路器实现，允许在电路打开时执行 fallback 机制。最关键的地方就在 HystrixCommand 的方法 run() 和 getFallback()：\n run() 是要实际执行的代码 e.g. 从报价服务中获取价格； getFallback() 获取当断路器打开时的 fallback 结果 e.g. 返回缓存的价格。  Spring Cloud 是建立在 Spring Boot 之上的框架，它提供了与 Spring 的良好集成。它让开发者在处理 Hystrix 命令对象的实例化时，只需注释所需的 fallback 方法。\n实现断路器的方法有两种，一种是黑盒方式，另一种是白盒方式。Istio 作为一种代理管理工具，使用了黑盒方式，它实现起来很简单，不依赖于底层技术栈，而且可以在事后配置。另一方面，Hystrix 库使用白盒方式，它允许所有不同类型的 fallback:\n 单个默认值； 一个缓存； 调用其他服务。  它还提供了级联回退（cascading fallbacks）。这些额外的特性是有代价的：它需要在开发阶段就做出fallback 的决策。\n这两种方法之间的最佳匹配可能会依靠自己的上下文: 在某些情况下，如引用的服务，一个白盒战略后备可能是一个更好的选择，而对于其他情况下快速失败可能是完全可以接受的，如一个集中的远程登录服务。\n常用的熔断方法包括自动熔断与手动熔断。发生熔断时也可以选择 fail-fast 或者 fallback。这些用户都可以基于需求灵活使用。\n智能路由 最后，我们来看一下智能路由带来的高可用。智能路由这里包括（客户端）负载均衡与实例容错策略。对于 Spring Cloud 框架来说，这部分能力由 Ribbon 来提供，Ribbon 支持随机、轮询、响应时间权重等负载均衡算法。而对于 Service Mesh 框架，这部分能力由 Envoy 提供，Envoy 支持随机、轮询（加权）、环哈希等算法。为了实现两套系统的规则统一对齐，可以采用其交集。\n而容错策略包括：\n failover：失败后自动切换其他服务器，支持配置重试次数； failfast：失败立即报错，不再重试； failresnd：将失败请求放入缓存队列、异步处理，搭配 failover 使用。  Istio 支持重试策略配置，而 fail-fast 即对应与重试次数为0。\n总结 微服务的高可用是一个复杂的问题，往往需要从多个角度去看，包括：\n 从手段看高可用。主要使用的技术手段是服务和数据的冗余备份和失效转移，一组服务或一组数据都能在多节点上，之间相互备份。当一台机器宕机或出现问题的时候，可以从当前的服务切换到其他可用的服务，不影响系统的可用性，也不会导致数据丢失。 从架构看高可用。保持简单的架构，目前多数网站采用的是比较经典的分层架构，应用层、服务层、数据层。应用层是处理一些业务逻辑，服务层提供一些数据和业务紧密相关服务，数据层负责对数据进行读写。简单的架构可以使应用层，服务层可以保持无状态化进行水平扩展，这个属于计算高可用。同时在做架构设计的时候，也应该考虑 CAP 理论。 从硬件看高可用。首先得确认硬件总是可能坏的，网络总是不稳定的。解决它的方法也是一个服务器不够就来多几个，一个机柜不够就来几个，一个机房不够就来几个。 从软件看高可用。软件的开发不严谨，发布不规范也是导致各种不可用出现，通过控制软件开发过程质量监控，通过测试，预发布，灰度发布等手段也是减少不可用的措施。 从治理看高可用。将服务规范化，事前做好服务分割，做好服务监控，预判不可用的出现，在不可用出现之前发现问题，解决问题。比如在服务上线后，根据经验，配置服务限流规则以及自动熔断规则。  参考资料  Service Mesh 概述 Consul 作为注册中心在云环境的实践与应用 有了这三个锦囊，再也不用担心微服务治理了 一文理解微服务高可用的常用手段 微服务断路器模式实现：Istio vs Hystrix  ","permalink":"https://cloudnative.to/blog/microservices-ha-practice/","tags":["service mesh","Microservices","Spring Cloud"],"title":"混合微服务高可用在企业级生产中的实践"},{"categories":["开源社区"],"contents":"2020 年伊始，受新冠疫情影响，全球各地的员工开启了在家办公的模式，因此人与人之间的距离感觉被拉远了。但是云原生圈子里有我们这样一群人，因为一个共同的愿景聚集到了一起，组建了社区管理委员会，并在过去的三个月里利用业余时间，齐心协力完成了社区的筹备工作。今天我们要正式宣布云原生社区正式成立了。\n成立背景  Software is eating the world. —— Marc Andreessen\n “软件正在吞噬这个世界” 已被大家多次引用，随着云原生（Cloud Native）的崛起，我们想说的是“Cloud Native is eating the software”。随着越来越多的企业将服务迁移上云，企业原有的开发模式以及技术架构已无法适应云的应用场景，其正在被重塑，向着云原生的方向演进。\n那么什么是云原生？云原生是一系列架构、研发流程、团队文化的最佳实践组合，以此支撑更快的创新速度、极致的用户体验、稳定可靠的用户服务、高效的研发效率。开源社区与云原生的关系密不可分，正是开源社区尤其是终端用户社区的存在，极大地促进了以容器、服务网格、微服务等为代表的云原生技术的持续演进！\n随着云计算的不断发展，云原生技术在全球范围内变得越来越受关注，同时国内社区同学也展现了对云原生技术热爱。近些年中国已经孕育众多的云原生技术爱好者，也有自发组织的一些相关技术交流和 meetup，同时在云原生领域也涌现了众多优秀的开源项目，在这样的背景下，一个有理想，有组织，有温度的云原生社区应运而生。\n关于云原生社区 云原生社区是一个有技术、有温度、有情怀的开源社区。由一群开源的狂热爱好者自发成立，秉持“共识、共治、共建、共享”的原则。社区的宗旨是：连接、中立、开源。立足中国，面向世界，企业中立，关注开源，回馈开源。\n关于云原生社区初创成员请查看初创成员列表。\n加入云原生社区，你将获得：\n 更接近源头的知识资讯 更富有价值的人际网络 更专业个性的咨询解答 更亲近意见领袖的机会 更快速高效的个人成长 更多知识分享曝光机会 更多行业人才挖掘发现  加入社区 关注云原生社区微信公众号，进入公众号后台，点击“加入社区”。\n","permalink":"https://cloudnative.to/blog/cnc-announcement/","tags":["社区"],"title":"云原生社区成立"},{"categories":null,"contents":"招聘对象 本次实习生招聘的要求为 将于 2021 年毕业且可以在 2020 年来实习的同学。\n岗位类型 研发类：操作系统、虚拟化、容器、安全、网络等方向，Go、Rust、C/C++、Java 等语言\n蚂蚁集团可信原生技术部介绍 蚂蚁集团可信原生技术部(TNT)是蚂蚁集团的计算基础设施的维护者，领域涵盖操作系统与虚拟化、容器与调度系统、网络与服务网格、中间件与平台服务等，更肩负着面向金融和民生服务的全栈可信的使命。\n我们也是开源社区的重要贡献力量，这里有Kata Containers 的创始团队，这里维护着 MOSN、SOFAStack、Occlum 等开源项目，还是 Kubernetes、Istio 等开源社区的积极贡献者。我们期待着你的加入。\n招聘流程 简历投递 -\u0026gt; 在线笔试及测评 -\u0026gt; 面试 -\u0026gt; 发放 offer -\u0026gt; 实习入职\nTips\n 一位同学不可以同时面好几个部门，进入哪个部门的招聘流程以同学首次确认的内推部门链接为准。 可以登录阿里巴巴集团招聘官网 https://job.alibaba.com 个人中心查看招聘进展。  实习与转正 拿到 offer 就可以正式入职，实习时长将根据同学的情况和业务实际情况进行安排，具体时间可以跟主管或 HR 商量。我们会在 8 到 9 月安排实习生转正面试，通过就会发放校招正式 offer！\n投递简历 请跳转到联系页面，填写表格，或者扫描二维码添加微信与我联系，欢迎邮件简历并说明对应的组，我们将尽快安排面试。\n关于蚂蚁集团云原生团队 蚂蚁集团云原生团队是服务于整个蚂蚁集团集团的核心技术团队，打造了世界领先的金融级分布式基础架构平台，拥有世界规模最大的 Kubernetes 集群，是 Service Mesh 领域的破局者和引路人，同时在积极探索 Serverless 领域，并将持续在云原生领域探索和深耕。\n","permalink":"https://cloudnative.to/job/intern-tnt/","tags":null,"title":"[实习生招聘] 蚂蚁集团可信原生技术部"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/lihui/","tags":null,"title":"厉辉"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/art-institute.1/","tags":null,"title":"Art Institute of Chicago"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/art-institute/","tags":null,"title":"Art Institute of Chicago"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/carpe-diem/","tags":null,"title":"Carpe Diem Santorini"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/celebrate-with/","tags":null,"title":"Celebrate with Stoli"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/essential-looks.1/","tags":null,"title":"Essential Looks Trend Report"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/essential-looks/","tags":null,"title":"Essential Looks Trend Report"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/zhangliying/","tags":null,"title":"张丽颖"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/jimmysong/","tags":null,"title":"宋净超（Jimmy Song）"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/suwei/","tags":null,"title":"粟伟"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/luoguangming/","tags":null,"title":"罗广明"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/dongyitao/","tags":null,"title":"董一韬"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/longheng/","tags":null,"title":"龙恒"}]