<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>敖小剑 | 云原生社区</title>
    <link>https://cloudnative.to/author/%E6%95%96%E5%B0%8F%E5%89%91/</link>
      <atom:link href="https://cloudnative.to/author/%E6%95%96%E5%B0%8F%E5%89%91/index.xml" rel="self" type="application/rss+xml" />
    <description>敖小剑</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Sat, 22 May 2021 13:00:00 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/author/%E6%95%96%E5%B0%8F%E5%89%91/avatar_hue38add62c87b7486d80c9f3fda25dfc1_12220_270x270_fill_q75_lanczos_center.jpg</url>
      <title>敖小剑</title>
      <link>https://cloudnative.to/author/%E6%95%96%E5%B0%8F%E5%89%91/</link>
    </image>
    
    <item>
      <title>云原生社区 meetup 第四期广州站</title>
      <link>https://cloudnative.to/event/cloud-native-meetup-guangzhou-04/</link>
      <pubDate>Sat, 22 May 2021 13:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/cloud-native-meetup-guangzhou-04/</guid>
      <description>&lt;h3 id=&#34;开场致辞&#34;&gt;开场致辞&lt;/h3&gt;
&lt;p&gt;讲师：宋净超（Tetrate 布道师、云原生社区创始人）&lt;/p&gt;
&lt;p&gt;讲师介绍：Tetrate 云原生布道师，云原生社区创始人，CNCF Ambassador。&lt;/p&gt;
&lt;h3 id=&#34;有了-nginx-和-kong为什么还需要-apache-apisix&#34;&gt;有了 Nginx 和 Kong，为什么还需要 Apache APISIX？&lt;/h3&gt;
&lt;p&gt;讲师：王院生&lt;/p&gt;
&lt;p&gt;个人介绍：支流科技联合创始人 CTO&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;演讲概要&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在云原生时代，k8s 和微服务已经成为主流，在带来巨大生产力提升的同时，也增加了系统的复杂度。如何发布、管理和可视化服务，成为了一个重要的问题。每次修改配置都要 reload 的 Nginx、依赖 postgres 才能工作的 Kong，都不是云原生时代的理想之选。这正是我们创造 Apache APISIX 的原因：没有 reload、毫秒内全集群生效、不依赖数据库、极致性能、支持 Java 和 Go 开发插件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听众收益&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;更好的理解 API 网关、服务网格，以及各个开源项目的优劣势&lt;/p&gt;
&lt;h3 id=&#34;云原生时代的研发效能&#34;&gt;云原生时代的研发效能&lt;/h3&gt;
&lt;p&gt;讲师：黄国峰&lt;/p&gt;
&lt;p&gt;个人介绍：腾讯 PCG 工程效能专家。10 多年的软件和互联网从业经验；现任腾讯工程效能部，负责持续集成、研发流程和构建系统等平台；曾任职唯品会高级经理，负责架构团队。在云原生平台下的研发效能方向有丰富的理论知识和实践经验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;演讲概要&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;云原生时代，软件研发的逻辑彻底改变了。传统的软件开发在本机编码 / 调试、部署到测试环境测试、再发布到生产环境；而云原生时代的开发，基于不可变设施，研发流程从编码、构建、持续测试、持续集成到持续部署，整个过程几乎完全代码化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听众收益&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解云原生开发的新挑战和难点&lt;/li&gt;
&lt;li&gt;了解腾讯云原生开发实践的流程和思路&lt;/li&gt;
&lt;li&gt;了解腾讯云原生开发中的遇到的坑和解决思路&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;37-手游-go-微服务架构演进和云原生实践&#34;&gt;37 手游 Go 微服务架构演进和云原生实践&lt;/h3&gt;
&lt;p&gt;讲师：吴凌峰&lt;/p&gt;
&lt;p&gt;个人介绍：任职于三七互娱集团 37 手游技术部基础架构组，负责平台 golang 基础框架以及 DevOps、CI/CD 生态建设，从业以来一直专注于云原生、DevOps 和容器化等技术应用和推广，在 golang 工程化领域有一定的心得。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;演讲概要&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Golang 微服务应用和云原生的概念近年越来越火热，传统技术栈公司随着业务规模增长，在云原生技术应用落地探索和转型的过程中一定会遇到很多共通的问题以及有各自不同的思考，包括如何更好地提升我们的开发效率、提升服务稳定性、降低运维成本？面对不断增长的服务数量和不断变长变复杂的调用关系网，怎样才能更好地观测、管理和保证核心服务高可用，本次演讲分享将会围绕 37 手游转型为 Go 微服务架构以及建设云原生 DevOps 体系的历程、过程中的领悟和思考展开。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听众收益&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解 Golang 云原生微服务框架的关键技术和优化实践经验&lt;/li&gt;
&lt;li&gt;了解云原生观测体系如链路追踪、监控等 Golang 微服务落地实践经验&lt;/li&gt;
&lt;li&gt;了解混合云混合部署 DevOps 和 CI/CD 体系的企业实践经验&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;死生之地不可不察论-api-标准化对-dapr-的重要性&#34;&gt;死生之地不可不察：论 API 标准化对 Dapr 的重要性&lt;/h3&gt;
&lt;p&gt;讲师：敖小剑&lt;/p&gt;
&lt;p&gt;个人介绍：资深码农，十九年软件开发经验，微服务专家，Service Mesh 布道师，Servicemesher 社区联合创始人，Dapr Maintainer。专注于基础架构，Cloud Native 拥护者，敏捷实践者，坚守开发一线打磨匠艺的架构师。曾在亚信、爱立信、唯品会、蚂蚁金服等任职，对基础架构和微服务有过深入研究和实践。目前就职阿里云，在云原生应用平台全职从事 Dapr 开发。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;演讲概要&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dapr 作为新兴的云原生项目，以 &amp;ldquo;应用运行时&amp;rdquo; 之名致力于围绕云原生应用的各种分布式需求打造一个通用而可移植的抽象能力层。这个愿景有着令人兴奋而向往的美好前景：一个受到普通认可和遵循的云原生业界标准，基于此开发的云原生应用可以在不同的厂家的云上自由的部署和迁移，恍惚间一派云原生下世界大同的美景。然而事情往往没这么简单，API 的标准化之路异常的艰辛而痛苦，Dapr 的分布式能力抽象在实践中会遇到各种挑战和困扰。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听众收益&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解 Dapr 的愿景和分布式能力抽象层的重要&lt;/li&gt;
&lt;li&gt;了解 Dapr API 在抽象和实现时遇到的实际问题，尤其是取舍之间的艰难&lt;/li&gt;
&lt;li&gt;了解目前 Dapr 在 API 抽象上正在进行的努力和新近准备增加的 API&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh Meetup #6 广州站</title>
      <link>https://cloudnative.to/event/service-mesh-meetup-06/</link>
      <pubDate>Sun, 11 Aug 2019 13:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/service-mesh-meetup-06/</guid>
      <description>&lt;h2 id=&#34;讲师与演讲话题&#34;&gt;讲师与演讲话题&lt;/h2&gt;
&lt;h4 id=&#34;虎牙直播在微服务改造方面的实践&#34;&gt;虎牙直播在微服务改造方面的实践&lt;/h4&gt;
&lt;p&gt;张波 虎牙基础保障部中间件团队负责人&lt;/p&gt;
&lt;p&gt;本次主要分享虎牙注册中心、名字服务、DNS 的改造实践，以及如何通过 Nacos 实现与 istio 打通实现，使微服务平滑过渡到 service mesh。&lt;/p&gt;
&lt;h4 id=&#34;service-mesh-在蚂蚁集团的生产级安全实践&#34;&gt;Service Mesh 在蚂蚁集团的生产级安全实践&lt;/h4&gt;
&lt;p&gt;彭泽文 蚂蚁集团高级开发工程师&lt;/p&gt;
&lt;p&gt;介绍通过 Envoy SDS（Secret Discovery Service）实现 Sidecar 证书管理的落地方案；分享如何为可信身份服务构建敏感信息数据下发通道，以及 Service Mesh Sidecar 的 TLS 生产级落地实践。&lt;/p&gt;
&lt;h4 id=&#34;基于-kubernetes-的微服务实践&#34;&gt;基于 Kubernetes 的微服务实践&lt;/h4&gt;
&lt;p&gt;涂小刚 慧择网运维经理&lt;/p&gt;
&lt;p&gt;介绍如何跟据现有业务环境情况制定容器化整体解决方案，导入业务进入 K8S 平台，容器和原有业务环境互通。制订接入规范、配置中心对接 K8S 服务、网络互通方案、DNS 互通方案、jenkins-pipeline 流水线构建方案、日志采集方案、监控方案等。&lt;/p&gt;
&lt;h4 id=&#34;service-mesh-发展趋势续棋到中盘路往何方&#34;&gt;Service Mesh 发展趋势（续）：棋到中盘路往何方&lt;/h4&gt;
&lt;p&gt;敖小剑 蚂蚁集团高级技术专家&lt;/p&gt;
&lt;p&gt;继续探讨 Service Mesh 发展趋势：深度分析 Istio 的重大革新 Mixer v2，Envoy 支持 Web Assembly 的意义所在，以及在 Mixer v2 出来之前的权宜之计; 深入介绍 Google Traffic Director 对虚拟机模式的创新支持方式，以及最近围绕 SMI 发生的故事。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh Meetup #5 广州站</title>
      <link>https://cloudnative.to/event/service-mesh-meetup-05/</link>
      <pubDate>Sun, 06 Jan 2019 13:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/service-mesh-meetup-05/</guid>
      <description>&lt;h3 id=&#34;讲师与演讲话题&#34;&gt;讲师与演讲话题&lt;/h3&gt;
&lt;h4 id=&#34;唯品会-service-mesh-的实践分享&#34;&gt;唯品会 Service Mesh 的实践分享&lt;/h4&gt;
&lt;p&gt;郑德惠 唯品会Java资深开发工程师，内部Service Mesh框架负责人，唯品会开源项目vjtools重要开发者，10年电信与互联网后台开发经验。&lt;/p&gt;
&lt;h4 id=&#34;sofamosn-持续演进路径及实践案例&#34;&gt;SOFAMosn 持续演进路径及实践案例&lt;/h4&gt;
&lt;p&gt;陈逸凡 花名无钩，蚂蚁集团资深开发工程师。专注于网络接入层，高性能服务器研发，SOFAMosn团队核心成员&lt;/p&gt;
&lt;h4 id=&#34;在网格的边缘试探企业-istio-试水指南&#34;&gt;在网格的边缘试探——企业 Istio 试水指南&lt;/h4&gt;
&lt;p&gt;崔秀龙 HPE 软件分析师，Kubernetes 权威指南作者之一，Kubernetes、Istio 项目成员&lt;/p&gt;
&lt;h4 id=&#34;roundtable回顾2018service-mesh-蓄势待发&#34;&gt;Roundtable：回顾2018，Service Mesh 蓄势待发&lt;/h4&gt;
&lt;p&gt;主持人：宋净超，ServiceMesher 社区联合创始人&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>蚂蚁金服Service Mesh渐进式迁移方案</title>
      <link>https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/</link>
      <pubDate>Thu, 29 Nov 2018 14:51:19 +0800</pubDate>
      <guid>https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxs8jrwxj30qo0f0dip_hu4a3b32a88c8396d265cfc59ec77d7192_167449_8a242ddad2282a0685afab3cc2f5f44d.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxs8jrwxj30qo0f0dip_hu4a3b32a88c8396d265cfc59ec77d7192_167449_37985eac874242e92d4ec0fb83e5063c.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxs8jrwxj30qo0f0dip_hu4a3b32a88c8396d265cfc59ec77d7192_167449_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxs8jrwxj30qo0f0dip_hu4a3b32a88c8396d265cfc59ec77d7192_167449_8a242ddad2282a0685afab3cc2f5f44d.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;大家好，今天给大家带来的演讲主题是“蚂蚁金服Service Mesh渐进式迁移方案”，给大家介绍一下我们蚂蚁金服主站的Service Mesh迁移方案，在稍后的内容中我会给大家解释什么是“渐进式”。今天的演讲方式有些特殊，将会是两位讲师合作。我是敖小剑，来自蚂蚁金服中间件团队，另外一位讲师 龙轼 ，来自 UC 基础研发部。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsexhquj30qo0f0n08_hu977e838d7c4f5e8372ce741d84e80edd_68984_86f353eb36286633f33d64f9924f8f18.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsexhquj30qo0f0n08_hu977e838d7c4f5e8372ce741d84e80edd_68984_d6e598ab1db77d4053b2ffecfb42f05b.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsexhquj30qo0f0n08_hu977e838d7c4f5e8372ce741d84e80edd_68984_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsexhquj30qo0f0n08_hu977e838d7c4f5e8372ce741d84e80edd_68984_86f353eb36286633f33d64f9924f8f18.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;今天的内容将会有四块主要内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Service Mesh演进路线：介绍蚂蚁金服计划在主站落地Service Mesh的方案，由于涉及到大量的存量应用和超大规模，又要保证迁移过程的平滑，因此我们的落地方案相比社区方案要复杂的多。&lt;/li&gt;
&lt;li&gt;实现平滑迁移的关键：介绍在整个迁移方案中，为了实现平滑迁移的几个关键做法，然后今天我们将详细展开其他的一个关键点：DNS寻址方案。&lt;/li&gt;
&lt;li&gt;DNS寻址方案的演进：详细介绍Kubernetes/Istio/SOFAMesh一路演进过来的DNS寻址方式&lt;/li&gt;
&lt;li&gt;DNS寻址方案的后续规划：介绍我们在DNS寻址方案上的后续规划&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;前两块内容将由我来为大家介绍，后两块内容将由我的同事 龙轼 为大家介绍。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsiq2z5j30qo0f0grx_hu4526358426093cb81d1d511445dc3bc4_98449_8342359fd492952ac642be0a0b54c95b.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsiq2z5j30qo0f0grx_hu4526358426093cb81d1d511445dc3bc4_98449_d120787dbed485378c8202032e136354.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsiq2z5j30qo0f0grx_hu4526358426093cb81d1d511445dc3bc4_98449_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsiq2z5j30qo0f0grx_hu4526358426093cb81d1d511445dc3bc4_98449_8342359fd492952ac642be0a0b54c95b.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在展开内容之前，先看一下背景，Service Mesh在蚂蚁金服主站落地的背景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目标：需要满足我们对长期目标的认可，具体指服务间通讯走Service Mesh，而且是Istio这种带完整的控制平面的Service Mesh形态，基础设施要构建在k8s之上，而应用的形态要向微服务靠拢。&lt;/li&gt;
&lt;li&gt;现状：而现实是存在很多挑战，首先还有很多应用没有实现微服务化，而且我们的k8s普及程度也不够，还有非常多的应用没有运行在kubernets之上。Istio的成熟程度也稍显不足，不够稳定，更大的挑战的是Istio目前无法原生支持我们蚂蚁金服的规模，我们还在试图对Istio进行改进和扩展。最后，在落地时必须考虑的非常现实的一点：现有系统中为数众多的应用不可能一夜之间全部迁移。&lt;/li&gt;
&lt;li&gt;关键需求：因此在落地实施时，非常重要的需求是：要实现平滑迁移。简单说，微服务 + Service Mesh + kubernetes 是我们的目标，但是如何从现有体系出发，向目标平稳和坚实的迈进，必须给出可行的实践指导。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今天演讲的内容，要给大家介绍的就是，在这样的背景下，我们蚂蚁金服选择的Service Mesh主站落地演进方案。这个方案预期会在2019年初全面铺开。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsmb5l9j30qo0f0q4s_hu402aa2e88802ea32909fa949f402e459_82037_0e9b30a10c71f1d4454fecc2f82ffb82.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsmb5l9j30qo0f0q4s_hu402aa2e88802ea32909fa949f402e459_82037_a5b9d6bf9a0479f74fcea8cf44b2a893.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsmb5l9j30qo0f0q4s_hu402aa2e88802ea32909fa949f402e459_82037_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsmb5l9j30qo0f0q4s_hu402aa2e88802ea32909fa949f402e459_82037_0e9b30a10c71f1d4454fecc2f82ffb82.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;主站落地方案的实施原则，这是我们在过去半年的实践中，总结归纳出来的行为指导：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;符合远期规划：一定要有清晰的长期目标，明确的知道未来的大方向。避免走弯路，避免浪费投资，理想状态是计划中的每一步都可以为下一步奠定坚实的基础。即使因为某些原因不得已妥协或绕行，也应该清晰的知道后面应该如何回归，谢绝中途推倒重来——代价太高，无法承受。&lt;/li&gt;
&lt;li&gt;循序渐进：认清现实，如此之大的变革，一定是需要分步进行，不要心存一步登天的幻想，现实可行的方式是小步快跑。将整个过程拆解为若干个大步骤，每一步的工作量和复杂度都控制在一个可以接受的范围内，以保证每一步都简单方便，切实可行。&lt;/li&gt;
&lt;li&gt;有可操作性：在操作层面上，要有足够的弹性，即每个步骤中的工作内容，都应该是可以分批进行。以步步为营的方式，逐步扩大战果，杜绝一刀切。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在接下来的演进路线中，大家将会体会到这三个原则在实际落地时的指导作用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsq62x9j30qo0f0ac4_hu3bf363c7e8d4732518622ceb41127651_135314_8024961fdb7abbdabafb5de19c59e249.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsq62x9j30qo0f0ac4_hu3bf363c7e8d4732518622ceb41127651_135314_5a47b980fc17064ee9eefbad58b196c0.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsq62x9j30qo0f0ac4_hu3bf363c7e8d4732518622ceb41127651_135314_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsq62x9j30qo0f0ac4_hu3bf363c7e8d4732518622ceb41127651_135314_8024961fdb7abbdabafb5de19c59e249.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这个图的信息量有点大，描述的是 Service Mesh 和 k8s 落地可能的多种演进路线。&lt;/p&gt;
&lt;p&gt;我们先从最下面开始看，这是当前蚂蚁金服主站大多数应用的现状：即应用&amp;quot;部署在非k8s上&amp;quot;，应用也&amp;quot;不是Service Mesh形态&amp;quot;。 然后看最上面，这是我们期望的蚂蚁金服主站未来的应用终极形态：应用&amp;quot;部署在k8s上&amp;quot;，应用也迁移到了&amp;quot;Service Mesh形态&amp;quot;。&lt;/p&gt;
&lt;p&gt;这里有个特别的地方，我们将Service Mesh形态细分为两种模式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sidecar模式：只有Sidecar，没有控制平面，和外部系统的各种集成都是在Sidecar中直接进行。这是第一代的Service Mesh，Linkerd/Envoy都是如此，华为基于ServiceComb演进而来的mesher，新浪微博的Mesh，包括我们蚂蚁金服基于MOSN开发的用于取代多语言客户端的Mesh方案。&lt;/li&gt;
&lt;li&gt;Istio模式：有完善的控制平面，可以提供强大的控制能力，而且从数据平面分离，这是第二代的Service Mesh，典型如Istio和Conkduit/Linkerd 2.0。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之所以将Service Mesh形态细分，是因为我们有着这样一个特殊背景：目前的原生Istio无法支撑我们蚂蚁金服的规模，因此在改进完善Istio之前，我们不得不暂时在Sidecar模式下短暂停留。另外一个原因就是考虑到存量应用的迁移，多一个Sidecar模式作为中间缓冲，会让整个迁移过程平滑很多。&lt;/p&gt;
&lt;p&gt;现在我们来介绍图中展示的四条演进路线：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;左边的路线1，思路是先将应用迁移k8s部署，再迁移到Service Mesh形态。这条路线的最大好处，是过程中每个阶段的绝大多数投资都将最终得以保留，因为符合k8s+service mesh的远期目标&lt;/li&gt;
&lt;li&gt;右边的路线2，思路是跳过k8s，先迁移到Service Mesh形态，一路演进到Istio模式，然后最后迁移到k8s。&lt;/li&gt;
&lt;li&gt;中间的路线3，直接一步到位，这个路线是Istio默认的方式，或者说Istio根本没有考虑过迁移的问题，默认客户已经有完善的k8s，然后将改造好的应用直接部署在Istio上。这个路线对于蚂蚁金服主站的复杂场景，当然是不现实的。（补充：只是对蚂蚁金服主站不合适，对于大多数公司，规模不是那么巨大，也没有历史负担，也有k8s基础，完全可行。）&lt;/li&gt;
&lt;li&gt;还有一条特别的路线4，走位飘忽，先和路线2一样迁移到Sidecar模式，然后走回路线1，上k8s，再在有k8s支持的情况下继续演进到Istio模式。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面我们来详细分析各条演进路线的优劣和实施条件。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxstzrdqj30qo0f040q_hu62b11a76dad8a88e316ad3163be615bd_115780_fd7458b3e103aaae9c1d8b98697f4791.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxstzrdqj30qo0f040q_hu62b11a76dad8a88e316ad3163be615bd_115780_54787580d7a6c358bf0a0d9da4577e00.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxstzrdqj30qo0f040q_hu62b11a76dad8a88e316ad3163be615bd_115780_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxstzrdqj30qo0f040q_hu62b11a76dad8a88e316ad3163be615bd_115780_fd7458b3e103aaae9c1d8b98697f4791.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;演进路线2，和路线1的核心差别，在于：是先上k8s，还是先上Service Mesh。而且路线2是在非k8s条件下一路演进Service Mesh到我们期望的终极形态Istio模式，这意味着过程中和最终目标有非常大的偏移。&lt;/p&gt;
&lt;p&gt;演进路线2的好处，在于第一步非常的自然：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有k8s的限制，因此不依赖基础设施，实施方便。毕竟，k8s普及度是个大问题&lt;/li&gt;
&lt;li&gt;在原有的侵入式框架的客户端SDK基础上，通过包裹一个proxy，重用原有SDK的能力，可以非常快速的得到一个基本可用的Sidecar&lt;/li&gt;
&lt;li&gt;除了多一个proxy外，没有引入太多的新概念和新思想，符合现有开发人员/运维人员的心智，容易接受&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，路线2特别容易落地，可以快速达成短期目标，直接拿到Service Mesh的部分红利，如：多语言支持，方便类库升级等。&lt;/p&gt;
&lt;p&gt;但是，这个路线的问题在于再往后走，开始完善Service Mesh的功能以向Istio模式靠拢时，由于没有k8s的底层支持，因此不得不做大量的工作来提供类k8s的功能。尤其是Istio的非k8s支持，官方方案基本上只是一个demo，完全不具备生产可用性，要完善好，工作量很大。而关键点在于，这些投入，在迁移到k8s时，又因为和k8s提供的功能重复而被放弃。&lt;/p&gt;
&lt;p&gt;因此，结合我们前面的原则（符合远期规划，不浪费投资），路线2对蚂蚁金服主站落地是不合适的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsx61iuj30qo0f0wg9_hu3c9b62438d33ebf51afa853a20e2b041_111945_11a5fbf86949b8cd92b4dff4bfd357a9.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsx61iuj30qo0f0wg9_hu3c9b62438d33ebf51afa853a20e2b041_111945_f813a0595c5572cf4c7f9ea878cb4ddb.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsx61iuj30qo0f0wg9_hu3c9b62438d33ebf51afa853a20e2b041_111945_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxsx61iuj30qo0f0wg9_hu3c9b62438d33ebf51afa853a20e2b041_111945_11a5fbf86949b8cd92b4dff4bfd357a9.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;演进路线4是一个非常特殊的路线，可以理解为路线1（先上k8s再上Service Mesh）的短期妥协版本。因为路线1的前提条件是要先大规模铺开k8s，将现有应用迁移到k8s之后再继续往Service Mesh演进，这对于还没有普及k8s的公司来说是一个非常高的门槛，很容易因此受阻而无法启动。&lt;/p&gt;
&lt;p&gt;因此，如果暂时不具备k8s条件， 又不想就此止步，那么选择路线2是唯一的出路。而上面我们分析过，路线2虽然能够在第一步快速拿到短期红利，但是由于偏离长期目标后续发展会有问题。怎么办？&lt;/p&gt;
&lt;p&gt;路线4可以是这种场景下的一个折衷选择：在k8s没有铺开之前，第一步沿路线2走，先吃下非k8s下Sidecar模式快速落地的红利。然后第二步避开非k8s下继续演进到Istio模式的大坑，切换到路线1，回归长期目标。&lt;/p&gt;
&lt;p&gt;好处非常明显：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在k8s未铺开前，先往前迈进一步，避免就此卡壳&lt;/li&gt;
&lt;li&gt;和路线2一样，第一步可以快速的拿到短期红利&lt;/li&gt;
&lt;li&gt;后续转为路线1后，因为符合远期规划，因此后续演进不存在投资浪费的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点就是存在少量的投资浪费，毕竟非k8s下的Sidecar模式还是有些工作内容在迁移到k8s之后会有改动。不过，这个改动不会太大，和拿到的红利相比还是值得的。&lt;/p&gt;
&lt;p&gt;路线4在操作时，存在一个变数：现有应用在向Sidecar模式的Service Mesh迁移，是需要一定时间的。有一种可能，就是在迁移过程中，k8s的普及开始了。这个变数的发生，取决于Sidecar模式的Service Mesh普及快，还是k8s的普及快。&lt;/p&gt;
&lt;p&gt;对路线4的分析结果：这是（k8s没有普及的）特殊时期的选择。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxszj2wkj30qo0f0abt_hu722e4117e2e626dfd92d368860c5d25e_118020_0cdfcaee56adb92ece39049ca5a609e3.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxszj2wkj30qo0f0abt_hu722e4117e2e626dfd92d368860c5d25e_118020_cda8a13b46344ecbbbae37743bcdc046.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxszj2wkj30qo0f0abt_hu722e4117e2e626dfd92d368860c5d25e_118020_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxszj2wkj30qo0f0abt_hu722e4117e2e626dfd92d368860c5d25e_118020_0cdfcaee56adb92ece39049ca5a609e3.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在对四条可能的演进路线分析完成之后，我们来具体介绍蚂蚁金服的最终选择。&lt;/p&gt;
&lt;p&gt;坦言说，在过去半年中，我们的演进路线有几次摇摆和修订，今天我们公布的路线，和过去几个月中我们通过 meetup/技术大会/博客文章 等方式透露出来的方式会有一些变化。主要原因是在过去的这半年中，一方面我们对Sercice Mesh的认知更加深入，另一方面是蚂蚁金服的k8s背景也在变化。&lt;/p&gt;
&lt;p&gt;首先，在今年年初，我们确认Service Mesh大方向时，k8s还没有在蚂蚁金服普及，而且也没有明确的时间表。因此，我们在一番调研之后，选择了两条腿走路的方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在非k8s环境下，以Sidecar模式先进行少量落地，主要是替换掉原有的多语言客户端 （拿短期红利）&lt;/li&gt;
&lt;li&gt;开发SOFAMesh，集成MOSN到Istio，增加对多种RPC协议的支持，增加对RPC服务模式的兼容（为最终目标做准备 ）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在今年6月底的杭州第一届Service Mesh 线下 meetup 中，我们公布了 SOFAMesh 项目，我当时做了一个演讲 &lt;a href=&#34;https://skyao.io/publication/201806-service-mesh-explore/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;大规模微服务架构下的Service Mesh探索之路&lt;/a&gt; ，有兴趣的同学可以去回顾一下我们当时的背景/需求/设计方案。&lt;/p&gt;
&lt;p&gt;大概在今年九月，我们完成了对非k8s下运行istio的深入调研，得出的结论是要实现这个模式需要非常多的工作。而且，我们对Service Mesh的认知也更加深刻，明确了通过Service Mesh将传统中间件能力向以k8s为代表的基础设施层下沉的战略方向。期间，内部也明确了k8s普及的大方向，因此，综合这两个重要输入，我们选择放弃继续在路线2上继续演进（即 istio on 非k8s）的想法。关于这一点，有兴趣的同学可以去阅读我在10月份QCon大会上的演讲内容 &lt;a href=&#34;https://skyao.io/publication/201810-ant-finance-service-mesh-practice/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;长路漫漫踏歌而行：蚂蚁金服Service Mesh实践探索&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;最近，k8s普及的时间表再一次明确提前，蚂蚁金服将会在短时间内开启k8s的大面积普及。因此，我们的演进路线再一次发生变化。目前最新的演进路线将会是这样：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当前还没有开始迁移的应用（处于演进路线图最下方），将按照路线1的方式进行迁移：先迁移到k8s，再迁移到Sidecar模式的Service Mesh&lt;/li&gt;
&lt;li&gt;目前部分已经迁移的应用（路线2/4的第一步，非k8s部署的 Sidecar 模式），将沿路线4迁移，和路线1会师&lt;/li&gt;
&lt;li&gt;由于应用众多，因此预计到 k8s + Sidecar模式 的迁移工作会持续比较长时间，在此期间，我们会同步完善Istio，和Istio官方一起合作来实现Istio对超大规模部署的支持&lt;/li&gt;
&lt;li&gt;最后一步，迁移到最终目标（当然这一步的方案依然有很多待定内容，继续努力）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;需要强调的是：这个演进路线针对的是蚂蚁金服主站的特殊场景，并不具体普适性。大家可以在理解我们演进路线背后的思路和权衡方式之后，再结合自身的实际情况进行决策。比如，我们在UC落地时，由于UC有完善的k8s支持，而且目前落地的规模没那么夸张，因此是直接从&amp;quot;部署在k8s上&amp;quot; + &amp;ldquo;不是Service Mesh形态&amp;rdquo;，直接迁移到终态的。预计在金融云落实时，也会是如此，因为客户也不会有如此规模。&lt;/p&gt;
&lt;p&gt;总结：前面我们介绍了当应用程序向Service Mesh和K8s迁移时的几种可能的演进路线，分析了各条路线的利弊。并以蚂蚁金服主站为例，介绍了我们迁移的背景和演进路线的选择思路，希望能够帮助大家更好的理解Service Mesh的落地实践，以便在未来设计自家的落地方案时能有所参考。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt3aatgj30qo0f0juh_hud6d28e89c2570976eff46bb02abe27c8_70362_b286ed958b4244bc8eda7bfe1014ade3.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt3aatgj30qo0f0juh_hud6d28e89c2570976eff46bb02abe27c8_70362_d38df97efc4e9a8d55bae95ba83e4d09.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt3aatgj30qo0f0juh_hud6d28e89c2570976eff46bb02abe27c8_70362_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt3aatgj30qo0f0juh_hud6d28e89c2570976eff46bb02abe27c8_70362_b286ed958b4244bc8eda7bfe1014ade3.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;前面给大家介绍了蚂蚁金服主站的Service Mesh演进路线，期间谈到要实现现有应用的平滑迁移。今天的第二个内容，将给大家介绍平滑迁移实现中的几个关键做法。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt72zxjj30qo0f0jse_hu1f1582dc4302e2622069dcc8a4e2fa75_80006_7cab0e070d31baa0760efc8d1c444e12.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt72zxjj30qo0f0jse_hu1f1582dc4302e2622069dcc8a4e2fa75_80006_d35a9a9368b894c58b1a9800527d0ba7.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt72zxjj30qo0f0jse_hu1f1582dc4302e2622069dcc8a4e2fa75_80006_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt72zxjj30qo0f0jse_hu1f1582dc4302e2622069dcc8a4e2fa75_80006_7cab0e070d31baa0760efc8d1c444e12.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;首先，第一个关键是尽量保证迁移前后服务间网络互通。&lt;/p&gt;
&lt;p&gt;以向k8s迁移为例，在非k8s环境，典型的服务间访问方式是这样：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个服务向注册中心注册&lt;/li&gt;
&lt;li&gt;客户端发起访问前，通过注册中心得到目标服务的实例列表信息，如IP地址/端口等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在向k8s迁移的过程中，我们的做法是保证k8s内外网络打通，即服务的IP地址（在k8s中是pod ip）是可以相互直接访问的。基于这个前提，服务在迁移到k8s的过程中，原有的服务注册/服务发现/发起请求等逻辑都无需修改，是不是在k8s内，是不是pod ip，对原有服务化体系完全是透明的。&lt;/p&gt;
&lt;p&gt;因此，向k8s的迁移可以做到对业务应用非常的平滑，基本感知。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt9dqbsj30qo0f00uq_hu38f90e61ee08e13f3127d98191d7fc59_117364_e48be22c73a5f82b68930ba7d2e62077.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt9dqbsj30qo0f00uq_hu38f90e61ee08e13f3127d98191d7fc59_117364_5589029536eafab14e990610731e9524.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt9dqbsj30qo0f00uq_hu38f90e61ee08e13f3127d98191d7fc59_117364_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxt9dqbsj30qo0f00uq_hu38f90e61ee08e13f3127d98191d7fc59_117364_e48be22c73a5f82b68930ba7d2e62077.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;透明拦截在迁移过程中，可以起到非常关键的作用。&lt;/p&gt;
&lt;p&gt;以Service-A要访问Service-B，在应用向Sidecar模式的Service Mesh迁移前后，会有有四种排列组合场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Service-A和Service-B都没有迁移到Serive Mesh：此时请求会直接从Service-A发送到Service-B，称为直连，这是应用在开始迁移到Service Mesh之前的标准工作方式&lt;/li&gt;
&lt;li&gt;Service-A已经迁移到Service Mesh，Service-B还没有：此时Service-A发出来的请求，会被劫持，然后发送到和Service-A一起部署的Sidecar（称为Outbound Sidecar），此时链路中只有一个Sidecar，称为（客户端）单跳&lt;/li&gt;
&lt;li&gt;Service-B已经迁移到Service Mesh，Service-A还没有：此时Service-A发出来的请求，在到达Service-B时，会被劫持到和Service-B一起部署的Sidecar（称为Inbound Sidecar），此时链路中也只有一个Sidecar，称为（服务器端）单跳&lt;/li&gt;
&lt;li&gt;Service-A和Service-B都迁移到Serive Mesh：此时Service-A发出来的请求，会被两次劫持，分别进入Outbound Sidecar和Inbound Sidecar，此时链路中有两个Sidecar，称为双跳。这是Istio的标准工作模式，也是我们迁移完成之后的最终工作模式。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在这四种场景中，所有的网络请求，请求报文都是完全一致的，即不管是否被劫持到Sidecar，对请求报文都没有影响，也就是对发出请求报文的客户端和接受请求报文的客户端都是透明的，完全无感之。&lt;/p&gt;
&lt;p&gt;因此，在迁移过程中，可以单个服务逐个迁移，甚至服务的单个实例逐个迁移，而无需修改应用本身。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtcjj4wj30qo0f0jt1_hu55e4dd56695cccb8061149bd9672512b_123646_39d371b9297d55493c047c9a6de7d6a3.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtcjj4wj30qo0f0jt1_hu55e4dd56695cccb8061149bd9672512b_123646_d681b6b33e2d792ade6428c8ed5adbee.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtcjj4wj30qo0f0jt1_hu55e4dd56695cccb8061149bd9672512b_123646_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtcjj4wj30qo0f0jt1_hu55e4dd56695cccb8061149bd9672512b_123646_39d371b9297d55493c047c9a6de7d6a3.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在展开第三个关键点之前，我们来探讨一下：在Service Mesh时代，理想的客户端应该是什么样子？&lt;/p&gt;
&lt;p&gt;图中我们列举了一个传统的侵入式框架的客户端所包含的功能，在侵入式框架中，大部分的功能都是由客户端实现，因此会包含非常多的功能，如服务发现、负载均衡等基本功能，加密、认证、路由等高级功能。在应用迁移到Service Mesh之后，这些功能都下沉到Service Mesh中。因此，Service Mesh下的客户端可以进行大幅度的简化，成为一个新的轻量级客户端。&lt;/p&gt;
&lt;p&gt;对于这个轻量级客户端，我们希望可以尽可能的做的轻薄通用：实现简单，不管哪个编程语言都可以做到轻松实现，因此跨语言就方便了。而且越简单之后升级的可能性就会越少，以避免升级客户端。&lt;/p&gt;
&lt;p&gt;那我们来继续看，这个轻量级客户端里面最后还能剩下什么内容？&lt;/p&gt;
&lt;p&gt;图中列出了三个，其中最重要的，也是必不可少的是目标服务的标识，即无论如何简化，最低限度应该告之要访问谁吧？然后是序列化，对于RPC类肯定需要提供编解码功能，不过对于HTTP/REST类很多语言直接内置了标准实现。然后链路追踪，需要做一点工作来传递诸如SpanID之类的参数，同样这块也有可能通过自动埋点来实现。因此，最理想最单薄的客户端，可能只保留最后一个信息：目标服务的标示。&lt;/p&gt;
&lt;p&gt;在侵入式框架下，目标服务的标示是和服务注册/服务发现是直接关联的，这个标示通常都是服务名，通过服务发现机制实现了一个服务名到服务实例的寻址方式。在Service Mesh机制下，由于服务发现机制被下沉到Service Mesh中，因此只要底层Service Mesh能支持，这个目标服务的标示可以不必拘泥于服务名。&lt;/p&gt;
&lt;p&gt;那么，问题来了，对客户端来说：最简单，最通用，支持最广泛的寻址方式是什么？是DNS！&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtezb6wj30qo0f0dh6_hu276e0156b89c7cfccb5165a5dddfd158_89918_16e797ea267703b35b38b64cbf01e58a.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtezb6wj30qo0f0dh6_hu276e0156b89c7cfccb5165a5dddfd158_89918_600c11689dede876c2a4af5bf096d127.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtezb6wj30qo0f0dh6_hu276e0156b89c7cfccb5165a5dddfd158_89918_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtezb6wj30qo0f0dh6_hu276e0156b89c7cfccb5165a5dddfd158_89918_16e797ea267703b35b38b64cbf01e58a.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在我们的迁移方案中，我们考虑引入DNS寻址方式。除了前面说的DNS是支持度最好，使用最普遍的寻址方式，在所有的编程语言和平台上都可以支持之外，我们还希望将DNS寻址方式作为未来产品的长期方向：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在SOFAMesh和SOFAMosn中，我们已经基于名为x-protocol的方式实现了DNS通用寻址方式，用来解决Dubbo/HSF/SOFA等传统SOA服务模型在Service Mesh下的访问问题 （备注: 具体内容请见我的博客文章 &lt;a href=&#34;https://skyao.io/post/201809-xprotocol-common-address-solution/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列(1)-DNS通用寻址方案&lt;/a&gt; )&lt;/li&gt;
&lt;li&gt;未来在我们的serverless产品中，我们希望可以为运行其上的Function提供DNS寻址支持&lt;/li&gt;
&lt;li&gt;可能还会有其他更加广泛的使用场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，在我们的演进过程中，对于客户端SDK，我们有这样一个思路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一方面简化原有的SDK，去除和Sidecar重复的内容（满足短期需求）&lt;/li&gt;
&lt;li&gt;另一方面，考虑到必然有一次客户端SDK的更换过程，那么我们希望在简化的同时引入基于DNS的通用寻址方式，以便在未来的后续迁移和功能扩展中可以依托这个机制来实现 （符合长期目标）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxti92oij30qo0f0wg2_hu6e7742b8c5713cd94b227311d55beca4_96742_cc467811e8dca4d44a5abfe7b69c5563.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxti92oij30qo0f0wg2_hu6e7742b8c5713cd94b227311d55beca4_96742_ddc73176263baaa188eadc03b51c4dcf.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxti92oij30qo0f0wg2_hu6e7742b8c5713cd94b227311d55beca4_96742_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxti92oij30qo0f0wg2_hu6e7742b8c5713cd94b227311d55beca4_96742_cc467811e8dca4d44a5abfe7b69c5563.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图中描述的是在Service Mesh下，客户端通过域名来指定要访问的目标服务，然后通过DNS解析机制来串联底层的服务注册/DNS记录更新/透明劫持传递原始信息/Sidecar查找路由目标等详细实现机制。&lt;/p&gt;
&lt;p&gt;这里仅做简单示意，我就不详细展开了。在接下来的内容中，我的同事，来自UC基础研发部的 龙轼 同学，将为大家详细的展开DNS寻址方案的细节实现。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtk2cbej30qo0f0ad5_hu11d97a0fe81461e050a80a215a935a79_70682_46526dc98b792c7ccf0a98129459d054.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtk2cbej30qo0f0ad5_hu11d97a0fe81461e050a80a215a935a79_70682_4e8c90fbffe6889fc5988ae5eeb01f64.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtk2cbej30qo0f0ad5_hu11d97a0fe81461e050a80a215a935a79_70682_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtk2cbej30qo0f0ad5_hu11d97a0fe81461e050a80a215a935a79_70682_46526dc98b792c7ccf0a98129459d054.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;大家好，我是来自UC基础研发部的龙轼。 感谢小剑老师给我们介绍了蚂蚁和UC共建的Service Mesh的演进路线和实现平滑迁移的关键。&lt;/p&gt;
&lt;p&gt;接下来由我来向大家分享下实现平滑迁移的关键中的DNS寻址方案的演进。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtlzs10j30qo0f0q4l_hucff4e4aaaae9c2aa003bc8c17d4ce327_50390_c86bc0a945cebd726719feb414007fb7.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtlzs10j30qo0f0q4l_hucff4e4aaaae9c2aa003bc8c17d4ce327_50390_ed4d4a87fa9cffc319da28cd3de22eef.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtlzs10j30qo0f0q4l_hucff4e4aaaae9c2aa003bc8c17d4ce327_50390_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtlzs10j30qo0f0q4l_hucff4e4aaaae9c2aa003bc8c17d4ce327_50390_c86bc0a945cebd726719feb414007fb7.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;大家可以看上面的所示的DNS寻址方案的演进，我们先了解下各个服务寻址方案的背景。&lt;/p&gt;
&lt;p&gt;从 SOA 的寻址，到 Kubernetes 的寻址，然后再到 Istio 的寻址，最后是我们的 SOFAMesh 的DNS寻址方案。&lt;/p&gt;
&lt;p&gt;它们的寻址方案有什么不同，我们将一一分析它们的细节和总体寻址方案的演进路线。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtnvgf0j30qo0f0gmq_huae44791e6f56e121283af2689ccfa21d_76287_89d59d11c38a28fa9d60d8aa6a0245a3.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtnvgf0j30qo0f0gmq_huae44791e6f56e121283af2689ccfa21d_76287_5c76e3759d6780d7e3280fb8d523097c.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtnvgf0j30qo0f0gmq_huae44791e6f56e121283af2689ccfa21d_76287_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtnvgf0j30qo0f0gmq_huae44791e6f56e121283af2689ccfa21d_76287_89d59d11c38a28fa9d60d8aa6a0245a3.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;现在大家可以先来看下 SOA 架构下基于服务注册和服务发现的寻址。&lt;/p&gt;
&lt;p&gt;我们可以看到图中的 SOA 其实是单进程多接口的，依赖于 SOA 的服务注册与服务发现的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtovfoxj30qo0f0myc_huec855fa81fca6a581e18a01f8fd8df21_87739_3c8d8204d16a9f8f7babfc060339a9f4.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtovfoxj30qo0f0myc_huec855fa81fca6a581e18a01f8fd8df21_87739_d89fda1ef6123866eca530e77345660e.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtovfoxj30qo0f0myc_huec855fa81fca6a581e18a01f8fd8df21_87739_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtovfoxj30qo0f0myc_huec855fa81fca6a581e18a01f8fd8df21_87739_3c8d8204d16a9f8f7babfc060339a9f4.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;接下来我们看下 Kubernetes 的 DNS 寻址方式，它的寻址方式其实是通过DNS 的。&lt;/p&gt;
&lt;p&gt;从图中我们可以看到部署到K8S 上面的userservice 服务会生成一条DNS记录指向K8S 的ClusterIP。&lt;/p&gt;
&lt;p&gt;我们在 Pod 里面发起请求时通过 DNS 的 SearchDomain 域名补全规则就会从 DNS 里面查询得到ClusterIP，我们可以看出 Kubernetes 的寻址方案是单进程单接口的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtr32x9j30qo0f0gmy_hu52d156c21110330ab557b912090dc8d5_96400_9bbe4224e943bb8d1cc1b56d918f9745.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtr32x9j30qo0f0gmy_hu52d156c21110330ab557b912090dc8d5_96400_40644bbe36a1b49959ab37bc3c6a5180.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtr32x9j30qo0f0gmy_hu52d156c21110330ab557b912090dc8d5_96400_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtr32x9j30qo0f0gmy_hu52d156c21110330ab557b912090dc8d5_96400_9bbe4224e943bb8d1cc1b56d918f9745.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;看完 Kubernetes 的服务发现之后我们继续来看 Istio 的服务发现。&lt;/p&gt;
&lt;p&gt;从图中我们可以看出之前的流程都和 K8S 一脉相承，不同的地方在于 Istio 里面有个 SideCar 它把ClusterIP 拿到之后根据 ClusterIP 从 VirtualHost 里面匹配到 Rule 规则 转发给目标的 Pod 地址。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtt2236j30qo0f00tq_hu5bb3ddbb9a41e433b58bc16642719e31_83393_6a3254691b6ca6b6e890045becd88e5d.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtt2236j30qo0f00tq_hu5bb3ddbb9a41e433b58bc16642719e31_83393_c38e2452aded60c6e2fe1c9fa7a1e504.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtt2236j30qo0f00tq_hu5bb3ddbb9a41e433b58bc16642719e31_83393_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtt2236j30qo0f00tq_hu5bb3ddbb9a41e433b58bc16642719e31_83393_6a3254691b6ca6b6e890045becd88e5d.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后我们来看下 SOFAMesh 的 DNS 通用寻址方案。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据我们之前分析的 SOA 寻址方案和 Kubernetes 寻址方案，我们可以看出如果我们的微服务不经过拆分和改造想上 Service Mesh 的话我们需要支持SOA之前的那种单个Pod 多个接口的。&lt;/li&gt;
&lt;li&gt;从图中看就是我们需要支持 &lt;code&gt;com.alipay.userservice.interface1&lt;/code&gt;, &lt;code&gt;com.alipay.userservice.interface2&lt;/code&gt; 这些接口解析到 ClusterIP, 我们知道k8s 中的service 是不支持的。&lt;/li&gt;
&lt;li&gt;那该如何是好，我们只能在DNS 上做文章修改DNS的记录来实现这一功能。确定了这一方案之后我们来看下我们设计的DNS寻址方案实现细节。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtx8cboj30qo0f0q3y_hu7ba11f5b4726e00e026a1f23e0a57f1f_74263_cac45e0c8aed8cc4f69a19fbef2a23f8.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtx8cboj30qo0f0q3y_hu7ba11f5b4726e00e026a1f23e0a57f1f_74263_573170805ff01174caf83e97fc6cab5b.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtx8cboj30qo0f0q3y_hu7ba11f5b4726e00e026a1f23e0a57f1f_74263_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxtx8cboj30qo0f0q3y_hu7ba11f5b4726e00e026a1f23e0a57f1f_74263_cac45e0c8aed8cc4f69a19fbef2a23f8.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;大家看这张图:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们用 CRD 定义了一个 RPCService 和之前的 Service 有同样的 selector 的标签。&lt;/li&gt;
&lt;li&gt;然后用 RPC Service Controller 对 RPCService 做 Watch，当 RPCService 有更新的时候我们就把接口就是上述的 &lt;code&gt;com.alipay.userservice.interface1&lt;/code&gt; 的记录写入 CoreDNS 里面&lt;/li&gt;
&lt;li&gt;而 interface 是通过 Pod 里面的 Register Agent 来获取 Dubbo 里面暴露的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu1urkdj30qo0f0wf6_hu9fab8ae1b29dac0867f7eb707deadec8_55186_28f3ea590f284b051e2291469532d265.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu1urkdj30qo0f0wf6_hu9fab8ae1b29dac0867f7eb707deadec8_55186_659df9c219809984a82da739f30717ea.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu1urkdj30qo0f0wf6_hu9fab8ae1b29dac0867f7eb707deadec8_55186_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu1urkdj30qo0f0wf6_hu9fab8ae1b29dac0867f7eb707deadec8_55186_28f3ea590f284b051e2291469532d265.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;好的，说完这个方案的细节之后。我们可以看出其实其他的问题都不大，但是要更新DNS的这个我们需要支持。&lt;/p&gt;
&lt;p&gt;一开始我们 K8S 集群里面是用 Kube-DNS 来做 DNS 寻址的，但我们看这张 Kube-DNS 的架构图。&lt;/p&gt;
&lt;p&gt;可以看出修改它成本是比较大的，而且所有的DNS 都在同一个域里面，这个风险系数很高。 如果一旦修改错误势必会影响到之前的 k8s 的 service，导致线上的故障。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu6p6cgj30qo0f0q5b_hu08162841c058f09dee4a79f6ee372c9c_76318_ba50a8138853b1b5c676dc393f30de42.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu6p6cgj30qo0f0q5b_hu08162841c058f09dee4a79f6ee372c9c_76318_e4a0e7301a13c465cac73f5047b91af2.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu6p6cgj30qo0f0q5b_hu08162841c058f09dee4a79f6ee372c9c_76318_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxu6p6cgj30qo0f0q5b_hu08162841c058f09dee4a79f6ee372c9c_76318_ba50a8138853b1b5c676dc393f30de42.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;这个时候我们跟踪到社区的 CoreDNS 项目，我们来看下 CoreDNS 的具体的架构。  它采用作为 Web 服务器 Caddy 的服务器框架，延用了Caddy 中的插件机制，大大的增加了 CoreDNS 的灵活性。&lt;/li&gt;
&lt;li&gt;它的插件机制也特别简单，把所有的插件注册进一个Map里面来，在调用的时候从Map拿出他们有共同接口的函数。有兴趣的同学可以看下 Caddy 的插件代码实现。&lt;/li&gt;
&lt;li&gt;它的 DNS 协议库采用是由 Google 工程师 Meikg 开发的 DNS 库，他同时也是 SkyDNS 的开发者。&lt;/li&gt;
&lt;li&gt;后端可以采用 UDP/TCP、TLS 或者 gRPC 作为后端数据查询。上面有个Google工程师用 gRPC 做了一个 CoreDNS 插件的后端数据查询例子，有兴趣的同学可以看下。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxubqi33j30qo0f0djp_hua47193bce8796867a754f8cd85319aba_90490_cc6eaaf29ad054663ef65d35b9a73290.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxubqi33j30qo0f0djp_hua47193bce8796867a754f8cd85319aba_90490_fb1ec9d6fd2b3dd04a0d16c6cf0ffd72.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxubqi33j30qo0f0djp_hua47193bce8796867a754f8cd85319aba_90490_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxubqi33j30qo0f0djp_hua47193bce8796867a754f8cd85319aba_90490_cc6eaaf29ad054663ef65d35b9a73290.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OK，既然 CoreDNS 的 Plugins 这么强大，我们可不可以用它来实现我们刚才说到的 Renew DNS的机制。 答案很显然是可以。&lt;/p&gt;
&lt;p&gt;我们看下上面的图，实现CoreDNS 的插件很简单，只需要继承上面的接口就可以了。 CoreDNS 官网有具体的教程在教我们怎么写一个插件。这个就不具体的展开了。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuel9hoj30qo0f03zw_hu43ec8127aef600f0f6c15b03c279e382_106894_0f8bb2e625700a6c840a672042c40c0f.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuel9hoj30qo0f03zw_hu43ec8127aef600f0f6c15b03c279e382_106894_c88d27b879398208889c20f42a586b2f.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuel9hoj30qo0f03zw_hu43ec8127aef600f0f6c15b03c279e382_106894_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuel9hoj30qo0f03zw_hu43ec8127aef600f0f6c15b03c279e382_106894_0f8bb2e625700a6c840a672042c40c0f.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;到了我们最关键的点了：我们应该怎么更新我们的DNS。其实这点 CoreDNS 社区里面已经有人提出需求用 REST API 的形式提供更新 DNS 的接口。&lt;/li&gt;
&lt;li&gt;互联网任务工程小组也早在 rfc2136 定义了标准的 DNS UPDATE。 Google Cloud 和AWS 都有相应的实现。&lt;/li&gt;
&lt;li&gt;CoreDNS 社区其实已经把接口实现了，但是后端存储是基于file 的，数据没有落地。 蚂蚁和UC 这边扩展了 ETCD 插件的接口，把对应 DNS UPDATE 接口给实现了，实现 DNS 数据写入ETCD 里面。&lt;/li&gt;
&lt;li&gt;从图中我们可以看到 &lt;code&gt;rpc.cluster.local&lt;/code&gt; 这个域 和 k8s 域 cluster.local 是在不同的插件链上的。
这样在k8s域中没有 dynapirest 插件，我们就不能对k8s域中的DNS进行更新，这样就把之前Kube-DNS改造之后会对k8s域里面造成影响给去除了，更加的安全。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuhvylcj30qo0f0n35_hucd16b21ae63c61db0002380cf86b233c_90090_d2e9e7fcfd6afa38e28e734a7376a97f.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuhvylcj30qo0f0n35_hucd16b21ae63c61db0002380cf86b233c_90090_33170a3c7008e99ec4679985d3f524d0.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuhvylcj30qo0f0n35_hucd16b21ae63c61db0002380cf86b233c_90090_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuhvylcj30qo0f0n35_hucd16b21ae63c61db0002380cf86b233c_90090_d2e9e7fcfd6afa38e28e734a7376a97f.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们可以看下 CoreDNS 后端存储的接口，其实和我们之前对数据操作的接口是没有什么差别的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuk3x3zj30qo0f0go6_hu14a6099f294e540dd3d63bb64cac7b20_67347_8d8d9fa277a6d73dd82e43c295c35684.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuk3x3zj30qo0f0go6_hu14a6099f294e540dd3d63bb64cac7b20_67347_ba158e23616e82817af8b61aa3d3cc46.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuk3x3zj30qo0f0go6_hu14a6099f294e540dd3d63bb64cac7b20_67347_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuk3x3zj30qo0f0go6_hu14a6099f294e540dd3d63bb64cac7b20_67347_8d8d9fa277a6d73dd82e43c295c35684.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;目前 CoreDNS 的 DynAPI 还在主库代码没合并的状态。之后 DynAPI 这个项目会独立成一个插件项目。我们可以看下 CoreDNS 社区的 DynAPI 插件进展。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxumjxr1j30qo0f00vw_hu7fc7fe8e296367d535a86fcd95604a00_71477_6012444b30b1eda317d809ba4e60996b.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxumjxr1j30qo0f00vw_hu7fc7fe8e296367d535a86fcd95604a00_71477_07a1d2a0c0a871cc4c3900d5af29d64f.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxumjxr1j30qo0f00vw_hu7fc7fe8e296367d535a86fcd95604a00_71477_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxumjxr1j30qo0f00vw_hu7fc7fe8e296367d535a86fcd95604a00_71477_6012444b30b1eda317d809ba4e60996b.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OK，我们来看下我们的DynAPI 实现DNS 更新的一个效果。从图中我们可以看出 record.json 里面的一个域名的更新。通过 DynAPI 我们成功把 record.json 的DNS 记录给更新进去并且dns正常工作了。到现在我们通过CoreDNS 的插件就把DNS 更新的需求给解决了。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuoytkjj30qo0f0q4a_huaec21a2b3b53fb840cd1992029a0619d_46524_70958cacc1fd3e45873a1f135aba6028.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuoytkjj30qo0f0q4a_huaec21a2b3b53fb840cd1992029a0619d_46524_01f38d441e1c799d44ba39d1a691e75c.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuoytkjj30qo0f0q4a_huaec21a2b3b53fb840cd1992029a0619d_46524_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuoytkjj30qo0f0q4a_huaec21a2b3b53fb840cd1992029a0619d_46524_70958cacc1fd3e45873a1f135aba6028.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;其实CoreDNS 官网还有许多有趣的插件，可以丰富 CoreDNS 的功能和提升 CoreDNS 的性能。 大家可以看下中间的 autopath 插件，他把我们多次的在 searchdomain 拼凑的 DNS 记录的查询在在服务器上给实现了。 避免了多次的 Client 端和 Server 端的数据交互。有兴趣的同学可以看下 &lt;a href=&#34;https://github.com/coredns/presentations/blob/master/A-Deep-Dive-into-CoreDNS-2018.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A-Deep-Dive-into-CoreDNS-2018&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxurlu6tj30qo0f0q46_hu3317101224be3e9c58b317df29dae987_72056_5ca73e9172f0d53a8c569ac6427188cd.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxurlu6tj30qo0f0q46_hu3317101224be3e9c58b317df29dae987_72056_3ca0b0fb4e2c5235706fb6919971b68e.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxurlu6tj30qo0f0q46_hu3317101224be3e9c58b317df29dae987_72056_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxurlu6tj30qo0f0q46_hu3317101224be3e9c58b317df29dae987_72056_5ca73e9172f0d53a8c569ac6427188cd.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们把 CoreDNS 的功能开发完了，上线的话很多人关注它的性能。 我们这边做了一个简单的性能测试，可以看出 CoreDNS 和 Bind DNS 这种现在比较通用的DNS的性能还是有点差距的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuu4eu0j30qo0f0tf3_hu728e3dc71335cd78f9b610bfbe9b54fc_101204_2c7bc2fb82276d08ed69cd7058f61d73.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuu4eu0j30qo0f0tf3_hu728e3dc71335cd78f9b610bfbe9b54fc_101204_5a7bb62e2daf1bc7aec8845dcfa306db.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuu4eu0j30qo0f0tf3_hu728e3dc71335cd78f9b610bfbe9b54fc_101204_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuu4eu0j30qo0f0tf3_hu728e3dc71335cd78f9b610bfbe9b54fc_101204_2c7bc2fb82276d08ed69cd7058f61d73.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;但是,我们通过上面的图可以看到在一定的QPS 下，CoreDNS 的延时是很低的。 我们可以看到所有的延时都落在4ms 之内。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuwnsanj30qo0f0abw_huc7bfb2873c942a5fdf1e8889793e383e_59035_c6b442a0963400923cbe00500c1c8419.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuwnsanj30qo0f0abw_huc7bfb2873c942a5fdf1e8889793e383e_59035_0ec77cc727d9db88d777d93713179f22.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuwnsanj30qo0f0abw_huc7bfb2873c942a5fdf1e8889793e383e_59035_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuwnsanj30qo0f0abw_huc7bfb2873c942a5fdf1e8889793e383e_59035_c6b442a0963400923cbe00500c1c8419.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;为了解决QPS的问题，我们通过 Kubernetes 的 HPA 给 CoreDNS 进行横向的扩展。&lt;/p&gt;
&lt;p&gt;一开始我们只是通过CPU的维度给 CoreDNS 扩展，但发现波动有点大。 之后我们切换成通过QPS的维度来进行扩容。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuz1c5ej30qo0f0gmc_hu8df209efa44e285eba9da6be6b8eb170_67235_ce86ba1b994d5e69d93018f7d11dddef.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuz1c5ej30qo0f0gmc_hu8df209efa44e285eba9da6be6b8eb170_67235_283d944ee7cbddf94346d4e599fca47f.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuz1c5ej30qo0f0gmc_hu8df209efa44e285eba9da6be6b8eb170_67235_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxuz1c5ej30qo0f0gmc_hu8df209efa44e285eba9da6be6b8eb170_67235_ce86ba1b994d5e69d93018f7d11dddef.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;CoreDNS 将会在Kubernetes 1.13 之后成为 Kubernetes 的默认的DNS服务。我们将会紧跟社区实施我们的方案并且反馈给社区。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv0youwj30qo0f0tbs_hu69a50a3911deb5c28498a52ef0474853_70283_37d12f0c25b8302ac4a3d23a220e957b.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv0youwj30qo0f0tbs_hu69a50a3911deb5c28498a52ef0474853_70283_c04ab31707643fca7f2422c1124c337d.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv0youwj30qo0f0tbs_hu69a50a3911deb5c28498a52ef0474853_70283_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv0youwj30qo0f0tbs_hu69a50a3911deb5c28498a52ef0474853_70283_37d12f0c25b8302ac4a3d23a220e957b.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们再来看下我们后续的一些规划。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv3cwjjj30qo0f075p_hufe0d34bcedf7c8bc51b69d436e191951_54905_e57e7de2cecf4e31c808c4b5e50fcc6e.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv3cwjjj30qo0f075p_hufe0d34bcedf7c8bc51b69d436e191951_54905_17805b5099f6a57cc937f4dca8ce76d0.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv3cwjjj30qo0f075p_hufe0d34bcedf7c8bc51b69d436e191951_54905_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv3cwjjj30qo0f075p_hufe0d34bcedf7c8bc51b69d436e191951_54905_e57e7de2cecf4e31c808c4b5e50fcc6e.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;可以看到我们的 DynAPI 其实在安全上还是有欠缺的。我们后续会把 HTTP 加强成 HTTPS 协议来增强 DynAPI 的安全性。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv5rwbbj30qo0f0dik_hud28a551a5623a2d05e7c77b8de10c321_66170_cc4d52d146d8ff98163a907e27deffca.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv5rwbbj30qo0f0dik_hud28a551a5623a2d05e7c77b8de10c321_66170_4378649b91d1b5914f9a9ab218e649ce.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv5rwbbj30qo0f0dik_hud28a551a5623a2d05e7c77b8de10c321_66170_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv5rwbbj30qo0f0dik_hud28a551a5623a2d05e7c77b8de10c321_66170_cc4d52d146d8ff98163a907e27deffca.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;还有如果我们 CoreDNS 的后端变化的更新的 Watch 由于 Watch的范围过大的话，会返回过多的数据。这样会影响到 Watch 的性能，CoreOS 在 ETCD3.2 增加了proxy 可以让我们根据不同的 ETCD KeySpace 去Watch,这样大大的提高了Watch的性能。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv8070fj30qo0f0ab1_hu6485f23e60e2e8e9568294bae27898e8_64699_ba5855a52150ea4c23f3e1223840e916.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv8070fj30qo0f0ab1_hu6485f23e60e2e8e9568294bae27898e8_64699_1a155b965fc813b9eeaae068e35548b1.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv8070fj30qo0f0ab1_hu6485f23e60e2e8e9568294bae27898e8_64699_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxv8070fj30qo0f0ab1_hu6485f23e60e2e8e9568294bae27898e8_64699_ba5855a52150ea4c23f3e1223840e916.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后一个，我们建议在创建 Kubernetes 集群的时候把 idc 的信息给带进Kubernetes的后缀域名中。这样我们之后可以通过 kubernetai 插件把不同的 Kubernetes 集群的域名进行整合通过本 IDC 缓存提高跨 IDC DNS 的访问速度。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvatmutj30qo0f0whk_hu1cab0928f2234e0e78760bb88429250d_68823_6d86661c2d407b0843741edd96bcc515.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvatmutj30qo0f0whk_hu1cab0928f2234e0e78760bb88429250d_68823_632fc1b33d4e8b3e55c9ac83201e7bb0.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvatmutj30qo0f0whk_hu1cab0928f2234e0e78760bb88429250d_68823_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvatmutj30qo0f0whk_hu1cab0928f2234e0e78760bb88429250d_68823_6d86661c2d407b0843741edd96bcc515.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvdouf2j30qo0f0gnc_hu14b0225721bb4b722864f076d47ecef1_59050_3062ca600c440776de5dc91537524bec.webp 400w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvdouf2j30qo0f0gnc_hu14b0225721bb4b722864f076d47ecef1_59050_c474dca6c104b049fc040328af531493.webp 760w,
               /blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvdouf2j30qo0f0gnc_hu14b0225721bb4b722864f076d47ecef1_59050_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/ant-financial-service-mesh-adoption-plan/006tNbRwly1fxoxvdouf2j30qo0f0gnc_hu14b0225721bb4b722864f076d47ecef1_59050_3062ca600c440776de5dc91537524bec.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后我们总结下，总体方面小剑老师给我们讲了蚂蚁金服主站 Service Mesh 的渐进式演进路线和实现平滑迁移的几个关键。 具体细节方面我们通过CoreDNS 的单点突破解决了 SOFAMesh 的 DNS 寻址的问题。&lt;/p&gt;
&lt;p&gt;感谢大家，希望这次演讲能让大家有所收获。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh Meetup #4 上海站</title>
      <link>https://cloudnative.to/event/service-mesh-meetup-04/</link>
      <pubDate>Sun, 25 Nov 2018 13:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/service-mesh-meetup-04/</guid>
      <description>&lt;h2 id=&#34;讲师与演讲话题&#34;&gt;讲师与演讲话题&lt;/h2&gt;
&lt;h4 id=&#34;observability-and-istio-telemetry&#34;&gt;Observability and Istio telemetry&lt;/h4&gt;
&lt;p&gt;吴晟 Apache SkyWalking创始人、Apache Sharding-Sphere原型作者、比特大陆资深技术专家、CNCF OpenTracing标准化委员会成员&lt;/p&gt;
&lt;h4 id=&#34;蚂蚁集团-service-mesh-渐进式迁移方案&#34;&gt;蚂蚁集团 Service Mesh 渐进式迁移方案&lt;/h4&gt;
&lt;p&gt;敖小剑 蚂蚁集团高级技术专家，十六年软件开发经验，微服务专家，Service Mesh布道师，Servicemesher社区联合创始人&lt;/p&gt;
&lt;p&gt;张瑜标 阿里巴巴技术专家、前京东Hadoop负责人、Hadoop代码贡献者、现负责UC 基于Kubernetes自研的PaaS平台整体的稳定性&lt;/p&gt;
&lt;h4 id=&#34;探讨和实践基于isito的微服务治理事件监控&#34;&gt;探讨和实践基于Isito的微服务治理事件监控&lt;/h4&gt;
&lt;p&gt;徐运元 谐云科技云平台架构师，致力于容器 PaaS 平台、企业级容器云平台的方案设计和技术落地&lt;/p&gt;
&lt;h4 id=&#34;envoycontour与kubernetes实践&#34;&gt;Envoy、Contour与Kubernetes实践&lt;/h4&gt;
&lt;p&gt;冯玮 七牛容器云平台产品架构师，曾在百度和华为从事公有云领域高性能分布式计算和存储平台的架构设计和产品研发&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SOFAMesh中的多协议通用解决方案x-protocol介绍系列（3）——TCP协议扩展</title>
      <link>https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/</link>
      <pubDate>Sun, 14 Oct 2018 14:53:04 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是SOFAMesh中的多协议通用解决方案x-protocol介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（3）——TCP协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，这两个是Istio/Envoy中的一等公民。而基于HTTP/1.1的REST和基于HTTP/2的gRPC，一个是目前社区最主流的通讯协议，一个是未来的主流，google的宠儿，CNCF御用的RPC方案，这两个组成了目前Istio和Envoy（乃至CNCF所有项目）的黄金组合。&lt;/p&gt;
&lt;p&gt;而我们SOFAMesh，在第一时间就遇到和Istio/Envoy不同的情况，我们需要支持REST和gRPC之外的众多协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOFARPC：这是蚂蚁金服大量使用的RPC协议(已开源)&lt;/li&gt;
&lt;li&gt;HSF RPC：这是阿里集团内部大量使用的RPC协议(未开源)&lt;/li&gt;
&lt;li&gt;Dubbo RPC: 这是社区广泛使用的RPC协议(已开源)&lt;/li&gt;
&lt;li&gt;其他私有协议：在过去几个月间，我们收到需求，期望在SOFAMesh上运行其他TCP协议，部分是私有协议&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为此，我们需要考虑在SOFAMesh和SOFAMosn中增加这些通讯协议的支持，尤其是要可以让我们的客户非常方便的扩展支持各种私有TCP协议：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu4b5d390c7844cf8ce6c3b61c782fb02f_53835_96bf233de48cd2acb4637589e4fe3f3e.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu4b5d390c7844cf8ce6c3b61c782fb02f_53835_4039512cf820b6f8115926323ca2477d.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu4b5d390c7844cf8ce6c3b61c782fb02f_53835_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/supported-protocol_hu4b5d390c7844cf8ce6c3b61c782fb02f_53835_96bf233de48cd2acb4637589e4fe3f3e.webp&#34;
               width=&#34;594&#34;
               height=&#34;485&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;实现分析&#34;&gt;实现分析&lt;/h2&gt;
&lt;p&gt;我们来大体看一下，在SOFAMesh/Istio中要新增一个通讯协议需要有哪些工作：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/tbd_hu7d50621cc2c2d0cbfb0d52e5292ba5ed_74747_001a7162a502f365fedca28651376e34.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/tbd_hu7d50621cc2c2d0cbfb0d52e5292ba5ed_74747_0214ad754e89123678577c7d0bcedab9.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/tbd_hu7d50621cc2c2d0cbfb0d52e5292ba5ed_74747_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/tbd_hu7d50621cc2c2d0cbfb0d52e5292ba5ed_74747_001a7162a502f365fedca28651376e34.webp&#34;
               width=&#34;760&#34;
               height=&#34;327&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;protocol decoder：负责解析协议，读取协议字段&lt;/li&gt;
&lt;li&gt;protocol encoder：负责生成请求报文，注意通常会有改动，比如修改某些header&lt;/li&gt;
&lt;li&gt;在pilot中需要为新协议生成 Virtual Host 等配置，有 inbound 和 outbound 两份，分别下发到Sidecar&lt;/li&gt;
&lt;li&gt;在Sidecar中，根据下发的 Virtual Host 等配置，进行请求匹配，以决定请求该转发到何处&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：实际下发的配置不止 Virtual Host 配置，为了简单起见，我们仅以 Virtual Host 为例做讲解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其中，protocol encoder和protocol decoder是容易理解的，对于新的通讯协议肯定需要有协议编解码层面的工作必须要完成，这块有工作量是很自然的。&lt;/p&gt;
&lt;p&gt;我们来看看第三块的工作量是什么，inbound 和 outbound 的Virtual Host配置示例如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/outbound_hud9b9c178eae581b5514140397bcba88a_138013_5f999d0367ef66529fdd902599b51a33.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/outbound_hud9b9c178eae581b5514140397bcba88a_138013_075d4a4f0921f3fbd3c769dddbc184f6.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/outbound_hud9b9c178eae581b5514140397bcba88a_138013_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/outbound_hud9b9c178eae581b5514140397bcba88a_138013_5f999d0367ef66529fdd902599b51a33.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;outbound 配置中，注意 domains 字段是各种域名和ClusterIP，而 routes 中，match是通过prefix来匹配。我们结合HTTP/1.1，domains字段是用来和请求的Host header进行域名匹配的，比如 &lt;code&gt;Host: istio-telemetry&lt;/code&gt;，这决定了哪些请求是要转发到 istio-telemetry 这个服务的。routes的match用来进行路由匹配的，通过HTTP请求的path进行匹配。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/inbound_hu16ee50cfe930c8b969e366dc6e9e5cd3_83832_7ba33ac6272d9ec125ff21c6bf4241a7.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/inbound_hu16ee50cfe930c8b969e366dc6e9e5cd3_83832_4ea401904937228e9ecc73455d654b50.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/inbound_hu16ee50cfe930c8b969e366dc6e9e5cd3_83832_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/inbound_hu16ee50cfe930c8b969e366dc6e9e5cd3_83832_7ba33ac6272d9ec125ff21c6bf4241a7.webp&#34;
               width=&#34;760&#34;
               height=&#34;526&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;inbound 配置类似，只是inbound更简单，domains匹配&lt;code&gt;*&lt;/code&gt;就可以。&lt;/p&gt;
&lt;p&gt;从上面的例子中可以看到，Istio和Envoy的设计有非常浓重的HTTP协议的味道，各种语义都是和HTTP直接相关。而当我们进行TCP协议的转发时，就需要将请求的协议字段进行映射，映射到HTTP的相应语义。&lt;/p&gt;
&lt;p&gt;比如，最基本的Destination，原始语义是请求的目的地，在前面的文章中我们指出过这是请求转发最关键的字段。在HTTP协议中，通常是通过Host header和Path表示，对于REST而言还有重要的Method字段。&lt;/p&gt;
&lt;p&gt;下面的格式是其他各种协议对这个Destination原始语义的实际实现方式：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;协议&lt;/th&gt;
&lt;th&gt;实现&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;原始语义&lt;/td&gt;
&lt;td&gt;请求的目的地(Destination)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HTTP/1.1&lt;/td&gt;
&lt;td&gt;Host header，Method，Path&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HTTP/2&lt;/td&gt;
&lt;td&gt;Header帧中的伪header &lt;code&gt;:authority&lt;/code&gt;，&lt;code&gt;:path&lt;/code&gt;和&lt;code&gt;:method&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bolt协议&lt;/td&gt;
&lt;td&gt;header map中key为”service”的字段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HSF协议&lt;/td&gt;
&lt;td&gt;协议头中的服务接口名和服务方法名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dubbo协议&lt;/td&gt;
&lt;td&gt;data字段（payload）中的path/method&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这些通讯协议在下发规则和进行请求匹配时，就需要进行协调：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;定义好 Virtual Host 配置中的 domains 字段和 route 中的 match 用到的字段在当前通讯协议中的实际语义&lt;/li&gt;
&lt;li&gt;在 protocol encoder 中读取请求的协议字段，和上面的字段对应&lt;/li&gt;
&lt;li&gt;然后进行请求路由规则匹配（参照HTTP/1.1中的domain和route match的匹配）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而这些都是需要以代码的方式进行实现，以满足新通讯协议的要求。正规的做法，是每次新增一个通讯协议就将上述的工作内容重复一遍。这会直接导致大量的高度类似的重复代码。&lt;/p&gt;
&lt;h2 id=&#34;x-protocol的实现&#34;&gt;x-protocol的实现&lt;/h2&gt;
&lt;p&gt;在上述需要在协议扩展时修改的四个内容中，有一块是特别的：生成 Virtual Host 配置的工作是在Pilot中实现的，而其他三个是在Sidecar （Envoy或MOSN）中。考虑到 protocol encoder 和 protocol decoder 的工作是必不可少的，必然会修改Sidecar来增加实现代码，因此简化开发的第一个想法就是：能不能做到不修改Pilot？&lt;/p&gt;
&lt;p&gt;基本思路就是固定好原始语义，避免每个通讯协议都映射一遍。从前面我们列出来的各个协议的映射情况看，对于RPC协议而言，一般目的地信息都是服务名(有些是接口名)+方法名居多，因此可以考虑直接将服务名和方法名固定下来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RPC协议在 Virtual Host 配置中就固定为服务名对应 domains 字段，方法名对应 route 中的 match 用到的字段，这样只要修改一次然后各个RPC协议公用此配置，以后就不用再重复修改Pilot。&lt;/li&gt;
&lt;li&gt;protocol encoder 在解析通讯协议完成之后，就直接将协议中对应服务名和方法名的字段提取出来，后面的匹配处理过程就可以公用一套通用实现，这样路由匹配这块也可以不用在重复开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，在x-protocol中，如果需要引入一个新的通讯协议，需要的工作内容只有必不可少的protocol encoder 和 protocol decoder，和实现以下几个接口：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hubd616638a7c4cda2e92c6e1356d3dc05_121697_32ec12f1beda6cf1f0f350b3cb3961dd.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hubd616638a7c4cda2e92c6e1356d3dc05_121697_14405b6a5e44af921f4231125dc7043c.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hubd616638a7c4cda2e92c6e1356d3dc05_121697_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hubd616638a7c4cda2e92c6e1356d3dc05_121697_32ec12f1beda6cf1f0f350b3cb3961dd.webp&#34;
               width=&#34;503&#34;
               height=&#34;517&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;X-protocol 在支持新通讯协议上的做法并无新奇之处，只是由于需求特殊有众多通讯协议需要支持，在开发时发现大量重复工作，因此我们选择了一条可以让后面更舒服一点的道路。&lt;/p&gt;
&lt;p&gt;目前这个方案在SOFAMesh中采用，我们将进一步检验实际效果，也会和合作的小伙伴时验证，看他们在自行扩展新协议时是否足够理想。这个方案理论上应该可以同样适用于Istio、Envoy体系，随着社区对Istio的接受程度的提高，在Istio上支持各种TCP通讯协议的需求会越来越多，有理由相信Istio后续可能也会出现类似的方案。毕竟，每次都改一大堆类似的东西，不是一个好做法。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发</title>
      <link>https://cloudnative.to/blog/x-protocol-rapid-decode-forward/</link>
      <pubDate>Wed, 10 Oct 2018 11:45:26 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-rapid-decode-forward/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是SOFAMesh中的多协议通用解决方案x-protocol介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（3）——TCP协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在Istio和Envoy中，对通讯协议的支持，主要体现在HTTP/1.1和HTTP/2上，而我们SOFAMesh，则需要支持以下几个RPC协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOFARPC：这是蚂蚁金服大量使用的RPC协议（已开源）&lt;/li&gt;
&lt;li&gt;HSF RPC：这是阿里集团内部大量使用的RPC协议（未开源）&lt;/li&gt;
&lt;li&gt;Dubbo RPC: 这是社区广泛使用的RPC协议（已开源）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;更适合的平衡点性能和功能&#34;&gt;更适合的平衡点：性能和功能&lt;/h3&gt;
&lt;p&gt;对于服务间通讯解决方案，性能永远是一个值得关注的点。而SOFAMesh在项目启动时就明确要求在性能上要有更高的追求，为此，我们不得不在Istio标准实现之外寻求可以获取更高性能的方式，比如支持各种RPC协议。&lt;/p&gt;
&lt;p&gt;期间有两个发现：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Istio在处理所有的请求转发如REST/gRPC时，会解码整个请求的header信息，拿到各种数据，提取为Attribute，然后以此为基础，提供各种丰富的功能，典型如Content Based Routing。&lt;/li&gt;
&lt;li&gt;而在测试中，我们发现：解码请求协议的header部分，对CPU消耗较大，直接影响性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，我们有了一个很简单的想法：是不是可以在转发时，不开启部分功能，以此换取转发过程中的更少更快的解码消耗？毕竟，不是每个服务都需要用到Content Based Routing这样的高级特性，大部分服务只使用 Version Based Routing，尤其是使用RPC通讯协议的服务，没有HTTP那么表现力丰富的header，对Content Based Routing的需求要低很多。&lt;/p&gt;
&lt;p&gt;此外，对于部分对性能有极高追求的服务，不开启高级特性而换取更高的性能，也是一种满足性能要求的折中方案。考虑到系统中总存在个别服务对性能非常敏感，我们觉得Service Mesh提供一种性能可以接近直连的方案会是一个有益的补充。为了满足这些特例而不至于因此整体否决Service Mesh方案，我们需要在Service Mesh的大框架下提供一个折中方案。&lt;/p&gt;
&lt;h2 id=&#34;请求转发&#34;&gt;请求转发&lt;/h2&gt;
&lt;p&gt;在我们进一步深入前，我们先来探讨一下实现请求转发的技术细节。&lt;/p&gt;
&lt;p&gt;有一个关键问题：当Envoy/SOFA MOSN这样的代理程序，接收到来自客户端的TCP请求时，需要获得哪些信息，才可以正确的转发请求到上游的服务器端？&lt;/p&gt;
&lt;h3 id=&#34;最关键的信息destination&#34;&gt;最关键的信息：destination&lt;/h3&gt;
&lt;p&gt;首先，毫无疑问的，必须拿到destination/目的地，也就是客户端请求必须通过某种方式明确的告之代理该请求的destination，这样代理程序才能根据这个destionation去找到正确的目标服务器，然后才有后续的连接目标服务器和转发请求等操作。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu9f0c3f794f1b39435da5a9e2ced97ad4_55269_c112d8b80500d16f6c4a88362193f251.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu9f0c3f794f1b39435da5a9e2ced97ad4_55269_dd6d1fbf6a675f4852386e4d04790289.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu9f0c3f794f1b39435da5a9e2ced97ad4_55269_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu9f0c3f794f1b39435da5a9e2ced97ad4_55269_c112d8b80500d16f6c4a88362193f251.webp&#34;
               width=&#34;760&#34;
               height=&#34;314&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Destination信息的表述形式可能有：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. IP地址&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可能是服务器端实例实际工作的IP地址和端口，也可能是某种转发机制，如Nginx/HAProxy等反向代理的地址或者Kubernetes中的ClusterIP。&lt;/p&gt;
&lt;p&gt;举例：“192.168.1.1:8080”是实际IP地址和端口，“10.2.0.100:80”是ngxin反向代理地址，“172.168.1.105:80”是Kubernetes的ClusterIP。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 目标服务的标识符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可用于名字查找，如服务名，可能带有各种前缀后缀。然后通过名字查找/服务发现等方式，得到地址列表（通常是IP地址+端口形式）。&lt;/p&gt;
&lt;p&gt;举例：“userservice”是标准服务名， “com.alipay/userservice”是加了域名前缀的服务名， “service.default.svc.cluster.local”是k8s下完整的全限定名。&lt;/p&gt;
&lt;p&gt;Destination信息在请求报文中的携带方式有：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 通过通讯协议传递&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是最常见的形式，标准做法是通过header头，典型如HTTP/1.1下一般使用 host header，举例如“Host: userservice”。HTTP/2下，类似的使用“:authority” header。&lt;/p&gt;
&lt;p&gt;对于非HTTP协议，通常也会有类似的设计，通过协议中某些字段来承载目标地址信息，只是不同协议中这个字段的名字各有不同。如SOFARPC，HSF等。&lt;/p&gt;
&lt;p&gt;有些通讯协议，可能会将这个信息存放在payload中，比如后面我们会介绍到的dubbo协议，导致需要反序列化payload之后才能拿到这个重要信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 通过TCP协议传递&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一种非常特殊的方式，通过在TCP option传递，上一节中我们介绍Istio DNS寻址时已经详细介绍过了。&lt;/p&gt;
&lt;h3 id=&#34;tcp拆包&#34;&gt;TCP拆包&lt;/h3&gt;
&lt;p&gt;如何从请求的通讯协议中获取destination？这涉及到具体通讯协议的解码，其中第一个要解决的问题就是如何在连续的TCP报文中将每个请求内容拆分开，这里就涉及到经典的TCP沾包、拆包问题。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_huac2d5e1ad3ab35d69f68868f41314cd2_27400_f386bb847534eecd9acda4df69fbddef.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_huac2d5e1ad3ab35d69f68868f41314cd2_27400_56ef6e37244ac3cb4bd9efd8dde7751a.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_huac2d5e1ad3ab35d69f68868f41314cd2_27400_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_huac2d5e1ad3ab35d69f68868f41314cd2_27400_f386bb847534eecd9acda4df69fbddef.webp&#34;
               width=&#34;760&#34;
               height=&#34;261&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;转发请求时，由于涉及到负载均衡，我们需要将请求发送给多个服务器端实例。因此，有一个非常明确的要求：就是必须以单个请求为单位进行转发。即单个请求必须完整的转发给某台服务器端实例，负载均衡需要以请求为单位，不能将一个请求的多个报文包分别转发到不同的服务器端实例。所以，拆包是请求转发的必备基础。&lt;/p&gt;
&lt;p&gt;由于篇幅和主题限制，我们不在这里展开TCP沾包、拆包的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的解决方案。&lt;/p&gt;
&lt;h3 id=&#34;多路复用的关键参数requestid&#34;&gt;多路复用的关键参数：RequestId&lt;/h3&gt;
&lt;p&gt;RequestId用来关联request和对应的response，请求报文中携带一个唯一的id值，应答报文中原值返回，以便在处理response时可以找到对应的request。当然在不同协议中，这个参数的名字可能不同（如streamid等）。&lt;/p&gt;
&lt;p&gt;严格说，RequestId对于请求转发是可选的，也有很多通讯协议不提供支持，比如经典的HTTP1.1就没有支持。但是如果有这个参数，则可以实现多路复用，从而可以大幅度提高TCP连接的使用效率，避免出现大量连接。稍微新一点的通讯协议，基本都会原生支持这个特性，比如SOFARPC、Dubbo、HSF，还有HTTP/2就直接內建了多路复用的支持。&lt;/p&gt;
&lt;p&gt;HTTP/1.1不支持多路复用（http1.1有提过支持幂等方法的pipeline机制但是未能普及），用的是经典的ping-pong模式：在请求发送之后，必须独占当前连接，等待服务器端给出这个请求的应答，然后才能释放连接。因此HTTP/1.1下，并发多个请求就必须采用多连接，为了提升性能通常会使用长连接+连接池的设计。而如果有了requestid和多路复用的支持，客户端和Mesh之间理论上就可以只用一条连接（实践中可能会选择建立多条）来支持并发请求：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu66f57cb2738cf11b4a7472f20cd482c4_84062_67767ff83d835a87a644fbf681f05504.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu66f57cb2738cf11b4a7472f20cd482c4_84062_7b62b1394361094b9753d1c5af682b30.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu66f57cb2738cf11b4a7472f20cd482c4_84062_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu66f57cb2738cf11b4a7472f20cd482c4_84062_67767ff83d835a87a644fbf681f05504.webp&#34;
               width=&#34;760&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;而Mesh与服务器（也可能是对端的Mesh）之间，也同样可以受益于多路复用技术，来自不同客户端而去往同一个目的地的请求可以混杂在同一条连接上发送。通过RequestId的关联，Mesh可以正确将reponse发送到请求来自的客户端。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu3d7dedf9a92b6b92c0e3e0b3bf4c9c5f_76118_764e1cb64fa8920272c005d391e6558f.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu3d7dedf9a92b6b92c0e3e0b3bf4c9c5f_76118_6f2e411c39499be0e19734ff33f2b6a0.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu3d7dedf9a92b6b92c0e3e0b3bf4c9c5f_76118_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu3d7dedf9a92b6b92c0e3e0b3bf4c9c5f_76118_764e1cb64fa8920272c005d391e6558f.webp&#34;
               width=&#34;760&#34;
               height=&#34;289&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;由于篇幅和主题限制，我们不在这里展开多路复用的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的支持情况。&lt;/p&gt;
&lt;h3 id=&#34;请求转发参数总结&#34;&gt;请求转发参数总结&lt;/h3&gt;
&lt;p&gt;上面的分析中，我们可以总结到，对于Sidecar，要正确转发请求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;必须获取到destination信息，得到转发的目的地，才能进行服务发现类的寻址&lt;/li&gt;
&lt;li&gt;必须要能够正确的拆包，然后以请求为单位进行转发，这是负载均衡的基础&lt;/li&gt;
&lt;li&gt;可选的RequestId，这是开启多路复用的基础&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，这里我们的第一个优化思路就出来了：尽量只解码获取这三个信息，满足转发的基本要求。其他信息如果有性能开销则跳过解码，所谓“快速解码转发”。基本原理就是牺牲信息完整性追求性能最大化。&lt;/p&gt;
&lt;p&gt;而结合上一节中我们引入的DNS通用寻址方案，我们是可以从请求的TCP options中得到ClusterIP，从而实现寻址。这个方式可以实现不解码请求报文，尤其是header部分解码destination信息开销大时。这是我们的第二个优化思路：跳过解码destination信息，直接通过ClusterIP进行寻址。&lt;/p&gt;
&lt;p&gt;具体的实现则需要结合特定通讯协议的实际情况进行。&lt;/p&gt;
&lt;h2 id=&#34;主流通讯协议&#34;&gt;主流通讯协议&lt;/h2&gt;
&lt;p&gt;现在我们开始，以Proxy、Sidecar、Service Mesh的角度来看看目前主流的通讯协议和我们前面列举的需要在SOFAMesh中支持的几个协议。&lt;/p&gt;
&lt;h3 id=&#34;sofarpcbolt协议&#34;&gt;SOFARPC/bolt协议&lt;/h3&gt;
&lt;p&gt;SOFARPC 是一款基于 Java 实现的 RPC 服务框架，详细资料可以查阅 官方文档。SOFARPC 支持 bolt，rest，dubbo 协议进行通信。REST、dubbo后面单独展开，这里我们关注bolt协议。&lt;/p&gt;
&lt;p&gt;bolt 是蚂蚁金服集团开放的基于 Netty 开发的网络通信框架，其协议格式是变长，即协议头+payload。具体格式定义如下，以request为例（response类似）：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu6340bce4925169de04e94fd9d5c61230_45016_3ac6b6ad06d1766f766fd402215a6f5f.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu6340bce4925169de04e94fd9d5c61230_45016_edaa3a16c13167b9886faf6efb709fae.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu6340bce4925169de04e94fd9d5c61230_45016_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu6340bce4925169de04e94fd9d5c61230_45016_3ac6b6ad06d1766f766fd402215a6f5f.webp&#34;
               width=&#34;760&#34;
               height=&#34;160&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们只关注和请求转发直接相关的字段：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TCP拆包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;bolt协议是定长+变长的复合结构，前面22个字节长度固定，每个字节和协议字段的对应如图所示。其中classLen、headerLen和contentLen三个字段指出后面三个变长字段className、header、content的实际长度。和通常的变长方案相比只是变长字段有三个。拆包时思路简单明了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先读取前22个字节，解出各个协议字段的实际值，包括classLen，headerLen和contentLen&lt;/li&gt;
&lt;li&gt;按照classLen、headerLen和contentLen的大小，继续读取className、header、content&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Destination&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bolt协议中的header字段是一个map，其中有一个key为“service”的字段，传递的是接口名/服务名。读取稍微麻烦一点点，需要先解码整个header字段，这里对性能有影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RequestId&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Blot协议固定字段中的&lt;code&gt;requestID&lt;/code&gt;字段，可以直接读取。&lt;/p&gt;
&lt;p&gt;SOFARPC中的bolt协议，设计的比较符合请求转发的需要，TCP拆包，读取RequestID，都没有性能问题。只是Destination的获取需要解码整个header，性能开销稍大。&lt;/p&gt;
&lt;p&gt;总结：适合配合DNS通用解码方案，跳过对整个header部分的解码，从而提升性能。当然由于这个header本身也不算大，优化的空间有限，具体提升需要等对比测试的结果出来。&lt;/p&gt;
&lt;h3 id=&#34;hsf协议&#34;&gt;HSF协议&lt;/h3&gt;
&lt;p&gt;HSF协议是经过精心设计工作在4层的私有协议，由于该协议没有开源，因此不便直接暴露具体格式和字段详细定义。&lt;/p&gt;
&lt;p&gt;不过基本的设计和bolt非常类似：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用变长格式，即协议头+payload&lt;/li&gt;
&lt;li&gt;在协议头中可以直接拿到服务接口名和服务方法名作为Destination&lt;/li&gt;
&lt;li&gt;有RequestID字段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基本和bolt一致，考虑到Destination可以直接读取，比bolt还要方便一些，HSF协议可以说是对请求转发最完美的协议。&lt;/p&gt;
&lt;p&gt;总结：目前的实现方案也只解码了这三个关键字段，速度足够快，不需要继续优化。&lt;/p&gt;
&lt;h3 id=&#34;dubbo协议&#34;&gt;Dubbo协议&lt;/h3&gt;
&lt;p&gt;Dubbo协议也是类似的协议头+payload的变长结构，其协议格式如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu0b8dc765a7e27095af575f7fcfa0c7b7_16331_3296c35060c747183623284e386cf571.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu0b8dc765a7e27095af575f7fcfa0c7b7_16331_420e1d1f471374f59375a0979ca16129.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu0b8dc765a7e27095af575f7fcfa0c7b7_16331_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu0b8dc765a7e27095af575f7fcfa0c7b7_16331_3296c35060c747183623284e386cf571.webp&#34;
               width=&#34;760&#34;
               height=&#34;107&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;其中long类型的&lt;code&gt;id&lt;/code&gt;字段用来把请求request和返回的response对应上，即我们所说的&lt;code&gt;RequestId&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这样TCP拆包和多路复用都轻松实现，稍微麻烦一点的是：Destination在哪里？Dubbo在这里的设计有点不够理想，在协议头中没有字段可以直接读取到Destination，需要去读取data字段，也就是payload，里面的path字段通常用来保存服务名或者接口名。method字段用来表示方法名。&lt;/p&gt;
&lt;p&gt;从设计上看，path字段和method字段被存放在payload中有些美中不足。庆幸的是，读取这两个字段的时候不需要完整的解开整个payload，好险，不然，那性能会没法接受的。&lt;/p&gt;
&lt;p&gt;以hession2为例，data字段的组合是：dubbo version + path + interface version + method + ParameterTypes + Arguments + Attachments。每个字段都是一个byte的长度+字段值的UTF bytes。因此读取时并不复杂，速度也足够快。&lt;/p&gt;
&lt;p&gt;基本和HSF一致，就是Destination的读取稍微麻烦一点，放在payload中的设计让人吓了一跳，好在有惊无险。整体说还是很适合转发的。&lt;/p&gt;
&lt;p&gt;总结：同HSF，不需要继续优化。&lt;/p&gt;
&lt;h3 id=&#34;http11&#34;&gt;HTTP/1.1&lt;/h3&gt;
&lt;p&gt;HTTP/1.1的格式应该大家都熟悉，而在这里，不得不指出，HTTP/1.1协议对请求转发是非常不友好的（甚至可以说是恶劣！）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HTTP请求在拆包时，需要先按照HTTP header的格式，一行一行读取，直到出现空行表示header结束&lt;/li&gt;
&lt;li&gt;然后必须将整个header的内容全部解析出来，才能取出&lt;code&gt;Content-Length header&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;Content-Length&lt;/code&gt; 值，才能完成对body内容的读取，实现正确拆包&lt;/li&gt;
&lt;li&gt;如果是chunked方式，则更复杂一些&lt;/li&gt;
&lt;li&gt;Destination通常从&lt;code&gt;Host&lt;/code&gt; header中获取&lt;/li&gt;
&lt;li&gt;没有RequestId，完全无法实现多路复用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这意味着，为了完成最基本的TCP拆包，必须完整的解析全部的HTTP header信息，没有任何可以优化的空间。对比上面几个RPC协议，轻松自如的快速获取几个关键信息，HTTP无疑要重很多。这也造成了在ServiceMesh下，HTTP/1.1和REST协议的性能总是和其他RPC方案存在巨大差异。&lt;/p&gt;
&lt;p&gt;对于注定要解码整个header部分，完全没有优化空间可言的HTTP/1.1协议来说，Content Based Routing 的解码开销是必须付出的，无论是否使用 Content Based Routing 。因此，快速解码的构想，对HTTP/1.1无效。&lt;/p&gt;
&lt;p&gt;总结：受HTTP/1.1协议格式限制，上述两个优化思路都无法操作。&lt;/p&gt;
&lt;h3 id=&#34;http2和grpc&#34;&gt;HTTP/2和gRPC&lt;/h3&gt;
&lt;p&gt;作为HTTP/1.1的接班人，HTTP/2则表现的要好很多。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：当然HTTP/2的协议格式复杂多了，由于篇幅和主题的限制，这里不详细介绍HTTP/2的格式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先HTTP/2是以帧的方式组织报文的，所有的帧都是变长，固定的9个字节+可变的payload，Length字段指定payload的大小：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu66681c5396a650417d0611390f2bac2b_32603_1743756b27c37e88b116da49acea6985.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu66681c5396a650417d0611390f2bac2b_32603_3d235647056ea0157bbbcb9e9ce59bd6.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu66681c5396a650417d0611390f2bac2b_32603_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu66681c5396a650417d0611390f2bac2b_32603_1743756b27c37e88b116da49acea6985.webp&#34;
               width=&#34;700&#34;
               height=&#34;221&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;HTTP2的请求和应答，也被称为Message，是由多个帧构成，在去除控制帧之外，Message通常由Header帧开始，后面接CONTINUATION帧和Data帧（也可能没有，如GET请求）。每个帧都可以通过头部的Flags字段来设置END_STREAM标志，表示请求或者应答的结束。即TCP拆包的问题在HTTP/2下是有非常标准而统一的方式完成，完全和HTTP/2上承载的协议无关。&lt;/p&gt;
&lt;p&gt;HTTP/2通过Stream內建多路复用，这里的&lt;code&gt;Stream Identifier&lt;/code&gt; 扮演了类似前面的&lt;code&gt;RequestId&lt;/code&gt;的角色。&lt;/p&gt;
&lt;p&gt;而Destination信息则通过Header帧中的伪header &lt;code&gt;:authority&lt;/code&gt; 来传递，类似HTTP/1.1中的&lt;code&gt;Host&lt;/code&gt; header。不过HTTP/2下header会进行压缩，读取时稍微复杂一点，也存在需要解压缩整个header帧的性能开销。考虑到拆包和获取RequestId都不需要解包（只需读取协议头，即HTTP/2帧的固定字段），速度足够快，因此存在很大的优化空间：不解码header帧，直接通过DNS通用寻址方案，这样性能开销大为减少，有望获得极高的转发速度。&lt;/p&gt;
&lt;p&gt;总结：HTTP/2的帧设计，在请求转发时表现的非常友好。唯独Destination信息放在header中，会造成必须解码header帧。好在DNS通用寻址方案可以弥补，实现快速解码和转发。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh时代的rpc理想方案&#34;&gt;Service Mesh时代的RPC理想方案&lt;/h2&gt;
&lt;p&gt;在文章的最后，我们总结并探讨一下，对于Service Mesh而言，什么样的RPC方案是最理想的？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;必须可以方便做TCP拆包，最好在协议头中就简单搞定，标准方式如固定协议头+length字段+可变payload。HSF协议、 bolt协议和dubbo协议表现完美，HTTP/2采用帧的方式，配合END_STREAM标志，方式独特但有效。HTTP/1.1则是反面典型。&lt;/li&gt;
&lt;li&gt;必须可以方便的获取destination字段，同样最好在协议头中就简单搞定。HSF协议表现完美，dubbo协议藏在payload中但终究还是可以快速解码有惊无险的过关，bolt协议和HTTP/2协议就很遗憾必须解码header才能拿到，好在DNS通用寻址方案可以弥补，但终究丢失了服务名和方法名信息。HTTP/1.1依然是反面典型。&lt;/li&gt;
&lt;li&gt;最好有RequestId字段，同样最好在协议头中就简单搞定。这方面HSF协议、dubbo协议、bolt协议表现完美，HTTP/2协议更是直接內建支持。HTTP/1.1继续反面典型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，仅以方便用最佳性能进行转发，对Service Mesh、sidecar友好而言，最理想的RPC方案是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;传统的变长协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;固定协议头+length字段+可变payload，然后在固定协议头中直接提供RequestId和destination。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于帧的协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以HTTP/2为基础，除了请求结束的标志位和RequestId外，还需要通过帧的固定字段来提供destination信息。&lt;/p&gt;
&lt;p&gt;或许，在未来，在Service Mesh普及之后，对Service Mesh友好成为RPC协议的特别优化方向，我们会看到表现完美更适合Service Mesh时代的新型RPC方案。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案</title>
      <link>https://cloudnative.to/blog/x-protocol-common-address-solution/</link>
      <pubDate>Mon, 08 Oct 2018 14:58:03 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-common-address-solution/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是SOFAMesh中的多协议通用解决方案x-protocol介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（1）——DNS通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh中的多协议通用解决方案x-protocol介绍系列（3）——TCP协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在2018年上半年，蚂蚁金服决定基于 Istio 订制自己的 ServiceMesh 解决方案，在6月底对外公布了 SOFAMesh，详情请见之前的文章: &lt;a href=&#34;https://skyao.io/publication/201806-service-mesh-explore/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;大规模微服务架构下的Service Mesh探索之路&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;在 SOFAMesh 的开发过程中，针对遇到的实际问题，我们给出了一套名为 x-protocol 的解决方案，定位是云原生、高性能、低侵入性的通用 Service Mesh 落地方案，依托 Kubernetes 基座，利用其原生的服务注册和服务发现机制，支持各种私有 RPC 协议低成本、易扩展的接入，快速享受 Service Mesh 所带来的红利。&lt;/p&gt;
&lt;p&gt;具体解决的问题包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多通讯协议支持问题，减少开发工作量，简单快捷的接入新协议&lt;/li&gt;
&lt;li&gt;尽量提升性能，提供更灵活的性能与功能的平衡点选择，满足特定高性能场景&lt;/li&gt;
&lt;li&gt;兼容现有SOA体系，提供通过接口进行访问的方式，实现不修改业务代码也能顺利接入 Service Mesh&lt;/li&gt;
&lt;li&gt;支持单进程多服务的传统SOA程序，可以在微服务改造之前，先受益于 Service Mesh 带来的强大功能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本系列文章中，我们将对此进行详细的讲解，首先是“DNS通用寻址方案”。&lt;/p&gt;
&lt;h2 id=&#34;背景和需求&#34;&gt;背景和需求&lt;/h2&gt;
&lt;h3 id=&#34;soa的服务模型&#34;&gt;SOA的服务模型&lt;/h3&gt;
&lt;p&gt;在SOFAMesh计划支持的RPC框架中，SOFARPC、HSF、Dubbo都是一脉相承的SOA体系，也都支持经典的SOA服务模型，通常称为”单进程多服务”，或者叫做”单进程多接口”。（备注：由于服务一词使用过于频繁，下文都统一称为接口以便区分）&lt;/p&gt;
&lt;p&gt;SOA标准的服务注册，服务发现和调用流程如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://skyao.io/post/201809-xprotocol-common-address-solution/images/soa-standard-process.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在单个SOA应用进程内，存在多个接口&lt;/li&gt;
&lt;li&gt;服务注册时，以接口为单位进行多次独立的服务注册&lt;/li&gt;
&lt;li&gt;当客户端进行调用时，按照接口进行服务发现，然后发起调用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当我们试图将这些SOA架构的应用搬迁到ServiceMesh时，就会遇到服务模型的问题：微服务是单服务模型，也就是一个进程里面只承载一个服务。以Kubernetes的服务注册为例，在单进程单服务的模型下，服务名和应用名可以视为一体，Kubernetes的自动服务注册会将应用名作为服务注册的标示。&lt;/p&gt;
&lt;p&gt;这就直接导致了SOA模型和微服务模型的不匹配问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOA以接口为单位做服务注册和服务发现，而微服务下是服务名&lt;/li&gt;
&lt;li&gt;SOA是”单进程多接口”，而微服务是”单进程单服务”&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;一步接一步的需求&#34;&gt;一步接一步的需求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;先上车后补票&lt;/p&gt;
&lt;p&gt;最理想的做法当然是先进行微服务改造，实现微服务拆分。但是考虑到现有应用数量众多，我们可能更愿意在大规模微服务改造之前，先想办法让这些应用可以运行在ServiceMesh下，提前受益于Service Mesh带来的强大功能。因此，我们需要找到一个合适的方案，让ServiceMesh支持没有做微服务改造依然是”单进程多接口”形式的传统SOA应用，所谓”先上车后补票”。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不修改代码&lt;/p&gt;
&lt;p&gt;考虑到原有的SOA应用，相互之间错综复杂的调用关系，最好不要修改代码，即保持客户端依然通过接口名来访问的方式。当然，SOA架构的客户端SDK可能要进行改动，将原有的通过接口名进行服务发现再自行负载均衡进行远程调用的方式，精简为标准的Servicemesh调用（即走Sidecar），因此修改SDK依赖包和重新打包应用是不可避免。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持带特殊字符的接口名&lt;/p&gt;
&lt;p&gt;Kubernetes的服务注册，Service名是不能携带”.“号的。而SOA架构下，接口名有时出于管理方便，有可能是加了域名前缀，如”com.alipay.demo.interface-2”。为了实现不修改原有代码，就只能想办法支持这种带特殊字符的接口名。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考kubernetes和istio&#34;&gt;参考Kubernetes和Istio&lt;/h2&gt;
&lt;p&gt;在进一步讨论解决方案之前，我们先来看一下kubernetes和Istio中的标准请求寻址方式。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：过程稍显复杂，涉及到Kubernetes/Istio的一些底层细节。但是了解这个过程对后续的理解非常重要，也可以帮助大家了解Kubernetes和Kubernetes的工作原理，强烈推荐阅读。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;kubernetes下的dns寻址方式&#34;&gt;Kubernetes下的DNS寻址方式&lt;/h3&gt;
&lt;p&gt;在Kubernetes下，如图所示，假定我们部署了一个名为userservice的应用，有三个实例，分别在三个pod中。则应用部署之后，Kubernetes会为这个应用分配ClusterIP和域名，并在DNS中生成一条DNS记录，将域名映射到ClusterIP：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kubernetes下的dns寻址方式&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kubernetes下的DNS寻址方式&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_15613344dc5be49873e3d6ec05161780.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_134fba3c143d902958318d84a0c40e57.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_15613344dc5be49873e3d6ec05161780.webp&#34;
               width=&#34;760&#34;
               height=&#34;354&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Kubernetes下的DNS寻址方式
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;当部署在Kubernetes下的某个充当客户端的应用发起请求时，如图中的HTTP GET请求，目标URL地址为 “&lt;a href=&#34;http://userservice/id/1000221&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://userservice/id/1000221&lt;/a&gt;&amp;quot;。请求的寻址方式和过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先进行域名解析，分别尝试解析”userservice”/“userservie.default.svc.cluster.local”等域名，得到ClusterIP&lt;/li&gt;
&lt;li&gt;然后客户端发出请求的报文，目标地址为ClusterIP，源地址为当前客户端所在的pod IP（简单起见，端口先忽略）&lt;/li&gt;
&lt;li&gt;请求报文随即被kube-proxy拦截，kube-proxy根据ClusterIP，拿到ClusterIP对应的多个实际服务实例所在的pod ip，取其中一个，修改目标地址为这个pod IP&lt;/li&gt;
&lt;li&gt;请求报文最终就被发送到服务实例所在的pod IP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应答回来的方式类似，userservice发出的应答报文会被kube-proxy拦截并修改为发送到客户端所在的pod IP。&lt;/p&gt;
&lt;p&gt;我们详细看一下请求和应答全称的四个请求包的具体内容（简单起见继续忽略端口）：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kubernetes-dns寻址&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kubernetes DNS寻址&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu940ecb223adbf7d6d7e250daba854838_190420_bbd6ac14ad3cd33fcb3219108cca4c60.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu940ecb223adbf7d6d7e250daba854838_190420_02c6e1fbcab93444469b968111cd85be.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu940ecb223adbf7d6d7e250daba854838_190420_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu940ecb223adbf7d6d7e250daba854838_190420_bbd6ac14ad3cd33fcb3219108cca4c60.webp&#34;
               width=&#34;760&#34;
               height=&#34;289&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Kubernetes DNS寻址
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;重点关注请求和应答报文的源地址和目标地址：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端发出的请求，为”客户端到ClusterIP”&lt;/li&gt;
&lt;li&gt;kube-proxy拦截到请求后，将请求修改为”客户端到服务器端”&lt;/li&gt;
&lt;li&gt;服务器端收到请求时，表现为”客户端到服务器端”，ClusterIP被kube-proxy屏蔽&lt;/li&gt;
&lt;li&gt;服务器端发送应答，因为收到的请求看似来自客户端，因此应答报文为”服务器端到客户端”&lt;/li&gt;
&lt;li&gt;应答报文被kube-proxy拦截，将应答修改为”ClusterIP到服务器端”&lt;/li&gt;
&lt;li&gt;客户端收到应答，表现为”ClusterIP到服务器端”，服务器端IP被kube-proxy屏蔽&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;kube-proxy在客户端和服务器端之间拦截并修改请求和应答的报文，联通两者，但各自屏蔽了一些信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在客户端看来它是在和ClusterIP交互，userservice的具体服务器端实例对客户端是无感知的&lt;/li&gt;
&lt;li&gt;在服务器端看来，客户端是直接在和它交互，ClusterIP的存在对服务器端是无感知的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更深入一步，看kube-proxy在两个拦截和修改报文中的逻辑处理关系，即kube-proxy是如何在收到应答时正确的找回原有的ClusterIP：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kube-proxy与clusterip&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;kube-proxy与ClusterIP&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu767170f1f85ec1ab4ee47b414979e780_155681_0f7b528c0c0a97a73ba2e9df4921f3d9.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu767170f1f85ec1ab4ee47b414979e780_155681_c015b96f021d944ef6d9b48ef93a92b5.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu767170f1f85ec1ab4ee47b414979e780_155681_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu767170f1f85ec1ab4ee47b414979e780_155681_0f7b528c0c0a97a73ba2e9df4921f3d9.webp&#34;
               width=&#34;760&#34;
               height=&#34;269&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      kube-proxy与ClusterIP
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在拦截并修改请求报文之后，kube-proxy会保存报文修改的5元组对应关系（5元组指源IP地址，源端口，协议，目的地IP地址，目的地端口）&lt;/li&gt;
&lt;li&gt;在收到应答报文后，根据应答报文中的5元组，在保存的5元组对应关系中，找到对应信息，得到原有的ClusterIP和端口，然后修改应答报文&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总结，通过上述Kubernetes下的寻址方式，客户端只需发送带简单寻址信息的请求（如 “&lt;a href=&#34;http://userservice/id/1000221%22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://userservice/id/1000221&amp;quot;&lt;/a&gt; 中的”userservice” ），就可以寻址到正确的服务器端。这期间有两个关注点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过DNS，建立了域名和ClusterIP的关系。&lt;/p&gt;
&lt;p&gt;对于客户端，这是它能看到的内容，非常的简单，域名、DNS是非常容易使用的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而通过kube-proxy的拦截和转发，又打通了ClusterIP和服务器端实际的Pod IP&lt;/p&gt;
&lt;p&gt;对于客户端，这些是看不到的内容，不管有多复杂，都是Kubernetes在底层完成，对客户端，或者说使用者透明。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以客户端的视角看来，这个DNS寻址方式非常的简单直白：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kube-proxy与dns&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;kube-proxy与DNS&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu8acff34e85e8902181101f5302d33196_123490_6dfe9284b09bc576632150ecc64cf42f.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu8acff34e85e8902181101f5302d33196_123490_973d80fefde33f71916f5f9d0b5f7772.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu8acff34e85e8902181101f5302d33196_123490_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu8acff34e85e8902181101f5302d33196_123490_6dfe9284b09bc576632150ecc64cf42f.webp&#34;
               width=&#34;760&#34;
               height=&#34;205&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      kube-proxy与DNS
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;istio的dns寻址方式&#34;&gt;Istio的DNS寻址方式&lt;/h2&gt;
&lt;p&gt;Istio的请求寻址方式和普通kubernetes非常相似，原理相同，只是kube-proxy被sidecar取代，然后sidecar的部署方式是在pod内部署，而且客户端和服务器端各有一个sidecar。其他基本一致，除了图中红色文本的部分：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio的dns寻址方式&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio的DNS寻址方式&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hudb016e4fed9f5ddd2e7046c2021a8d2c_224282_bacf2e9f4fc2adc3fe6cd1b4edc9685a.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hudb016e4fed9f5ddd2e7046c2021a8d2c_224282_765df2880002c635cf55faac66bfef5f.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hudb016e4fed9f5ddd2e7046c2021a8d2c_224282_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hudb016e4fed9f5ddd2e7046c2021a8d2c_224282_bacf2e9f4fc2adc3fe6cd1b4edc9685a.webp&#34;
               width=&#34;760&#34;
               height=&#34;297&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio的DNS寻址方式
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;iptables在劫持流量时，除了将请求转发到localhost的Sidecar处外，还额外的在请求报文的TCP options 中将 ClusterIP 保存为 original dest。&lt;/li&gt;
&lt;li&gt;在 Sidecar （Istio默认是Envoy）中，从请求报文 TCP options 的 original dest 处获取 ClusterIP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过TCP options 的 original dest，iptables就实现了在劫持流量到Sidecar的过程中，额外传递了 ClusterIP 这个重要参数。Istio为什么要如此费力的传递这个 ClusterIP 呢？&lt;/p&gt;
&lt;p&gt;看下图就知道了，这是一个 Virtual Host 的示例， Istio 通过 Pilot 将这个规则发送给 Sidecar/Envoy ，依靠这个信息来匹配路由请求找到处理请求的cluster：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio中的pilot注册信息&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio中的Pilot注册信息&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_33870b26a7d8898807a8f5406a1976aa.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_00afda41b65d40aa48abc9f5fa7d7ccc.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_33870b26a7d8898807a8f5406a1976aa.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio中的Pilot注册信息
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;domains中，除了列出域名外，还有一个特殊的IP地址，这个就是Kubernetes服务的 ClusterIP！因此，Sidecar可以通过前面传递过来的 ClusterIP 在这里进行路由匹配（当然也可以从报文中获取destination然后通过域名匹配）。&lt;/p&gt;
&lt;p&gt;总结，Istio延续了Kubernetes的寻址方式，客户端同样只需发送带简单寻址信息的请求，就可以寻址到正确的服务器端。这期间同样有两个关注点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过DNS，建立了域名和ClusterIP的关系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过 ClusterIP 和 Pilot 下发给 Virtual Host 的配置，Sidecar 可以完成路由匹配，将ClusterIP和目标服务器关联起来&lt;/p&gt;
&lt;p&gt;同样，对于客户端，这些是看不到的内容。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，以客户端的视角看来，Istio的这个DNS寻址方式同样的简单直白！&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-客户端请求&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;客户端请求&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hueb9d2aa3b3857aca22b5114281301898_19197_e958dff0e97a0bca99b89658ae0d47a4.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hueb9d2aa3b3857aca22b5114281301898_19197_eade5e070c6a67680cf189c750420eab.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hueb9d2aa3b3857aca22b5114281301898_19197_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hueb9d2aa3b3857aca22b5114281301898_19197_e958dff0e97a0bca99b89658ae0d47a4.webp&#34;
               width=&#34;760&#34;
               height=&#34;103&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      客户端请求
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;dns通用寻址方案&#34;&gt;DNS通用寻址方案&lt;/h2&gt;
&lt;h3 id=&#34;解决问题的思路&#34;&gt;解决问题的思路&lt;/h3&gt;
&lt;p&gt;在详细讲述了Kubernetes和Istio的DNS寻址方案之后，我们继续回到我们的主题，我们要解决的问题：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如何在不修改代码，继续使用接口的情况下，实现在Service Mesh上运行现有的Dubbo/HSF/SOFA等传统SOA应用？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dns通用寻址方案&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;DNS通用寻址方案&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_8880cc331bfadc73ea91e160ca689da0.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_b0bed091b05e84bbf2e82776565118b5.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu527db2b14071a3bcd7a4a2435809673c_111731_8880cc331bfadc73ea91e160ca689da0.webp&#34;
               width=&#34;760&#34;
               height=&#34;354&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      DNS通用寻址方案
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这里有一个关键点：Kubernetes的服务注册是以基于Service或者说基于应用(app name)，而我们的客户端代码是基于接口的。因此，在 Virtual Host 进行路由匹配时，是不能通过域名匹配的。当然，这里理论上还有一个思路，就是将接口注册为Kubernetes Service。但是，还记得要支持接口特殊字符的需求吗？带点号的接口名，Kubernetes是不能接受它作为Service Name的，直接堵死了将接口名注册到Kubernetes Service的道路。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio中注册的服务名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio中注册的服务名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_3c393d91872ce033ce82ff89856df931.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_dee3ceef5fbb4e0bbcdde55b76f31375.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu4204cb8ce9eade41ae09467315de1374_118475_3c393d91872ce033ce82ff89856df931.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio中注册的服务名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这样，我们就只有一条路可以走了：效仿Istio的做法，通过 ClusterIP 匹配！&lt;/p&gt;
&lt;p&gt;而要将接口名（如”com.alipay.demo.interface-1”）和 ClusterIP 关联，最简单直接的方式就是&lt;strong&gt;打通DNS&lt;/strong&gt; ：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-sidecar注册dns名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Sidecar注册DNS名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2a370b8e2f63a851e7635b968500b823_178297_ff226092a343f5e1d15c157a628c8791.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2a370b8e2f63a851e7635b968500b823_178297_fa17f8ec3f32ceaf7edd19e2c087bc24.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2a370b8e2f63a851e7635b968500b823_178297_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2a370b8e2f63a851e7635b968500b823_178297_ff226092a343f5e1d15c157a628c8791.webp&#34;
               width=&#34;760&#34;
               height=&#34;227&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Sidecar注册DNS名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;只需要在DNS记录中，增加接口到 ClusterIP 的映射，然后就可以完全延续Istio的标准做法！其他的步骤，如域名解析到ClusterIP，iptables拦截并传递ClusterIP，sidecar读取ClusterIP并匹配路由，都完全可以重用原有方案。&lt;/p&gt;
&lt;h3 id=&#34;具体实现方案&#34;&gt;具体实现方案&lt;/h3&gt;
&lt;p&gt;实现时，我们选择了使用 CoreDNS 作为Kubernetes的DNS解决方案，然后通过 Service Controller 操作 CoreDNS 的记录来实现DNS解析。&lt;/p&gt;
&lt;p&gt;为了收集到SOA应用的接口信息，我们还提供了一个 Register Agent 给 Service Controller 收集信息。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-通过coredns注册接口名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;通过CoreDNS注册接口名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu02fbabbc25a786738523a9af5785edaf_44911_b065b37d9ee8ace1a8dde046f9494096.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu02fbabbc25a786738523a9af5785edaf_44911_538c25f579d1c99644059aa4bcfc4baa.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu02fbabbc25a786738523a9af5785edaf_44911_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu02fbabbc25a786738523a9af5785edaf_44911_b065b37d9ee8ace1a8dde046f9494096.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      通过CoreDNS注册接口名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;详细的实现方案，不在本文中重复讲述，请参阅我们之前的分享文章 &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247484175&amp;amp;idx=1&amp;amp;sn=5cb26b1afe615ac7e06b2ccbee6235b3&amp;amp;chksm=faa0ecd5cdd765c3f285bcb3b23f4f1f3e27f6e99021ad4659480ccc47f9bf25a05107f4fee2&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0828t5isWXmyeWhTeoAoeogw&amp;amp;pass_ticket=DqnjSkiuBZW9Oe68Fjiq%2Bqa6fFCyysQTR7Qgd8%2BX9FfooybAg7NXVAQdLmfG6gRX#rd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOFAMesh 的通用协议扩展&lt;/a&gt; 中的DNS寻址方案一节。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：暂时修改 CoreDNS 记录的方式是直接修改 CoreDNS 的底层数据，不够优雅。未来将修改为通过 CoreDNS 的 Dynamic updates API 接口进行，不过 CoreDNS 的这个API还在开发中，需要等待完成。详情见&lt;a href=&#34;https://github.com/coredns/coredns/pull/1822&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt; 。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;单进程多接口问题的解决&#34;&gt;单进程多接口问题的解决&lt;/h3&gt;
&lt;p&gt;上面的解决方案，在解决通过接口实现访问的同时，也将”单进程多接口”的问题一起解决了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原SOA应用上Kubernetes时，可以注册为标准的Kubernetes Service，获取ClusterIP。此时使用应用名注册，和接口无关。&lt;/li&gt;
&lt;li&gt;通过操作 CoreDNS，我们将该SOA应用的各个接口都添加为 DNS 记录，指向该应用的ClusterIP&lt;/li&gt;
&lt;li&gt;当客户端代码使用不同的接口名访问时，DNS解析出来的都是同一个ClusterIP，后续步骤就和接口名无关了&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;欠缺微服务改造带来的限制&#34;&gt;欠缺微服务改造带来的限制&lt;/h3&gt;
&lt;p&gt;需要特别指出的是，DNS通用寻址方案虽然可以解决使用接口名访问和支持单进程多接口的问题，但是这种方案只是完成了“寻址”，也就是打通端到端的访问通道。由于应用没有进行微服务改造，部署上是依然一个应用（体现为一个进程，在Kubernetes上体现为一个Service）中包含多个接口，本质上：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务注册依然是以应用名为基础，对应的Kubernetes service和service上的label也是应用级别&lt;/li&gt;
&lt;li&gt;因此提供的服务治理功能，也是以Kubernetes的Service为基本单位，包括灰度，蓝绿，版本拆分等所有的Version Based Routing功能&lt;/li&gt;
&lt;li&gt;这意味着，只能进行&lt;strong&gt;应用级别&lt;/strong&gt;的服务治理，而不能继续细分到&lt;strong&gt;接口级别&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个限制来源于应用没有进行微服务改造，没有按照接口将应用拆分为多个独立的微服务，因此无法得到更小的服务治理粒度。这也就是我们前面说的“先上车后补票”的含义：在微服务改造前，先获得Service Mesh的服务治理的绝大部分功能，再慢慢进行微服务改造。&lt;/p&gt;
&lt;h2 id=&#34;dns通用寻址方案-1&#34;&gt;DNS通用寻址方案&lt;/h2&gt;
&lt;p&gt;我们将这个方案称为”DNS通用寻址方案”，是因为这个方案真的非常的通用，体现在以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对使用者来说，通过域名和DNS解析的方式来访问，是非常简单直白而易于接受的，同时也是广泛使用的，适用于各种语言、平台、框架&lt;/li&gt;
&lt;li&gt;这个方案延续了Kubernetes和Istio的做法，保持了一致的方式，对用户提供了相同的体验&lt;/li&gt;
&lt;li&gt;这个寻址方案，不仅仅可以用于Dubbo、SOFA、HSF等RPC框架往Service Mesh的迁移，也可以适用于基于HTTP/REST协议的SOA应用，甚至最传统的web应用（例如tomcat下部署多个war包）迁移到Service Mesh&lt;/li&gt;
&lt;li&gt;我们也在考虑在未来的Serverless项目中，将Function的寻址也统一到这套方案中，而无需要求每个Function都进行一次服务注册&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;概括的说，有了这套DNS通用寻址方案，不管需要寻址的实体是什么形态，只要它部署在Service Mesh上，满足以下条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有正常注册为Kubernetes Service，分配有ClusterIP&lt;/li&gt;
&lt;li&gt;为实体（或者更细分的子实体）分配域名或子域名，然后添加到DNS，解析到ClusterIP&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么我们的DNS通用寻址方案，就可以工作，从而将请求正确的转发到目的地。而在此基础上，Service Mesh 所有的强大功能都可以为这些实体所用，实现我们前面的目标：在不修改代码不做微服务改造的情况下，也能提前受益于Service Mesh带来的强大服务治理功能。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh Meetup #1 杭州站</title>
      <link>https://cloudnative.to/event/service-mesh-meetup-01/</link>
      <pubDate>Sat, 30 Jun 2018 13:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/service-mesh-meetup-01/</guid>
      <description>&lt;h2 id=&#34;讲师分享&#34;&gt;讲师分享&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV19h411p7jn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区 meetup 第七期深圳站开场致辞 - 宋净超&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1WQ4y1z7zQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 IAST 构建高效的 DevSecOps 流程 - 董志勇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1hf4y1E7KJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生场景下的开发和调试-汪晟杰，黄金浩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1LL411476c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy 在腾讯游戏云原生平台应用 - 田甜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1TQ4y1C7xx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 KubeVela 构建混合云应用管理平台 - 邓洪超&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SOFAStack Cloud Native Workshop</title>
      <link>https://cloudnative.to/event/sofastack-cloud-native-workshop/</link>
      <pubDate>Sun, 24 Jun 2018 10:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/sofastack-cloud-native-workshop/</guid>
      <description>&lt;p&gt;SOFAStack（Scalable Open Financial Architecture Stack）是蚂蚁集团自主研发并开源的金融级分布式架构，包含了构建金融级云原生架构所需的各个组件，是在金融场景里锤炼出来的最佳实践。SOFAStack 官方网站：&lt;a href=&#34;https://www.sofastack.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.sofastack.tech/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参加此次 Meetup 您将获得：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于 SOFAStack 快速构建微服务&lt;/li&gt;
&lt;li&gt;金融场景下的分布式事务最佳实践&lt;/li&gt;
&lt;li&gt;基于 Kubernetes 的云原生部署体验&lt;/li&gt;
&lt;li&gt;云上的 Service Mesh 基本使用场景体验&lt;/li&gt;
&lt;li&gt;基于 Serverless 轻松构建云上应用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如何注册：此活动须提前注册。请将 SOFAStack Cloud Native Workshop 添加到您 KubeCon + CloudNativeCon + Open Source Summit 的&lt;a href=&#34;https://www.lfasiallc.com/events/kubecon-cloudnativecon-china-2019/register/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;注册表&lt;/a&gt;里。您可以使用 &lt;code&gt;KCCN19COMATF&lt;/code&gt; 折扣码获取 KubeCon 半价门票！&lt;/p&gt;
&lt;p&gt;如果对此活动有任何疑问，请发送邮件至 &lt;a href=&#34;mailto:jingchao.sjc@antfin.com&#34;&gt;jingchao.sjc@antfin.com&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;活动详情&#34;&gt;活动详情&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;9:00 - 9:20 开场演讲 SOFAStack 云原生开源体系介绍 by 余淮&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9:20 - 10:10 使用 SOFAStack 快速构建微服务 by 玄北&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于 SOFA 技术栈构建微服务应用。通过本 workshop ，您可以了解在 SOFA 体系中如何上报应用监控数据、服务链路数据以及发布及订阅服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10:15 - 11:05 SOFABoot 动态模块实践 by 卫恒&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在本 workshop 中，您可以基于 SOFADashboard 的 ARK 管控能力来实现 SOFAArk 提供的合并部署和动态模块推送的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11:10 - 12:00 使用 Seata 保障支付一致性 by 屹远&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务架构下，分布式事务问题是一个业界难题。通过本workshop，您可以了解到分布式架构下，分布式事务问题产生的背景，以及常见的分布式事务解决方案；并亲身体验到如何使用开源分布式事务框架Seata的AT模式、TCC模式解决业务数据的最终一致性问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12:00 - 13:00 午餐时间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13:00 - 13:30 蚂蚁集团的云原生探索与实践 by 首仁&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13:30 - 14:40 通过 Serverless 快速上云 by 隐秀&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;作为云原生技术前进方向之一，Serverless 架构让您进一步提高资源利用率，更专注于业务研发。通过我们的 workshop，您可以体验到快速创建 Serveless 应用、根据业务请求秒级 0-1-N 自动伸缩、通过日志查看器快速排错、按时间触发应用等产品新功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14:50 - 16:00 使用 CloudMesh 轻松实践 Service Mesh by 敖小剑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Service Mesh 将服务间通信能力下沉到基础设施，让应用解耦并轻量化。但 Service Mesh 本身的复杂度依然存在，CloudMesh 通过将 Service Mesh 托管在云上，使得您可以轻松的实践 Service Mesh 技术。通过我们的 workshop，您可以快速部署应用到 CloudMesh ，对服务进行访问，通过监控查看流量，体验服务治理、Sidecar管理和对服务的新版本进行灰度发布等实用功能。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
