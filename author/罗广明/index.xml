<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>罗广明 | 云原生社区（中国）</title>
    <link>https://cloudnative.to/author/%E7%BD%97%E5%B9%BF%E6%98%8E/</link>
      <atom:link href="https://cloudnative.to/author/%E7%BD%97%E5%B9%BF%E6%98%8E/index.xml" rel="self" type="application/rss+xml" />
    <description>罗广明</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Sat, 22 Apr 2023 09:30:00 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/author/%E7%BD%97%E5%B9%BF%E6%98%8E/avatar_hu15307285741086540024.jpg</url>
      <title>罗广明</title>
      <link>https://cloudnative.to/author/%E7%BD%97%E5%B9%BF%E6%98%8E/</link>
    </image>
    
    <item>
      <title>可观测性峰会 2023</title>
      <link>https://cloudnative.to/event/observability-summit-2023/</link>
      <pubDate>Sat, 22 Apr 2023 09:30:00 +0800</pubDate>
      <guid>https://cloudnative.to/event/observability-summit-2023/</guid>
      <description>&lt;p&gt;活动日程请见&lt;a href=&#34;https://huodongxing.com/event/6695157778700&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;活动行&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>解秘开源与社区</title>
      <link>https://cloudnative.to/blog/opensource-and-community/</link>
      <pubDate>Sat, 06 Jun 2020 12:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/opensource-and-community/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;开源已经无处不在，当下已经很难找到一款软件是完全和开源没有任何关系的了。开源软件，正在成为现代社会的基础设施。&lt;/p&gt;
&lt;p&gt;“Open up your phone. Your social media, your news, your medical records, your bank: they are all using free and public code.” - Nadia Eghbal 《Roads and Bridges: The Unseen Labor Behind Our Digital Infrastructure》&lt;/p&gt;
&lt;p&gt;开源，并非与你不相关，并非离你很遥远，开源就在你身边！&lt;/p&gt;
&lt;p&gt;而谈到开源软件的开发模式，不得不提及 Eric S.Raymond 在其著名的论文《大教堂与集市》中论证了开源的软件工程理论。如他所定义的 Linus 定律：众目睽睽之下，Bug 将无处藏身，模块化、去中心化、快速发布快速反馈等等是可行的，Kernel 就是成功的案例。&lt;/p&gt;
&lt;p&gt;随着 Linux、Apache、Perl/Python/PHP、MySQL/PostgreSQL 等开源技术的崛起，以及技术的更新迭代，开源已经不再是稀缺，而是一种过剩，架构师在最初构建业务系统的时候，面临的不是创造，而是选择。于是开源项目又有了新的优势：&lt;/p&gt;
&lt;p&gt;可以让业务快速的搭建原型
几乎以零成本的方式来进行
让产品迅速进入市场，获得及时反馈&lt;/p&gt;
&lt;h2 id=&#34;开源社区&#34;&gt;开源社区&lt;/h2&gt;
&lt;p&gt;开源的理论知识或许太过深奥、晦涩。接下来我就接地气地讨论下面几个实际问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为什么要加入开源社区？&lt;/li&gt;
&lt;li&gt;加入社区的门槛有哪些？&lt;/li&gt;
&lt;li&gt;加入社区你能做什么？&lt;/li&gt;
&lt;li&gt;加入社区如何正确互动提问？&lt;/li&gt;
&lt;li&gt;加入社区有哪些收益？&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么要加入开源社区&#34;&gt;为什么要加入开源社区？&lt;/h3&gt;
&lt;p&gt;本文开篇说到过，开源已经无处不在，不管你是从事架构、开发、运维、算法还是产品、运营，只要你从事计算机与互联网相关工作，总有“一款”开源社区适合你，你可以从该社区中获益。&lt;/p&gt;
&lt;h3 id=&#34;加入社区的门槛有哪些&#34;&gt;加入社区的门槛有哪些？&lt;/h3&gt;
&lt;p&gt;最近在邀请身边的朋友加入社区时，偶尔发现有人这样回答：我现在水平还不够，等以后知识水平提升了再加入吧。如果这位是在诚实地回答，我想告诉你的是，加入开源社区原则上并没有门槛。不限于其经验水平、性别、性别认同和表达、性取向、残疾、个人外貌、体型、人种、种族、年龄、宗教或国籍等。如果一定要在加上一个门槛的话，我希望你能有参与社区建设的热情、你懂得社交的基本礼仪、你有一定责任心与荣辱感，你能遵守社区的行为准则与国家地区的法律法规！&lt;/p&gt;
&lt;h3 id=&#34;加入社区你能做什么&#34;&gt;加入社区你能做什么？&lt;/h3&gt;
&lt;p&gt;很重要的一点，加入社区的个体可以做什么，可以在其中扮演怎样的角色！这个可能需要看社区本身的性质。如果是开源项目官方社区，加入社区后，你可以参与讨论如何贡献代码，参与技术方案的决策，当然也可以参与“疑难杂症”的讨论或者提问。如果社区的性质是终端用户社区，比如某个技术领域或者某个开源项目在中国的本地社区，那么加入社区你有很多事可以做，包括但不限于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参与技术话题讨论与交流&lt;/li&gt;
&lt;li&gt;参与官方文档汉化活动（翻译）&lt;/li&gt;
&lt;li&gt;参与或协办线上线下活动&lt;/li&gt;
&lt;li&gt;技术文章（原创/翻译）投稿&lt;/li&gt;
&lt;li&gt;在社区内进行技术分享&lt;/li&gt;
&lt;li&gt;参与社区组织的电子书的写作&lt;/li&gt;
&lt;li&gt;参与社区网站的构建和维护&lt;/li&gt;
&lt;li&gt;宣传自己热爱的开源项目&lt;/li&gt;
&lt;li&gt;其它&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正如第二点所说，加入社区本身没有门槛，但是加入社区后具体能做些什么取决于个体本身的水平和能力。社区是由个体组成，社区伴随个体共同成长。&lt;/p&gt;
&lt;p&gt;值得一提的是，很多人加入社区长期处于潜水状态，我这里强烈建议这部分群体浮出水面。被动接受地知识不易于真正吸纳，参与讨论，最终将知识产出反馈给社区，这样才能形成良性循环。另外有一部分人加入社区后，只有工作中遇到问题时才活跃起来，在社区中提问，其它社区活动也不参与，也没有任何反馈，这样单方面索取的行为不利于社区的发展，久而久之，社区就不再有知识产出了，自己也很难从社区中获得提升。&lt;/p&gt;
&lt;h3 id=&#34;加入社区如何正确互动提问&#34;&gt;加入社区如何正确互动提问？&lt;/h3&gt;
&lt;p&gt;紧接上面的话题，大部分参与开源社区主要的活动就是参与互动或者提问。&lt;/p&gt;
&lt;p&gt;参与社区互动其实也是一个社交活动，需要个人把握社交分寸，遵守基本的社交礼仪。不可接受的参与者行为包括但不限于：讨论问题上升到人身攻击，挑衅、侮辱或贬低性评论、公开或私下骚扰、未经允许发布他人私人信息、未经允许发布广告或者其它不良信息、无故刷屏刷帖从而占用公共资源等。&lt;/p&gt;
&lt;p&gt;另外，在社区里提问或者发起相关技术话题讨论是被鼓励的，但是提问也是一门艺术，需要提问着好好把握。有一个知名 Github 项目 &lt;a href=&#34;https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/master/README-zh_CN.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How-To-Ask-Questions-The-Smart-Way&lt;/a&gt;对提问的智慧进行完整的整理，我这里简单整理几点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提问之前先尝试自己通过各种手段搜索答案，包括但不限于百度、谷歌、相关技术论坛、技术手册等。当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并不是一个不劳而获且浪费别人的时间的提问者。&lt;/li&gt;
&lt;li&gt;提问时，使用清晰、正确、精准的语句描述问题，话不在多而在精。无效的问题，往往浪费大家的时间去阅读和理解，并且可能没有人去给你解答，因此清楚明确地表达你的问题以及需求至关重要。&lt;/li&gt;
&lt;li&gt;提问时要有一定的礼貌，尤其通过社区向个人提问时至关重要。虽然同为社区成员，但往往素不相识，别人没有义务一定要给你解决问题，尤其当该问题需要花费不少时间去梳理和解答。向个人提问时，一般需要首先做个自我介绍，然后礼貌地请教问题，不管问题最终是否得到解答，都能够表示感谢。尤其当你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;加入社区有哪些收益&#34;&gt;加入社区有哪些收益？&lt;/h3&gt;
&lt;p&gt;简单来说，加入社区，肯定是有利可图的，你能够收获知识与成长、收获人脉、以及其它长期收益。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收获知识与成长。长期参与社区技术话题讨论，阅读社区提供的学习资源，参与社区活动，甚至直接给开源项目提交 PR，久而久之，在该领域的知识水平与解决问题的能力就会得到提升。以社区里面的技术达人为目标或者榜样，往往能督促个人朝着正确的方向快速前进。&lt;/li&gt;
&lt;li&gt;收获人脉。有一句俗话，参与开源社区就是混技术圈子的。在这个圈子里，你能找到志同道合的人，结交更多的朋友。三人行，必有我师焉。圈子里面技术大牛如云，结交和认识社区里面的技术达人，除了向强者学习之外，还有利于扩展自己的人脉资源，人脉多了，路就越走越宽了。&lt;/li&gt;
&lt;li&gt;收获影响力与认同感。一旦积极参与了社区活动，包括技术博客投稿，参与社区技术文档撰写，个人的技术影响力也会逐步提升，同时也会有更多人对你表示赞同与尊敬。替人解疑答惑，不仅自己的知识得到巩固和传播，也能收获别人的感激之情。&lt;/li&gt;
&lt;li&gt;其它长期收益。加入社区的收益往往很难在短期之内显现，而且即使你投入很多，也很难获得物质上的回报。如果你把目光放长远，你会发现，加入社区的长期收益有很多，包括个人技术影响力的提升、自身技术视野的提升、社交水平的提升，对于一些公司和部门来说，长期活跃在开源社区也能有助于职业的晋升。&lt;/li&gt;
&lt;li&gt;更多的收益取决于你愿意贡献多少精力在开源上。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;写在最后&#34;&gt;写在最后&lt;/h2&gt;
&lt;p&gt;对于广大中国开发者而言，终端用户开源社区是最容易接触的，也是最容易从中受益的。终端用户，这里指开源项目的最终收益者/使用者。而终端用户社区即由一群终端用户成立的社区。对于这样的社区，一般的宗旨为：拥抱开源、反馈开源。终端用户开源社区不仅仅是对开源项目与技术的传播、布道、交流，也会引导社区成员在力所能及的前提之下对开源项目进行反馈，包括提 bug，提交 PR，参与项目重要决策或设计等等。&lt;/p&gt;
&lt;p&gt;在开发者真正拥抱开源的同时，一个开放、多样且极具成长空间的开源社区不该被错过，它将为开发者回馈更大的价值。无论是社区本身，还是参与其中的众多开发者，相信都能在良性的互动中，相互促进，获得快速且长足的发展。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>混合微服务高可用在企业级生产中的实践</title>
      <link>https://cloudnative.to/blog/microservices-ha-practice/</link>
      <pubDate>Wed, 20 May 2020 06:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/microservices-ha-practice/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;Service Mesh 在企业落地中有诸多挑战，当与传统微服务应用共同部署治理时可用性挑战更为严峻。本文将以 Service Mesh 与 Spring Cloud 应用互联互通共同治理为前提，着重介绍基于 Consul 的注册中心高可用方案，通过各种限流、熔断策略保证后端服务的高可用，以及通过智能路由策略（负载均衡、实例容错等）实现服务间调用的高可用。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh-与-spring-cloud-应用的互通互联&#34;&gt;Service Mesh 与 Spring Cloud 应用的互通、互联&lt;/h2&gt;
&lt;p&gt;微服务是时下技术热点，大量互联网公司都在做微服务架构的推广和落地。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。而在这个技术转型中，国内有一个现象，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。近年来，新兴的 Service Mesh 技术也越来越火热，受到越来越多开发者的关注，大有后来居上的趋势。&lt;/p&gt;
&lt;p&gt;在听到社区里很多人谈到微服务技术选型时，注意到他们讨论一个非此即彼的问题：采用 Spring Cloud 还是以 Istio 为代表的 Service Mesh 技术？然而这个答案并非非黑即白、非你即我，一部分应用采用 Spring Cloud，另一部分采用 Service Mesh（Istio）是完全可能的。今天我就和大家一起来讨论这个问题。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu5232373274199076448.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu13364694799720913598.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu16655212501359513036.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu5232373274199076448.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;首先，我们来看一下 Spring Cloud 这个传统侵入式微服务框架。它包含以下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集大成者，Spring Cloud 包含了微服务架构的方方面面；选用目前各家公司开发的比较成熟的、经得住实践考验的服务框架；&lt;/li&gt;
&lt;li&gt;轻量级组件，Spring Cloud 整合的组件大多比较轻量级，且都是各自领域的佼佼者；&lt;/li&gt;
&lt;li&gt;开发简便，Spring Cloud 对各个组件进行了大量的封装，从而简化了开发；&lt;/li&gt;
&lt;li&gt;开发灵活，Spring Cloud 的组件都是解耦的，开发人员可以灵活按需选择组件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特别感谢 Netflix，这家很早就成功实践微服务的公司，几年前把自家几乎整个微服务框架栈贡献给了社区，早期的 Spring Cloud 主要是对 Netflix 开源组件的进一步封装。不过近两年，Spring Cloud 社区开始自研了很多新的组件，也接入了其他一些互联网公司的优秀实践。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu15987251394040066483.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu17429068481025247710.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu6378056854535702760.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu15987251394040066483.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;接下来，我们简单看一下 Service Mesh 框架。它带来了两大变革：微服务治理与业务逻辑的解耦，异构系统的统一治理。此外，服务网格相对于传统微服务框架，还拥有三大技术优势：可观察性、流量控制、安全。服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。&lt;/p&gt;
&lt;p&gt;然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。这些局限性包括：增加了链路与运维的复杂度、需要更专业的运维技能、带来了一定的延迟以及对平台的适配。&lt;/p&gt;
&lt;p&gt;更多关于 Spring Cloud 与 Service Mesh 的优缺点与比较，请阅读 Istio-Handbook [&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Mesh 概述&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15577610507585818048.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15100585947657452087.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu288238570600553650.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15577610507585818048.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;前面提到过，对于传统微服务框架 Spring Cloud 与新兴微服务框架 Service Mesh，并非是个非黑即白，非你即我，延伸到微服务与单体架构，它们也是可以共存的。&lt;/p&gt;
&lt;p&gt;也可以将其与混合云相类比，混合云中包含了公有云、私有云，可能还有其它的自有基础设施。目前来看，混合云是一种流行的实践方式；实际上，可能很难找到一个完全单一云模式的组织。对多数组织来说，将一个单体应用完全重构为微服务的过程中，对开发资源的调动是一个很严峻的问题；采用混合微服务策略是一个较好的方式，对开发团队来说，这种方式让微服务架构触手可及；否则的话，开发团队可能会因为时间、经验等方面的欠缺，无法接受对单体应用的重构工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构建混合微服务架构的最佳实践：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;最大化收益的部分优先重构；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非 Java 应用优先采用 Service Mesh 框架。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;混合微服务出现的原因是为了更好的支持平滑迁移，最大限度的提升服务治理水平，降低运维通信成本等，并且可能会在一个较长的周期存在着。而实现这一架构的前提，就是各服务的“互联互通”。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu725579676662698448.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu4792505942952485241.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu10271270990008246573.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu725579676662698448.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;要想实现上述“混合微服务架构”，运行时支撑服务必不可少，它主要包括服务注册中心、服务网关和集中式配置中心三个产品。&lt;/p&gt;
&lt;p&gt;传统微服务和 Service Mesh 双剑合璧（双模微服务），即“基于 SDK 的传统微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互联互通：两个体系中的应用可以相互访问；&lt;/li&gt;
&lt;li&gt;平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知；&lt;/li&gt;
&lt;li&gt;灵活演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里还包括对应用运行平台的要求，即两个体系下的应用，既可以运行在虚拟机之上，也可以运行在容器 /K8s  之上。我们不希望把用户绑定在 K8s 上，因此 Service Mesh 没有采用 K8s 的 Service 机制来做服务注册与发现，这里就突出了注册中心的重要性。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu15181670200628006254.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu8300215569814611852.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu17683058378532183422.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu15181670200628006254.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;百度智能云 CNAP 团队实现了上述混合微服务架构，即实现了两个微服务体系的应用互联互通、平滑迁移、灵活演进。上述混合微服务架构图包括以下几个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;API Server：前后端解耦，接口权限控制、请求转发、异常本地化处理等等；&lt;/li&gt;
&lt;li&gt;微服务控制中心：微服务治理的主要逻辑，包括服务注册的多租户处理、治理规则（路由、限流、熔断）的创建和转换、微服务配置的管理；&lt;/li&gt;
&lt;li&gt;监控数据存储、消息队列：主要是基于 Trace 的监控方案使用的组件；&lt;/li&gt;
&lt;li&gt;配置中心：微服务配置中心，最主要的功能是支持配置管理，包括治理规则、用户配置等所有微服务配置的存储和下发，微服务配置中心的特色是借助 SDK 可以实现配置/规则热更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来主要看一下注册中心的服务注册和发现机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spring Cloud 应用通过 SDK、Service Mesh 应用实现 Sidecar 分别向注册中心注册，注册的请求先通过微服务控制中心进行认证处理与多租户隔离；&lt;/li&gt;
&lt;li&gt;Mesh 控制面直接对接注册中心获取服务实例、Spring Cloud 应用通过 SDK 获取服务实例；&lt;/li&gt;
&lt;li&gt;双模异构，支持容器与虚机两种模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;注册中心与高可用方案&#34;&gt;注册中心与高可用方案&lt;/h2&gt;
&lt;p&gt;前面提到过，要想实现实现混合微服务架构，注册中心很关键。谈到注册中心，目前主流的开源注册中心包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper：Yahoo 公司开发的分布式协调系统，可用于注册中心，目前仍有很多公司使用其作为注册中心；&lt;/li&gt;
&lt;li&gt;Eureka：Netflix 开源组件，可用于服务注册发现组件，被广大 Spring Cloud 开发者熟知，遗憾的是目前已经不再维护，也不再被 Spring Cloud 生态推荐使用；&lt;/li&gt;
&lt;li&gt;Consul：HashiCorp 公司推出的产品，其可作为实现注册中心，也是本文介绍的重点；&lt;/li&gt;
&lt;li&gt;Etcd：Etcd 官方将其定义为可靠的分布式 KV 存储。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们注册中心选择了 Consul，Consul 包含了以下几个重要的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务发现：可以注册服务，也可以通过 Http 或 DNS 的方式发现已经注册的服务；&lt;/li&gt;
&lt;li&gt;丰富的健康检查机制；&lt;/li&gt;
&lt;li&gt;服务网格能力，最新版本已经支持 Envoy 作为数据面；&lt;/li&gt;
&lt;li&gt;KV 存储：可以基于 Consul KV 存储实现一个分布式配置中心；&lt;/li&gt;
&lt;li&gt;多数据中心：借助多数据中心，无需使用额外的抽象层，即可构建多地域的场景，支持多 DC 数据同步、异地容灾。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu14621623930298174895.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu9059818947501224796.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu6818294187213151446.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu14621623930298174895.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上图是 Consul 官网提供的架构图。Consul 架构中几个核心的概念如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agent: Agent 是运行在 Consul 集群的每个节点上的 Daemon 进程，通过 Consul Agent 命令将其启动，Agent 可以运行在 Client 或者 Server 模式下；&lt;/li&gt;
&lt;li&gt;Client：Client 是一种 Agent，其将会重定向所有的 RPC 请求到 Server，Client 是无状态的，其主要参与 LAN Gossip 协议池，其占用很少的资源，并且消耗很少的网络带宽；&lt;/li&gt;
&lt;li&gt;Server：Server 是一种 Agent，其包含了一系列的责任包括：参与 Raft 协议写半数（Raft Quorum）、维护集群状态、响应 RPC 响应、和其他 Datacenter 通过 WAN gossip 交换信息和重定向查询请求至 Leader 或者远端 Datacenter；&lt;/li&gt;
&lt;li&gt;Datacenter: Datacenter 其是私有的、低延迟、高带宽的网络环境，去除了在公共网络上的网络交互。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注册中心作为基础组件，其自身的可用性显得尤为重要，高可用的设计需要对其进行分布式部署，同时因在分布式环境下的复杂性，节点因各种原因都有可能发生故障，因此在分布式集群部署中，希望在部分节点故障时，集群依然能够正常对外服务。注册中心作为微服务基础设施，因此对其容灾和其健壮性有一定的要求，主要体现在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注册中心作为微服务基础设施，因此要求出现某些故障（如节点挂掉、网络分区）后注册中心仍然能够正常运行；&lt;/li&gt;
&lt;li&gt;当注册中心的发生故障时，不能影响服务间的正常调用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu7696585241858185244.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu17005445808160016604.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu3290646043431517625.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu7696585241858185244.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Consul 使用 Raft 协议作为其分布式一致性协议，本身对故障节点有一定的容忍性，在单个 DataCenter 中 Consul 集群中节点的数量控制在 2*n + 1 个节点，其中 n 为可容忍的宕机个数。Quorum size: Raft 协议选举需要半数以上节点写入成功。&lt;/p&gt;
&lt;p&gt;Q1:  节点的个数是否可以为偶数个？&lt;/p&gt;
&lt;p&gt;A2：答案是可以的，但是不建议部署偶数个节点。一方面如上表中偶数节点 4 和奇数节点 3 可容忍的故障数是一样的，另一方面，偶数个节点在选主节点的时候可能会出现瓜分选票的情形（虽然 Consul 通过重置 election timeout 来重新选举），所以还是建议选取奇数个节点。&lt;/p&gt;
&lt;p&gt;Q2:  是不是 Server 节点个数越多越好？&lt;/p&gt;
&lt;p&gt;A2：答案是否定的，虽然上表中显示 Server 数量越多可容忍的故障数越多，熟悉 Raft 协议的读者肯定熟悉 Log Replication（如上文介绍，日志复制时过半写成功才返回写成功），随着 Server 的数量越来越多，性能就会越低，所以结合实际场景一般建议 Server 部署 3 个节点。&lt;/p&gt;
&lt;p&gt;推荐采用三节点或五节点，最为有效，且能容错。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu12723312876342639059.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu2284294943191028328.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu2783807051860965115.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu12723312876342639059.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;注册中心设计的一个重要前提是：注册中心不能因为自身的原因或故障影响服务之间的相互调用。因此在实践过程中，如果注册中心本身发生了宕机故障/不可用，绝对不能影响服务之间的调用。这要求对接注册中心的 SDK 针对这种特殊情况进行客户端容灾设计，『客户端缓存』就是一种行之有效的手段。当注册中心发生故障无法提供服务时，服务本身并不会更新本地客户端缓存，利用其已经缓存的服务列表信息，正常完成服务间调用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7533524420930965430.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7514042313289374509.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu12991132331120068858.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7533524420930965430.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们在设计时采用同 Datacenter 集群内部部署 3 个 Server 节点，来保障高可用性，当集群中 1 个节点发生故障后，集群仍然能够正常运行，同时这 3 个节点部署在不同的机房，达到机房容灾的能力。&lt;/p&gt;
&lt;p&gt;在云上环境，涉及多 region 环境，因此在架构设计设计时，我们首先将 Consul 的一个 Datacenter 对应云上一个 region，这样更符合 Consul 对于 Datecenter 的定义（DataCenter 数据中心是私有性、低延迟、高带宽的网络环境）。中间代理层实现了服务鉴权、多租户隔离等功能；还可以通过中间代理层，对接多注册中心。&lt;/p&gt;
&lt;p&gt;云上环境存在多租户隔离的需求，即：A 租户的服务只能发现 A 租户服务的实例。针对此场景，需要在 『中间代理层』完成对多租户隔离功能的实现，其主要实践思路为使用 Consul  Api Feature 具备 Filtering 功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 Filtering 功能实现租户隔离需求；&lt;/li&gt;
&lt;li&gt;减少查询注册中心接口时网络负载。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;通过治理策略保证服务高可用&#34;&gt;通过治理策略保证服务高可用&lt;/h2&gt;
&lt;p&gt;什么是高可用？维基百科这么定义：系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。我们通常用 N 个 9 来定义系统的可用性，如果能达到 4 个 9，则说明系统具备自动恢复能力；如果能达到 5 个 9，则说明系统极其健壮，具有极高可用性，而能达到这个指标则是非常难的。&lt;/p&gt;
&lt;p&gt;常见的系统不可用因素包括：程序和配置出 bug、机器故障、机房故障、容量不足、依赖服务出现响应超时等。高可用的抓手包括：研发质量、测试质量、变更管理、监控告警、故障预案、容量规划、放火盲测、值班巡检等。这里，将主要介绍通过借助治理策略采用高可用设计手段来保障高可用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11691072992097189929.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11672523877399572764.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu2247716859581423531.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11691072992097189929.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;高可用是一个比较复杂的命题，所以设计高可用方案也涉及到了方方面面。这中间将会出现的细节是多种多样的，所以我们需要对这样一个微服务高可用方案进行一个顶层的设计。&lt;/p&gt;
&lt;p&gt;比如服务冗余：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;冗余策略：每个机器每个服务都可能出现问题，所以第一个考虑到的就是每个服务必须不止一份，而是多份。所谓多份一致的服务就是服务的冗余，这里说的服务泛指了机器的服务、容器的服务、还有微服务本身的服务。在机器服务层面需要考虑，各个机器间的冗余是否有在物理空间进行隔离冗余。&lt;/li&gt;
&lt;li&gt;无状态化：我们可以随时对服务进行扩容或者缩容，想要对服务进行随时随地的扩缩容，就要求我们的服务是一个无状态化，所谓无状态化就是每个服务的服务内容和数据都是一致的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如柔性化/异步化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所谓的柔性化，就是在我们业务允许的情况下，做不到给予用户百分百可用的，通过降级的手段给到用户尽可能多的服务，而不是非得每次都交出去要么 100 分或 0 分的答卷。柔性化更多是一种思维，需要对业务场景有深入的了解。&lt;/li&gt;
&lt;li&gt;异步化：在每一次调用，时间越长存在超时的风险就越大，逻辑越复杂执行的步骤越多，存在失败的风险也就越大。如果在业务允许的情况下，用户调用只给用户必须要的结果，不是需要同步的结果可以放在另外的地方异步去操作，这就减少了超时的风险也把复杂业务进行拆分减低复杂度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面讲到的几种提高服务高可用的手段，大多需要从业务以及部署运维的角度实现。而接下来会重点介绍，可以通过 SDK/Sidecar 手段提供服务高可用的治理策略，这些策略往往对业务是非侵入或者弱侵入的，能够让绝大多数服务轻松实现服务高可用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu10931811979774022813.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu9949460287785823897.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu17782557879256910721.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu10931811979774022813.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;微服务之间一旦建立起路由，就意味着会有数据在服务之间流通。由于不同服务可以提供的资源和对数据流量的承载能力不尽相同，为了防止单个 Consumer 占用 Provider 过多的资源，或者突发的大流量冲击导致 Provider 故障，需要服务限流来保证服务的高可用。&lt;/p&gt;
&lt;p&gt;在服务治理中，虽然我们可以通过限流规则尽量避免服务承受过高的流量，但是在实际生产中服务故障依然难以完全避免。当整个系统中某些服务产生故障时，如果不及时采取措施，这种故障就有可能因为服务之间的互相访问而被传播开来，最终导致故障规模的扩大，甚至导致整个系统奔溃，这种现象我们称之为“雪崩”。熔断降级其实不只是服务治理中，在金融行业也有很广泛的应用。比如当股指的波动幅度超过规定的熔断点时，交易所为了控制风险采取的暂停交易措施。&lt;/p&gt;
&lt;p&gt;负载均衡是高可用架构的一个关键组件，主要用来提高性能和可用性，通过负载均衡将流量分发到多个服务器，同时多服务器能够消除这部分的单点故障。&lt;/p&gt;
&lt;p&gt;以上治理规则在某种程度上可以在 Spring Cloud 与 Service Mesh 两个框架上进行对齐，即同一套治理配置，可以通过转换分发到 Spring Cloud 应用的 SDK 上以及 Service Mesh 的 Sidecar 上。可以由 Config-server 负责规则下发，也可以由 Service Mesh 的控制面负责下发，取决于具体的架构方案。&lt;/p&gt;
&lt;h3 id=&#34;服务限流&#34;&gt;服务限流&lt;/h3&gt;
&lt;p&gt;对于一个应用系统来说一定会有极限并发/请求数，即总有一个 TPS/QPS 阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务或进行流量整形。&lt;/p&gt;
&lt;p&gt;常用的微服务限流架构包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接入层（api-gateway）限流：
&lt;ul&gt;
&lt;li&gt;单实例；&lt;/li&gt;
&lt;li&gt;多实例：分布式限流算法；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;调用外部限流服务限流：
&lt;ul&gt;
&lt;li&gt;微服务收到请求后，通过限流服务暴露的 RPC 接口查询是否超过阈值；&lt;/li&gt;
&lt;li&gt;需单独部署限流服务；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;切面层限流（SDK）：
&lt;ul&gt;
&lt;li&gt;限流功能集成在微服务系统切面层，与业务解耦；&lt;/li&gt;
&lt;li&gt;可结合远程配置中心使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的限流策略包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拒绝策略：
&lt;ul&gt;
&lt;li&gt;超过阈值直接返回错误；&lt;/li&gt;
&lt;li&gt;调用方可做熔断降级处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;延迟处理：
&lt;ul&gt;
&lt;li&gt;前端设置一个流量缓冲池，将所有的请求全部缓冲进这个池子，不立即处理。然后后端真正的业务处理程序从这个池子中取出请求依次处理，常见的可以用队列模式来实现（MQ：削峰填谷）；&lt;/li&gt;
&lt;li&gt;用异步的方式去减少了后端的处理压力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特权处理：
&lt;ul&gt;
&lt;li&gt;这个模式需要将用户进行分类，通过预设的分类，让系统优先处理需要高保障的用户群体，其它用户群的请求就会延迟处理或者直接不处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的限流算法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;固定时间窗口限流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先需要选定一个时间起点，之后每次接口请求到来都累加计数器，如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次接口请求），累加访问次数超过限流值，则限流熔断拒绝接口请求。当进入下一个时间窗口之后，计数器清零重新计数；&lt;/li&gt;
&lt;li&gt;缺点在于：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;滑动时间窗口算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题，是对固定时间窗口算法的一种改进；&lt;/li&gt;
&lt;li&gt;缺点在于：需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;令牌桶算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中；&lt;/li&gt;
&lt;li&gt;桶中最多可以存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 会被丢弃；&lt;/li&gt;
&lt;li&gt;接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 就阻塞或者拒绝服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;漏桶算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于取令牌的频率也有限制，要按照 t/n 固定的速度来取令牌；&lt;/li&gt;
&lt;li&gt;实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃；&lt;/li&gt;
&lt;li&gt;令牌桶和漏桶算法的算法思想大体类似，漏桶算法作为令牌桶限流算法的改进版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;令牌桶算法和漏桶算法，在某些场景下（内存消耗、应对突发流量），这两种算法会优于时间窗口算法成为首选。&lt;/p&gt;
&lt;h3 id=&#34;熔断&#34;&gt;熔断&lt;/h3&gt;
&lt;p&gt;断路器模式是微服务架构中广泛采用的模式之一，旨在将故障的影响降到最低，防止级联故障和雪崩，并确保端到端性能。我们将比较使用两种不同方法实现它的优缺点：Hystrix 和 Istio。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-熔断png&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;熔断.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu12227589584932449959.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu13853160177254565633.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu17680794763748597382.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu12227589584932449959.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      熔断.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在电路领域中，断路器是为保护电路而设计的一种自动操作的电气开关。它的基本功能是在检测到故障后中断电流，然后可以重置 (手动或自动)，以在故障解决后恢复正常操作。这看起来与我们的问题非常相似：为了保护应用程序不受过多请求的影响，最好在后端检测到重复出现的错误时立即中断前端和后端之间的通信。Michael Nygard 在他的《Release It》一书中使用了这个类比，并为应用于上述超时问题的设计模式提供了一个典型案例，可以用上图来总结。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu15070006048435518010.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu505864961362440863.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu18322367428924516166.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu15070006048435518010.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Istio 通过 DestinationRule 实现断路器模式，或者更具体的路径 TrafficPolicy (原断路器) -&amp;gt;  OutlierDetection，根据上图模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consecutiveErrors 断路器打开前的出错次数；&lt;/li&gt;
&lt;li&gt;interval 断路器检查分析的时间间隔；&lt;/li&gt;
&lt;li&gt;baseEjectionTime 最小的开放时间，该电路将保持一段时间等于最小弹射持续时间和电路已打开的次数的乘积；&lt;/li&gt;
&lt;li&gt;maxEjectionPercent 可以弹出的上游服务的负载平衡池中主机的最大百分比，如果驱逐的主机数量超过阈值，则主机不会被驱逐。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与上述公称断路器相比，有两个主要偏差：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有半开放的状态。然而，断路器持续打开的时间取决于被调用服务之前失败的次数，持续的故障服务将导致断路器的开路时间越来越长。&lt;/li&gt;
&lt;li&gt;在基本模式中，只有一个被调用的应用程序 (后端)。在更实际的生产环境中，负载均衡器后面可能部署同一个应用程序的多个实例。某些情况下有些实例可能会失败，而有些实例可能会工作。因为 Istio 也有负载均衡器的功能，能够追踪失败的实例，并把它们从负载均衡池中移除，在一定程度上：‘maxEjectionPercent’属性的作用是保持一小部分的实例池。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hystrix 提供了一个断路器实现，允许在电路打开时执行 fallback 机制。最关键的地方就在 HystrixCommand 的方法 run() 和 getFallback()：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run() 是要实际执行的代码 e.g. 从报价服务中获取价格；&lt;/li&gt;
&lt;li&gt;getFallback() 获取当断路器打开时的 fallback 结果 e.g. 返回缓存的价格。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spring Cloud 是建立在 Spring Boot 之上的框架，它提供了与 Spring 的良好集成。它让开发者在处理 Hystrix 命令对象的实例化时，只需注释所需的 fallback 方法。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu217600569368768926.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu2167969886597103558.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu3292752890040765061.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu217600569368768926.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;实现断路器的方法有两种，一种是黑盒方式，另一种是白盒方式。Istio 作为一种代理管理工具，使用了黑盒方式，它实现起来很简单，不依赖于底层技术栈，而且可以在事后配置。另一方面，Hystrix 库使用白盒方式，它允许所有不同类型的 fallback:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个默认值；&lt;/li&gt;
&lt;li&gt;一个缓存；&lt;/li&gt;
&lt;li&gt;调用其他服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它还提供了级联回退（cascading fallbacks）。这些额外的特性是有代价的：它需要在开发阶段就做出 fallback 的决策。&lt;/p&gt;
&lt;p&gt;这两种方法之间的最佳匹配可能会依靠自己的上下文：在某些情况下，如引用的服务，一个白盒战略后备可能是一个更好的选择，而对于其他情况下快速失败可能是完全可以接受的，如一个集中的远程登录服务。&lt;/p&gt;
&lt;p&gt;常用的熔断方法包括自动熔断与手动熔断。发生熔断时也可以选择 fail-fast 或者 fallback。这些用户都可以基于需求灵活使用。&lt;/p&gt;
&lt;h3 id=&#34;智能路由&#34;&gt;智能路由&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/microservices-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu1255300304719981453.webp 400w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu9899594518319898844.webp 760w,
               /blog/microservices-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu17424190256816888510.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/microservices-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu1255300304719981453.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后，我们来看一下智能路由带来的高可用。智能路由这里包括（客户端）负载均衡与实例容错策略。对于 Spring Cloud 框架来说，这部分能力由 Ribbon 来提供，Ribbon 支持随机、轮询、响应时间权重等负载均衡算法。而对于 Service Mesh 框架，这部分能力由 Envoy 提供，Envoy 支持随机、轮询（加权）、环哈希等算法。为了实现两套系统的规则统一对齐，可以采用其交集。&lt;/p&gt;
&lt;p&gt;而容错策略包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;failover：失败后自动切换其他服务器，支持配置重试次数；&lt;/li&gt;
&lt;li&gt;failfast：失败立即报错，不再重试；&lt;/li&gt;
&lt;li&gt;failresnd：将失败请求放入缓存队列、异步处理，搭配 failover 使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio 支持重试策略配置，而 fail-fast 即对应与重试次数为 0。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;微服务的高可用是一个复杂的问题，往往需要从多个角度去看，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从手段看高可用。主要使用的技术手段是服务和数据的冗余备份和失效转移，一组服务或一组数据都能在多节点上，之间相互备份。当一台机器宕机或出现问题的时候，可以从当前的服务切换到其他可用的服务，不影响系统的可用性，也不会导致数据丢失。&lt;/li&gt;
&lt;li&gt;从架构看高可用。保持简单的架构，目前多数网站采用的是比较经典的分层架构，应用层、服务层、数据层。应用层是处理一些业务逻辑，服务层提供一些数据和业务紧密相关服务，数据层负责对数据进行读写。简单的架构可以使应用层，服务层可以保持无状态化进行水平扩展，这个属于计算高可用。同时在做架构设计的时候，也应该考虑 CAP 理论。&lt;/li&gt;
&lt;li&gt;从硬件看高可用。首先得确认硬件总是可能坏的，网络总是不稳定的。解决它的方法也是一个服务器不够就来多几个，一个机柜不够就来几个，一个机房不够就来几个。&lt;/li&gt;
&lt;li&gt;从软件看高可用。软件的开发不严谨，发布不规范也是导致各种不可用出现，通过控制软件开发过程质量监控，通过测试，预发布，灰度发布等手段也是减少不可用的措施。&lt;/li&gt;
&lt;li&gt;从治理看高可用。将服务规范化，事前做好服务分割，做好服务监控，预判不可用的出现，在不可用出现之前发现问题，解决问题。比如在服务上线后，根据经验，配置服务限流规则以及自动熔断规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Mesh 概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/zoS-5oyfh9EV6S5PLy54yg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Consul 作为注册中心在云环境的实践与应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/62237UuEEJiOP_b3xRrZog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;有了这三个锦囊，再也不用担心微服务治理了&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/oky8g1Nisdr2T4kYG-DFhg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一文理解微服务高可用的常用手段&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/blog/istio-vs-hystrix-circuit-breaker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务断路器模式实现：Istio vs Hystrix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh 高可用在企业级生产中的实践</title>
      <link>https://cloudnative.to/blog/baidu-service-mesh-ha-practice/</link>
      <pubDate>Tue, 19 May 2020 10:20:46 +0800</pubDate>
      <guid>https://cloudnative.to/blog/baidu-service-mesh-ha-practice/</guid>
      <description>&lt;p&gt;Service Mesh Virtual Meetup 是 ServiceMesher 社区和 CNCF 联合主办的线上系列直播。本期为 Service Mesh Virtual Meetup#1，邀请了四位来自不同公司的嘉宾，从不同角度展开了 Service Mesh 的应用实践分享，分享涵盖来自陌陌和百度的 Service Mesh 生产实践，Service Mesh 的可观察性和生产实践以及与传统微服务中可观察性的区别，还有如何使用 SkyWalking 来观测 Service Mesh。&lt;/p&gt;
&lt;p&gt;本文根据 5 月 13 日晚，百度高级工程师罗广明的主题分享《Service Mesh 高可用在企业级生产中的实践》整理。文末包含本次分享的视频回顾链接以及 PPT 下载地址。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;Service Mesh 在企业落地中有诸多挑战，当与传统微服务应用共同部署治理时可用性挑战更为严峻。本次分享将以 Service Mesh 与 Spring Cloud 应用互联互通共同治理为前提，着重介绍基于 Consul 的注册中心高可用方案，通过各种限流、熔断策略保证后端服务的高可用，以及通过智能路由策略（负载均衡、实例容错等）实现服务间调用的高可用。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh-与-spring-cloud-应用的互通互联&#34;&gt;Service Mesh 与 Spring Cloud 应用的互通、互联&lt;/h2&gt;
&lt;p&gt;微服务是时下技术热点，大量互联网公司都在做微服务架构的推广和落地。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。而在这个技术转型中，国内有一个现象，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。近年来，新兴的 Service Mesh 技术也越来越火热，受到越来越多开发者的关注，大有后来居上的趋势。&lt;/p&gt;
&lt;p&gt;在听到社区里很多人谈到微服务技术选型时，注意到他们讨论一个非此即彼的问题：采用 Spring Cloud 还是以 Istio 为代表的 Service Mesh 技术？然而这个答案并非非黑即白、非你即我，一部分应用采用 Spring Cloud，另一部分采用 Service Mesh（Istio）是完全可能的。今天我就和大家一起来讨论这个问题。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu5232373274199076448.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu13364694799720913598.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu16655212501359513036.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexuwzhhgsj30qo0f0nmp_hu5232373274199076448.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;首先，我们来看一下 Spring Cloud 这个传统侵入式微服务框架。它包含以下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集大成者，Spring Cloud 包含了微服务架构的方方面面；选用目前各家公司开发的比较成熟的、经得住实践考验的服务框架；&lt;/li&gt;
&lt;li&gt;轻量级组件，Spring Cloud 整合的组件大多比较轻量级，且都是各自领域的佼佼者；&lt;/li&gt;
&lt;li&gt;开发简便，Spring Cloud 对各个组件进行了大量的封装，从而简化了开发；&lt;/li&gt;
&lt;li&gt;开发灵活，Spring Cloud 的组件都是解耦的，开发人员可以灵活按需选择组件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特别感谢 Netflix，这家很早就成功实践微服务的公司，几年前把自家几乎整个微服务框架栈贡献给了社区，早期的 Spring Cloud 主要是对 Netflix 开源组件的进一步封装。不过近两年，Spring Cloud 社区开始自研了很多新的组件，也接入了其他一些互联网公司的优秀实践。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu15987251394040066483.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu17429068481025247710.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu6378056854535702760.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7038qj30qo0f01ie_hu15987251394040066483.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;接下来，我们简单看一下 Service Mesh 框架。它带来了两大变革：微服务治理与业务逻辑的解耦，异构系统的统一治理。此外，服务网格相对于传统微服务框架，还拥有三大技术优势：可观察性、流量控制、安全。服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。&lt;/p&gt;
&lt;p&gt;然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。这些局限性包括：增加了链路与运维的复杂度、需要更专业的运维技能、带来了一定的延迟以及对平台的适配。&lt;/p&gt;
&lt;p&gt;更多关于 Spring Cloud 与 Service Mesh 的优缺点与比较，请阅读 Istio-Handbook [&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Mesh 概述&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15577610507585818048.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15100585947657452087.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu288238570600553650.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux8sg9oj30qo0f0nn8_hu15577610507585818048.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;前面提到过，对于传统微服务框架 Spring Cloud 与新兴微服务框架 Service Mesh，并非是个非黑即白，非你即我，延伸到微服务与单体架构，它们也是可以共存的。&lt;/p&gt;
&lt;p&gt;也可以将其与混合云相类比，混合云中包含了公有云、私有云，可能还有其它的自有基础设施。目前来看，混合云是一种流行的实践方式；实际上，可能很难找到一个完全单一云模式的组织。对多数组织来说，将一个单体应用完全重构为微服务的过程中，对开发资源的调动是一个很严峻的问题；采用混合微服务策略是一个较好的方式，对开发团队来说，这种方式让微服务架构触手可及；否则的话，开发团队可能会因为时间、经验等方面的欠缺，无法接受对单体应用的重构工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构建混合微服务架构的最佳实践：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;最大化收益的部分优先重构；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非 Java 应用优先采用 Service Mesh 框架。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;混合微服务出现的原因是为了更好的支持平滑迁移，最大限度的提升服务治理水平，降低运维通信成本等，并且可能会在一个较长的周期存在着。而实现这一架构的前提，就是各服务的“互联互通”。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu725579676662698448.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu4792505942952485241.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu10271270990008246573.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux44f5nj30qo0f0hb0_hu725579676662698448.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;要想实现上述“混合微服务架构”，运行时支撑服务必不可少，它主要包括服务注册中心、服务网关和集中式配置中心三个产品。&lt;/p&gt;
&lt;p&gt;传统微服务和 Service Mesh 双剑合璧（双模微服务），即“基于 SDK 的传统微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互联互通：两个体系中的应用可以相互访问；&lt;/li&gt;
&lt;li&gt;平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知；&lt;/li&gt;
&lt;li&gt;灵活演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里还包括对应用运行平台的要求，即两个体系下的应用，既可以运行在虚拟机之上，也可以运行在容器 /K8s  之上。我们不希望把用户绑定在 K8s 上，因此 Service Mesh 没有采用 K8s 的 Service 机制来做服务注册与发现，这里就突出了注册中心的重要性。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu15181670200628006254.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu8300215569814611852.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu17683058378532183422.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux89mk3j30qo0f04hm_hu15181670200628006254.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;百度智能云 CNAP 团队实现了上述混合微服务架构，即实现了两个微服务体系的应用互联互通、平滑迁移、灵活演进。上述混合微服务架构图包括以下几个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;API Server：前后端解耦，接口权限控制、请求转发、异常本地化处理等等；&lt;/li&gt;
&lt;li&gt;微服务控制中心：微服务治理的主要逻辑，包括服务注册的多租户处理、治理规则（路由、限流、熔断）的创建和转换、微服务配置的管理；&lt;/li&gt;
&lt;li&gt;监控数据存储、消息队列：主要是基于 Trace 的监控方案使用的组件；&lt;/li&gt;
&lt;li&gt;配置中心：微服务配置中心，最主要的功能是支持配置管理，包括治理规则、用户配置等所有微服务配置的存储和下发，微服务配置中心的特色是借助 SDK 可以实现配置/规则热更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来主要看一下注册中心的服务注册和发现机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spring Cloud 应用通过 SDK、Service Mesh 应用实现 Sidecar 分别向注册中心注册，注册的请求先通过微服务控制中心进行认证处理与多租户隔离；&lt;/li&gt;
&lt;li&gt;Mesh 控制面直接对接注册中心获取服务实例、Spring Cloud 应用通过 SDK 获取服务实例；&lt;/li&gt;
&lt;li&gt;双模异构，支持容器与虚机两种模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;注册中心与高可用方案&#34;&gt;注册中心与高可用方案&lt;/h2&gt;
&lt;p&gt;前面提到过，要想实现实现混合微服务架构，注册中心很关键。谈到注册中心，目前主流的开源注册中心包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper：Yahoo 公司开发的分布式协调系统，可用于注册中心，目前仍有很多公司使用其作为注册中心；&lt;/li&gt;
&lt;li&gt;Eureka：Netflix 开源组件，可用于服务注册发现组件，被广大 Spring Cloud 开发者熟知，遗憾的是目前已经不再维护，也不再被 Spring Cloud 生态推荐使用；&lt;/li&gt;
&lt;li&gt;Consul：HashiCorp 公司推出的产品，其可作为实现注册中心，也是本文介绍的重点；&lt;/li&gt;
&lt;li&gt;Etcd：Etcd 官方将其定义为可靠的分布式 KV 存储。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们注册中心选择了 Consul，Consul 包含了以下几个重要的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务发现：可以注册服务，也可以通过 Http 或 DNS 的方式发现已经注册的服务；&lt;/li&gt;
&lt;li&gt;丰富的健康检查机制；&lt;/li&gt;
&lt;li&gt;服务网格能力，最新版本已经支持 Envoy 作为数据面；&lt;/li&gt;
&lt;li&gt;KV 存储：可以基于 Consul KV 存储实现一个分布式配置中心；&lt;/li&gt;
&lt;li&gt;多数据中心：借助多数据中心，无需使用额外的抽象层，即可构建多地域的场景，支持多 DC 数据同步、异地容灾。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu14621623930298174895.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu9059818947501224796.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu6818294187213151446.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux5nmosj30qo0f0kas_hu14621623930298174895.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上图是 Consul 官网提供的架构图。Consul 架构中几个核心的概念如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agent: Agent 是运行在 Consul 集群的每个节点上的 Daemon 进程，通过 Consul Agent 命令将其启动，Agent 可以运行在 Client 或者 Server 模式下；&lt;/li&gt;
&lt;li&gt;Client：Client 是一种 Agent，其将会重定向所有的 RPC 请求到 Server，Client 是无状态的，其主要参与 LAN Gossip 协议池，其占用很少的资源，并且消耗很少的网络带宽；&lt;/li&gt;
&lt;li&gt;Server：Server 是一种 Agent，其包含了一系列的责任包括：参与 Raft 协议写半数（Raft Quorum）、维护集群状态、响应 RPC 响应、和其他 Datacenter 通过 WAN gossip 交换信息和重定向查询请求至 Leader 或者远端 Datacenter；&lt;/li&gt;
&lt;li&gt;Datacenter: Datacenter 其是私有的、低延迟、高带宽的网络环境，去除了在公共网络上的网络交互。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注册中心作为基础组件，其自身的可用性显得尤为重要，高可用的设计需要对其进行分布式部署，同时因在分布式环境下的复杂性，节点因各种原因都有可能发生故障，因此在分布式集群部署中，希望在部分节点故障时，集群依然能够正常对外服务。注册中心作为微服务基础设施，因此对其容灾和其健壮性有一定的要求，主要体现在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注册中心作为微服务基础设施，因此要求出现某些故障（如节点挂掉、网络分区）后注册中心仍然能够正常运行；&lt;/li&gt;
&lt;li&gt;当注册中心的发生故障时，不能影响服务间的正常调用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu7696585241858185244.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu17005445808160016604.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu3290646043431517625.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7c3c9j30qo0f0dun_hu7696585241858185244.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Consul 使用 Raft 协议作为其分布式一致性协议，本身对故障节点有一定的容忍性，在单个 DataCenter 中 Consul 集群中节点的数量控制在 2*n + 1 个节点，其中 n 为可容忍的宕机个数。Quorum size: Raft 协议选举需要半数以上节点写入成功。&lt;/p&gt;
&lt;p&gt;Q1:  节点的个数是否可以为偶数个？&lt;/p&gt;
&lt;p&gt;A2：答案是可以的，但是不建议部署偶数个节点。一方面如上表中偶数节点 4 和奇数节点 3 可容忍的故障数是一样的，另一方面，偶数个节点在选主节点的时候可能会出现瓜分选票的情形（虽然 Consul 通过重置 election timeout 来重新选举），所以还是建议选取奇数个节点。&lt;/p&gt;
&lt;p&gt;Q2:  是不是 Server 节点个数越多越好？&lt;/p&gt;
&lt;p&gt;A2：答案是否定的，虽然上表中显示 Server 数量越多可容忍的故障数越多，熟悉 Raft 协议的读者肯定熟悉 Log Replication（如上文介绍，日志复制时过半写成功才返回写成功），随着 Server 的数量越来越多，性能就会越低，所以结合实际场景一般建议 Server 部署 3 个节点。&lt;/p&gt;
&lt;p&gt;推荐采用三节点或五节点，最为有效，且能容错。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu12723312876342639059.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu2284294943191028328.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu2783807051860965115.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux00anvj30qo0f0wvy_hu12723312876342639059.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;注册中心设计的一个重要前提是：注册中心不能因为自身的原因或故障影响服务之间的相互调用。因此在实践过程中，如果注册中心本身发生了宕机故障/不可用，绝对不能影响服务之间的调用。这要求对接注册中心的 SDK 针对这种特殊情况进行客户端容灾设计，『客户端缓存』就是一种行之有效的手段。当注册中心发生故障无法提供服务时，服务本身并不会更新本地客户端缓存，利用其已经缓存的服务列表信息，正常完成服务间调用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7533524420930965430.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7514042313289374509.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu12991132331120068858.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux6iipzj30qo0f0qk6_hu7533524420930965430.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们在设计时采用同 Datacenter 集群内部部署 3 个 Server 节点，来保障高可用性，当集群中 1 个节点发生故障后，集群仍然能够正常运行，同时这 3 个节点部署在不同的机房，达到机房容灾的能力。&lt;/p&gt;
&lt;p&gt;在云上环境，涉及多 region 环境，因此在架构设计设计时，我们首先将 Consul 的一个 Datacenter 对应云上一个 region，这样更符合 Consul 对于 Datecenter 的定义（DataCenter 数据中心是私有性、低延迟、高带宽的网络环境）。中间代理层实现了服务鉴权、多租户隔离等功能；还可以通过中间代理层，对接多注册中心。&lt;/p&gt;
&lt;p&gt;云上环境存在多租户隔离的需求，即：A 租户的服务只能发现 A 租户服务的实例。针对此场景，需要在 『中间代理层』完成对多租户隔离功能的实现，其主要实践思路为使用 Consul  Api Feature 具备 Filtering 功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 Filtering 功能实现租户隔离需求；&lt;/li&gt;
&lt;li&gt;减少查询注册中心接口时网络负载。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;通过治理策略保证服务高可用&#34;&gt;通过治理策略保证服务高可用&lt;/h2&gt;
&lt;p&gt;什么是高可用？维基百科这么定义：系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。我们通常用 N 个 9 来定义系统的可用性，如果能达到 4 个 9，则说明系统具备自动恢复能力；如果能达到 5 个 9，则说明系统极其健壮，具有极高可用性，而能达到这个指标则是非常难的。&lt;/p&gt;
&lt;p&gt;常见的系统不可用因素包括：程序和配置出 bug、机器故障、机房故障、容量不足、依赖服务出现响应超时等。高可用的抓手包括：研发质量、测试质量、变更管理、监控告警、故障预案、容量规划、放火盲测、值班巡检等。这里，将主要介绍通过借助治理策略采用高可用设计手段来保障高可用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11691072992097189929.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11672523877399572764.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu2247716859581423531.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux2paejj30qo0f0nje_hu11691072992097189929.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;高可用是一个比较复杂的命题，所以设计高可用方案也涉及到了方方面面。这中间将会出现的细节是多种多样的，所以我们需要对这样一个微服务高可用方案进行一个顶层的设计。&lt;/p&gt;
&lt;p&gt;比如服务冗余：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;冗余策略：每个机器每个服务都可能出现问题，所以第一个考虑到的就是每个服务必须不止一份，而是多份。所谓多份一致的服务就是服务的冗余，这里说的服务泛指了机器的服务、容器的服务、还有微服务本身的服务。在机器服务层面需要考虑，各个机器间的冗余是否有在物理空间进行隔离冗余。&lt;/li&gt;
&lt;li&gt;无状态化：我们可以随时对服务进行扩容或者缩容，想要对服务进行随时随地的扩缩容，就要求我们的服务是一个无状态化，所谓无状态化就是每个服务的服务内容和数据都是一致的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如柔性化/异步化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所谓的柔性化，就是在我们业务允许的情况下，做不到给予用户百分百可用的，通过降级的手段给到用户尽可能多的服务，而不是非得每次都交出去要么 100 分或 0 分的答卷。柔性化更多是一种思维，需要对业务场景有深入的了解。&lt;/li&gt;
&lt;li&gt;异步化：在每一次调用，时间越长存在超时的风险就越大，逻辑越复杂执行的步骤越多，存在失败的风险也就越大。如果在业务允许的情况下，用户调用只给用户必须要的结果，不是需要同步的结果可以放在另外的地方异步去操作，这就减少了超时的风险也把复杂业务进行拆分减低复杂度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面讲到的几种提高服务高可用的手段，大多需要从业务以及部署运维的角度实现。而接下来会重点介绍，可以通过 SDK/Sidecar 手段提供服务高可用的治理策略，这些策略往往对业务是非侵入或者弱侵入的，能够让绝大多数服务轻松实现服务高可用。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu10931811979774022813.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu9949460287785823897.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu17782557879256910721.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux37m1nj30qo0f01ih_hu10931811979774022813.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;微服务之间一旦建立起路由，就意味着会有数据在服务之间流通。由于不同服务可以提供的资源和对数据流量的承载能力不尽相同，为了防止单个 Consumer 占用 Provider 过多的资源，或者突发的大流量冲击导致 Provider 故障，需要服务限流来保证服务的高可用。&lt;/p&gt;
&lt;p&gt;在服务治理中，虽然我们可以通过限流规则尽量避免服务承受过高的流量，但是在实际生产中服务故障依然难以完全避免。当整个系统中某些服务产生故障时，如果不及时采取措施，这种故障就有可能因为服务之间的互相访问而被传播开来，最终导致故障规模的扩大，甚至导致整个系统奔溃，这种现象我们称之为“雪崩”。熔断降级其实不只是服务治理中，在金融行业也有很广泛的应用。比如当股指的波动幅度超过规定的熔断点时，交易所为了控制风险采取的暂停交易措施。&lt;/p&gt;
&lt;p&gt;负载均衡是高可用架构的一个关键组件，主要用来提高性能和可用性，通过负载均衡将流量分发到多个服务器，同时多服务器能够消除这部分的单点故障。&lt;/p&gt;
&lt;p&gt;以上治理规则在某种程度上可以在 Spring Cloud 与 Service Mesh 两个框架上进行对齐，即同一套治理配置，可以通过转换分发到 Spring Cloud 应用的 SDK 上以及 Service Mesh 的 Sidecar 上。可以由 Config-server 负责规则下发，也可以由 Service Mesh 的控制面负责下发，取决于具体的架构方案。&lt;/p&gt;
&lt;h3 id=&#34;服务限流&#34;&gt;服务限流&lt;/h3&gt;
&lt;p&gt;对于一个应用系统来说一定会有极限并发/请求数，即总有一个 TPS/QPS 阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务或进行流量整形。&lt;/p&gt;
&lt;p&gt;常用的微服务限流架构包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接入层（api-gateway）限流：
&lt;ul&gt;
&lt;li&gt;单实例；&lt;/li&gt;
&lt;li&gt;多实例：分布式限流算法；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;调用外部限流服务限流：
&lt;ul&gt;
&lt;li&gt;微服务收到请求后，通过限流服务暴露的 RPC 接口查询是否超过阈值；&lt;/li&gt;
&lt;li&gt;需单独部署限流服务；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;切面层限流（SDK）：
&lt;ul&gt;
&lt;li&gt;限流功能集成在微服务系统切面层，与业务解耦；&lt;/li&gt;
&lt;li&gt;可结合远程配置中心使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的限流策略包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拒绝策略：
&lt;ul&gt;
&lt;li&gt;超过阈值直接返回错误；&lt;/li&gt;
&lt;li&gt;调用方可做熔断降级处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;延迟处理：
&lt;ul&gt;
&lt;li&gt;前端设置一个流量缓冲池，将所有的请求全部缓冲进这个池子，不立即处理。然后后端真正的业务处理程序从这个池子中取出请求依次处理，常见的可以用队列模式来实现（MQ：削峰填谷）；&lt;/li&gt;
&lt;li&gt;用异步的方式去减少了后端的处理压力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特权处理：
&lt;ul&gt;
&lt;li&gt;这个模式需要将用户进行分类，通过预设的分类，让系统优先处理需要高保障的用户群体，其它用户群的请求就会延迟处理或者直接不处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的限流算法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;固定时间窗口限流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先需要选定一个时间起点，之后每次接口请求到来都累加计数器，如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次接口请求），累加访问次数超过限流值，则限流熔断拒绝接口请求。当进入下一个时间窗口之后，计数器清零重新计数；&lt;/li&gt;
&lt;li&gt;缺点在于：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;滑动时间窗口算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题，是对固定时间窗口算法的一种改进；&lt;/li&gt;
&lt;li&gt;缺点在于：需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;令牌桶算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中；&lt;/li&gt;
&lt;li&gt;桶中最多可以存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 会被丢弃；&lt;/li&gt;
&lt;li&gt;接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 就阻塞或者拒绝服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;漏桶算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于取令牌的频率也有限制，要按照 t/n 固定的速度来取令牌；&lt;/li&gt;
&lt;li&gt;实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃；&lt;/li&gt;
&lt;li&gt;令牌桶和漏桶算法的算法思想大体类似，漏桶算法作为令牌桶限流算法的改进版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;令牌桶算法和漏桶算法，在某些场景下（内存消耗、应对突发流量），这两种算法会优于时间窗口算法成为首选。&lt;/p&gt;
&lt;h3 id=&#34;熔断&#34;&gt;熔断&lt;/h3&gt;
&lt;p&gt;断路器模式是微服务架构中广泛采用的模式之一，旨在将故障的影响降到最低，防止级联故障和雪崩，并确保端到端性能。我们将比较使用两种不同方法实现它的优缺点：Hystrix 和 Istio。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-熔断png&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;熔断.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu12227589584932449959.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu13853160177254565633.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu17680794763748597382.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gey0mpg1u4j30qo0f0jyx_hu12227589584932449959.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      熔断.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在电路领域中，断路器是为保护电路而设计的一种自动操作的电气开关。它的基本功能是在检测到故障后中断电流，然后可以重置 (手动或自动)，以在故障解决后恢复正常操作。这看起来与我们的问题非常相似：为了保护应用程序不受过多请求的影响，最好在后端检测到重复出现的错误时立即中断前端和后端之间的通信。Michael Nygard 在他的《Release It》一书中使用了这个类比，并为应用于上述超时问题的设计模式提供了一个典型案例，可以用上图来总结。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu15070006048435518010.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu505864961362440863.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu18322367428924516166.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux51ylej30qo0f0tqg_hu15070006048435518010.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Istio 通过 DestinationRule 实现断路器模式，或者更具体的路径 TrafficPolicy (原断路器) -&amp;gt;  OutlierDetection，根据上图模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consecutiveErrors 断路器打开前的出错次数；&lt;/li&gt;
&lt;li&gt;interval 断路器检查分析的时间间隔；&lt;/li&gt;
&lt;li&gt;baseEjectionTime 最小的开放时间，该电路将保持一段时间等于最小弹射持续时间和电路已打开的次数的乘积；&lt;/li&gt;
&lt;li&gt;maxEjectionPercent 可以弹出的上游服务的负载平衡池中主机的最大百分比，如果驱逐的主机数量超过阈值，则主机不会被驱逐。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与上述公称断路器相比，有两个主要偏差：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有半开放的状态。然而，断路器持续打开的时间取决于被调用服务之前失败的次数，持续的故障服务将导致断路器的开路时间越来越长。&lt;/li&gt;
&lt;li&gt;在基本模式中，只有一个被调用的应用程序 (后端)。在更实际的生产环境中，负载均衡器后面可能部署同一个应用程序的多个实例。某些情况下有些实例可能会失败，而有些实例可能会工作。因为 Istio 也有负载均衡器的功能，能够追踪失败的实例，并把它们从负载均衡池中移除，在一定程度上：‘maxEjectionPercent’属性的作用是保持一小部分的实例池。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hystrix 提供了一个断路器实现，允许在电路打开时执行 fallback 机制。最关键的地方就在 HystrixCommand 的方法 run() 和 getFallback()：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run() 是要实际执行的代码 e.g. 从报价服务中获取价格；&lt;/li&gt;
&lt;li&gt;getFallback() 获取当断路器打开时的 fallback 结果 e.g. 返回缓存的价格。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spring Cloud 是建立在 Spring Boot 之上的框架，它提供了与 Spring 的良好集成。它让开发者在处理 Hystrix 命令对象的实例化时，只需注释所需的 fallback 方法。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu217600569368768926.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu2167969886597103558.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu3292752890040765061.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux4np4zj30qo0f01da_hu217600569368768926.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;实现断路器的方法有两种，一种是黑盒方式，另一种是白盒方式。Istio 作为一种代理管理工具，使用了黑盒方式，它实现起来很简单，不依赖于底层技术栈，而且可以在事后配置。另一方面，Hystrix 库使用白盒方式，它允许所有不同类型的 fallback:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个默认值；&lt;/li&gt;
&lt;li&gt;一个缓存；&lt;/li&gt;
&lt;li&gt;调用其他服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它还提供了级联回退（cascading fallbacks）。这些额外的特性是有代价的：它需要在开发阶段就做出 fallback 的决策。&lt;/p&gt;
&lt;p&gt;这两种方法之间的最佳匹配可能会依靠自己的上下文：在某些情况下，如引用的服务，一个白盒战略后备可能是一个更好的选择，而对于其他情况下快速失败可能是完全可以接受的，如一个集中的远程登录服务。&lt;/p&gt;
&lt;p&gt;常用的熔断方法包括自动熔断与手动熔断。发生熔断时也可以选择 fail-fast 或者 fallback。这些用户都可以基于需求灵活使用。&lt;/p&gt;
&lt;h3 id=&#34;智能路由&#34;&gt;智能路由&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu1255300304719981453.webp 400w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu9899594518319898844.webp 760w,
               /blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu17424190256816888510.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/baidu-service-mesh-ha-practice/007S8ZIlly1gexux7waasj30qo0f04o0_hu1255300304719981453.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后，我们来看一下智能路由带来的高可用。智能路由这里包括（客户端）负载均衡与实例容错策略。对于 Spring Cloud 框架来说，这部分能力由 Ribbon 来提供，Ribbon 支持随机、轮询、响应时间权重等负载均衡算法。而对于 Service Mesh 框架，这部分能力由 Envoy 提供，Envoy 支持随机、轮询（加权）、环哈希等算法。为了实现两套系统的规则统一对齐，可以采用其交集。&lt;/p&gt;
&lt;p&gt;而容错策略包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;failover：失败后自动切换其他服务器，支持配置重试次数；&lt;/li&gt;
&lt;li&gt;failfast：失败立即报错，不再重试；&lt;/li&gt;
&lt;li&gt;failresnd：将失败请求放入缓存队列、异步处理，搭配 failover 使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio 支持重试策略配置，而 fail-fast 即对应与重试次数为 0。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;微服务的高可用是一个复杂的问题，往往需要从多个角度去看，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从手段看高可用。主要使用的技术手段是服务和数据的冗余备份和失效转移，一组服务或一组数据都能在多节点上，之间相互备份。当一台机器宕机或出现问题的时候，可以从当前的服务切换到其他可用的服务，不影响系统的可用性，也不会导致数据丢失。&lt;/li&gt;
&lt;li&gt;从架构看高可用。保持简单的架构，目前多数网站采用的是比较经典的分层架构，应用层、服务层、数据层。应用层是处理一些业务逻辑，服务层提供一些数据和业务紧密相关服务，数据层负责对数据进行读写。简单的架构可以使应用层，服务层可以保持无状态化进行水平扩展，这个属于计算高可用。同时在做架构设计的时候，也应该考虑 CAP 理论。&lt;/li&gt;
&lt;li&gt;从硬件看高可用。首先得确认硬件总是可能坏的，网络总是不稳定的。解决它的方法也是一个服务器不够就来多几个，一个机柜不够就来几个，一个机房不够就来几个。&lt;/li&gt;
&lt;li&gt;从软件看高可用。软件的开发不严谨，发布不规范也是导致各种不可用出现，通过控制软件开发过程质量监控，通过测试，预发布，灰度发布等手段也是减少不可用的措施。&lt;/li&gt;
&lt;li&gt;从治理看高可用。将服务规范化，事前做好服务分割，做好服务监控，预判不可用的出现，在不可用出现之前发现问题，解决问题。比如在服务上线后，根据经验，配置服务限流规则以及自动熔断规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上就是本期分享的全部内容。&lt;/p&gt;
&lt;p&gt;直播回放地址：https://www.bilibili.com/video/BV1WT4y1u73W&lt;/p&gt;
&lt;p&gt;分享 PPT 下载地址：https://github.com/servicemesher/meetup-slides/tree/master/2020/05/virtual&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Mesh &lt;/a&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;概述&lt;/a&gt;：https://www.servicemesher.com/istio-handbook/concepts/overview.html&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/zoS-5oyfh9EV6S5PLy54yg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Consul&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s/zoS-5oyfh9EV6S5PLy54yg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;作为注册中心在云环境的实践与应用&lt;/a&gt;：https://mp.weixin.qq.com/s/zoS-5oyfh9EV6S5PLy54yg&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/62237UuEEJiOP_b3xRrZog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;有了这三个锦囊，再也不用担心微服务治理了&lt;/a&gt;：https://mp.weixin.qq.com/s/62237UuEEJiOP_b3xRrZog&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/oky8g1Nisdr2T4kYG-DFhg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一文理解微服务高可用的常用手段&lt;/a&gt;：https://mp.weixin.qq.com/s/oky8g1Nisdr2T4kYG-DFhg&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/blog/istio-vs-hystrix-circuit-breaker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务断路器模式实现：&lt;/a&gt;&lt;a href=&#34;https://www.servicemesher.com/blog/istio-vs-hystrix-circuit-breaker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio vs Hystrix&lt;/a&gt;：https://www.servicemesher.com/blog/istio-vs-hystrix-circuit-breaker/&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2020 年 Service Mesh 技术展望</title>
      <link>https://cloudnative.to/blog/service-mesh-technology-outlook-2020/</link>
      <pubDate>Sun, 02 Feb 2020 10:36:06 +0800</pubDate>
      <guid>https://cloudnative.to/blog/service-mesh-technology-outlook-2020/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;有&lt;a href=&#34;https://thenewstack.io/the-top-3-service-mesh-developments-in-2020/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;外文&lt;/a&gt;指出，2020 年 Service Mesh 技术将有以下三大发展：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;快速增长的服务网格需求；&lt;/li&gt;
&lt;li&gt;Istio 很难被打败，很可能成为服务网格技术的事实标准；&lt;/li&gt;
&lt;li&gt;出现更多的服务网格用例，WebAssembly 将带来新的可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对 Service Mesh 技术，ServiceMesher 社区治理委员会成员在 2020 新年伊始发表了他们各自的看法，并邀请云原生与服务网格领域业界大牛抒发各自的见解，汇总成文，希望能给读者们带来一些思考和启发。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文&lt;/h2&gt;
&lt;h3 id=&#34;宋净超蚂蚁金服&#34;&gt;宋净超（蚂蚁金服）&lt;/h3&gt;
&lt;p&gt;用一句话概括 Service Mesh 近几年的发展——道阻且长，行则将至。这几年来我一直在探寻云原生之道，从容器、Kubernetes 再到 Service Mesh，从底层的基础设施到越来越趋向于业务层面，Service Mesh 肯定不是云原生的终极形式，其复杂性依然很高，且业界标准也尚未形成，它的发展也远没有同期的 Kubernetes 那么顺利，但是很多人都已意识到了服务网格价值，现在它正在远离最初市场宣传时的喧嚣，走向真正的落地。&lt;/p&gt;
&lt;h3 id=&#34;罗广明百度&#34;&gt;罗广明（百度）&lt;/h3&gt;
&lt;p&gt;据了解，2020 年的 Kubecon EU 的提案中，很少有涉及服务网格落地场景，由此来看，服务网格技术离大规模生产落地还有很远的路要走。当前 Istio 架构体现出来的性能问题迟迟没有得到优化，使用原生的 Istio 大规模上生产还不太靠谱，有的公司选择将 mixer 功能下层至自研的数据面，有的公司通过向容器注入探针解决可观察性。总的来看，在当前服务网格部分落地场景中，大多都是基于 Istio 和 envoy，但对其或多或少都有改动，以满足公有云/私有云的需求。&lt;/p&gt;
&lt;p&gt;此外，在 Service Mesh 落地的过程中，现有传统微服务应用（Spring Cloud/Dubbo 应用）如何平滑迁移到 Service Mesh，也是一个至关重要的话题。“双模微服务”的互联互通、共同治理有望成为 2020 年服务网格落地的关键技术之一，这也是国内几家典型云厂商力求打造的亮点产品。&lt;/p&gt;
&lt;h3 id=&#34;马若飞freewheel&#34;&gt;马若飞（FreeWheel）&lt;/h3&gt;
&lt;p&gt;我个人认为 Service Mesh 想要真正发展成熟并大规模落地还有很长的一段路要走。一方面业界基于微服务构建的一系列服务治理框架和产品相当稳定和成熟，在功能上和 Service Mesh 有很多重合的地方，使得开发者对 Service Mesh 的需求并不迫切；另一方面，目前 Service Mesh 领域产品的成熟度还有待提高，冒险迁移过于激进，也容易面临兼容性的问题，这也制约了 Service Mesh 的落地。&lt;/p&gt;
&lt;p&gt;从近半年厂商的动作来看，主要方向是提供托管的控制平面，并整合成熟的数据面（如 Envoy）；同时提供多环境支持（如多云、混合云、VM 等）。这也和目前应用复杂多样的的部署现状有关，厂商的目的是先让你上云，再 Mesh 化。这也是一个相对稳妥且折中的方案。我司作为一个重度使用 AWS 服务的公司，选择了 AWS App Mesh 托管服务作为 mesh 的解决方案，使得和现有服务能更容易的整合，减少维护和迁移成本。&lt;/p&gt;
&lt;h3 id=&#34;邱世达--bocloud&#34;&gt;邱世达  (BoCloud)&lt;/h3&gt;
&lt;p&gt;目前来看，Kubernetes 已经逐步在企业中落地，服务上云已然是大势所趋。而随着云计算基础设施层的日益完备，在可以预见的未来，应用层服务治理必然成为新的焦点，也是在大规模微服务场景下必须要解决的问题。在 Service Mesh 领域，Istio 无疑是明星项目，除了具备一定自研能力的科技公司会定制开发自己的服务治理工具，大多数中小型企业通常会选择以 Istio 为代表的开源服务治理方案进行初步试水。实践过程中遇到问题并不可怕，我认为这反而是一种正向推动力，作为一种良性反馈，能更加积极地促使 Service Mesh 技术趋于成熟和稳定。拥抱服务网格，拥抱云原生，让我们期待 Service Mesh 在新的一年取得更大的发展！&lt;/p&gt;
&lt;h3 id=&#34;孙海洲中国科学院计算技术研究所&#34;&gt;孙海洲（中国科学院计算技术研究所）&lt;/h3&gt;
&lt;p&gt;对于 Service Mesh 来说，2019 年是极不平凡的一年，也是从观望走向生产落地的一年。在这一年里，以 Istio 为代表的 Service Mesh 开始加快发布周期，可以看到社区从以优雅架构到开始追求性能。最近社区里大家积极地参与到 Istio 文档的本地化工作中。在业界可以看到国内各个大厂开始有所举动，蚂蚁在双十一的成功大规模落地为 Service Mesh 走向生产打下了坚实的基础，同时也为大家提供了很多宝贵的经验，腾讯、百度、华为等云服务提供商也都纷纷发布相关的产品。关于 Service Mesh  的图书在今年也出版了几本，社区多次组织线下的 Service Mesh Meetup 场场爆满，可见大家对 Service Mesh  的热情与日俱增。2020 年应该可以看到会有更多的 Service Mesh  的成功落地，但是当前还有很多企业还处于过渡时期，如何更好更便捷地解决向云原生迁移依赖值得关注。Service Mesh  社区的推广和布道工作依然任重而道远，需要我们更加积极努力地投入到 Service Mesh  事业中去。&lt;/p&gt;
&lt;h3 id=&#34;赵化冰中兴通讯&#34;&gt;赵化冰（中兴通讯）&lt;/h3&gt;
&lt;p&gt;在 2019 年里，我看到的一个有趣的现象是出现了各种各样的开源 Service Mesh 项目，基于开源 Service Mesh 项目的初创公司，以及各大云厂商的闭源 Service Mesh 实现。和 2018 年大部分项目围绕 Istio 搭建生态有所不同（至少大部分项目声称自己兼容 Istio），2019 年整个 Service Mesh 生态出现了百花齐放，百家争鸣的趋势。这也许和 Istio 项目的进度有一定关系。Istio 在项目最开始发布时搭建了一个非常漂亮的架构，但实际开发的进展较慢。目前 Mixer V2 还没有能够正式发布（处于 alpha 版本），其安全模型也在近期进行了较大的变动，导致除了流量管控之外的其他功能基本无法在生产中使用；除此之外，Istio 对于非 Kubernetes 环境的支持也非常有限。所有这些因素在一定程度上给其他 Service Mesh 项目留出了较大的发展空间。&lt;/p&gt;
&lt;p&gt;在 Service Mesh 的不同实现纷纷涌现的情况下，要最大化利用 Service Mesh 提供了服务通信和管控能力，必须统一 Service Mesh 的标准接口。通过一个标准北向接口，对 Service Mesh 提供的流量控制，安全策略，拓扑信息、性能指标等基本能力进行组合，并加以创新，可以创建大量端到端的高附加值业务，例如支持业务平滑升级的灰度发布，测试微服务系统健壮性的混沌测试，微服务的监控系统等等。而采用一个标准的南向接口，则可以构建一个良好的数据面代理生态，甚至可能将一些传统的硬件代理设备纳入 Service Mesh 控制面进行统一管理。&lt;/p&gt;
&lt;p&gt;在 2020 年里，我希望 Istio 项目在 telemetry 和 security 方面取得更多实际性的进展，并出现更多的商用案例。希望能够制定一个 Service Mesh 的标准接口，或者出现一个足够强大的事实标准，并看到建立在标准北向接口上的更多应用，这是 Service Mesh 的核心价值所在，也许会成为 Service Mesh 的下一个热点。&lt;/p&gt;
&lt;h3 id=&#34;钟华腾讯云&#34;&gt;钟华（腾讯云）&lt;/h3&gt;
&lt;p&gt;还记得 2019 年初，我们对打磨半年之久的 Istio 新版本翘首以盼，大家对 Istio 的高度抽象模型褒贬不一，社区里偶尔会看到朋友问「到底有没有公司在生产环境落地了 Istio？」&lt;/p&gt;
&lt;p&gt;在过去的一年里，Istio 持续发力，核心功能迭代更加稳定，发布了四个子版本，同时也更注重用户体验的优化。各大云厂商在 2019 年陆续实现了对 Istio 的支持，业界也出现了越来越多的 Service Mesh 生产实践，其中典型的是蚂蚁双十一大规模落地案例；笔者所在的腾讯云 TKE Mesh 团队，支持了数十个团队的 Service Mesh 改造过程，其中不乏一些场景复杂、体量庞大的核心系统。&lt;/p&gt;
&lt;p&gt;Service Mesh 技术前景广阔，但远未成熟。展望 2020，作为 Service Mesh 头号玩家的，Istio 还会持续快速发展，我个人很期待的一些演进：支持 webassembly 扩展的数据面，真正生产可用的 Mixer V2，更易安装和运维的单体控制面 istiod，更容易理解和操纵的用户接口，以及提升 Istio 自身的可观测性。&lt;/p&gt;
&lt;p&gt;Service Mesh 技术本质上是各种最佳实践的组合运用。Istio 试图运用精巧的模型，去联结各种平台、观测系统和用户应用。未来的 Istio，一定会更加复杂，这些「复杂」的目的，是让用户能更「简单」地使用 Service Mesh 领域的最佳实践。&lt;/p&gt;
&lt;h3 id=&#34;william-morgan&#34;&gt;William Morgan&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Buoyant CEO, author of Linkerd, the originator of the concept &lt;code&gt;Service Mesh&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天的服务网格处于有点不幸的状态：虽然有真实和重要的价值，但市场营销已经超过了技术本身。云供应商特别利用服务网格作为区分他们的容器产品的一种方式，而由此产生的狂热的市场推广给终端用户带来了实质性的损害。&lt;/p&gt;
&lt;p&gt;然而，如果应用正确，服务网格确实能提供一些真正变革性的功能。从 Linkerd 的角度来看，创建服务网格的项目，我们仍然认为最小化服务网格的成本，特别是由复杂性引起的长期运营成本是最重要的。&lt;/p&gt;
&lt;p&gt;在 2020 年，Linkerd 将继续专注于提供“可观察的安全性”的目标，同时最小化复杂性和使用成本 — Linkerd 的超轻、超快 Rust 代理、极简控制平面，以及“少做，而不是多做”的理念已经在这里得到了鲜明的体现。最重要的是，Linkerd 对开放治理和中立基础的承诺将确保 Linkerd 将继续成为一个为所有工程师服务的项目，而不是为某个特定云供应商的客户服务。&lt;/p&gt;
&lt;h3 id=&#34;christian-posta&#34;&gt;Christian Posta&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Field CTO at solo.io, author Istio in Action and Microservices for Java Developers, open-source enthusiast, cloud application development, committer @ Apache, Serverless, Cloud, Integration, Kubernetes, Docker, Istio, Envoy blogger, blog &lt;a href=&#34;https://blog.christianposta.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.christianposta.com/&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;回顾-2019&#34;&gt;回顾 2019&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;更多的 Service Mesh 产品发布了！API/软件网络领域的每个人都正在实践自己的服务网格。我认为这对市场来说是一件好事，因为它表明这是有价值的，并且应该探索不同的实现方式。这也将指引我们在未来殊途同归。&lt;/li&gt;
&lt;li&gt;越来越多的组织参与到服务网格技术中（从去年的架构讨论开始）可用性是关键！像 linkerd 这样的网格技术展示了如何简化使用和操作，其他产品也注意到了这一点，并尝试提高它们的可用性。&lt;/li&gt;
&lt;li&gt;Istio 已经持续的进行定期发布，这证明了它开始走向稳定并具有可预测性。&lt;/li&gt;
&lt;li&gt;Consul 推出了和 consul 模型无缝结合的 L7 路由特性。&lt;/li&gt;
&lt;li&gt;不可忽视，虽然更多的人开始着手服务网格技术的实践，但依然有很多争议：
&lt;ul&gt;
&lt;li&gt;谁来支持？&lt;/li&gt;
&lt;li&gt;多租户支持的不好&lt;/li&gt;
&lt;li&gt;对现有应用不总是透明的&lt;/li&gt;
&lt;li&gt;VM+容器支持不够好&lt;/li&gt;
&lt;li&gt;暴露什么样的 API 给用户&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2020-年展望&#34;&gt;2020 年展望&lt;/h4&gt;
&lt;p&gt;服务网格在 2019 年引领了潮流，我期待它能变得更加强大。2020 年，会有更多的组织落地服务网格，继续与现有的网格技术集成，如 Istio 和其他产品：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多网格的存在！虽然现在已经有很多网格实现，但最终还是会收敛的。然而，有趣的是，我不认为融合会像 kubernetes 那样发生（我们都落在一件事情上）。我怀疑总会有多种服务网格实现会成为主流。每个云提供商都有自己的托管网格产品，这可能与本地网格不同。因此，多集群和网格的多分布将成为主要的部署实现。&lt;/li&gt;
&lt;li&gt;Web assembly 正在流行：它提供了一种在类似 Envoy 这样的代理中安全地运行用户代码的方法，我们将很快看到服务网格和 API 网关，如 istio 和 gloo 对它提供支持。Web assembly将允许用户/供应商/组织提供功能模块，用以定制化代理并改变其默认行为。Web assembly 工具集将开始出现并对其进行管理。对于那些努力将服务网格集成到现有环境并维护组织兼容性的人来说，这将是令人兴奋的。&lt;/li&gt;
&lt;li&gt;优化服务网格数据平面：去年我在第一个 ServiceMeshCon 演讲（PPT：&lt;a href=&#34;https://www.slideshare.net/ceposta/the-truth-about-the-service-mesh-data-plane&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/ceposta/the-truth-about-the-service-mesh-data-plane&lt;/a&gt;）讨论了如何在服务网格数据平面进行调优，就像直接运行你的代码一样。作为代理，和共享的代理。例如，gRPC 最近增加了对&lt;a href=&#34;https://github.com/grpc/proposal/pull/170&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS API&lt;/a&gt;的支持，CNCF 也有一个工作组来帮助将这个“通用数据平面 API”标准化以用于其他用途：&lt;a href=&#34;https://github.com/cncf/udpa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/cncf/udpa&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Envoy 功能点详解之异常点检测</title>
      <link>https://cloudnative.to/blog/envoy-feature-explain-outlier-detection/</link>
      <pubDate>Fri, 21 Jun 2019 19:20:19 +0800</pubDate>
      <guid>https://cloudnative.to/blog/envoy-feature-explain-outlier-detection/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;很多人学习和使用 envoy 时，很容易混淆一些概念，比如把异常点驱逐和微服务熔断混为一谈，分不清最大驱逐比与恐慌阈值的区别等。本文将基于 envoy 官方文档 (&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;v1.10.0&lt;/a&gt;)，详细介绍异常点检测的类型、驱逐算法以及相关概念的解析，并且最后对易混淆的几个概念进行辨析。&lt;/p&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;异常点检测 (Outlier detection) 和驱逐 (Ejection) 是用来动态确定&lt;code&gt;上游集群&lt;/code&gt;中是否有表现不同于其他主机的实例，并将它们从健康&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/load_balancing/overview#arch-overview-load-balancing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;负载均衡&lt;/a&gt;集中移除的过程。性能可能会沿着不同的轴变化，如连续失败，一时的成功率，短时间内的延迟等。异常值检测是一种&lt;code&gt;被动的&lt;/code&gt;健康检查形式。Envoy 还支持&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/health_checking#arch-overview-health-checking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;主动健康检查&lt;/a&gt;。被动和主动健康检查功能可以一起或独立使用，它们共同构成整个上游健康检查解决方案的基础。&lt;/p&gt;
&lt;h2 id=&#34;驱逐算法&#34;&gt;驱逐算法&lt;/h2&gt;
&lt;p&gt;根据异常值检测的类型，驱逐要么以直线方式运行（例如在连续返回 5xx 的情况下），要么以指定的间隔运行（例如在周期性成功率的情况下）。驱逐算法的工作原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主机被确定为异常点。&lt;/li&gt;
&lt;li&gt;如果没有主机被驱逐，Envoy 会立即驱逐主机。否则，它会检查以确保驱逐主机的数量低于允许的阈值（通过 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-max-ejection-percent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.max_ejection_percent&lt;/a&gt;设置指定）。如果驱逐的主机数量超过阈值，则主机不会被驱逐。&lt;/li&gt;
&lt;li&gt;主机被驱逐的状态会保持一小段时间（以毫秒为单位）。被驱逐意味着该主机被标记为不健康，并且在负载均衡期间不会被使用，除非负载均衡器处于&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/load_balancing/panic_threshold#arch-overview-load-balancing-panic-threshold&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;恐慌&lt;/a&gt;状态。被驱逐的时间等于&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-base-ejection-time&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.base_ejection_time_ms&lt;/a&gt;的值乘以该主机被驱逐的次数。这意味着，如果该主机连续失败，它被驱逐的时间将越来越长。&lt;/li&gt;
&lt;li&gt;驱逐时间满足后，被驱逐主机将自动恢复服务。通常情况下，异常值检测与主动健康检查 (&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/health_checking#arch-overview-health-checking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;active health checking&lt;/a&gt;) 一起使用，以获得全面的健康检查解决方案。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;检测类型&#34;&gt;检测类型&lt;/h2&gt;
&lt;p&gt;Envoy 支持以下异常点检测类型：&lt;/p&gt;
&lt;h3 id=&#34;连续返回-5xx&#34;&gt;连续返回 5xx&lt;/h3&gt;
&lt;p&gt;如果上游主机返回一些连续的 5xx，它将被驱逐。注意，在本例中，5xx 表示实际的 5xx 响应码，或者导致 HTTP 路由器代表上游返回该响应码的事件（重置、连接失败等）。驱逐所需的连续 5xx 的数量由&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-consecutive-5xx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.continutive_5xx&lt;/a&gt;值控制。&lt;/p&gt;
&lt;h3 id=&#34;连续网关失败&#34;&gt;连续网关失败&lt;/h3&gt;
&lt;p&gt;如果上游主机返回一些连续的&amp;quot;网关错误”（502、503 或 504 状态码），它将被驱逐。注意，这包括可能导致 HTTP 路由器代表上游返回其中一个状态码的事件（重置、连接失败等）。驱逐所需的连续网关故障数量由&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-consecutive-gateway-failure&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.consecutive_gateway_failure&lt;/a&gt;值所决定的。&lt;/p&gt;
&lt;h3 id=&#34;成功率&#34;&gt;成功率&lt;/h3&gt;
&lt;p&gt;基于成功率的异常点驱逐聚合了集群中每个主机的成功率数据。然后在给定的时间间隔内，基于统计的异常点检测数据对主机进行驱逐。如果主机的请求量汇总时间间隔小于&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-success-rate-request-volume&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.success_rate_request_volume&lt;/a&gt;值，该异常点驱逐将不会被计算。另外，如果一个间隔中具有最小所需请求卷的主机数量小于&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/api/v2/cluster/outlier_detection.proto#envoy-api-field-cluster-outlierdetection-success-rate-minimum-hosts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier_detection.success_rate_minimum_hosts&lt;/a&gt; 值，检测将不能进行。&lt;/p&gt;
&lt;h2 id=&#34;驱逐事件日志&#34;&gt;驱逐事件日志&lt;/h2&gt;
&lt;p&gt;异常点驱逐事件的日志可以由 Envoy 选择性地生成。这在日常操作中非常有用，因为全局统计信息不能提供关于哪些主机被驱逐以及出于什么原因被驱逐的足够信息。日志被结构化为基于 protobuf 的&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/data/cluster/v2alpha/outlier_detection_event.proto#envoy-api-msg-data-cluster-v2alpha-outlierdetectionevent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OutlierDetectionEvent messages&lt;/a&gt;转存文件。驱逐事件日志是在集群管理器&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/api-v2/config/bootstrap/v2/bootstrap.proto#envoy-api-field-config-bootstrap-v2-clustermanager-outlier-detection&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;outlier detection configuration&lt;/a&gt;中配置的。&lt;/p&gt;
&lt;h2 id=&#34;相关概念&#34;&gt;相关概念&lt;/h2&gt;
&lt;h3 id=&#34;主动健康检查&#34;&gt;主动健康检查&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/health_checking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;主动健康检查&lt;/a&gt;可以在每个上游集群的基础上进行配置。主动运行健康检查和 EDS 类型服务发现会同时进行。但是，即使使用其他服务发现类型，也有其他需要进行主动健康检查的情况。Envoy 支持三种不同类型的健康检查（HTTP,  L3/L4, Redis）及各种设置（检查时间间隔、主机不健康标记为故障、主机健康时标记为成功等）。&lt;/p&gt;
&lt;p&gt;在同时使用主动健康检查和被动健康检查 (异常点检测) 时，通常使用较长的健康检查间隔来避免大量的主动健康检查流量。在这种情况下，当使用&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/operations/admin#operations-admin-interface-healthcheck-fail&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;/healthcheck/fail&lt;/a&gt;管理端点时，能够快速耗尽上游主机仍然是有用的，&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/configuration/http_filters/router_filter#config-http-filters-router&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;router filter&lt;/a&gt;会在&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/configuration/http_filters/router_filter#config-http-filters-router-x-envoy-immediate-health-check-fail&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;x-envoy-immediate-health-check-fail&lt;/a&gt; header 里面响应来支持它的实现。如果 header 由上游主机设置标记，Envoy 将立即将主机标记为主动健康检查失败。注意，只有在主机集群的主动健康检查&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/configuration/cluster_manager/cluster_hc#config-cluster-manager-cluster-hc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;已配置&lt;/a&gt;时才会发生这种情况。如果 Envoy 已经通过&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/operations/admin#operations-admin-interface-healthcheck-fail&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;/healthcheck/fail&lt;/a&gt;管理端点标记为失败，&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/configuration/http_filters/health_check_filter#config-http-filters-health-check&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;健康检查过滤器&lt;/a&gt;将自动设置这个 header。&lt;/p&gt;
&lt;h3 id=&#34;恐慌阈值&#34;&gt;恐慌阈值&lt;/h3&gt;
&lt;p&gt;在负载均衡期间，Envoy 通常只会考虑上游集群中健康的主机。但是，如果集群中健康主机的百分比变得过低，envoy 将忽视所有主机中的健康状况和均衡。这被称为&lt;em&gt;恐慌阈值 (panic threshold)&lt;/em&gt;。缺省恐慌阈值是 50％。这可以通过&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/configuration/cluster_manager/cluster_runtime#config-cluster-manager-cluster-runtime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行时配置&lt;/a&gt;或者&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/cds.proto#envoy-api-field-cluster-commonlbconfig-healthy-panic-threshold&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;集群配置&lt;/a&gt;进行配置。恐慌阈值用于避免在负载增加时主机故障导致整个集群中级联故障的情况。注意：恐慌阈值不同于驱逐算法第 2 点提到的最大驱逐百分比 (outlier_detection.max_ejection_percent)。&lt;/p&gt;
&lt;p&gt;另外，恐慌阈值与优先级协同工作。如果某个优先级的可用主机数量下降，Envoy 将尝试将一些流量转移到较低的优先级。如果它成功地在较低的优先级找到足够的可用主机，Envoy 将不顾恐慌阈值。在数学术语中，如果所有优先级的规范化 (normalized) 总可用性为 100%，Envoy 将忽略恐慌阈值，并继续根据这里描述的算法在优先级之间分配流量负载。然而，当规范化总可用性下降到 100% 以下时，Envoy 假定在所有优先级上都没有足够的可用主机。它将继续跨优先级分配流量负载，但是如果给定优先级的可用性低于 panic 阈值，则流量将负载均衡到该优先级的所有主机，而不管它们的可用性如何。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;P=0 healthy endpoints&lt;/th&gt;
          &lt;th&gt;P=1 healthy endpoints&lt;/th&gt;
          &lt;th&gt;Traffic to P=0&lt;/th&gt;
          &lt;th&gt;P=0 in panic&lt;/th&gt;
          &lt;th&gt;Traffic to P=1&lt;/th&gt;
          &lt;th&gt;P=1 in panic&lt;/th&gt;
          &lt;th&gt;normalized total health&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;72%&lt;/td&gt;
          &lt;td&gt;72%&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;0%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;71%&lt;/td&gt;
          &lt;td&gt;71%&lt;/td&gt;
          &lt;td&gt;99%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;1%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;50%&lt;/td&gt;
          &lt;td&gt;60%&lt;/td&gt;
          &lt;td&gt;50%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;50%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;25%&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
          &lt;td&gt;25%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;75%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;25%&lt;/td&gt;
          &lt;td&gt;25%&lt;/td&gt;
          &lt;td&gt;50%&lt;/td&gt;
          &lt;td&gt;YES&lt;/td&gt;
          &lt;td&gt;50%&lt;/td&gt;
          &lt;td&gt;YES&lt;/td&gt;
          &lt;td&gt;70%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;5%&lt;/td&gt;
          &lt;td&gt;65%&lt;/td&gt;
          &lt;td&gt;7%&lt;/td&gt;
          &lt;td&gt;YES&lt;/td&gt;
          &lt;td&gt;93%&lt;/td&gt;
          &lt;td&gt;NO&lt;/td&gt;
          &lt;td&gt;98%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;结合以上介绍来看，异常点检测是一种被动的健康检查，区别于主动健康检查，它不是向主机发送心跳或者通过长链接探活来判定实例的健康，而是通过对该主机发起的请求的返回值做分析，基于不同的检测类型以及不同的驱逐算法，对目标主机做驱逐或者恢复。&lt;/p&gt;
&lt;p&gt;而微服务中的熔断主要是一种系统保护策略，它的基本功能是在检测到故障后切断链路，通过直接返回错误或者 fallback 值，来直接提高系统可用性，防止该故障程序出现问题蔓延至整个网络造成雪崩效果。笔者以为，envoy 中的异常点检测可以理解为&amp;quot;实例级别&amp;quot;的熔断，并且没有半开放状态。关于该实例级别的熔断与公称断路器的区别的详细介绍，可以参考&lt;a href=&#34;http://www.servicemesher.com/blog/istio-vs-hystrix-circuit-breaker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务断路器模式实现：Istio vs Hystrix&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;并且，envoy 异常点检测中的&lt;code&gt;maxEjectionPercent&lt;/code&gt;属性的作用会保持一部分的实例池，即使其中部分实例不可用。其目的是为了避免在负载增加时主机故障导致整个集群中级联故障雪崩，这一点和恐慌阈值的作用相似。但是&amp;rsquo;maxEjectionPercent&amp;rsquo;与&amp;rsquo;panic threshold&amp;rsquo;的作用域却完全不同。达到恐慌阈值后，流量将负载均衡到该优先级的所有主机，所有主机包括被异常点检测标记为不健康的实例和健康的实例，并且如果驱逐达到了‘maxEjectionPercent’设定值，那么这组健康的实例中还可能包含不可用的实例。&lt;/p&gt;
&lt;p&gt;最后 Envoy 自身还实现了网络级别的&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/circuit_breaking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;分布式断路器&lt;/a&gt;，这才是 istio/envoy 提供的&amp;quot;正统&amp;quot;断路器。作为一个分布式断路器，它的特点是在网络级别强制实现断路，而不必为每个应用程序单独配置或者编程，实现零侵入。Envoy 支持的分布式断路包括：集群最大连接数、集群最大挂起请求数、集群最大请求数、集群最大活动重试次数等。&lt;/p&gt;
&lt;p&gt;总而言之，不管是 envoy 的异常点检测还是网络级别的分布式断路器，作为一种 sidecar 代理，采用的是黑盒方式的实现，并且对应用程序零侵入。但是如果你的系统需要对某个应用程序做到方法级别的精确熔断，设置各种超时重试等参数，设置不同的 fallback 返回值，抑或是调用其它的服务做降级处理等等，则需要侵入式的断路器（可参考 Resilience4J 与 Hystrix）。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
