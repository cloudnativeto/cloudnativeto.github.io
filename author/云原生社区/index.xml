<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>云原生社区 | 云原生社区（中国）</title>
    <link>https://cloudnative.to/author/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%A4%BE%E5%8C%BA/</link>
      <atom:link href="https://cloudnative.to/author/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%A4%BE%E5%8C%BA/index.xml" rel="self" type="application/rss+xml" />
    <description>云原生社区</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Tue, 08 Oct 2024 16:08:47 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/author/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%A4%BE%E5%8C%BA/avatar_hu160136486424020243.png</url>
      <title>云原生社区</title>
      <link>https://cloudnative.to/author/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%A4%BE%E5%8C%BA/</link>
    </image>
    
    <item>
      <title>AWS 宣布将停用 App Mesh，鼓励用户迁移至 Amazon ECS Service Connect</title>
      <link>https://cloudnative.to/blog/migrating-from-aws-app-mesh-to-amazon-ecs-service-connect/</link>
      <pubDate>Tue, 08 Oct 2024 16:08:47 +0800</pubDate>
      <guid>https://cloudnative.to/blog/migrating-from-aws-app-mesh-to-amazon-ecs-service-connect/</guid>
      <description>&lt;p&gt;近日，AWS &lt;a href=&#34;https://aws.amazon.com/blogs/containers/migrating-from-aws-app-mesh-to-amazon-ecs-service-connect/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方博客&lt;/a&gt;发布公告，宣布将于&lt;strong&gt;2026 年 9 月 30 日&lt;/strong&gt;正式停用 AWS App Mesh 服务。从&lt;strong&gt;2024 年 9 月 24 日&lt;/strong&gt;起，新用户将无法再使用 App Mesh。AWS 建议现有的 App Mesh 用户开始规划迁移到 Amazon ECS Service Connect，以充分利用其改进的特性和功能。&lt;/p&gt;
&lt;h2 id=&#34;amazon-ecs-service-connect-的优势&#34;&gt;Amazon ECS Service Connect 的优势&lt;/h2&gt;
&lt;p&gt;在 2022 年的 re:Invent 大会上，AWS 推出了&lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon ECS Service Connect&lt;/a&gt;，这是一种连接 Amazon Elastic Container Service（Amazon ECS）中微服务的新方式。Service Connect 通过内置的健康检查、异常检测和重试机制，显著提高了容器化微服务的可靠性。此外，它还能将应用层网络指标发送到 Amazon CloudWatch，增强了系统的可观测性。&lt;/p&gt;
&lt;p&gt;与 App Mesh 不同，Service Connect 使用了 AWS 托管的网络数据平面，消除了管理 sidecar 代理的繁琐工作。这意味着开发者可以更专注于业务逻辑，而无需处理底层网络管理的细节。&lt;/p&gt;
&lt;h2 id=&#34;迁移策略从-app-mesh-到-service-connect&#34;&gt;迁移策略：从 App Mesh 到 Service Connect&lt;/h2&gt;
&lt;p&gt;由于 Amazon ECS 服务不能同时属于 App Mesh Mesh 和 Service Connect 命名空间，因此迁移过程需要重新创建 Amazon ECS 服务。为了避免服务中断，AWS 建议采用&lt;a href=&#34;https://docs.aws.amazon.com/whitepapers/latest/overview-deployment-options/bluegreen-deployments.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;蓝绿部署&lt;/a&gt;的迁移策略。这种方法允许在新旧环境之间逐步切换流量，确保迁移的平滑过渡。&lt;/p&gt;
&lt;p&gt;在迁移过程中，可以利用多种流量控制手段，如 &lt;a href=&#34;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-weighted.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon Route 53 加权路由&lt;/a&gt;、&lt;a href=&#34;https://aws.amazon.com/blogs/networking-and-content-delivery/achieving-zero-downtime-deployments-with-amazon-cloudfront-using-blue-green-continuous-deployments/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon CloudFront 持续部署&lt;/a&gt;或&lt;a href=&#34;https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html#rule-action-types&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用程序负载均衡器的多目标组路由&lt;/a&gt;，实现流量的细粒度转移。&lt;/p&gt;
&lt;p&gt;需要注意的是，两个环境之间的网络是隔离的，即在 App Mesh 环境中运行的服务无法直接与 Service Connect 环境中的服务通信。因此，完整的迁移策略对于确保服务的连续性至关重要。&lt;/p&gt;
&lt;h2 id=&#34;功能对比app-mesh-vs-service-connect&#34;&gt;功能对比：App Mesh vs. Service Connect&lt;/h2&gt;
&lt;p&gt;下面是 App Mesh 和 Service Connect 在关键功能方面的对比：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;App Mesh&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Service Connect&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;网络可靠性&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;使用 Envoy 的异常检测、健康检查和重试机制，可以对这些参数进行细粒度的调整。&lt;/td&gt;
          &lt;td&gt;使用 Envoy 的异常检测、健康检查和重试机制，提供默认配置，用户只能调整超时时间。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;高级流量路由&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;支持通过虚拟路由器在多个虚拟节点之间实现高级流量路由，如 AB 测试和金丝雀发布。&lt;/td&gt;
          &lt;td&gt;目前不支持高级流量路由功能。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;可观测性&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;用户需要自行收集和监控流量指标。&lt;/td&gt;
          &lt;td&gt;自动将应用层的网络指标发送到 Amazon CloudWatch，用户可直接查看，降低了监控的复杂性。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;安全性&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;支持 TLS 加密通信，可与 AWS PCA 的通用证书结合，支持双向的 mTLS 认证。&lt;/td&gt;
          &lt;td&gt;支持 TLS 加密通信，但不支持双向认证，只能使用 AWS PCA 的短期证书。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;资源共享&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;可通过 AWS 资源访问管理器（AWS RAM）在多个 AWS 账户之间共享 Mesh，支持跨账户服务通信。&lt;/td&gt;
          &lt;td&gt;目前不支持在多个账户之间共享命名空间，所有服务需部署在同一 AWS 账户内。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;
&lt;p&gt;AWS 宣布停用 App Mesh 并鼓励用户迁移至 Amazon ECS Service Connect，体现了其在简化服务网格管理和提升用户体验方面的战略方向。对于云原生社区的开发者和企业而言，这是一个重新评估和优化服务架构的契机。&lt;/p&gt;
&lt;p&gt;我们建议所有仍在使用 App Mesh 的用户，尽快制定迁移计划，充分利用 Service Connect 带来的优势。有关详细的迁移步骤和实践经验，请参考 AWS 提供的 &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon ECS 文档&lt;/a&gt; 和 &lt;a href=&#34;https://catalog.workshops.aws/ecs-immersion-day/en-US/60-networking/ecs-service-connect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon ECS Immersion Day workshop&lt;/a&gt;，获取更多技术支持。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>外企远程岗位内推通道（直招）</title>
      <link>https://cloudnative.to/blog/jd-grandshorestech/</link>
      <pubDate>Thu, 19 Sep 2024 14:46:32 +0800</pubDate>
      <guid>https://cloudnative.to/blog/jd-grandshorestech/</guid>
      <description>&lt;p&gt;我们的核心团队成员来自腾讯、JP Morgan、富途证券、E投睿、高盛等国际顶级金融机构和互联网巨头（BAT），团队成员拥有丰富的亿级规模用户项目经验。现在，我们正在招聘以下岗位：&lt;/p&gt;
&lt;h2 id=&#34;招聘岗位&#34;&gt;招聘岗位&lt;/h2&gt;
&lt;h3 id=&#34;市场类&#34;&gt;市场类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;品牌推广&lt;/li&gt;
&lt;li&gt;渠道管理&lt;/li&gt;
&lt;li&gt;商务BD&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;运营类&#34;&gt;运营类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;内容运营&lt;/li&gt;
&lt;li&gt;客户成功经理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;产品与研发类&#34;&gt;产品与研发类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;产品经理&lt;/li&gt;
&lt;li&gt;UI设计&lt;/li&gt;
&lt;li&gt;前端开发&lt;/li&gt;
&lt;li&gt;终端开发（Android、iOS）&lt;/li&gt;
&lt;li&gt;Java开发&lt;/li&gt;
&lt;li&gt;Golang开发&lt;/li&gt;
&lt;li&gt;云原生&lt;/li&gt;
&lt;li&gt;DBA&lt;/li&gt;
&lt;li&gt;安全运维&lt;/li&gt;
&lt;li&gt;测试工程师&lt;/li&gt;
&lt;li&gt;数据开发&lt;/li&gt;
&lt;li&gt;数据分析师&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;公司福利&#34;&gt;公司福利&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;高薪资&lt;/strong&gt;：薪资对标甚至高于BAT，年终奖在春节前发放。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;弹性工作&lt;/strong&gt;：不打卡，弹性工作制，工作氛围好，拒绝内卷，强调工作与生活平衡（WLB）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;远程办公&lt;/strong&gt;：支持海内外分布式远程办公，春节享有加长假期。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;完善保障&lt;/strong&gt;：七险一金，含2000元商业保险及1500元健康体检。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;丰富活动&lt;/strong&gt;：每周篮球、羽毛球、游泳、棋牌桌游等活动俱乐部。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;下午茶与零食&lt;/strong&gt;：周三下午茶花样多，办公室零食不断，节假日福利丰厚。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;团建与奖金&lt;/strong&gt;：团建经费充足，提供丰厚的团队建设奖金（TB）。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;公司：&lt;strong&gt;雄岸科技&lt;/strong&gt;&lt;br&gt;
总部：&lt;strong&gt;新加坡&lt;/strong&gt;（上市公司）&lt;br&gt;
&lt;strong&gt;长期招聘，外企远程岗位内推通道（直招）&lt;/strong&gt; : &lt;a href=&#34;https://t1kkfqulti.feishu.cn/share/base/form/shrcnNwo40aojwWrNdzlh3Ppsb3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://t1kkfqulti.feishu.cn/share/base/form/shrcnNwo40aojwWrNdzlh3Ppsb3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;福利待遇对标大厂甚至更高，如果你愿意付出 100% 的努力，我们将给予 500% 的回报。我们提供全球各地宽敞且舒适的工作环境，崇尚自由与生活协调的工作氛围。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linkerd 服务网格的发布模式变更： 开源版只提供 Edge 版本，稳定版需付费使用</title>
      <link>https://cloudnative.to/blog/linkerd-revise-release-model/</link>
      <pubDate>Tue, 27 Feb 2024 09:05:42 +0800</pubDate>
      <guid>https://cloudnative.to/blog/linkerd-revise-release-model/</guid>
      <description>&lt;p&gt;Linkerd 是一个开源的服务网格项目，由 Buoyant 公司创建并维护。服务 网格是一种云原生技术，可以为微服务架构提供统一的网络层，实现服务间的安全、可观测和可控的通信。 Linkerd 以其轻量、快速和易用的特点，赢得了许多 开发者和企业的青睐。&lt;/p&gt;
&lt;p&gt;然而，Buoyant 公司最近宣布了一个重大的变化，即从 5 月开始，如果用户想要 下载和运行 Linkerd 的最新 稳定版本，就必须使用 Buoyant 的 商业分发版，即 Buoyant Enterprise for Linkerd（BEL）。&lt;strong&gt;BEL 是一个面向企业的 Linkerd 分发版，对于个人和 50 人以下的 企业免费使用，对于 50 人以上的企业，在生产环境中使用则需要付费。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一变化意味着，Linkerd 的 开源版本将只提供 Edge 版本，即每 10 天左右发布一次的预发布版本，用于测试新功能，但可能存在一些不兼容的变化。而 稳定版本，即经过充分测试和优化的版本，将只在 BEL 中提供。&lt;/p&gt;
&lt;p&gt;Buoyant 公司的 CEO William Morgan 在接受 The New Stack 的采访时解释了这一变化的原因，他表示，这是为了确保 Linkerd 为 企业用户提供顺畅的运行体验。他说，打包发布版本的工作非常耗费资源，甚至比维护和推进核心软件本身还要困难。他将这种做法比作 Red Hat 对 Linux 的运作方式，即提供 Fedora 作为早期发布版，同时维护其 核心 Linux 产品，即 Red Hat Enterprise Linux（RHEL）供 商业客户使用。&lt;/p&gt;
&lt;p&gt;“如果你想要我们投入到稳定版本的工作，这主要是围绕着不仅仅是测试，还有在后续版本中最小化变化的工作，这是非常艰难的工作，需要世界领先的分布式系统专家的投入，”Morgan 说，“那么，这就是黑暗的、专有的一面。”&lt;/p&gt;
&lt;p&gt;除了 Linkerd 的 核心功能外， BEL 还提供了一些额外的 专有工具，如动态的区域感知负载均衡器、用于 Linkerd 安装和升级的 Kubernetes Operator，以及一套用于管理授权策略的工具。BEL 的 企业版价格为每月每集群 2000 美元，不过对于非营利组织、高容量使用场景和其他特殊需求，也有一些折扣。&lt;/p&gt;
&lt;p&gt;Linkerd 的 开源项目由 Cloud Native Computing Foundation（CNCF）管理， 版权由 Linkerd 的作者本身持有。Linkerd 采用 Apache 2.0 许可证。&lt;/p&gt;
&lt;p&gt;Linkerd 的最新版本 2.15，于本周发布，包括了一些新的功能。其中之一是 “ 网格扩展”，它可以让用户将非 Kubernetes 的工作负载，如来自 虚拟机或裸机服务器的工作负载，通过使用基于 Rust 的微代理，纳入到服务 网格中。&lt;/p&gt;
&lt;p&gt;我们将继续关注 Linkerd 的发展，以及它对云原生社区的影响。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cilium 2023 年度报告发布</title>
      <link>https://cloudnative.to/blog/cilium-2023-annual-report/</link>
      <pubDate>Tue, 09 Jan 2024 18:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/cilium-2023-annual-report/</guid>
      <description>&lt;p&gt;这份报告回顾了 Cilium 项目在 2023 年的成就和进展，包括贡献者增长、版本亮点、用户调查结果、生产环境案例、社区活动和引用、以及 2024 年的发展方向。报告显示，Cilium 项目已经成为云原生网络、可观测性和安全性的领导者，得到了广泛的认可和采用。报告还展示了 Cilium 项目的健康状况和活跃度，通过数据和图表展示了项目的里程碑和提交情况。报告最后感谢了社区的支持和贡献，以及期待未来的更多创新和协作。&lt;/p&gt;
&lt;p&gt;详情见：&lt;a href=&#34;https://www.cncf.io/blog/2023/12/21/ciliums-2023-annual-report/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cncf.io/blog/2023/12/21/ciliums-2023-annual-report/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载地址：&lt;a href=&#34;https://github.com/cilium/cilium.io/blob/main/Annual-Reports/Cilium%20Annual%20Report%202023.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以下内容选取自报告中的 release highlight 部分。&lt;/p&gt;
&lt;h2 id=&#34;版本更新&#34;&gt;版本更新&lt;/h2&gt;
&lt;p&gt;Cilium 在 2023 年进行了两次重大发布。Cilium 1.13 于 2 月发布，针对网络（特别是服务网格）、性能和软件供应链安全等方面进行了许多改进。Cilium 1.14 于 7 月发布，引入了一个备受期待的功能：与主要改进相结合的双向身份验证，同时扩展了 Kubernetes 之外的网络。Tetragon 1.0 于 10 月发布，带来了主要的更新和性能改进。&lt;/p&gt;
&lt;p&gt;以下是所有版本中包含的一些主要变化的概述：&lt;/p&gt;
&lt;h2 id=&#34;cilium-113&#34;&gt;Cilium 1.13&lt;/h2&gt;
&lt;h3 id=&#34;gateway-api&#34;&gt;Gateway API&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 1.13 带有 Gateway API 的完全兼容实现。这个 API 是用于北向负载均衡和流量路由到 Kubernetes 集群的新标准，是 Kubernetes Ingress API 的长期继任者。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;带注释的-kubernetes-服务的-l7-负载均衡&#34;&gt;带注释的 Kubernetes 服务的 L7 负载均衡&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 1.13 引入了使用 Cilium 内置的 Envoy 代理来实现现有 Kubernetes 服务的 L7 负载均衡的功能，通过应用以下注释：&lt;code&gt;&amp;quot;service.cilium.io/lb-l7&amp;quot;: &amp;quot;enabled&amp;quot;&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据面上的双向身份验证---beta&#34;&gt;数据面上的双向身份验证 - Beta&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;数据面级别添加了双向身份验证支持，以便 Cilium 能够对集群中对等节点上的终端进行身份验证，并根据成功的双向身份验证来控制数据平面连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;loadbalancer-服务和-bgp-服务广告的-ipam&#34;&gt;LoadBalancer 服务和 BGP 服务广告的 IPAM&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LoadBalancer IP 地址管理（LB-IPAM）是一个新功能，允许 Cilium 为 Kubernetes LoadBalancer 服务提供 IP 地址。Cilium BGP 通过引入服务地址广告得到了改进，这个功能可以与 LB-IPAM 功能无缝配合使用，帮助用户通过 BGP 广告 Kubernetes 服务的 IP 地址，从而不再需要 MetalLB，简化了网络堆栈。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;支持-kubernetes-上的-sctp&#34;&gt;支持 Kubernetes 上的 SCTP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SCTP 是一种在电信行业中经常用于支持 VoIP 和其他实时服务的传输层协议。Cilium 1.13 引入了 STCP 的基本支持，甚至支持在 Hubble 中进行可视化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性能&#34;&gt;性能&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 引入了支持 BIG TCP 的功能，通过提高吞吐量并减少节点的延迟来提高网络性能，帮助用户扩展到 100Gbps 集群甚至更大的规模。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;软件供应链安全&#34;&gt;软件供应链安全&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 和 Tetragon 容器镜像现在在创建时使用 cosign 进行签名。利用镜像签名，用户可以确信他们从容器注册表获取的镜像是维护者构建和发布的受信任的代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sboms&#34;&gt;SBOMs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;从版本 1.13 开始，Cilium 和 Tetragon 镜像现在包含了软件材料清单（SBOM）。这意味着用户可以确保 Cilium 中使用的组件和依赖关系是透明和可验证的，以便查找潜在的漏洞。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cilium-114&#34;&gt;Cilium 1.14&lt;/h2&gt;
&lt;h3 id=&#34;服务网格和双向身份验证&#34;&gt;服务网格和双向身份验证&lt;/h3&gt;
&lt;h4 id=&#34;双向身份验证---beta&#34;&gt;双向身份验证 - Beta&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 1.14 带来了新的双向身份验证支持，通过 SPIFFE（Secure Production Identity Framework for Everyone）和 SPIRE（SPIRE 是 SPIFFE API 的生产就绪实现）提供。有了这个新支持，Cilium 现在可以与 SPIRE 服务器一起部署，以启用双向身份验证。这允许工作负载在 SPIRE 服务器上创建和管理其身份，该服务器自动管理和旋转证书。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;envoy-daemonset&#34;&gt;Envoy DaemonSet&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;添加了 Envoy 作为 DaemonSet 的支持。这意味着 Envoy 代理不再需要在 Cilium 代理 Pod 内作为进程运行，从而允许独立的生命周期、独立的管理以及将问题的影响限制在 Envoy 代理或 Cilium 代理中的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wireguard-节点到节点加密和-layer-7-策略支持&#34;&gt;WireGuard 节点到节点加密和 Layer 7 策略支持&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 的使用 WireGuard 的加密已经得到增强。现在可以加密 Pod 之间、从 Pod 到节点以及节点之间的流量，并且还支持将 L7 网络策略应用于使用 WireGuard 加密的流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;超越-kubernetes-的网络&#34;&gt;超越 Kubernetes 的网络&lt;/h3&gt;
&lt;h4 id=&#34;l2-公告&#34;&gt;L2 公告&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cilium 1.14 带有一个名为 L2 Announcement policy 的新功能，它允许 Cilium 响应本地客户端对 ExternalIPs 和/或 LoadBalancer IP 的 ARP 请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;bgp-增强&#34;&gt;BGP 增强&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;为 Cilium 的 BGP 实现添加了新功能，包括：Cilium CLI 中的 BGP 命令，可以使用 Cilium CLI 显示所有节点的 BGP 对等状态；BGP Graceful Restart，可以在重新启动代理时保持对等方的路由；eBGP Multi-Hop，允许用户在没有明确的 TTL 跳数限制的情况下启用两个 EBGP 对等方之间的邻居连接；自定义 BGP 定时器，可以自定义 Cilium 和对等方之间的 BGP 会话的定时器。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;集群网格&#34;&gt;集群网格&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 KVStoreMesh 模式下，Cilium Cluster Mesh 实现了改进的可扩展性和隔离，面向大规模 Cluster Mesh 部署，支持多达 50,000 个节点和 500,000 个 Pod。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tetragon-10&#34;&gt;Tetragon 1.0&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cilium Tetragon 1.0 主要关注提高性能并减小系统开销。它是一个基于 Kubernetes 的工具，通过 eBPF 应用策略和过滤，确保以最小的性能影响实现深度可观测性。Tetragon 跟踪各种活动，如进程执行、特权升级、文件和网络活动，提供一系列的开箱即用的安全可观测性策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tetragon 作为一个基于 Kubernetes 的本地工具，与 Kubernetes 无缝集成，以增强安全可观测性，通过为精确的策略应用丰富事件提供必要的元数据。它使用 eBPF 进行事件观察和过滤，确保最小的开销和高效的性能，显着减少了数据传输和执行操作中的延迟。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在性能测试中，其有效性得到了证明，在进程执行跟踪方面的开销不到 2%，即使在高 I/O 条件下也能够高效地监视文件完整性，对网络性能的影响也很小，展示了它有效和高效地观察网络流量的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>HashiCorp 创始人 Mitchell Hashimoto 宣布离职</title>
      <link>https://cloudnative.to/blog/mitchell-reflects-as-he-departs-hashicorp/</link>
      <pubDate>Fri, 15 Dec 2023 08:13:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/mitchell-reflects-as-he-departs-hashicorp/</guid>
      <description>&lt;p&gt;云原生社区报道：Mitchell Hashimoto 的离职意味着 HashiCorp 这一领先的云原生工具和解决方案提供商将迎来新的篇章。他在离开之际分享了对过去的回顾和对未来的展望。HashiCorp 社区和生态系统将继续发展壮大，我们期待看到他们在云原生领域取得更多的成功。&lt;/p&gt;
&lt;p&gt;下文是 Mitchell Hashimoto 在 Hashicorp 官网上发布的&lt;a href=&#34;https://www.hashicorp.com/blog/mitchell-reflects-as-he-departs-hashicorp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;离职感言&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文&lt;/h2&gt;
&lt;p&gt;在经过超过 11 年的时光后，HashiCorp 共同创始人 Mitchell Hashimoto 写下了一封深情的告别信，向他所帮助创立的公司告别。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2023 年 12 月 14 日，作者：&lt;a href=&#34;https://www.hashicorp.com/blog/authors/mitchell-hashimoto&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mitchell Hashimoto&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;本周早些时候，我向 HashiCorp 的员工发送了这封信，并在这里发布，以让整个 HashiCorp 社区了解我的计划：&lt;/p&gt;
&lt;p&gt;今天，我有一些双重情感要与大家分享：我决定离开 HashiCorp，不久后将不再是该公司的员工。我刚刚庆祝了自从开始 HashiCorp 以来的 11 年，回顾过去的十年，我认为自己无法找到更好的方式来度过我生命的这一部分。&lt;/p&gt;
&lt;p&gt;我离开 HashiCorp 是我长时间以来一直在思考和策划的事情。自从创立 HashiCorp 以来，我一直觉得有必要建立一个公司，我不必参与日常运营，其他领导者可以随着时间推移继续前进。随着时间的推移，我对此非常有意识：2016 年辞去首席执行官职务，随着时间的推移，不断改进领导层自治文化，不需要我的参与来做出决策，最终在 2021 年&lt;a href=&#34;https://www.hashicorp.com/blog/mitchell-s-new-role-at-hashicorp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;离开了领导团队和董事会&lt;/a&gt;。从那时起，我有幸全职从事我最喜欢的工作——作为一名全职的、亲自动手的工程师。&lt;/p&gt;
&lt;p&gt;作为一名工程师，我的激情不仅限于基础架构，我一直知道，某个时候——当公司和我准备好的时候——我会继续前进，承担新的、不同的挑战。我的家庭最近迎来了我们的第一个孩子，休息期间，我觉得现在是完成这个过渡的合适时机。云自动化和基础架构工具领域仍然充满了机遇和增长，但在专门从事这个领域的工具近 15 年后，我已经准备尝试新的领域。&lt;/p&gt;
&lt;p&gt;尽管我离开 HashiCorp 正是我计划的，但这仍然是一个令人难以忘怀的时刻。几乎我整个成年生活都与这家公司有关。我最具有决定性的记忆中有许多不容忽视的瞬间。在这里无法一一列举，但我想突出几个。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-mitchell-和-armon2013-年&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Mitchell 和 Armon，2013 年&#34; srcset=&#34;
               /blog/mitchell-reflects-as-he-departs-hashicorp/f1_hu14347652274942376307.webp 400w,
               /blog/mitchell-reflects-as-he-departs-hashicorp/f1_hu2773503286203580812.webp 760w,
               /blog/mitchell-reflects-as-he-departs-hashicorp/f1_hu7408110024587182446.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/mitchell-reflects-as-he-departs-hashicorp/f1_hu14347652274942376307.webp&#34;
               width=&#34;760&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Mitchell 和 Armon，2013 年
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;早在我们创办 HashiCorp 之前，我和 Armon [Dadgar，HashiCorp 共同创始人兼首席技术官] 经常讨论云、自动化和分布式系统。那时我们还是青少年，我们曾玩笑地——并非认真——说过类似的话：“如果有一天最大的公司使用我们的软件会怎么样？”然而，有一天，我们迈出了第一步，将一些想法变成了实际的代码。接下来，我们意识到我们拥有了成千上万的用户。然后，我们又迈出了一步，创办了一家公司。再过一段时间，我们又迈出了下一步，决定筹集资金。这就是 HashiCorp 今天的样子：我们像这样迈出了许多小小的步骤，直到我们发现那种玩味十足的、青少年的理想主义已经成为现实。&lt;/p&gt;
&lt;p&gt;正式开始后，我觉得一些“第一次”尤为重要。&lt;a href=&#34;https://www.hashicorp.com/blog/hashiconf-2015-wrap-up&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015 年的第一届 HashiConf&lt;/a&gt; 将永远是一个特殊的回忆。这是数字世界真正跨足物理世界的第一次，很难相信其中的任何一部分是真实的。我知道我们的下载量很高，我知道我每天都与社区成员在线互动，但看到数百人愿意亲自出席却是一种完全不同的体验。我感到非常自豪，但那也是我第一次感到责任的沉重。我感到内心挣扎，一方面想要建设，但另一方面需要引导我和 Armon 创建的这家公司。我非常感谢那些早期采用者和员工们参加了这次活动。&lt;/p&gt;
&lt;p&gt;几年后，我们的第一次全公司内部外出活动是我下一个重大的“哇”的经历。出席的人数比第一届 HashiConf 还要多！我和 Armon 一起创办了这家公司，专注于我对技术的激情，但像这样的时刻教会了我人员也同样重要。人和我们共享的经历是我现在最怀念的东西。&lt;/p&gt;
&lt;p&gt;在我与 HashiCorp 的历史中，还有许多类似的影响深远的时刻，我为其中每一个经验（甚至是艰难的经验）都感到感激，因为它是实现每个个体里程碑的必要步骤之一。&lt;/p&gt;
&lt;p&gt;我与 Armon 已经一起工作了将近 15 年（甚至在 HashiCorp 之前就开始了！），与 Dave [McJannet，HashiCorp CEO] 已经合作了 7 年多。我们一起领导了公司，直到我在 2021 年退出了领导团队。除了是同事，我们已经成为亲密的朋友。我继续信任他们的领导才能，将非常怀念与他们一起工作的时光。&lt;/p&gt;
&lt;p&gt;我们创办这家公司的多云等有争议的世界观现在已经成为主流，&lt;a href=&#34;https://www.hashicorp.com/state-of-the-cloud/2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;得到广泛接受&lt;/a&gt;。我帮助创办的软件被从业者广泛使用，从世界上最大的公司的业余爱好者到专业人士。最近，&lt;a href=&#34;https://solutionshub.epam.com/blog/post/programming-language-popularity-on-github&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Octoverse 报告&lt;/a&gt; 发现 HashiCorp 配置语言（HCL）再次成为开源项目中使用最多的语言之一。这些只是一些例子，显示了 HashiCorp 在行业中持续产生的影响、增长和光明未来。这已经超出了我所能期望的，我离开时为自己在实现这一切中扮演的小角色感到自豪。&lt;/p&gt;
&lt;p&gt;正如我之前所说，几乎我整个成年生活都与 HashiCorp 有关。这家公司不仅对我的生活产生了巨大的影响，也对许多人的生活产生了巨大的影响，包括我们充满激情的社区、珍贵的客户、众多亲密的生态伙伴和我们了不起的员工。感谢大家的支持和信任。最后，我衷心祝愿整个公司一切顺利。我将为你们加油打气，感激我为塑造 HashiCorp 的旅程做出的贡献，期待看到你们接下来将要做的事情。&lt;/p&gt;
&lt;h2 id=&#34;评价&#34;&gt;评价&lt;/h2&gt;
&lt;p&gt;Mitchell Hashimoto 的离职标志着他个人职业生涯的新篇章，同时也对 HashiCorp 公司和云原生领域带来了重大影响。作为公司的共同创始人之一，他在 HashiCorp 中度过了 11 年，为公司成功发展做出了巨大贡献。离开公司，他追求新的挑战，反映了公司文化演进，强调了领导力的重要性。他的工作对云原生社区和生态系统产生了深远影响，HashiCorp 的工具广泛应用于云原生领域。他的离职不会改变 HashiCorp 在该领域的地位，同时为他提供了继续成长和探索新领域的机会，也让公司有机会吸引新领导者和推动创新。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IBM 提出多云世界的新范式：App-centric Connectivity</title>
      <link>https://cloudnative.to/blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/</link>
      <pubDate>Fri, 08 Dec 2023 10:13:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/</guid>
      <description>&lt;p&gt;云原生社区最新报道：近日 IBM 发布了名为「IBM 混合云 Mesh」的多云网络解决方案，旨在为企业提供简单、可扩展、安全的应用程序中心化连接。该解决方案可帮助 CloudOps 团队实现可见性和优化，同时也有助于 DevOps 团队实现业务敏捷性。混合云 Mesh 通过连通各种环境，为应用程序和服务提供了无缝的入口。它还与 IBM NS1 Connect 的 DNS 流量引导功能相结合，提供可预测的延迟、带宽和成本。解决方案的核心组件包括 Mesh Manager 和 Gateways，用于集中管理、策略制定和数据传输。这一新范式将提高应用程序性能和安全性，促进团队协作，助力企业在多云环境中实现创新。&lt;/p&gt;
&lt;p&gt;在现代企业中，分布式软件应用程序需要始终可用、安全、响应迅速且全球优化的访问。为了为内部和外部用户提供这种应用体验，一个安全的混合云战略至关重要。我们对混合云的愿景非常清晰：帮助客户通过随时随地构建、部署和管理应用程序和服务，加速实现积极的业务成果。&lt;/p&gt;
&lt;p&gt;传统的 CloudOps 和 DevOps 模型涉及手动工作流程，可能无法提供所需的应用程序体验。IBM 坚信，现在是采取新方法的时候，这个方法是由应用程序本身驱动的。新的范式是通过安全、高性能的应用程序中心化网络来简化混合和多云应用程序交付，以帮助提高应用程序速度并改善 IT 团队之间的协作。&lt;/p&gt;
&lt;p&gt;就像云可以提供虚拟平台来使用底层资源，比如计算和存储，应用程序中心化连接提供了一个新的网络叠加层，专注于应用程序和服务端点的连接。它与提供物理连接的底层网络完全抽象，因此非常简化。&lt;/p&gt;
&lt;p&gt;应用程序中心化连接如何帮助 IT 团队？对于 CloudOps 团队，这种方法有助于实现可见性和优化。对于 DevOps 团队，它有助于实现业务敏捷性。两个团队都可以从更好的团队协作中受益，拥有共同的用户体验（UX），自定义拓扑视图以及管理和查看 SLO 和资源状态的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全新网络范式的实际应用：IBM 混合云 Mesh&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ibm.com/products/hybrid-cloud-mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IBM 混合云 Mesh&lt;/a&gt;，这是今年早些时候宣布的一款多云网络解决方案，现已推出。这款新的 SaaS 产品旨在允许组织建立简单、可扩展的安全应用程序中心化连接。该产品还被设计成可预测的，关于延迟、带宽和成本。它专为 CloudOps 和 DevOps 团队设计，以无缝地管理和扩展网络应用程序，包括运行在 Red Hat OpenShift 上的云原生应用程序。&lt;/p&gt;
&lt;p&gt;您将发现一种无缝的入口，用于在异构的其他环境中提供应用程序和服务，例如，将混合云 Mesh 与&lt;a href=&#34;https://www.ibm.com/products/ns1-connect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IBM NS1 Connect&lt;/a&gt;的 DNS 流量引导功能结合使用，这是一款用于向数百万用户交付内容、服务和应用程序的 SaaS 解决方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IBM 混合云 Mesh 的架构：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ibm-hybrid-cloud-mesh-架构&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;IBM Hybrid Cloud Mesh 架构&#34; srcset=&#34;
               /blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/image-20231208122302863_hu5526161949108312093.webp 400w,
               /blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/image-20231208122302863_hu705373969102025883.webp 760w,
               /blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/image-20231208122302863_hu7863713664886081500.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/app-centric-connectivity-a-new-paradigm-for-a-multicloud-world/image-20231208122302863_hu5526161949108312093.webp&#34;
               width=&#34;760&#34;
               height=&#34;388&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      IBM Hybrid Cloud Mesh 架构
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;该产品设计的关键是两个主要的架构组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mesh Manager 提供了集中的管理和策略平面，具有可观察性。&lt;/li&gt;
&lt;li&gt;Gateways 实施混合云 Mesh 的数据平面，并充当虚拟路由器和连接器。这些网关通过 Mesh Manager 进行集中管理，部署在云上和客户端上。有两种类型的网关：1) 边缘网关，部署在工作负载附近，用于转发、安全执行、负载平衡和遥测数据收集；2) Waypoint，在靠近互联网交换和共同机房点的出口点部署，用于路径、成本和拓扑优化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;IBM 混合云 Mesh 的主要特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;持续的基础设施和应用程序发现：&lt;/strong&gt; Mesh Manager 持续发现并更新多云部署基础设施，使部署的应用程序和服务的发现成为自动化体验。持续发现使 Mesh Manager 保持对云资产变化的感知。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无缝连接：&lt;/strong&gt; DevOps 或 CloudOps 可以通过 UI 或 CLI 表达其连接意图，Mesh 将连接指定的工作负载，无论它们的位置如何。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安全性：&lt;/strong&gt; 基于零信任原则，Mesh 只允许基于用户意图的通信。所有网关都经过签名，威胁表面得到解决，因为它们只能通过 Mesh Manager 进行配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可观察性：&lt;/strong&gt; Mesh 通过 Mesh Manager的day0/day1 UI 提供全面的监视，提供有关部署环境、网关、服务和连接指标的详细信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流量工程能力：&lt;/strong&gt; 利用 Waypoint，混合云 Mesh 被设计成可优化成本、延迟和带宽的路径，以增强应用程序性能和安全性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集成工作流程：&lt;/strong&gt; DevOps、NetOps、SecOps 和 FinOps 工作流程在协作的交响曲中汇聚，通过单一和和谐的玻璃窗口提供端到端的应用程序连接。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Envoy 创始人 Matt Klein 领衔 Bitdrift 创业，推出创新移动可观测性产品并获得 1500 万美元 A 轮融资</title>
      <link>https://cloudnative.to/blog/matt-created-bitdrift/</link>
      <pubDate>Tue, 05 Dec 2023 16:13:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/matt-created-bitdrift/</guid>
      <description>&lt;p&gt;















&lt;figure  id=&#34;figure-matt-klein-的推文宣布推出公司第一个产品及完成-a-轮融资&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Matt Klein 的推文宣布推出公司第一个产品及完成 A 轮融资&#34; srcset=&#34;
               /blog/matt-created-bitdrift/image-20231205162037349_hu13857095008054824333.webp 400w,
               /blog/matt-created-bitdrift/image-20231205162037349_hu10408850505089606120.webp 760w,
               /blog/matt-created-bitdrift/image-20231205162037349_hu10130331071533861671.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/matt-created-bitdrift/image-20231205162037349_hu13857095008054824333.webp&#34;
               width=&#34;760&#34;
               height=&#34;342&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Matt Klein 的推文宣布推出公司第一个产品及完成 A 轮融资
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;云原生社区报道：&lt;/p&gt;
&lt;p&gt;近期，Matt Klein——Envoy 代理的创造者——领导下的创业公司 Bitdrift 发布了他们的首款产品：Capture。这款专注于移动端可观测性的产品获得了 1500 万美元 A 轮融资，由 Amplify Partners 领投。这标志着 Bitdrift 在解决移动和服务器端可观测性问题方面迈出了重要的一步。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-bitdrift-初创团队&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Bitdrift 初创团队&#34; srcset=&#34;
               /blog/matt-created-bitdrift/team-photo_hu837592251849647281.webp 400w,
               /blog/matt-created-bitdrift/team-photo_hu11236423092527109592.webp 760w,
               /blog/matt-created-bitdrift/team-photo_hu7267570859233241580.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/matt-created-bitdrift/team-photo_hu837592251849647281.webp&#34;
               width=&#34;760&#34;
               height=&#34;346&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Bitdrift 初创团队
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Bitdrift 的创始缘起于团队在规模化构建互联网基础设施时的挑战和挫折。公司团队来自 Twitter、AWS、Square、Google、Microsoft、Netflix 等知名企业，他们认为当前的可观测性生态系统存在供应商和消费者之间的不匹配问题。Bitdrift 旨在通过实时动态控制，仅发出可能用于解决客户问题的遥测数据，以改变这一现状。&lt;/p&gt;
&lt;p&gt;目前，移动端可观测性被认为是浪费、无序且远落后于服务器端。大约 95% 用于监控系统健康的数据从未被阅读。与此同时，移动工程师在生产中拥有的分析事件集合通常是静态的，而且调整这些事件以调试正在进行的问题可能需要数周甚至数月的时间。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-capture-workflow&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Capture workflow&#34; srcset=&#34;
               /blog/matt-created-bitdrift/workflows_hu11321469684629917159.webp 400w,
               /blog/matt-created-bitdrift/workflows_hu15980593637410678937.webp 760w,
               /blog/matt-created-bitdrift/workflows_hu2030623002525409232.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/matt-created-bitdrift/workflows_hu11321469684629917159.webp&#34;
               width=&#34;760&#34;
               height=&#34;627&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Capture workflow
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Capture 通过在 iOS 和 Android 上实现发出会话遥测数据的动态实时控制，改变了可观测性游戏的规则。这个系统允许对设备进行即时定位，从所有客户端到特定群体，甚至个别设备。结合先进的本地存储和实时配置，Capture 支持分布式搜索和遥测数据，使得数据仅在解决客户问题时才被请求和发送。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ring-buffer&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ring buffer&#34; srcset=&#34;
               /blog/matt-created-bitdrift/ring_buffer_hu17398287387740171134.webp 400w,
               /blog/matt-created-bitdrift/ring_buffer_hu262080332326638237.webp 760w,
               /blog/matt-created-bitdrift/ring_buffer_hu4681973765246519059.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/matt-created-bitdrift/ring_buffer_hu17398287387740171134.webp&#34;
               width=&#34;604&#34;
               height=&#34;558&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ring buffer
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Capture 的本地存储解决方案核心是所谓的“环形缓冲区”，一种高性能的子系统，使用有界且实时可配置的 RAM 和磁盘空间。数据首先被刷新到 RAM，然后在后台级联到磁盘。Capture 还包括高效且注重隐私的会话回放实现，可以捕获移动屏幕状态的 2D 和 3D 表示。&lt;/p&gt;
&lt;p&gt;Capture 已在 Lyft 应用中部署到数百万设备上，并在大规模下经过战斗测试。它已准备好为全球的组织解决现实世界的挑战【18†source】。&lt;/p&gt;
&lt;p&gt;Bitdrift 的愿景是开创可观测性的未来。通过 Capture，Bitdrift 开始了一段旅程，将本地遥测存储与实时控制和分布式搜索相结合，这不仅适用于移动端，而且适用于整个分布式系统——从每个服务器到移动边缘。&lt;/p&gt;
&lt;p&gt;作为云原生社区，我们对 Matt Klein 和 Bitdrift 团队在改善可观测性生态系统方面的努力表示赞赏。他们的创新不仅对移动工程师，而且对整个分布式系统的健康和效率具有深远影响。欢迎来到可观测性的未来。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bitdrift.io/about&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bitdrift 介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.bitdrift.io/post/honey-i-shrunk-the-telemetry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Honey, I shrunk the telemetry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>云原生生态周报（Cloud Native Weekly）第 3 期</title>
      <link>https://cloudnative.to/blog/cloud-native-weekly-03/</link>
      <pubDate>Tue, 07 May 2019 15:12:53 +0800</pubDate>
      <guid>https://cloudnative.to/blog/cloud-native-weekly-03/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;摘要：&lt;/em&gt; Docker Hub 遭入侵，19 万账号被泄露；Java 8 终于开始提供良好的容器支持；Snyk 年度安全报告出炉，容器安全问题形势空前严峻。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;业界要闻&#34;&gt;业界要闻&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnbeta.com/articles/tech/841873.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Docker Hub 遭入侵，19 万账号被泄露&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;:&lt;/strong&gt; 4 月 25 日 Docker 官方邮件曝露，因为 Hub 的一个数据库收到非授权访问，影响了约 19 万用户的用户名和哈希后的密码，以及用户自动构建的 Github 和 Bitbucket Token。Docker 公司建议用户修改其登录密码。如果您在公有云上的应用依赖于来自 Docker Hub 的镜像，我们强烈建议您登录容器服务控制台更新相应的 docker login 信息或 kubernetes secret。此外，阿里云容器镜像服务&lt;a href=&#34;https://promotion.aliyun.com/ntms/act/acree.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;企业版&lt;/a&gt;提供网络访问控制、独享 OSS Bucket 加密存储等安全加固功能，最大程度保障您的镜像仓库的安全。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.softwaremill.com/docker-support-in-new-java-8-finally-fd595df0ca54&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Java 8 终于开始提供良好的容器支持&lt;/strong&gt;&lt;/a&gt;**：**长久以来，容器 和 Java 就像一对“欢喜冤家”。一方面，容器技术的“不可变基础设施”特性为开发者带来了无比宝贵的依赖与环境一致性保证；但另一方面，Linux 容器通过 Cgroups 对应用进行资源限制的方式跟所有依赖于 JVM 进行资源分配的编程语言都产生了本质的冲突。而就在上周，最近发布的 OpenJDK 镜像 &lt;strong&gt;openjdk:8u212-jdk&lt;/strong&gt; 终于能够让 Java 8 运行时在容器里面为应用分配出合理的 CPU 数目和堆栈大小了。自此，发布 Java 容器应用的痛苦经历，可能要一去不复返了。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Snyk 年度安全报告出炉，容器安全问题形势空前严峻：&lt;strong&gt;知名开源安全厂商 Snyk 在年初发布了 2019 年度安全报告。报告中指出：“随着容器技术在 2019 年继续在 IT 环境中爆发式增长，针对容器安全的威胁正在迅猛增加，&lt;strong&gt;任何一家企业现在都必须比以往更加重视&lt;/strong&gt;&lt;a href=&#34;https://help.aliyun.com/document_detail/60751.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;容器镜像安全&lt;/strong&gt;&lt;/a&gt;&lt;/strong&gt;，并将此作为企业的首要任务&lt;/strong&gt;”。报告详情，请&lt;a href=&#34;https://snyk.io/opensourcesecurity-2019/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击此处查看全文&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;上游重要进展&#34;&gt;上游重要进展&lt;/h2&gt;
&lt;p&gt;Kubernetes 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;**Kubernetes 集群联邦 v1（Federation v1）正式宣布废弃。**K8s 社区近日宣布将 Federation v1 代码库正式废弃。Federation v1 即 Kubernetes 项目原“集群联邦”特性，旨在通过一个统一的入口管理多个 Kubernetes 集群。&lt;strong&gt;但是，这个特性逐步被设计成了在多个 Kubernetes 集群之上构建一个“Federation 层”的方式来实现&lt;/strong&gt;，从而背离了 Kubernetes 项目的设计初衷。最终，在 RedHat、CoreOS、Google 等多位社区成员的推动下，社区开始全面拥抱 &lt;a href=&#34;https://github.com/kubernetes-sigs/federation-v2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Federation v2&lt;/a&gt;：&lt;strong&gt;一个完全旁路控制、以 K8s API 为核心的多集群管理方案。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/releases/release-1.15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Kubernetes 1.15 进入发布节奏&lt;/strong&gt; &lt;/a&gt;K8s 1.15 发布进入日程，5 月 30 日即将 Code Freeze（即：不接受任何功能性 PR）。&lt;/li&gt;
&lt;li&gt;[**&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/958&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KEP] Ephemeral Containers KEP 合并，进入编码阶段**&lt;/a&gt;。
Ephemeral container 旨在通过在 Pod 里启动一个临时容器的方式，来为用户提供对 Pod 和容器应用进行 debug 和 trouble shooting 的能力。**这种通过“容器设计模式”而非 SSH 等传统手段解决运维难题的思路，对于“不可变基础设施”的重要性不言而喻，**阿里巴巴在“全站云化”过程中也采用了同样的设计来解决类似问题。在上游完成该功能的编码实现后，会通过 kubectl debug 命令方便用户直接使用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Knative 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;**Knative 逐步弃用原 Build 项目。**按照计划，Tektoncd/Pipeline 子项目已经在 v0.2.0 时移除了对 Build 的依赖。最近，Knative Serving v1beta1 也移除了对 Build 的依赖，目前，社区已经开始制定弃用 Build 的确切方式并通知到 knative 开发者社区。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/knative/eventing/issues/930&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;knative 正在考虑为事件触发（Trigger）引入更高级的规则和策略。&lt;/strong&gt;&lt;/a&gt; 社区正在就 Advanced Filtering 设计一个 提案。该提案提议基于 &lt;a href=&#34;https://github.com/google/cel-spec/blob/9cdb3682ba04109d2e03d9b048986bae113bf36f/doc/intro.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CEL&lt;/a&gt; （Google 维护的一种表达式语言）来进行事件的过滤。具体来说，Trigger 的 filter 字段会增加一个 Spec 字段，然后在 Spec 字段下使用 CEL 语法完成对事件的过滤规则定义。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Istio/Envoy 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/about/notes/1.1.4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Istio 1.1.4 本周正式发布&lt;/strong&gt;&lt;/a&gt;，其中一个重要的功能是更改了 Pilot 的默认行为，对出口流量的控制变化。除了之前通过 Service Entry 与配置特定范围 IP 段来支持访问外部服务，新版本中通过设置环境变量 PILOT_ENABLE_FALLTHROUGH_ROUTE 允许 Envoy 代理将请求传递给未在网格内部配置的服务。更多可以参考&lt;a href=&#34;https://yq.aliyun.com/articles/655489?source_type=cnvol_429_wenzhang&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 流量管理实践&lt;/a&gt;系列文章。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy/issues/6614&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Envoy 正通过 ORCA 改善负载均衡的精准度&lt;/strong&gt;&lt;/a&gt;。
目前 Envoy 可以用于进行负载均衡决策的信息主要是权重和连接数等信息，为了能让 Envoy 的负载均衡更加精准需要为 Envoy 提供更多的决策因素。比如本地和远程机器的负载情况、CPU、内存等信息，更复杂的还可以利用应用程序特定的指标信息来进行决策，比如队列长度。而 ORCA 的目的是定义 Envoy 和上游代理之间传递这些信息的标准。该功能的提出者希望 ORCA 可以成为 Universal Data Plane API (UDPA)。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy/pull/5910&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Envoy 正引入 RPC 去代替共享内存机制以便提高统计模块的的扩展性&lt;/strong&gt;&lt;/a&gt;。
Envoy 当下通过共享内存的方式来保存 stats 数据的这种方式存在很多局限性，比如需要限制 stats 使用固定的内存大小，当有大量集群的时候没办法扩展。这给他升级 stats 子系统的架构带来了不少的阻碍。因此他希望可以通过将 stats 数据以堆内存的方式来保存，然后通过 RPC 在新老进程中传递。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy/pull/6552&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Envoy 正在 xDS 协议中增加 VHDS 协议减小动态路由信息的更新粒度&lt;/strong&gt;&lt;/a&gt;。
现状是，Envoy 中的路由配置是通过 RDS 来动态更新的，但是 RDS 的粒度太粗了，包含了一个 Listener 下所有的路由配置信息。由于一个 Listener 下面可能会有多个服务，每一个服务对应一个 Virtual Host，因此在更新路由的时候，如果只是其中一个 Virtual Host 更新了，那么会导致所有的路由配置都重新下发而导致通讯负荷偏重。引入 VHDS 就是为了只下发变化的路由信息，从而将更新的路由配置信息量缩小。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Containerd 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containerd/containerd/pull/3148&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Non-root&lt;/strong&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/pull/3148&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;用户运行&lt;/strong&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/pull/3148&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; &lt;strong&gt;containerd&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;：&lt;/strong&gt; 近日，社区正在尝试实现无需 root 权限就可以运行 containerd 的能力。在这种场景下，用户可以提前准备好容器所需要的 rootfs，但是 containerd 服务端在清理容器时依然会尝试去 unmount rootfs，对于没有 root 权限的 containerd 进程而言，该步骤必定会失败（mount 操作必须要有 root 权限）。目前 Pivotal 的工程师正在解决这个问题，这种 non-root 模式可以为解决云上安全问题提供新的思路，&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;开源项目推荐&#34;&gt;开源项目推荐&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;本周，我们向您推荐&lt;/strong&gt; &lt;a href=&#34;https://github.com/ilhaan/kubeCDN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;kubeCDN&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;项目&lt;/strong&gt;。
kubeCDN 项目是一个基于 Kubernetes 实现的自托管 CDN 方案，只要将它部署在分布在不同地域（Region）的 Kubernetes 集群上，你就拥有了一个跨地域进行内容分发的 CDN 网络。而更重要的是，通过 kubeCDN，用户不再需要第三方的内容分发网络，从而重新控制了原本就属于自己的从服务器到用户设备的数据流。kubeCDN 目前只是一个个人项目**，但是这里体现出来的思想确实至关重要的：在不久的未来，每一朵云、每一个数据中心里都会布满 Kubernetes 项目，这将会成为未来云时代基础设施的“第一假设”。** 推荐你阅读 &lt;a href=&#34;https://www.infoq.cn/article/trfu-uB4FPhAB4uLvL4R?utm_source=tuicool&amp;amp;utm_medium=referral&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;InfoQ 的解读文章&lt;/a&gt;来进一步了解 kubeCND。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;本周阅读推荐&#34;&gt;本周阅读推荐&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;《Knative 入门——构建基于 Kubernetes 的现代化 Serviceless 应用》中文版，这是一本 O’Reilly 出品的免费电子书，已经由 servicemesher 社区组织完成翻译。提供 &lt;a href=&#34;http://www.servicemesher.com/getting-started-with-knative/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在线阅读&lt;/a&gt; 和 &lt;a href=&#34;http://t.cn/EaB8g6d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF 下载&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;信通院发起的云原生产业联盟出具《云原生技术实践白皮书》，白皮书系统性地梳理了云原生概念、关键技术、应用场景、发展趋势及实践案例。&lt;a href=&#34;https://files.alicdn.com/tpsservice/dd44ce32c783473b595382cad5857ef5.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF 链接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《&lt;a href=&#34;https://www.infoq.cn/article/7642QHo6vmZvQxFw9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;阿里云 PB 级 Kubernetes 日志平台建设实践&lt;/a&gt;》Kubernetes 近两年来发展十分迅速，已经成为容器编排领域的事实标准，但是 Kubernetes 中日志采集相对困难。本文来自 InfoQ 记者的采访，文中谈及了如何让使用者专注在“分析”上，远离琐碎的工作。&lt;/li&gt;
&lt;li&gt;《&lt;a href=&#34;https://programmaticponderings.com/2019/04/17/istio-observability-with-go-grpc-and-protocol-buffers-based-microservices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Observability with Go, gRPC, and Protocol Buffers-based Microservices&lt;/a&gt;》，这是一篇很长的博文，介绍可以与 Istio 相适配的观测性组件，用实际的例子演示了如何对以 Go 语言、Protobuf 和 gRPC 为基础的微服务框架进行全面的观测。如果你还对 Prometheus、Grafana、Jaeger 和 Kiali 这几个组件感到既熟悉又陌生，并且好奇如何把它们组合在一起使用来提升微服务的可观测性，这个博客的内容应该会对你很有帮助。&lt;/li&gt;
&lt;li&gt;《&lt;a href=&#34;https://www.infoq.cn/article/hhk37_UC1FgJFCQyIk7c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生的新思考：为什么说容器已经无处不在了？&lt;/a&gt;》这篇文章在对云原生技术总结的同时，对未来应用趋势走向进行了展望。“云原生不但可以很好的支持互联网应用，也在深刻影响着新的计算架构、新的智能数据应用。以容器、服务网格、微服务、Serverless 为代表的云原生技术，带来一种全新的方式来构建应用。”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;名词解释：KEP - Kubernetes Enhancement Proposal，即 Kubernetes 上游设计文档&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本周报由阿里巴巴容器平台联合蚂蚁金服共同发布&lt;/p&gt;
&lt;p&gt;本周作者：张磊，临石，浔鸣，天千，至简，傅伟，汤志敏，王夕宁
责任编辑：木环&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>云原生生态周报（Cloud Native Weekly）第 2 期</title>
      <link>https://cloudnative.to/blog/cloud-native-weekly-02/</link>
      <pubDate>Tue, 23 Apr 2019 10:44:45 +0800</pubDate>
      <guid>https://cloudnative.to/blog/cloud-native-weekly-02/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/cloud-native-weekly-02/006tNc79ly1g2cdd5x4mfj31uo0m8di3_hu16923444954572749290.webp 400w,
               /blog/cloud-native-weekly-02/006tNc79ly1g2cdd5x4mfj31uo0m8di3_hu5463796587061588974.webp 760w,
               /blog/cloud-native-weekly-02/006tNc79ly1g2cdd5x4mfj31uo0m8di3_hu3484099937068859590.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/cloud-native-weekly-02/006tNc79ly1g2cdd5x4mfj31uo0m8di3_hu16923444954572749290.webp&#34;
               width=&#34;760&#34;
               height=&#34;253&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;本周报由阿里巴巴容器平台联合蚂蚁金服共同发布&lt;/p&gt;
&lt;p&gt;本周作者：傅伟，敖小剑，张磊，临石，南异，心贵，王夕宁，长虑&lt;/p&gt;
&lt;p&gt;责任编辑：木环&lt;/p&gt;
&lt;h2 id=&#34;业界要闻&#34;&gt;业界要闻&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tuicool.com/articles/Jfaeqy2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes External Secrets&lt;/a&gt;  近日，世界上最大的域名托管公司 Godaddy 公司，正式宣布并详细解读了其开源的 K8s 外部 Secrets 管理项目： &lt;a href=&#34;https://github.com/godaddy/kubernetes-external-secrets&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes External Secrets&lt;/a&gt;，简称 KES。这个项目定义了 ExternalSecrets API，让开发者可以在 K8s 内部以和使用内部 Secret 相似的方式使用外部系统提供的 Secrets，大大简化了开发者为了让应用获取外部 Secrets 所需要的工作量。从安全的角度，这个方案降低了使用外部 Secret 时候的攻击面（外部 Secret 是通过一个 K8s API 暴露的，而不是之前的每个应用自己实现），也降低了应用在适配外部 Secret 时候的难度。另外，&lt;a href=&#34;https://github.com/AliyunContainerService/ack-kms-plugin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes KMS plugin 开源插件&lt;/a&gt; ，采用信封加密的方式与密钥管理能力结合，对进行 K8s secret 的存储加密。建议安全相关技术人员重点关注。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/y2V3PwOK5qbdmjFsuNTGkg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 官方宣布&lt;/a&gt;为中国开发者提供免费的云原生技术公开课。这些课程将专注于云原生技术堆栈，包括技术深度探索与动手实验课程，旨在帮助和指导中国开发人员在生产环境中使用云原生技术，并了解其用例和优势。此前，著名社区 Stackoverflow 发布了 2019 年开发者调研报告，报告有近九万人参与，Top 3 最受热爱开发平台是分别是 Linux（83.1%）、Docker（77.8%）和 Kubernetes（76.8%）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;上游重要进展&#34;&gt;上游重要进展&lt;/h2&gt;
&lt;p&gt;Kubernetes 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[重要性能优化] 2X performance improvement on both required and preferred PodAffinity. (&lt;a href=&#34;https://github.com/kubernetes/kubernetes/pull/76243&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#76243&lt;/a&gt;, &lt;a href=&#34;https://github.com/Huang-Wei&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Huang-Wei&lt;/a&gt;) 这是一个重要的性能优化。这个提交将 PodAffinity 调度的效率实现了两倍的提高。&lt;strong&gt;要知道，PodAffinity/Anti-affinity 调度规则是目前 K8s 默认调度器最大的性能瓶颈点，这次修复很值得关注。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;[重要安全增强] &lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/944&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KEP: Node-Scoped DaemonSet&lt;/a&gt;: K8s 项目现在提供一种叫 Node-Scoped DaemonSet。这种 DaemonSet 的独特之处，在于它拥有、并且只能拥有自己所在的节点 kubelet 相同的权限，并且遵循同 kubelet 相同的鉴权流程。**这种设计，避免了以往 DaemonSet 权限泛滥的问题（比如：我们现在就可以让 DaemonSet 只能访问到属于该 Node 的 API 资源）。**这个特性发布后，DaemonSet 一直以来都 是 K8s 集群里最优先被黑客们关照的尴尬局面有望从根本上得到缓解。&lt;/li&gt;
&lt;li&gt;[重要功能补丁] &lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/953&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KEP: Add kubelet support lxcfs&lt;/a&gt;: 一直以来，容器里面通过 /proc 文件系统查看 CPU、内存等信息不准确都是一个让人头疼的问题，而挂载 lxcfs 则是这个问题的最常见解决办法。&lt;strong&gt;现在，K8s 上游正在提议将 lxcfs 作为默认支持&lt;/strong&gt;，如果得以合并的话，那对于开发者和运维人员来说，都是个喜闻乐见的事情。&lt;strong&gt;不过，lxcfs 本身是一个需要额外安装的软件，很可能会成为这个阻碍设计的 blocker。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Knative 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[Serving v1beta1 API proposal(https://docs.google.com/presentation/d/10wuLMFXyol731WKuO5x7lalWrH0A6YVHa4exIERQaQ8/edit#slide=id.p)&lt;strong&gt;Knative serving API 准备升级到 v1beta1 版本&lt;/strong&gt;，其目标之一是使用标准的 PodSpec，以便更方便的从 K8s Deployment 迁移过来。这个版本和 v1alpha1 对比主要变更有：去掉了 runLatest，缺省默认就是 runLatest；Release 模式可以通过配置 traffic 实现，可以指定各个版本的流量比例；取消 Manual 模式；提供 revision 生成名字的控制；停用 Serving 内置的 Build。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/knative/eventing/issues/918&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Triggers don&amp;rsquo;t use Istio VirtualServices&lt;/a&gt;：Knative Eventing 原有的实现，依赖于 Istio 的 VirtualService 来重写 Host Header，使得接下来 Broker 可以通过 Host  Header 来识别此 Event 是发给哪个 Trigger 的。而最新的做法，则是通过  URL 来进行区分（比如：http://foo-broker-filter-1da3a.default.svc.cluster.local/my-trigger 代表此事件是发送给 my-trigger 的)，&lt;strong&gt;从而解除了 Trigger 对 Istio  VirtualService 的依赖&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/knative/eventing/issues/294&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Remove Istio as a dependency&lt;/a&gt;：除了上述解耦之外，Knative Eventing Channel 和 Bus 的绑定目前也是通过 istio 的 VirtualService 实现的。在这个新的实现方案中，Provisioners 直接把  Bus 的 主机名写到 channel 的状态当中，就不再需要 Istio VirtualService 来充当 Proxy 了。&lt;strong&gt;这些提交，都在透出这样一个事实：Knative 正在逐步减少对 Istio 的各种依赖，这对于一个真正、适用于更广泛场景的 Serverless 基础设施来说，是非常重要的。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Istio 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[重要安全增强]最近在 Envoy 代理中发现了两个安全漏洞（CVE 2019-9900 和 CVE 2019-9901）。这些漏洞现在已经在 Envoy 版本 1.9.1 中修补，并且相应地嵌入在 Istio 1.1.2 和 Istio 1.0.7 中的 Envoy 版本中。由于 Envoy 是 Istio 不可分割的一部分，因此建议用户立即更新 Istio 以降低这些漏洞带来的安全风险。&lt;/li&gt;
&lt;li&gt;[性能提升] Istio 1.1 中的新增强功能可以提高应用程序性能和服务管理效率，从而实现扩展，Pilot CPU 使用率降低了 90％, 内存使用率降低 50％。业界已有尝试在 Kubernetes 中使用 Pilot 实现服务的流量管理，对应用服务提供多版本管理、灵活的流量治理策略，以支持多种灰度发布场景。可以参考&lt;a href=&#34;https://yq.aliyun.com/articles/667297?source_type=cnvol_422_wenzhang&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;通过 Istio 管理应用的灰度发布&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;containerd 项目&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containerd/containerd/issues/3198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;runc v2 shim &lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/issues/3198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;支持&lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/issues/3198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; cgroup &lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/issues/3198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;设置&lt;/a&gt;：containerd 目前支持多个容器使用&lt;a href=&#34;https://github.com/containerd/containerd/pull/3004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;同一个&lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/pull/3004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; containerd-shim &lt;/a&gt;&lt;a href=&#34;https://github.com/containerd/containerd/pull/3004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;来管理&lt;/a&gt; - 一个 Pod 就可以使用一个 containerd-shim 来管理一组容器，减少 containerd-shim 对系统资源的开销。但是目前新的 shim v2 没有提供配置 Cgroup 接口，这个功能会在 1.3 Release 中解决。有了这个能力之后，上层应用就可以将 containerd-shim 资源控制也纳入 Pod 资源管理体系中，严格控制系统服务占用的资源大小。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containerd/containerd/issues/3210&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;containerd 插件 ID 管理&lt;/a&gt;：containerd 允许开发者将自定义的组件注册到服务里，提供了可插拔的能力。但是当前 containerd 插件的管理是假设 ID 是唯一，这会导致相同 ID 的插件加载结果不可预测。当前该问题还在讨论中，计划在 1.3 Release 中解决。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;本周云原生最佳实践&#34;&gt;本周云原生最佳实践&lt;/h2&gt;
&lt;p&gt;传统富容器运维模式如何云原生化？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在很多企业当中长期以来都在使用富容器模式，即：在业务容器里安装 systemd、sshd、监控进程等系统进程，模拟一个虚拟机的行为。这种运维方式固然方便业务迁入，但是也跟云原生理念中的“不可变基础设施”产生了本质冲突。比如：容器里的内容被操作人员频繁变化给升级、发布带来了众多运维隐患；富容器模式导致开发人员其实并不了解容器概念，在容器里随机位置写日志甚至用户数据等高风险的行为屡见不鲜。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;来自阿里巴巴“全站云化”的实践&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;将富容器容器运行时替换为支持 CRI 体系的标准容器运行时比如 containerd 等。目前阿里已经将 PouchContainer 全面升级为 containerd 发行版。&lt;/li&gt;
&lt;li&gt;把富容器里面的耦合在一起进程、服务进行拆分，变成一个 Pod 里的多个容器，下面是“全站云化”采用的拆分方法：   (1)  业务容器：运行业务主进程，允许 exec 方式进入；(2)  运维 Sidecar 容器：日志收集、debugger、运维辅助进程等；(3)  业务辅助容器：Service Mesh 的 agent&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;开源项目推荐&#34;&gt;开源项目推荐&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;本周我们向您推荐&lt;a href=&#34;https://spiffe.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPIFFE 项目&lt;/a&gt;。SPIFFE，从运维人员的第一感觉而言，是解决证书下发问题的。以往的安全体系更注重自然人的身份认证，而在 SPIFFE 里面所有的运行实体都有身份。一个案例就是 K8s 上的每个 pod 都配置相应的身份，对于多云和混合云的安全角度讲，SPIFFE 的好处在于不被供应商的安全认证体系绑定，可以达到跨云/跨域的身份认证，从而确保安全。下面是我们搜集的一些关于 SPIFFE 的不错的公开资料，有兴趣可以去了解：
&lt;ul&gt;
&lt;li&gt;项目的主要发起人 Evan 的&lt;a href=&#34;https://v.qq.com/x/page/t07113umnwq.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;演讲&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SPIRE 是 SPIFFE 的实现，和 Service Mesh 结合详见&lt;a href=&#34;https://segmentfault.com/a/1190000018432444&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这篇文章&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aqniu.com/learn/39145.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPIRE&lt;/a&gt;&lt;a href=&#34;https://www.aqniu.com/learn/39145.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;的零信任安全机制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;本周阅读推荐&#34;&gt;本周阅读推荐&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.servicemesher.com/blog/knative-whittling-down-the-code/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative：精简代码之道&lt;/a&gt;，作者 Brian McClain | 译者 孙海洲。这篇文章用循序渐进的例子对“什么是 Knative”做出了很好的回答。如果你现在对 Knative 的认识还停留在三张分别叫做 Build，Serving 和 Eventing 的插图的话，那可能阅读一下这篇文章会让你对它们的理解更加形象。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yq.aliyun.com/articles/695315?source_type=cnvol_422_wenzhang&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spark in action on Kubernetes - 存储篇&lt;/a&gt;，by Alibaba 莫源。存储永远是大数据计算的核心之一，随着新计算场景的不断涌现和硬件技术的飞速发展，存储的适配关系到大规模计算的成本、性能、稳定性等核心竞争要素。本文继上面分析 K8s 中的 Spark Operator 之后，从硬件限制、计算成本和存储成本几个角度，讨论了云原生时代来临后存储如何解决&lt;strong&gt;成本低、存得多、读写快&lt;/strong&gt;这几个挑战，详细介绍了阿里云上相关产品在不同场景下的表现，并总结了不同场景下适用的存储解决方案以及选择的原因。如果你是 K8s 和大数据方面的开发者和使用者，这是一篇你不应该错过的博客，可以快速的帮你梳理当前技术下存储的场景和典型解决方案。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>云原生生态周报（Cloud Native Weekly）第 1 期</title>
      <link>https://cloudnative.to/blog/cloud-native-weekly-01/</link>
      <pubDate>Tue, 16 Apr 2019 19:35:39 +0800</pubDate>
      <guid>https://cloudnative.to/blog/cloud-native-weekly-01/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本周作者：张磊 临石 禅鸣 至简 宋净超&lt;/p&gt;
&lt;p&gt;编辑：木环&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是 Cloud Native 周报第一期。&lt;/p&gt;
&lt;h2 id=&#34;业界要闻&#34;&gt;业界要闻&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在上周于旧金山举办的 Google Cloud Next 2019 大会上，Google Cloud 正式发布了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/run/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt;。这是一个跟 Microsoft Azure ACI，AWS Fargate 类似的容器实例服务。但与 ACI 和 Fargate 基于虚拟机技术栈的实现不同，Google 的 Cloud Run 服务则是基于 &lt;a href=&#34;https://github.com/knative/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative&lt;/a&gt; 这个 Kubernetes 原生的 Serverless 基础设施项目完成的。这也是业界第一个基于 Knative + Kubernetes + gVisor 体系的 Serverless 服务。此外，&lt;a href=&#34;https://cloud.google.com/run/pricing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run 的计费模型&lt;/a&gt;也颇具创新性：它不像 Fargate 那样完全按请求数目计费，而是将所有并发的请求算在一个计费单位内，这有望大大减低用户需要支付的成本。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/traffic-director/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Traffic Director&lt;/a&gt;。一个与 AWS App Mesh 对标的 Service Mesh 产品。Traffic Director 通过 xDS 协议与数据平面的 Envoy 进行通讯，可分别与 Google Cloud 的&lt;a href=&#34;https://cloud.google.com/compute/docs/instance-groups/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIG&lt;/a&gt;和&lt;a href=&#34;https://cloud.google.com/load-balancing/docs/negs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEG&lt;/a&gt;两款产品结合去提供 Service Mesh 的能力。Traffic Director 的功能与开源 Istio 项目中的 Pilot-discovery 相似，也复用了 Istio 的不少技术实现（比如，通过 iptables 完成流量透明拦截）。Traffic Director 支持全球负载均衡、集中式的集群健康检查、流量驱动的自动扩缩容等功能，帮助客户在全球部署与管理高弹性的无状态应用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于 Google Cloud Next 上其他一些比较有意思的发布，你可以阅读 &lt;a href=&#34;https://techcrunch.com/2019/04/10/the-6-most-important-announcements-from-google-cloud-next-2019/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TechCrunch 上的这篇文章&lt;/a&gt;来进一步了解。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;上游重要进展&#34;&gt;上游重要进展&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/900&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KEP: Rebase K8s images to distroless&lt;/a&gt;  Kubernetes 即将使用 gcr.io/distroless/static:latest 作为 K8s 核心镜像和 addon 镜像的统一 base 镜像。优势如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使得镜像体积更小，也更加安全。&lt;/li&gt;
&lt;li&gt;极大的减少冗余的 K8s image 的数量。&lt;/li&gt;
&lt;li&gt;通过对底层镜像的统一管理，可以使得 K8s image 更加安全（比如 CVE 的防护），更易于维护。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/906/files&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kustomize: Generator and Transformer Plugins&lt;/a&gt; 将 Kustomize 进行解耦，各项功能由各个 plugin 进行实现，现有的基础功能会作为内置插件。这意味着 Kubernetes 在向基于 Kustomize 的原生应用管理能力上又迈出了坚实的一步。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/830/files&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Port Troubleshooting Running Pods proposal to KEP&lt;/a&gt; 为 kubectl 添加一个 debug 命令，开发者可以用这个命令来和特定 pod 中的所有容器进行交互和访问。这里的关键设计，在于 Kubernetes 巧妙的利用了 sidecar 容器实现了对应用的非侵入式的 debug，非常值得学习。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/887/files&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keps: sig-node: initial pod overhead proposal&lt;/a&gt; 这个 KEP（Kubernetes Enhancement Proposal）设计了一套机制，使 Pod 能够对系统层面的 额外资源消耗（overhead）进行审计。这里的 overhead 主要包括以下两个部分。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;系统组件比如 kubelet，Docker, Linux Kernel，以及 Fluentd 等日志组件带来的 额外资源消耗&lt;/li&gt;
&lt;li&gt;沙箱容器运行时（Sandbox container runtime，比如 KataContainers）本身因为虚拟化和独立 Guest Kernel 所带来的额外的资源消耗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/enhancements/pull/909/files&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RuntimeClass scheduling] native scheduler support, ready to implement&lt;/a&gt; 在这个设计中，Kubernetes RuntimeClass 的信息会被 Kubernetes 直接转义成 Toleration/Taint 信息从而使用 Kubernetes 的默认调度器即可处理。这个设计实现后，Kubernetes 就有了根据应用的需求，自主选择使用 KataContainers 还是 Docker 来运行应用的能力，值得期待。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;开源项目推荐&#34;&gt;开源项目推荐&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/kubecost/introducing-kubecost-a-better-approach-to-kubernetes-cost-monitoring-b5450c3ae940&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubecost: 让你的 Kubernetes 服务花费一目了然&lt;/a&gt; 本周，我们强烈推荐你了解一下这个名叫 &lt;a href=&#34;https://github.com/kubecost&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubecost&lt;/a&gt; 的开源项目。它能够按照 Kubernetes 的原生 API 比如 Pod，Deployment，Service，Namespace 等概念逐层监控并详细的计算和展现出每一层上你的真实花费。更重要的是，无论你下层用的是 AWS 还是 GCP，Kubecost 内置的成本模型都可以应对自如。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本周阅读推荐&#34;&gt;本周阅读推荐&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;技术博文：&lt;a href=&#34;https://leebriggs.co.uk/blog/2019/04/13/the-fargate-illusion.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Fargate 幻象》&lt;/a&gt;by Lee Briggs。众所周知，Fargate 是 AWS 目前主推的容器实例服务产品。但是，Fargate 这种产品形态，是不是就是开发者想要的云产品的未来呢？本周，推荐你阅读一篇深入剖析 Fargate 服务的技术博文《Fargate 幻象》。这篇文章不仅能带你理解关于 Fargate 服务的方方面面，也能从一位开发者的角度，跟你聊聊作者眼中到底什么才是 Kubernetes 最具吸引力的“魔法”所在。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术博文：&lt;a href=&#34;https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-updated-april-2019-4a9886efe9c4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Benchmark results of Kubernetes netwokr plugins (CNI) over 10Gbit/s network》&lt;/a&gt;，by Alexis Ducastel。这个系列博客专注对 K8s 不同 CNI 网络插件的性能测试，上一篇博客发布于 2018 年 11 月，随着 K8s 1.14 的发布，作者对 up-to-date 的网络插件的性能重新进行了对比。对比的 CNI 包括：Calico v3.3，Canal v3.3，Cilium 1.3.0，Flannel 0.10.0，Kube-router 0.2.1，Romana 2.0.2，WeavNet 2.4.1；对比的内容包括安装难度（Installation）、安全、性能和资源消耗。测试结果不出意外的说明了没有一个 CNI 是所有方面的全能冠军，如何根据自身的需求选择合适的 CNI 方案？阅读这篇文章也需要可以给你很多启发。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术博文：&lt;a href=&#34;https://crate.io/a/infrastructure-as-code-part-one/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Infrastructure as Code, Part One》&lt;/a&gt;，by Emily Woods。Infrastructure as Code（IaC）是时下非常火热的概念，然而究竟什么是 IaC，谁应该去关心它，它能解决什么痛点，不同的人有不同的答案。这篇博客从一个常见的升级失败展开，讨论我们需要什么样的集群和应用管理方式，集群管理者和应用开发者究竟以什么样的方式共享知识才能更加高效的协作，并描述 IaC 的实践应该如何展开。这篇文章对每一个软件工程师都会有帮助。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术博文：&lt;a href=&#34;http://www.servicemesher.com/blog/data-plane-setup/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Istio Sidecar 注入过程解密》&lt;/a&gt;by Manish Chugtu，崔秀龙 译。Sidecar 模式是 Istio 项目工作的核心依赖，也是 Kubernetes 项目“容器设计模式”的最重要的一种。那么你是否会好奇，Istio 中 Istio Sidecar 注入到底是如何完成的呢？相信这篇精心翻译的博文一定能帮你一解究竟。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术博文：&lt;a href=&#34;http://www.servicemesher.com/blog/istio-cni-note/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Istio 学习笔记：Istio CNI 插件》&lt;/a&gt;by 陈鹏。当前实现将用户 Pod 流量转发到 proxy 的默认方式是使用 privileged 权限的 istio-init 这个 InitContainer 来做的（运行脚本写入 iptables），而 Istio CNI 插件的主要设计目标是消除这个 privileged 权限的 InitContainer，换成利用 k8s CNI 机制来实现相同功能的替代方案。你是否好奇过，这个改进到底是如何实现的？这篇文章，三言两语之间就能为你解释清楚。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
