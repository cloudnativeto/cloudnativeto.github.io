<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The New Stack | 云原生社区（中国）</title>
    <link>https://cloudnativecn.com/author/the-new-stack/</link>
      <atom:link href="https://cloudnativecn.com/author/the-new-stack/index.xml" rel="self" type="application/rss+xml" />
    <description>The New Stack</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://cloudnativecn.com/author/the-new-stack/avatar_hu17128050063926439810.png</url>
      <title>The New Stack</title>
      <link>https://cloudnativecn.com/author/the-new-stack/</link>
    </image>
    
    <item>
      <title>API 网关的自查清单：你的 API 前门有多坚固？</title>
      <link>https://cloudnativecn.com/blog/api-gateway-checklist-strength/</link>
      <pubDate>Tue, 29 Oct 2024 17:43:25 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/api-gateway-checklist-strength/</guid>
      <description>&lt;p&gt;每个 API 都需要一个前门，一个迎接请求与响应的门户。这个“门”不仅要坚固，能承受高流量的压力，最好还能过滤掉“蚊虫”——也就是潜在的威胁行为者和 DDoS 攻击。同时，一些额外的功能可以让整个体验更加愉快。&lt;/p&gt;
&lt;p&gt;API 网关便是你 API 的前门，它不仅仅负责流量的调度，还包括执行安全策略、优化性能等任务。然而，涉及大规模基础设施的决策总是难以把握，特别是当你已经开始构建新的 API，可能很难判断是否在正确的轨道上前行。&lt;/p&gt;
&lt;p&gt;受云原生计算基金会（CNCF）的 &lt;a href=&#34;https://maturitymodel.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生成熟度模型&lt;/a&gt; 启发，我试图帮助你从全局视角出发，客观评估 API 前门的当前状态，并了解接下来的优化方向。&lt;/p&gt;
&lt;h4 id=&#34;基础阶段打好地基&#34;&gt;基础阶段：打好地基&lt;/h4&gt;
&lt;p&gt;在这个阶段，你正处于 API 网关的 MVP 或预生产阶段，验证工具并分配各项责任，以便正式上线。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;决定 API 网关基础架构的基本形态（如云托管或本地部署），选择独立代理或通过 SDK 嵌入 API 网关功能，或者利用 Kubernetes 原生特性如 Gateway API。&lt;/li&gt;
&lt;li&gt;实施安全基本策略，从基本认证开始，逐步升级到 JSON Web Tokens（JWT）。&lt;/li&gt;
&lt;li&gt;设定速率限制和 IP 限制以防滥用。&lt;/li&gt;
&lt;li&gt;实施负载均衡，探索 DDoS 保护选项。&lt;/li&gt;
&lt;li&gt;利用 API 网关的功能来根据流量条件执行特定操作。&lt;/li&gt;
&lt;li&gt;制定 API 管理的基础政策，即便当前还未具备技术条件或专业人员来执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在构建过程中，请随时记录每项决策和实施如何影响开发周期。API 开发人员是否仍然能自由地构建？DevOps、基础设施和平台工程师是否拥有适当的工具来管理此平台？&lt;/p&gt;
&lt;p&gt;完成这些步骤后，你将拥有一个具备基本功能的 API 网关，能够顺利代理请求并具备初步的安全保护。&lt;/p&gt;
&lt;h4 id=&#34;运行阶段投入生产&#34;&gt;运行阶段：投入生产&lt;/h4&gt;
&lt;p&gt;当你的 MVP 完成测试，移至生产环境时，重点是集成、效率和为实时环境的挑战做好准备。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将 API 网关的配置和部署集成至 CI/CD 流程，进行安全和治理规则的集成测试。&lt;/li&gt;
&lt;li&gt;以代码形式管理所有 API 相关配置，以便进行版本控制、代码审查和质量保证。&lt;/li&gt;
&lt;li&gt;开始在多区域、多云和私有云环境中测试 API 网关，为未来扩展做准备。&lt;/li&gt;
&lt;li&gt;将 API 网关的安全、测试和操作任务提前至开发周期中，让 API 开发人员有更多控制权。&lt;/li&gt;
&lt;li&gt;为 API 的部署和操作编写详细的文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无论你处于此阶段的哪一步，都将受益于 API 网关对生产负载的自动化管理，并可利用早期的观测数据微调行为。如果效果不尽如人意，可能需要重新评估。&lt;/p&gt;
&lt;h4 id=&#34;扩展阶段准备增长&#34;&gt;扩展阶段：准备增长&lt;/h4&gt;
&lt;p&gt;此时，API 网关不再只是一个入口，而是你管理服务、区域、用户和高负载的核心工具。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用多区域和多云部署的经验提升性能和冗余性。&lt;/li&gt;
&lt;li&gt;为 API 网关和 API 服务构建或采用自动化故障切换机制。&lt;/li&gt;
&lt;li&gt;收集更多可观测数据，以便将流量、错误、请求和响应的趋势转化为可执行的数据。&lt;/li&gt;
&lt;li&gt;基于实际使用情况制定和实施高级流量策略，如精细的速率限制或细粒度访问控制。&lt;/li&gt;
&lt;li&gt;实施版本和弃用流程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下一个阶段？API 网关将不仅仅是一个工具，而是你团队快速、敏捷部署的核心支柱。&lt;/p&gt;
&lt;h4 id=&#34;改善阶段强化安全与治理&#34;&gt;改善阶段：强化安全与治理&lt;/h4&gt;
&lt;p&gt;这个阶段的重点在于精炼。你的 API 网关足够灵活和可扩展，但要保持持续发展，还需在不影响开发人员效率的情况下增加控制措施。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用允许 DevOps 和基础设施工程师集中管理安全的工具和工作流，同时让开发人员可以高效工作。Kubernetes Gateway API 是一个不错的例子，它基于角色进行配置。&lt;/li&gt;
&lt;li&gt;分析并优化 API 基础设施的整体成本。&lt;/li&gt;
&lt;li&gt;实现实时监控，以便向 API 的主要用户提供服务水平协议（SLA）。&lt;/li&gt;
&lt;li&gt;为开发人员提供自助开发环境，以测试 API 或网关的复杂场景或重大变更。&lt;/li&gt;
&lt;li&gt;精简 API 网关的工具和供应商。&lt;/li&gt;
&lt;li&gt;考虑使用 GitOps 等持续部署方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你几乎已经达成目标，但仍需不断努力。&lt;/p&gt;
&lt;h4 id=&#34;适应阶段回顾重建与再创新&#34;&gt;适应阶段：回顾、重建与再创新&lt;/h4&gt;
&lt;p&gt;此时，你不仅要应对 API 网关的现状，还要前瞻性地调整策略，保持领先地位。基于丰富的观测数据不断改进，同时还有更多工作要做。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过 API 网关测试套件实现质量控制，以减少缺陷和事故。&lt;/li&gt;
&lt;li&gt;将所有 API 发布和 API 网关配置更改迁移至 GitOps 工作流。&lt;/li&gt;
&lt;li&gt;启用蓝绿部署或金丝雀发布等高级部署技术。&lt;/li&gt;
&lt;li&gt;提供工具和培训，让 API 开发人员从开发的早期阶段便能实现和测试高级安全功能。&lt;/li&gt;
&lt;li&gt;创建自助环境，使开发人员能够在既定的安全范围内配置和管理 API 网关。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你已完成清单中的所有事项，恭喜你！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>如何通过修复 CNCF 项目治理问题实现社区共赢与商业化</title>
      <link>https://cloudnativecn.com/blog/how-to-fix-cncf-governance-and-create-business/</link>
      <pubDate>Wed, 23 Oct 2024 18:05:24 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/how-to-fix-cncf-governance-and-create-business/</guid>
      <description>&lt;p&gt;为什么我们的 OpenEBS 项目被归档了？我们是如何修复它的？以及通过修复它，我们如何创建了一个可持续的商业模式。&lt;/p&gt;
&lt;p&gt;当云原生计算基金会（CNCF）在 2024 年 2 月&lt;a href=&#34;https://thenewstack.io/openebs-lessons-we-learned-from-open-source/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;归档了我们的 OpenEBS 项目&lt;/a&gt;时，我们面临两个选择：放弃项目，或者解决发现的问题并重新申请进入 CNCF 的 Sandbox 项目，重新开始。重新开始是最困难的选择，但对于每月有 25,000 名用户加入的 &lt;a href=&#34;https://thenewstack.io/how-openebs-brings-container-attached-storage-to-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenEBS&lt;/a&gt; 来说，这是正确的做法。&lt;/p&gt;
&lt;p&gt;以下是 CNCF 归档我们项目的主要原因，我们是如何修复问题的，以及通过修复问题，我们是如何实现盈利的。&lt;/p&gt;
&lt;h2 id=&#34;所有权和控制问题&#34;&gt;所有权和控制问题&lt;/h2&gt;
&lt;p&gt;问题的核心是一个常见的治理问题。大约 60% 的 CNCF 项目都有一个企业赞助方——一个为项目提供资金的盈利公司。当公司将项目捐赠给 CNCF 时，项目就成为 CNCF 的财产，赞助公司放弃了对项目的所有权和控制权。&lt;/p&gt;
&lt;p&gt;但在项目尚未建立社区之前，赞助公司的员工通常仍在为该项目工作。许多 CEO 认为他们仍然拥有项目的所有权和控制权。“如果我的员工还在工作，那我就拥有决策权。”这种所有权和控制权的紧张关系导致了我们项目被归档，除非我们解决这个问题，否则问题将继续存在。&lt;/p&gt;
&lt;h2 id=&#34;通过赞助-cncf-项目盈利&#34;&gt;通过赞助 CNCF 项目盈利&lt;/h2&gt;
&lt;p&gt;我们向 CNCF 询问了如何解决这个问题。一个有用的 CNCF 资源是技术顾问组（TAG）贡献者策略治理工作组。联合主席 &lt;a href=&#34;https://github.com/jberkus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Josh Berkus&lt;/a&gt; 如此解释这个更广泛的问题和解决方案：“&lt;a href=&#34;https://thenewstack.io/20-years-in-open-source-resilience-failure-success/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;开源&lt;/a&gt;的前提是你可以获得大规模的用户采用，然后从这些采用者中的一小部分获取收入，这样的收入甚至可能与销售专有软件相当甚至更多。”&lt;/p&gt;
&lt;p&gt;当软件复杂且难以支持时（比如许多 Kubernetes 安装），这种方法效果特别好。&lt;/p&gt;
&lt;p&gt;对于 &lt;a href=&#34;https://thenewstack.io/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt; 来说，一种成功的商业化策略通常来自以下三种途径：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提供支持和专业服务&lt;/li&gt;
&lt;li&gt;提供带有行业认证或平台集成的专用发行版&lt;/li&gt;
&lt;li&gt;提供适用于大规模生产环境的附加产品（例如管理工具或报告工具）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对 Kubernetes 来说，“开放核心”模式不太常见，因为你必须不断决定哪些功能应该开放源码，哪些功能应该保留为专有版本，这重新引入了所有权和控制权的问题。&lt;/p&gt;
&lt;p&gt;假设大多数采用者不会为软件付费。如果他们必须付费，他们可能不会使用。这些采用者的生态系统有助于增强软件的稳定性，并为大规模采用带来的可信度提供支持。&lt;/p&gt;
&lt;p&gt;对于企业和大型组织来说，支付支持费用或使用专用发行版通常是一个有吸引力的选择，因为这可以缩短上市时间，降低风险，而这只是他们整个项目成本中的一小部分。&lt;/p&gt;
&lt;p&gt;这些策略被证明是有效的，对于我们来说，也提供了一个简单的解决方案，证明了继续赞助项目而不控制它是有利可图的。&lt;/p&gt;
&lt;h2 id=&#34;将所有权和控制权交给社区&#34;&gt;将所有权和控制权交给社区&lt;/h2&gt;
&lt;p&gt;为赞助公司找到一种不需要控制项目的盈利方法解决了一半的问题。但在赞助公司继续负责大部分维护人员和工程团队的情况下，所有权和控制权的紧张关系仍将继续存在。&lt;/p&gt;
&lt;p&gt;这时，Kubernetes 社区发挥了至关重要的作用。通过从项目的采用者用户群中招募维护人员和工程师，项目获得了额外的资源，赞助公司能够显著减少支持项目的成本（同时可以将部分工程师转移到其他附加产品上）。&lt;/p&gt;
&lt;p&gt;培养和维持一个社区需要付出努力；仅仅因为项目广泛采用并不意味着你会自动拥有一个社区。我们的团队必须努力做到包容和透明。我们需要花时间引导贡献者。我们还必须参与更广泛的 Kubernetes 社区，帮助其他人成功开发自己的项目。我们才刚刚开始，但已经看到了成效。&lt;/p&gt;
&lt;h2 id=&#34;结果&#34;&gt;结果&lt;/h2&gt;
&lt;p&gt;对于我们的项目，我们调整了商业化策略，现在我们有了支付支持和专业服务的客户。我们正在开始招募维护人员和工程师，并且发现有一个巨大的人才库可以帮助我们。&lt;/p&gt;
&lt;p&gt;赞助公司可以减少成本，同时看到项目的工程能力增加。通过放弃控制权和所有权，我们得到了很多回报。当我们完成时，这将真正成为一个社区的共同努力。&lt;/p&gt;
&lt;p&gt;Kubernetes 的创立基于这些原则——未来的基础设施不应该被任何人拥有或控制。我们将共同分享这个所有权和控制权。&lt;/p&gt;
&lt;p&gt;有时，这个过程可能会尴尬或痛苦。有时，你的项目会被归档，你必须重新开始工作。自由软件不是免费的——我们必须共同努力开发软件，建立围绕它的社区，保护它，有时我们甚至需要保护它不受我们自己的影响。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Weaveworks 倒闭：云原生行业的变革与挑战</title>
      <link>https://cloudnativecn.com/blog/end-of-an-era-weaveworks-closes-shop-amid-cloud-native-turbulence/</link>
      <pubDate>Wed, 07 Feb 2024 09:05:42 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/end-of-an-era-weaveworks-closes-shop-amid-cloud-native-turbulence/</guid>
      <description>&lt;p&gt;Weaveworks 的首席执行官兼联合创始人 Alexis Richardson 在 LinkedIn 上分享了公司关闭的沉重消息。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.weave.works/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Weaveworks&lt;/a&gt;，曾经在云原生容器管理领域是创新的先驱，如今宣布停止运营，这一举动反映了科技初创公司行业不稳定的本质。&lt;/p&gt;
&lt;p&gt;在周一发布的令人惊讶的&lt;a href=&#34;https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LinkedIn 帖子&lt;/a&gt;中，Weaveworks 首席执行官宣布公司即将停止运营。&lt;/p&gt;
&lt;p&gt;Weaveworks 的故事是一个典型的初创公司与市场动态和资金约束的潮起潮落的故事。尽管在 2023 年取得了两位数的增长，但公司面临着“波动”的销售和资金不足的局面，加剧了失败的收购谈判，这是许多初创公司都害怕但不可避免地会遇到的情况。&lt;/p&gt;
&lt;p&gt;成立于 2014 年，当时“云原生”这个词更多地是一个噱头而不是一个商业现实时，Weaveworks 立志于用他们的新概念&lt;a href=&#34;https://www.weave.works/technologies/gitops/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitOps&lt;/a&gt;来塑造未来的云基础设施管理。然而，尽管有着开拓精神和早期进入市场的优势，但该公司仍然与一个司空见惯的敌人搏斗：财务可持续性。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weaveworks/weave-gitops&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Weave GitOps&lt;/a&gt;是一个开源软件包，旨在简化从 Git 存储库到 Kubernetes 集群的连续交付（CD）过程中部署应用程序和更新的过程，对公司未来的光明有所期待。然而，这一切都成为了泡影。&lt;/p&gt;
&lt;p&gt;云原生领域的竞争在多年来不断加剧，竞争对手如&lt;a href=&#34;https://circleci.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CircleCI&lt;/a&gt;和&lt;a href=&#34;https://www.harness.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Harness Labs&lt;/a&gt;吸引了注意力和资金。Weaveworks 与这些资金更充裕的竞争对手的斗争凸显了初创公司生态系统的残酷现实，即单靠创新并不能保证成功。&lt;/p&gt;
&lt;p&gt;在其生命周期内，&lt;a href=&#34;https://www.crunchbase.com/organization/weaveworks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Weaveworks 筹集了超过 6100 万美元&lt;/a&gt;。但是，该公司 2020 年的最后一轮融资金额为 3600 万美元。这是不错的，但在风险投资界，四年已经是一段漫长的时间了。随着 2022 年经济的下滑，该公司 —— 像许多其他公司一样 —— 首先无法获得更多的投资，然后未能达成一项合并协议，这将为其提供前进的道路。&lt;/p&gt;
&lt;h2 id=&#34;短暂的科技&#34;&gt;短暂的科技&lt;/h2&gt;
&lt;p&gt;Richardson 的公告不仅是告别，也是对科技创业的暂时性提醒。他对公司的结局感到遗憾，但也指出了行业面临的更广泛挑战。这是许多初创公司都能够共鸣的情感，突显了即使是最有前景的企业在面对财务不稳定和市场饱和的现实时也可能失败。&lt;/p&gt;
&lt;p&gt;然而，Weaveworks 的遗产将永存。公司对开源社区的贡献，特别是通过&lt;a href=&#34;https://www.cncf.io/projects/flux/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Flux&lt;/a&gt;，证明了其致力于推动云原生技术发展的承诺。Richardson 希望 Flux 能够继续下去。&lt;/p&gt;
&lt;p&gt;“故事并没有就此结束 —— 我们的开源软件被广泛使用。我正在与几个大型组织合作，确保 CNCF Flux 处于最健康的状态，”Richardson 写道。&lt;/p&gt;
&lt;p&gt;在我们回顾 Weaveworks 的关闭时，很明显，科技生态系统既是机遇的乐土，也是耐力的战场。该公司的故事是对驱动科技行业向前发展的创业精神的感人提醒，即使在面对变革的必然性和商业运营的严酷现实时也是如此。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenTelemetry 的最新进展及其对可观测性的影响</title>
      <link>https://cloudnativecn.com/blog/why-the-latest-advances-in-opentelemetry-are-significant/</link>
      <pubDate>Fri, 12 Jan 2024 08:00:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/why-the-latest-advances-in-opentelemetry-are-significant/</guid>
      <description>&lt;p&gt;本文译自 &lt;a href=&#34;https://thenewstack.io/why-the-latest-advances-in-opentelemetry-are-significant/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why the Latest Advances in OpenTelemetry Are Significant&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;摘要：OpenTelemetry 是一个标准化观测性和遥测数据格式的项目，支持多种工具的互操作。本文介绍了该项目的新特性，如新的转换语言、日志支持和自动化修复能力。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;今年，在&lt;a href=&#34;https://cncf.io/?utm_content=inline-mention&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生计算基金会（Cloud Native Computing Foundation）&lt;/a&gt;中，一个备受关注的项目是&lt;a href=&#34;https://thenewstack.io/observability-in-2024-more-opentelemetry-less-confusion/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry&lt;/a&gt;和&lt;a href=&#34;https://thenewstack.io/how-the-opentelemetry-collector-scales-observability/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry Collector&lt;/a&gt;。这个项目是观测领域的一个非常令人兴奋的运动，旨在跨行业合作，达成观测和遥测的标准数据格式。&lt;/p&gt;
&lt;p&gt;这本身就非常重要，因为它允许多个观测和分析工具进行互操作，而以前的团队如果想要一个工具与另一个工具进行互操作，就必须多次转换数据。随着观测领域围绕人工智能/机器学习的炒作，公司更有可能从一个系统中存储和查看数据，然后在另一个系统中进行机器学习模型的训练。&lt;/p&gt;
&lt;p&gt;更棒的是，由于行业供应商和个人在&lt;a href=&#34;https://opentelemetry.io/docs/collector/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry Collector&lt;/a&gt;上合作，这个项目继续不断发展。它是一个标准化的代理和遥测收集器，提供高吞吐量的遥测数据收集和分析。该收集器已经支持跟踪和度量数据一段时间了，但直到去年的&lt;a href=&#34;https://thenewstack.io/kubeconcloudnativecon-2022-rolls-into-detroit/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KubeCon Detroit 2022&lt;/a&gt;，社区才吸纳了 OpenLogs 项目，并开始实施日志收集和分析功能。现在，日志支持已经完全成熟。&lt;/p&gt;
&lt;p&gt;在接下来的部分中，我将分享一些关于这个项目的新特性以及它们对社区的重要性。&lt;/p&gt;
&lt;h2 id=&#34;1-新的转换语言&#34;&gt;1. 新的转换语言&lt;/h2&gt;
&lt;p&gt;我发现许多代理的语法使得进行有意义的转换非常困难，需要使用一些奇怪的 YAML 或 TOML。Otel Collector 仍然依赖于 YAML 格式，但它的新转换语言允许使用基于函数的语句，执行起来非常快速，可以管理复杂性。查看一些&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;语法示例&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;2-日志正式发布&#34;&gt;2. 日志正式发布&lt;/h2&gt;
&lt;p&gt;在大约一年的开发时间内，日志收集和分析现在已经正式发布。该实施有一些收集日志的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，它作为一个独立的代理运行，并从文件系统收集日志。它可以直接发送到最终目的地，也可以转发到以收集器模式运行的 OpenTelemetry Collector，可以即时计算日志指标。&lt;/li&gt;
&lt;li&gt;其次，存在许多日志 SDK，可以直接在应用程序中实施，并将日志发送到中央收集器或直接发送到最终目的地，这有助于减少磁盘 IO 的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-自动仪器成熟度&#34;&gt;3. 自动仪器成熟度&lt;/h2&gt;
&lt;p&gt;自动仪器是自动将应用程序连接到发出跟踪和度量数据而无需或仅需进行最少代码更改的能力。Java 和.Net 得到了全面支持，其他语言正处于不同开发和发布阶段。这个功能是一些专有解决方案展示出来的特色，因为它通过减少开发人员的时间来降低部署复杂性，现在它将同样强大的功能带到了 OpenTelemetry 生态系统中。&lt;/p&gt;
&lt;h2 id=&#34;4-语义约定&#34;&gt;4. 语义约定&lt;/h2&gt;
&lt;p&gt;这一点非常重要，并且正在从 ElasticSearch 向 OpenTelemetry 项目捐赠 ECS（Elastic Common Schema）而受益。规范化日志和遥测结构具有挑战性，因为似乎几乎每个人都以稍微不同的格式生成遥测数据；但要能够分析、创建警报并以人性化的方式呈现数据，所有遥测字段都需要以某种方式映射。如果每个人和每个系统都略有不同，那么在创建可重用的仪表板和组件方面就会出现挑战。现在，软件供应商可以负责在多个平台上创建仪表板，合理地确保数据将以多个平台上的正确格式进行发送。与此同时，我们管理大量遥测数据的人可以通过使用众所周知的字段名称来提高摄取和查询效率，并且在大多数客户发送的内容依赖于这些字段名称时，可以提供更高级的功能，同时减少计算资源和内存开销。&lt;/p&gt;
&lt;p&gt;完整的架构仍然需要一段时间才能最终确定，但逐步正在批准这些约定。例如，在 KubeCon 上，他们宣布了 HTTP 架构的最终确定。&lt;/p&gt;
&lt;h2 id=&#34;5-插件框架和生态系统&#34;&gt;5. 插件框架和生态系统&lt;/h2&gt;
&lt;p&gt;生态系统正在不断成熟。可扩展性框架允许自定义任何摄取管道&lt;/p&gt;
&lt;p&gt;的任何阶段。有越来越多的接收器用于各种系统，处理器具有越来越先进的功能，目标也在增加。我特别对新版本的 OpenSearch 扩展感到兴奋，它可以发送预打包在简化的遥测或 ECS 格式中的日志数据。&lt;/p&gt;
&lt;p&gt;从开发者的角度来看，我发现模式和内部“p”消息模式的结构非常周到，内置了 protobuf。它在功能自由度和最小复杂度之间有一个良好的平衡。&lt;/p&gt;
&lt;h2 id=&#34;6-社区合作&#34;&gt;6. 社区合作&lt;/h2&gt;
&lt;p&gt;这对于 CNCF 社区来说并不是很新鲜，但这个项目的速度和影响体现了 CNCF 社区哲学的精神。竞争公司正在共同努力，使计算的一部分变得更好、更容易，以造福我们其他人。有些人可能担心去除供应商锁定会导致客户离开，或者共享代码可能泄漏专有 IP。&lt;/p&gt;
&lt;p&gt;然而，在遥测领域，代理和收集器的核心架构通常是已解决的问题。那么为什么不制作一些遵循惯例并在各个平台上运行的东西，以便公司不再必须维护代理代码，其中 80% 都是重复的呢？这使公司可以在互操作性和创新可以通过这个框架传递的专有处理器方面共同开发插件。好处也延伸到所有运营商和软件供应商。借助标准化的 Otel Collector SDK，供应商可以创建一个单一的集成来为其应用程序添加遥测，并极大简化了收集过程，试图让所有主要的观测提供商为你的应用程序实施支持。&lt;/p&gt;
&lt;p&gt;运营商也从“随处收集”和“随处发送”的理念中受益。通过标准的配置文件格式简化了设置，减少了新系统的引入复杂性。我还怀疑，许多日志系统的运营商在观测数据的语义约定项目减少了许多问题后，将大大减少字段映射的基数问题。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;向所有项目贡献者和社区成员表示衷心的“感谢”！这里有太多人要列出来了，但你可以在&lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/community-members.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub 上的 OpenTelemetry 项目&lt;/a&gt;上找到他们。&lt;/p&gt;
&lt;p&gt;OpenTelemetry 和 OpenTelemetry Collector 的功能和未来路径正在以极快的速度前进，过去一年是 CNCF 组合中贡献第二多的项目，仅次于 Kubernetes。有这么多贡献者保持组织和合作，成熟度将继续加速。这将有望通过增加互操作性并简化仪表系统的仪器化过程来促进观测领域的创新。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenTelemetry 与可观测性：展望未来</title>
      <link>https://cloudnativecn.com/blog/opentelemetry-and-observability-looking-forward/</link>
      <pubDate>Tue, 02 Jan 2024 08:00:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/opentelemetry-and-observability-looking-forward/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/opentelemetry-and-observability-looking-forward/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry and Observability: Looking Forward&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;让我们探讨一些令人兴奋的趋势，考虑到我们期待 2024 年会有什么样的可观测性发展。&lt;/p&gt;
&lt;p&gt;随着年底的临近，现在是一个停下来思考的好时机。2023 年对于 OpenTelemetry 来说是一个里程碑，因为其三个基本信号，跟踪、度量和日志，都达到了稳定版本。这一成就标志着&lt;a href=&#34;https://thenewstack.io/opentelemetry-gaining-traction-from-companies-and-vendors/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry&lt;/a&gt;最初愿景的实现，即提供一个基于标准的框架，用于仪器化和收集可观测性数据。&lt;/p&gt;
&lt;p&gt;让我们抓住这个机会，探讨一下我们所见证的一些令人兴奋的趋势，深入研究创新的产品和用例，并在期待 2024 年的到来时深思熟虑地考虑可观测性的不断演变。&lt;/p&gt;
&lt;h2 id=&#34;度量标准的崭露头角&#34;&gt;度量标准的崭露头角&lt;/h2&gt;
&lt;p&gt;尽管 OpenTelemetry 关于度量的规范在 2022 年 5 月被宣布为稳定版本，但今年看到了其被广泛采用。以下是一些从业者的文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由 VMware 的 Matthew Kocher 和 Carson Long 撰写的文章，标题为“&lt;a href=&#34;https://opentelemetry.io/blog/2023/cloud-foundry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;体验报告：在 Cloud Foundry 中采用 OpenTelemetry 进行度量&lt;/a&gt;”。&lt;/li&gt;
&lt;li&gt;我们自己的 Matheus Nogueira 撰写的文章，标题为“&lt;a href=&#34;https://tracetest.io/blog/adding-opentelemetry-metrics-in-your-go-app&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在你的 Go 应用程序中添加 OpenTelemetry 度量&lt;/a&gt;”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;展望 2024 年，可以预期会看到类似的日志运动和采用。&lt;/p&gt;
&lt;h2 id=&#34;关注在负载测试中使用分布式跟踪&#34;&gt;关注在负载测试中使用分布式跟踪&lt;/h2&gt;
&lt;p&gt;2023 年，两个领先的负载测试工具，&lt;a href=&#34;https://k6.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Grafana k6&lt;/a&gt;和&lt;a href=&#34;https://artillery.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Artillery.io&lt;/a&gt;，都添加了对 OpenTelemetry 的支持。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grafana k6 &lt;a href=&#34;https://github.com/grafana/xk6-distributed-tracing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;引入了跟踪&lt;/a&gt;功能，使性能工程师能够在&lt;a href=&#34;https://thenewstack.io/trace-based-testing-the-next-step-in-observability/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;负载测试&lt;/a&gt;期间识别系统瓶颈或故障。&lt;/li&gt;
&lt;li&gt;Artillery.io 随后也&lt;a href=&#34;https://www.artillery.io/blog/introducing-opentelemetry-support&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;添加了度量和分布式跟踪&lt;/a&gt;，提供了对系统性能更详细的分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tracetest 利用了 k6 测试中暴露的功能，以&lt;a href=&#34;https://docs.tracetest.io/tools-and-integrations/k6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;启用基于跟踪的负载测试&lt;/a&gt;，在运行测试时进行深入的断言。我们已经看到许多客户广泛使用了这个功能，比如&lt;a href=&#34;https://tracetest.io/case-studies/how-sigma-software-built-load-testing-for-their-microservices-with-k6-tracetest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sigma Software&lt;/a&gt;。在 2024 年，Tracetest 团队将考虑将这一能力添加到&lt;a href=&#34;http://artillery.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Artillery.io&lt;/a&gt;和其他负载测试工具中。&lt;/p&gt;
&lt;h2 id=&#34;opentelemetry-的支持和用例扩展&#34;&gt;OpenTelemetry 的支持和用例扩展&lt;/h2&gt;
&lt;p&gt;越来越多的供应商正在采用 OpenTelemetry 标准，以支持典型但非常重要的遥测数据分析之外的行动。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一些公司，比如&lt;a href=&#34;https://opentelemetry.io/blog/2023/tyk-api-gateway/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tyk 正在仪器化其 API 网关，以原生支持 OpenTelemetry&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;终端用户正在发现 OpenTelemetry 的新用例，比如&lt;a href=&#34;https://thenewstack.io/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用分布式跟踪来观察你的 CI/CD 流水线&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tracetest.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tracetest&lt;/a&gt;利用分布式跟踪数据进行集成和端到端测试。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;强调-opentelemetry-收集器&#34;&gt;强调 OpenTelemetry 收集器&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/how-adobe-uses-opentelemetry-collector/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry 收集器&lt;/a&gt;位于 OpenTelemetry 世界的中心，接收来自应用程序的信号，处理和转换这些信号，然后将它们导出到任意数量的后端系统。随着对 OpenTelemetry 的集成和供应商支持的扩展，对这个集中式收集器的需求和要求也在增加。&lt;/p&gt;
&lt;p&gt;2023 年引入了 OpenTelemetry Transformation Language (OTTL)，增强了 OpenTelemetry 收集器处理和转换传入信号的能力。&lt;/p&gt;
&lt;p&gt;在 Tracetest 中，我们能够利用&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/filterprocessor/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在过滤器处理器中使用 OTTL&lt;/a&gt;的能力，改进了我们从输出大量遥测数据的生产环境中收集跟踪数据的方式。这一变化对&lt;a href=&#34;https://tracetest.io/blog/opentelemetry-collectors-new-filter-processor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry 收集器的过滤器处理器&lt;/a&gt;使 Tracetest 适用于在高负载环境中运行测试，包括生产环境。&lt;/p&gt;
&lt;h2 id=&#34;无处不在的可观测性&#34;&gt;无处不在的可观测性&lt;/h2&gt;
&lt;p&gt;在最近的讨论中，我们发现了一种客户中不断增长的趋势，即“无处不在的可观测性”方法。这些公司不仅限于由网站可靠性工程师和 DevOps 传统使用，还包括了每个人，包括开发人员和测试人员，参与到可观测性中。这种转变重新定义&lt;/p&gt;
&lt;p&gt;了可观测性，使其从生产问题的一种反应性工具变成了在开发和测试中都有益的一种主动工具。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.honeycomb.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Honeycomb&lt;/a&gt;强调了&lt;a href=&#34;https://www.honeycomb.io/blog/observability-driven-development&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在开发过程中使用可观测性&lt;/a&gt;，而像&lt;a href=&#34;http://digma.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Digma.ai&lt;/a&gt;和 Tracetest 这样的工具正在推动这一前进。&lt;/p&gt;
&lt;h2 id=&#34;浏览器&#34;&gt;浏览器&lt;/h2&gt;
&lt;p&gt;OpenTelemetry 的主要作用一直局限于仪器化后端系统，而基于开放标准的浏览器仪器化仍然是实验性的，进展缓慢。正在努力改进和标准化这种仪器化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tracetest.io/case-studies/how-uzufly-built-end-to-end-testing-serverless-web-app-with-distributed-traces&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Uzufly&lt;/a&gt;在这方面脱颖而出。它使用现有的客户端仪器化来构建测试。展望未来，它的雄心是扩展基于跟踪的测试，以覆盖浏览器内部发起的前端操作所进行的测试。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这将实现前端和后端的全面端到端测试。请关注 2024 年更多关于这个主题的信息！&lt;/p&gt;
&lt;h2 id=&#34;2023-已经过去&#34;&gt;2023 已经过去&lt;/h2&gt;
&lt;p&gt;告别 2023，我们怀着热情期待 2024 年的到来。OpenTelemetry 具有势头，得到了标准和广泛采用的支持，推动了其增长。新的一年承诺带来令人兴奋的发展，围绕 OpenTelemetry 出现了创新的产品和用例。我迫不及待地想看到 2024 年将揭示的进步和创新。愿 OpenTelemetry 长存！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2024 年 API 管理趋势预测</title>
      <link>https://cloudnativecn.com/blog/what-will-be-the-api-management-trends-for-2024/</link>
      <pubDate>Mon, 01 Jan 2024 11:00:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/what-will-be-the-api-management-trends-for-2024/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/what-will-be-the-api-management-trends-for-2024/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What Will Be the API Management Trends for 2024?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们已经审视了 2023 年的发展，并确定了几个可能在明年主导 API 管理领域的关键趋势。&lt;/p&gt;
&lt;p&gt;根据一个想法：API 完全控制了数字世界，预测到本十年结束时，API 管理市场将增长六倍。&lt;/p&gt;
&lt;p&gt;随着越来越多的公司转向 API 为先的架构，API 管理的需求变得至关重要。一家组织可能会管理数百甚至数千个微服务，它们需要工具来有效地编排和监控这些 API。&lt;/p&gt;
&lt;p&gt;因此，随着这种增长的开始，API 管理在未来会带来什么？我们已经审视了 2023 年的发展，并确定了几个可能在 2024 年主导 API 管理领域的关键趋势。&lt;/p&gt;
&lt;h2 id=&#34;是时候实行零信任了这并不是坏事&#34;&gt;是时候实行零信任了（这并不是坏事！）&lt;/h2&gt;
&lt;p&gt;随着 API 的不断增加，安全漏洞、黑客和 API 问题的风险也在增加。将零信任安全概念与你的 API 战略结合起来，倡导一种安全模型，其中不管交互发生在网络边界内还是外部，都不会假定信任。&lt;/p&gt;
&lt;p&gt;这种方法要求对每个试图访问网络内资源的个人和设备进行严格的身份验证，有效地消除了传统的受信任的内部网络概念。在数据泄露和恶意行为者变得越来越复杂的时代，采用零信任框架对于全面的安全至关重要，包括 API、云服务和网络基础设施在内的所有技术方面。&lt;/p&gt;
&lt;p&gt;在 API 管理领域，API 网关在实施零信任架构中起着关键作用。作为第一道防线，这些网关对每个 API 请求执行严格的身份验证和授权策略。它们负责验证凭据，管理访问令牌，并确保每个请求，无论来自组织内部还是外部，都要经过相同严格的安全检查。&lt;/p&gt;
&lt;p&gt;在这个框架中，API 网关不仅仅是流量管理器；它们是安全姿态的一部分，将零信任原则嵌入到 API 交互的核心。它们帮助构建适应持续风险评估、基于上下文的访问控制和深度监控 API 使用模式的动态安全策略。&lt;/p&gt;
&lt;p&gt;在零信任模型中，API 网关演变为安全执行者，对流经 API 的数据的完整性和机密性至关重要。这种演变强调了高级 API 管理工具在维护零信任原则和确保安全和弹性基础设施方面的重要性。&lt;/p&gt;
&lt;h2 id=&#34;多体验架构将成为常态&#34;&gt;“多体验架构”将成为常态&lt;/h2&gt;
&lt;p&gt;随着 2024 年 Gartner 的“多体验架构”概念变得越来越普遍，API 管理的复杂性将升级。组织不再只处理一种类型的 API；他们在同一应用生态系统中处理多种协议和架构。这种情况是现代应用多样性的结果，这些应用不仅包括基于 Web 的门户和本机移动应用，还包括扩展，如手表应用、实时对话界面和人工智能集成。&lt;/p&gt;
&lt;p&gt;每个组件都需要特定的 API 方法。通常情况下，REST API 在外部通信中因其简单性和通用性而受欢迎，而 gRPC 由于其效率和速度而可能被选择用于内部服务通信。与此同时，GraphQL 因其创建联合图和子图的能力而越来越多地用于高度灵活和高效的数据检索，这对于复杂的客户端应用程序是必不可少的。此外，消息代理对于实现需要立即数据更新和交互的应用程序的实时通信至关重要。&lt;/p&gt;
&lt;p&gt;在这种环境下，API 管理的挑战是多方面的。它涉及编排不同类型的 API 并确保在这些不同的架构中实现无缝集成、一致的安全执行和有效的性能监控。解决方案在于高级 API 管理工具和网关，它们能够处理这种多样性。这些工具必须提供复杂的功能，如协议转换、统一的安全策略和可以适应每种 API 类型的独特需求的分析。&lt;/p&gt;
&lt;p&gt;因此，2024 年的 API 管理将涉及到拥抱和管理这种复杂性，提供一个有凝聚力和高效率的框架，支持多体验架构的各种需求。&lt;/p&gt;
&lt;h2 id=&#34;api-管理正在变成组织管理&#34;&gt;API 管理正在变成组织管理&lt;/h2&gt;
&lt;p&gt;有一个著名的故事，来自前亚马逊和谷歌工程师 Steve Yegge，讲述了 Jeff Bezos 在 2002 年在亚马逊网络服务（AWS）制定的一项核心任务：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;所有团队将通过服务接口公开其数据和功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;团队必须通过这些接口相互通信。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不允许其他形式的进程间通信：不允许直接链接，不允许直接读取另一个团队的数据存储，不允许共享内存模型，也不允许任何后门。唯一允许的通信是通过网络上的服务接口调用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;无论他们使用什么技术。HTTP、Corba、Pubsub、自定义协议——都无所谓。贝佐斯不关心。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有服务接口，没有例外，必须从头开始设计，以便能够将接口暴露给外部世界的开发人员。不允许例外。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不这样做的人将被解雇。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;贝佐斯正在为亚马逊的面向服务的体系结构打下基础。二十二年后，这一框架在技术领域普及。这意味着 API 管理实际上是团队在组织内部进行通信和操作的方式。&lt;/p&gt;
&lt;p&gt;API 已经成为组织过程的生命线，代表了从孤立的功能到集成系统的转变。这种转变将 API 管理从技术任务转变为组织领导的核心方面。这带来了几个具体的变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;战略对齐&lt;/strong&gt;。API 管理与业务战略密切对齐。它涉及理解 API 如何能够实现业务目标，如进入新市场、提升客户体验或简化运营。这种战略对齐要求 API 倡议与组织的方向和目标同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨职能合作&lt;/strong&gt;。API 不再仅仅是 IT 部门的责任。它们需要跨各种功能领域的合作，包括营销、销售、客户服务和业务发展。这种合作确保 API 以支持多样化的组织需求和机会的方式开发和管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;将 API 作为产品的思维方式&lt;/strong&gt;。API 越来越被视为产品，有专门的团队负责它们的生命周期，从构思到淘汰。这种方法涉及定期更新、用户反馈集成和持续改进，就像公司提供的任何其他产品或服务一样。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能指标和分析&lt;/strong&gt;。API 的成功不仅通过技术性能来衡量，还通过其对业务结果的影响来衡量。诸如 API 使用趋势、用户参与度和对收入增长的贡献等指标成为 API 有效性的重要指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，API 的管理不再仅仅关于技术规范或协议，而是关于管理信息分享和服务交付的方式，跨整个组织。这种方法促进了敏捷性、可扩展性和创新，这在今天不断发展的技术领域中是必不可少的。&lt;/p&gt;
&lt;h2 id=&#34;gitops-已经在-api-中使用&#34;&gt;GitOps 已经在 API 中使用&lt;/h2&gt;
&lt;p&gt;将 GitOps 集成到 API 管理中标志着 API 是如何更高效、透明和可靠地开发、部署和维护的一种显著转变。GitOps 是一种将 git 的版本控制原则应用于操作工作流程的方法，对于以更高效、透明和可靠的方式管理 API 的生命周期至关重要。&lt;/p&gt;
&lt;p&gt;在这个框架中，API 的每个方面，从其设计文档和配置到代码和部署清单，都存储在 git 存储库中。这种方法确保了整个 API 生命周期都受到版本控制，允许详细跟踪更改，以及在出现问题时轻松回滚，增强了团队成员之间的协作。&lt;/p&gt;
&lt;p&gt;自动化部署流程是使用 GitOps 管理 API 的一个关键优势。通过利用 git 作为唯一的真相来源，可以设置自动化流水线，以在提交更改时部署 API。这种自动化不仅限于简单的部署，还包括配置和策略的更新，确保 API 的所有方面都得到一致和可靠的更新。团队可以创建与 GitOps 工作流程直接集成的分散的声明性工作流，用于复杂的自定义配置。&lt;/p&gt;
&lt;p&gt;GitOps 还为 API 管理带来了更高级别的安全性。关于更改的拉取请求鼓励同行审查和批准，为引入修改提供了更健壮的流程。此外，git 存储库的不可变性增加了额外的安全性层，因为每个更改都是被跟踪和可审计的。&lt;/p&gt;
&lt;p&gt;GitOps 有望通过引入版本控制、自动化、安全和协作原则来改变 API 管理，从而使 API 开发和管理更加与现代敏捷实践相符，提高了效率和可靠性。&lt;/p&gt;
&lt;h2 id=&#34;开发者体验将成为标配&#34;&gt;开发者体验将成为标配&lt;/h2&gt;
&lt;p&gt;在 2024 年，提供卓越的开发者体验（DevX）将不再是奢侈；它将成为一项必需。未将 DevX 置于优先位置的 API 管理系统越来越有被淘汰的风险，因为以开发者为中心的模式正在成为标准。&lt;/p&gt;
&lt;p&gt;这一变革的基石在于认识到开发者需要与其工作流程相一致并增强生产力的工具和系统。这其中的一个关键方面是采用&lt;a href=&#34;https://thenewstack.io/why-use-infrastructure-as-code/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;基础设施即代码&lt;/a&gt;（IaC）实践。IaC 允许开发者通过代码而不是手动流程来管理和配置基础设施。&lt;/p&gt;
&lt;p&gt;另一个关键因素是 API 管理系统支持各种部署环境的能力。随着部署模型的多样化，从本地部署到&lt;a href=&#34;https://www.getambassador.io/kubernetes-glossary/cloud-native&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生&lt;/a&gt;等，一个灵活的 API 管理解决方案，能够适应不同的环境至关重要。&lt;/p&gt;
&lt;p&gt;API 管理系统必须不断发展，以满足现代软件开发实践的需求。未能提供以开发者为中心的体验的系统，其特点包括 IaC、与标准工具的集成、易用性、灵活性和强大的分析功能，将在开发者体验至关重要的环境中难以保持相关性。&lt;/p&gt;
&lt;h2 id=&#34;捆绑随后的解绑&#34;&gt;捆绑随后的解绑&lt;/h2&gt;
&lt;p&gt;API 管理工具的演变正在见证回归到捆绑解决方案，这是与最近的点对点解决方案的趋势相反。与旧的企业捆绑解决方案不同，这些新一代捆绑解决方案适用于更广泛的组织范围，提供了综合的、集成的解决方案。&lt;/p&gt;
&lt;p&gt;API 生态系统的不断复杂和规模的增加推动了这一转变。现代 API 管理需要一种全面的方法，包括强大的身份验证机制、严格的安全协议和自助开发者工具。通过将这些功能整合到&lt;a href=&#34;https://www.getambassador.io/products/edge-stack/api-gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;单一的、连贯的包中&lt;/a&gt;，捆绑解决方案提供了一种更简化和高效的 API 管理方式。&lt;/p&gt;
&lt;p&gt;在这些捆绑解决方案中包括网关对于流量管理至关重要，提供了速率限制、请求路由和协议转换等功能。身份验证是另一个关键组成部分，确保通过 OAuth 和 JSON Web Tokens（JWT）等机制安全访问 API。这些捆绑解决方案中的安全功能不仅限于身份验证，还提供了全面的保护，防止 SQL 注入、DDoS 攻击和数据泄露等威胁。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.getambassador.io/products/telepresence&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自助开发者工具&lt;/a&gt;是这些捆绑解决方案的重要组成部分。它们赋予开发者独立创建、测试和部署 API 的能力，减少了对 IT 团队的依赖，加速了开发。这些工具必须包括用户友好的界面、详细的文档和自动化的测试功能。&lt;/p&gt;
&lt;p&gt;API 管理中捆绑解决方案的再次出现代表着对现代 API 景观需求的适应。通过在一个统一的包中提供网关、身份验证、安全和开发者工具，这些捆绑解决方案提供了适用于各种组织需求的多功能和高效的解决方案。&lt;/p&gt;
&lt;h2 id=&#34;未知的人工智能&#34;&gt;未知的人工智能&lt;/h2&gt;
&lt;p&gt;人工智能正在颠覆数十个行业的规则，并以意想不到的方式重塑它们。&lt;/p&gt;
&lt;p&gt;“意想不到”是描述人工智能/机器学习技术将如何扰乱 API 管理生态系统的好方式。KubeCon North America 2023 与 OpenAI Dev Day 同时举行，但两者似乎天差地别。在 KubeCon 上，AI 只轻微&lt;a href=&#34;https://danielbryantuk.medium.com/kubecon-chicago-key-takeaways-3de5ca13b375&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;提及&lt;/a&gt;，似乎 DevOps 和 API 管理行业对人工智能没有太多（尚未！）言论。&lt;/p&gt;
&lt;p&gt;但是，将 AI 排除在外将严重低估 AI 发展的范围和速度。去年这个时候，ChatGPT 才两周大。那时没有人知道它将如何彻底改变技术的各个方面。&lt;/p&gt;
&lt;p&gt;因此，AI/机器学习与 API 战略的融合是不可避免的，可能会彻底改变 API 的开发、管理和优化方式。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI 驱动的分析可以提供对 API 使用模式的更深入洞察，从而实现更有效的资源管理和优化。&lt;/li&gt;
&lt;li&gt;AI 可以自动化和增强安全协议，比传统方法更有效地检测异常和潜在威胁。&lt;/li&gt;
&lt;li&gt;AI 可以显着简化 API 开发过程。通过使用机器学习算法，API 可以变得更加自适应和智能，能够以更高的准确性和效率处理复杂请求。这种集成可能导致自我优化的 API，根据实时反馈调整其行为。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AI 与 API 管理的交汇是即将到来的现实。随着 AI 继续渗透各个领域，其融入 API 生态系统将提供前所未有的效率、安全性和适应性水平，宣告了 API 管理和使用方式的新时代。&lt;/p&gt;
&lt;h2 id=&#34;未知的未知&#34;&gt;未知的未知&lt;/h2&gt;
&lt;p&gt;还有什么在未来？随着技术进步的极速和 API 已经吞噬了整个世界的方式，预测 API 管理的未来就像试图绘制未知领域一样困难。&lt;/p&gt;
&lt;p&gt;这个领域正在迅速发展，受新兴技术和 Paradigm 转变的推动，这使得难以预见未来的变化的全部范围。就像 API 已经改变了数字基础设施一样，未来的创新和方法将进一步重新定义我们今天对 API 管理的理解。&lt;/p&gt;
&lt;p&gt;请告诉我们你认为 2024 年将为 API 管理带来什么，以及你认为明年我们将使用什么令人兴奋的技术。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>给初学生成式 AI（GenAI）的开发人员的 7 条最佳实践</title>
      <link>https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/</link>
      <pubDate>Wed, 20 Dec 2023 11:30:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/</guid>
      <description>&lt;h2 id=&#34;编者按&#34;&gt;编者按&lt;/h2&gt;
&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/7-best-practices-for-developers-getting-started-with-genai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/7-best-practices-for-developers-getting-started-with-genai/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;编辑评论：这是一篇非常有价值的文章，向开发者展示了生成式 AI 的潜力和应用。生成式 AI 是一种利用大型语言模型来生成和转换文本的技术，它可以帮助开发者解决一些复杂的问题，如代码生成，文档编写，内容创作等。生成式 AI 也是一种云原生的技术，它需要大量的计算资源和数据，以及高效的部署和管理方式。文章提供了一些实用的工具和平台，如 GitHub Copilot，Bard，ChatGPT 等，让开发者可以轻松地尝试和使用生成式 AI。文章还给出了一些注意事项和建议，如保护数据隐私，验证输出质量，避免滥用等，让开发者可以负责任地使用生成式 AI。我认为这篇文章是一个很好的入门指南，让开发者可以了解和利用生成式 AI 来打造创新的云原生应用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文&lt;/h2&gt;
&lt;p&gt;通过一点经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习任何新技术一样，最好的方法就是动手实践。&lt;/p&gt;
&lt;p&gt;随着可访问的生成式人工智能进入主流，以及由此产生的通过简单语言转化整个人类知识的能力，每个企业都在竭力将人工智能整合到其技术体系中。对于开发人员来说，压力很大，但也有着令人兴奋的无限可能性。&lt;/p&gt;
&lt;p&gt;如果你有一些经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习自 HTML 诞生以来的每一项新技术一样。让我们看看你可以采取的七个步骤，以开始建立 GenAI 的基础，并最终逐步发展成一个完全运作、可扩展的应用程序。&lt;/p&gt;
&lt;h2 id=&#34;1-玩转现有的-genai-工具&#34;&gt;1. 玩转现有的 GenAI 工具&lt;/h2&gt;
&lt;p&gt;入门 GenAI 的最佳方法是实践，而且门槛非常低。市场上现在有许多免费选项，比如 Bard、ChatGPT、Bing 和 Anthropic，有很多可以学习的选择。&lt;/p&gt;
&lt;p&gt;尝试使用 GenAI 工具和代码生成解决方案进行实验（并鼓励你的团队进行实验），例如&lt;a href=&#34;https://github.com/features/copilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Copilot&lt;/a&gt;，它集成到每个流行的 IDE 中，充当一对程序员。Copilot 提供程序员建议，帮助解决代码问题，并生成整个函数，使学习和适应&lt;a href=&#34;https://us.resources.cio.com/resources/the-data-streaming-platform-key-to-ai-initiatives-4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GenAI&lt;/a&gt;变得更快更容易。&lt;/p&gt;
&lt;p&gt;当你首次使用这些现成的工具时，要小心使用专有或敏感的公司数据，即使只是提供给工具一个提示也要小心。Gen AI 供应商可能会存储并使用你的数据用于将来的训练运行，这是公司数据政策和信息安全协议的重大违规行为。确保你及时直接地向你的团队传达这一黄金规则。&lt;/p&gt;
&lt;h2 id=&#34;2-了解从-genai-中可以获得什么&#34;&gt;2. 了解从 GenAI 中可以获得什么&lt;/h2&gt;
&lt;p&gt;一旦你开始尝试 GenAI，你将很快了解到不同提示会产生什么类型的输出。大多数 GenAI 工具可以生成各种格式的文本，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;生成&lt;/strong&gt;新的故事、想法、文章或任意长度的文本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转换&lt;/strong&gt;现有文本为不同格式，如 JSON、Markdown 或 CSV。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;翻译&lt;/strong&gt;文本成不同语言。&lt;/li&gt;
&lt;li&gt;以聊天的方式&lt;strong&gt;对话&lt;/strong&gt;来回。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;审查&lt;/strong&gt;文本以展示特定元素。&lt;/li&gt;
&lt;li&gt;将长篇内容&lt;strong&gt;汇总&lt;/strong&gt;以获取洞察。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分析&lt;/strong&gt;文本的情感。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;任何人都可以生成这些类型的生成文本结果，无需编程技能。只需键入提示，文本就会产生。然而，大型语言模型（LLM）经过的培训越多，即它摄取的语言碎片越多，随着时间的推移，它在生成、更改和分析文本方面就会变得更加准确。&lt;/p&gt;
&lt;h2 id=&#34;3-学习提示工程&#34;&gt;3. 学习提示工程&lt;/h2&gt;
&lt;p&gt;部署 GenAI 的良好方法之一是掌握编写提示的技巧，这既是一门艺术又是一门科学。虽然提示工程师是一个实际的职位描述，但它也是任何希望提高他们使用 AI 的人的好绰号。优秀的提示工程师知道如何开发、完善和优化文本提示，以获得最佳结果并提高整个 AI 系统的性能。&lt;/p&gt;
&lt;p&gt;提示工程不需要特定的学位或背景，但从事这项工作的人需要擅长清晰解释事物。这是重要的，因为所有可用的 LLM 都是无状态的，这意味着没有长期记忆，每次交互只存在于小会话中。&lt;/p&gt;
&lt;p&gt;在提示工程中，以下三个因素变得重要：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;上下文&lt;/strong&gt;：你提出的问题、聊天历史记录和你设置的参数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;知识&lt;/strong&gt;：LLM 已经接受的培训内容以及你通过提示提供的新信息的结合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;形式&lt;/strong&gt;：你期望以何种方式生成信息的语气。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上下文、知识和形式的结合塑造了 GenAI 的大量知识存储成为你希望获得的响应类型。&lt;/p&gt;
&lt;h2 id=&#34;4-探索其他-genai-提示方法&#34;&gt;4. 探索其他 GenAI 提示方法&lt;/h2&gt;
&lt;p&gt;到目前为止，我们一直在谈论零-shot 提示，这基本上意味着提出一个带有一些上下文的问题。如果你从这种方法中没有得到期望的结果，还有四种提示 GenAI 的方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;单次提示&lt;/strong&gt;：提供你正在寻找的输出类型的示例。如果你想要特定类型的格式，例如[标题]和[4 个要点]，这将特别有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;少量提示&lt;/strong&gt;：这类似于单次提示，但你会提供三到五个示例而不仅仅是一个。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“让我们一步一步地思考”&lt;/strong&gt;：这种技巧对 LLM 和对人都同样有效。如果你有一个包含多个部分的复杂问题，请在末尾输入此短语，等待 LLM 分解问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;思路链提示&lt;/strong&gt;：对于涉及复杂算术或其他推理任务的问题，思路链提示会指示工具“展示其工作方式”并解释其如何得出答案。以下是可能的示例：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14801736640312961138.webp 400w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14731880502347286634.webp 760w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu5759154962722220918.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14801736640312961138.webp&#34;
               width=&#34;760&#34;
               height=&#34;402&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;5-查看其他-genai-工作示例&#34;&gt;5. 查看其他 GenAI 工作示例&lt;/h2&gt;
&lt;p&gt;一旦你熟悉了 GenAI 工具并了解如何编写出色的提示，&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;请查看 OpenAI 发布的一些示例&lt;/a&gt;，了解其他人正在做什么以及可能的其他可能性。随着你的实验，你将更加熟悉聊天界面，并学会如何对其进行微调，以便熟练地缩小响应范围，甚至将响应转换为 CSV 文件或其他类型的表格。&lt;/p&gt;
&lt;p&gt;考虑如何将你的 GenAI 知识应用于你的业务，以简化困难或重复性任务，生成创意并使信息易于让更广泛的受众访问。你可以想象出哪些新的用例？以前不可能的东西现在成为可能了吗？&lt;/p&gt;
&lt;h2 id=&#34;6-集成第三方-genai-工具和-api&#34;&gt;6. 集成第三方 GenAI 工具和 API&lt;/h2&gt;
&lt;p&gt;考虑使用 ChatGPT、Bard 和 Claude 2 等 API 通过 API 使用 LLMs 的角色。这些工具都提供了强大的 API，并有支持文档，因此入门门槛很低。大多数这些 API 是基于使用量的，因此更容易玩弄。&lt;/p&gt;
&lt;p&gt;通常情况下，通过语义搜索和由向量数据库支持的嵌入来将自定义或私有数据集成到 LLM 提示中，你还可以集成自定义或私有数据。通常称为 RAG（检索增强生成）。&lt;/p&gt;
&lt;p&gt;分解这两个术语：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;语义搜索&lt;/strong&gt;：使用词嵌入比较查询的含义与其索引中文档的含义，即使没有完全匹配的单词也能获得更相关的结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;嵌入&lt;/strong&gt;：将对象（如单词、句子或整个文档）的数值表示转化为多维空间。这使得评估不同实体之间的关系成为可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下是这可能看起来的一个示例：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu1009306822241985111.webp 400w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu11470018464599431523.webp 760w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu17865044914941909841.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu1009306822241985111.webp&#34;
               width=&#34;760&#34;
               height=&#34;608&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这幅图展示了“猫”和“狗”的概念比它们与“人”或“蜘蛛”的概念更接近，“车辆汽车”则是最远的，是概念中最不相关的。（&lt;a href=&#34;https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/#connecting-knowledge-base-to-gpt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里有更多关于如何使用语义搜索和嵌入的信息&lt;/a&gt;。）&lt;/p&gt;
&lt;h2 id=&#34;7-从头开始训练自己的模型&#34;&gt;7. 从头开始训练自己的模型&lt;/h2&gt;
&lt;p&gt;这最后的建议实际上不太像建议，更像是一个“可选的下一步”。训练自己的 GenAI 模型并不适合每个人，但如果你：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拥有独特而有价值的知识库。&lt;/li&gt;
&lt;li&gt;想要执行商业 LLM 无法完成的某些任务。&lt;/li&gt;
&lt;li&gt;发现商业 LLM 的推理成本在商业上没有意义。&lt;/li&gt;
&lt;li&gt;有特定的安全要求，需要托管自己的 LLM 数据，并且不愿通过第三方 API 传递数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;训练自己的模型的一种方法是使用开源模型，例如 Llama 2、Mosaic MPT-7B、Falcon 或 Vicuna，其中许多还提供了商业使用许可证。这些通常根据它们具有的参数数量进行标记：7B、13B、40B 等。 “B”代表模型的参数数目，以及它可以处理和存储的信息量。数字越高，模型就越复杂和复杂，但训练和运行成本也越高。如果你的用例不复杂，并且如果你计划在性能相当强大的现代笔记本电脑上运行模型，那么具有较低参数的模型是开始的最佳且最经济的方法。&lt;/p&gt;
&lt;p&gt;中大型组织可能会选择从头开始构建和训练一个 LLM 模型。这是一条非常昂贵、资源密集且耗时的 AI 之路。你需要难以招聘的技术人才，并具备长时间迭代的机会，因此对大多数组织来说，这条路线不现实。&lt;/p&gt;
&lt;h3 id=&#34;微调-llm&#34;&gt;微调 LLM&lt;/h3&gt;
&lt;p&gt;一些组织选择中间路径：微调基本开源 LLM 以实现模型预训练能力之外的特定功能。如果你希望以你品牌独特的声音创建虚拟助手或基于真实客户购买构建的推荐系统，那么这是一个很好的选择。这些模型会随着你纳入排名靠前的用户交互而不断地训练自己。事实上，&lt;a href=&#34;https://voicebot.ai/2023/08/23/openai-brings-fine-tuning-to-gpt-3-5-turbo-and-gpt-4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open AI 报告&lt;/a&gt;，使用此模型，可以将提示长度缩短多达 90%，同时保持性能不变。此外，Open AI 的商业 API 的最新增强功能使其与驱动 ChatGPT 和 Bing AI 的模型一样强大和易于访问。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes 在裸机上比虚拟机表现更好吗：Kubernetes 性能对比实验</title>
      <link>https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/</link>
      <pubDate>Mon, 18 Dec 2023 14:30:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：本文对比了虚拟机和裸机上 Kubernetes 集群的 CPU、RAM、存储和网络性能的详细比较。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;许多人认为部署在裸机上的 Kubernetes 集群比部署在虚拟机上的性能更好，但直到现在都没有关于这一假设的证据。在 Gcore，我们只提供基于充分证据的信息给客户，因此我们决定自行测试 Kubernetes 是否在&lt;a href=&#34;https://thenewstack.io/bare-metal-in-a-cloud-native-world/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;裸机上&lt;/a&gt;比在虚拟机上表现更好，如果是的话，差距有多大。我将分享我们内部测试的结果。&lt;/p&gt;
&lt;p&gt;我故意不讨论虚拟节点与裸机节点竞争的其他方面，如&lt;a href=&#34;https://gcore.com/blog/kubernetes-on-bare-metal/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;成本效益或基础设施控制级别&lt;/a&gt;。这超出了本文的范围，本文只关注性能比较。&lt;/p&gt;
&lt;h2 id=&#34;vm-和裸机-kubernetes-之间的区别&#34;&gt;VM 和裸机 Kubernetes 之间的区别&lt;/h2&gt;
&lt;p&gt;当您在虚拟机上部署 Kubernetes 集群时，与裸机（BM）相比，您会得到额外的基础设施层，即虚拟机监视器和客户操作系统。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-显示裸机和虚拟机架构差异的图表&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;显示裸机和虚拟机架构差异的图表&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781_hu15883057500611356443.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781_hu4426442748305589303.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781_hu9013060151492115554.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781_hu15883057500611356443.webp&#34;
               width=&#34;760&#34;
               height=&#34;331&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      显示裸机和虚拟机架构差异的图表
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 1：裸机和虚拟机架构的差异。&lt;/p&gt;
&lt;p&gt;这些层占用物理 CPU 和 RAM 来运行，从工作负载中拿走一些计算能力。虚拟化还会影响网络和存储性能：虚拟网络和存储比物理网络和存储慢。&lt;/p&gt;
&lt;p&gt;相比之下，当您在&lt;a href=&#34;https://thenewstack.io/provision-bare-metal-kubernetes-with-the-cluster-api/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;裸机服务器上部署 Kubernetes 集群&lt;/a&gt;时，您没有任何额外的基础设施层和虚拟化。服务器的物理资源完全专用于您的工作负载，容器化应用程序可以直接访问这些资源。&lt;/p&gt;
&lt;h2 id=&#34;我们如何比较虚拟机和裸机-k8s-性能&#34;&gt;我们如何比较虚拟机和裸机 K8s 性能&lt;/h2&gt;
&lt;p&gt;为了全面了解虚拟机和裸机集群性能的比较，我们测量了以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU：&lt;/strong&gt; 速度和利用率&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RAM：&lt;/strong&gt; 延迟&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;存储：&lt;/strong&gt; 每秒事务（TPS）和延迟&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络：&lt;/strong&gt; 带宽和延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了保持工作负载的一致性，所有测试应用程序都以容器化方式部署在比较的工作节点上。&lt;/p&gt;
&lt;h3 id=&#34;我们的测试条件&#34;&gt;我们的测试条件&lt;/h3&gt;
&lt;p&gt;在测试中，我们使用了运行在&lt;a href=&#34;https://gcore.com/cloud/managed-kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gcore 托管的 Kubernetes&lt;/a&gt;上的 K8s 集群。然而，由于托管的 Kubernetes 不会增加工作节点性能的任何开销，因此这些结果也与标准 Kubernetes 相关。&lt;/p&gt;
&lt;p&gt;为了保持工作负载的相同条件，我们选择了相似的虚拟机和裸机工作节点的配置。以下是这种比较配置的示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;裸机工作节点：&lt;/strong&gt; 1x Intel Xeon E-2388 8C/16T 3.2 GHz / 64 GB / Ubuntu 22.04&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;虚拟机工作节点：&lt;/strong&gt; 16 vCPU / 64 GiB 内存 / Ubuntu 22.04&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;测试结果摘要&#34;&gt;测试结果摘要&lt;/h2&gt;
&lt;p&gt;在测试中，我们比较了两个 Kubernetes 集群，一个部署在虚拟机（VMs）上，另一个部署在裸机上。它们的配置相似。作为测试工作负载，我们运行了以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用于 CPU 测试的 CPU 基准测试&lt;/li&gt;
&lt;li&gt;用于 RAM 测试的 Sysbench&lt;/li&gt;
&lt;li&gt;用于存储测试的 Pgbench&lt;/li&gt;
&lt;li&gt;用于网络测试的 Netperf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是总结最重要的测试结果的表格：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-测试结果表格&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;测试结果表格&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1_hu7118314951676424900.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1_hu6673537408299442938.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1_hu7158908024045810663.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1_hu7118314951676424900.webp&#34;
               width=&#34;760&#34;
               height=&#34;295&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      测试结果表格
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;显然，裸机集群在所有情况下效率更高。&lt;/p&gt;
&lt;p&gt;让我们详细查看结果，并确定裸机性能对您的工作负载意味着什么。&lt;/p&gt;
&lt;h2 id=&#34;详细测试结果&#34;&gt;详细测试结果&lt;/h2&gt;
&lt;p&gt;现在，让我们详细查看每个评估标准下裸机和 VM 集群的性能。&lt;/p&gt;
&lt;h2 id=&#34;cpu-速度和利用率&#34;&gt;CPU 速度和利用率&lt;/h2&gt;
&lt;p&gt;对于 CPU 速度比较，我们使用了 Alex Dedyura 的 &lt;a href=&#34;https://github.com/alexdedyura/cpu-benchmark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CPU 基准测试&lt;/a&gt;。这是一个计算到 10,000 位小数的 pi 的脚本。以秒为单位的计算时间，平均值在 10 次测试中被视为测试结果。计算 pi 是一个 CPU 密集型任务，因此该基准测试清晰地显示了被测试 CPU 的性能。&lt;/p&gt;
&lt;p&gt;以下是 CPU 速度比较的结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图表显示裸机集群的-cpu-速度比虚拟机集群的-cpu-快了两倍多&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图表显示，裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a_hu7590700065589710454.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a_hu9194157310494957751.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a_hu1951929181626291109.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a_hu7590700065589710454.webp&#34;
               width=&#34;760&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图表显示，裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 3：裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多。&lt;/p&gt;
&lt;p&gt;虚拟机集群的 10 次重试的平均时间为 47.07 秒；而裸机集群为 21.46 秒。因此，裸机集群快了两倍多。&lt;/p&gt;
&lt;p&gt;以下是虚拟机集群的 CPU 利用率测试结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-平均利用率为-8681&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;平均利用率为 86.81%&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a_hu13940636004228181467.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a_hu10574852521258537534.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a_hu5399063720231841400.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a_hu13940636004228181467.webp&#34;
               width=&#34;760&#34;
               height=&#34;162&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      平均利用率为 86.81%
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 4：虚拟机集群的 CPU 平均利用率为 86.81%。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-5虚拟机集群-cpu-的每个核心使用信息&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 5：虚拟机集群 CPU 的每个核心使用信息&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a_hu8416017473154672443.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a_hu15142550987573904795.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a_hu8477653307649727971.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a_hu8416017473154672443.webp&#34;
               width=&#34;760&#34;
               height=&#34;83&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 5：虚拟机集群 CPU 的每个核心使用信息
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 5：虚拟机集群 CPU 的每个核心使用信息。&lt;/p&gt;
&lt;p&gt;在上图 4 中，红色点表示最大的 CPU 核心负载*，绿色表示所有核心的总 CPU 负载。在执行脚本期间，大部分时间内核心都以 100% 的利用率运行；平均值为 86.81%。还有一个小的窃取时间峰值，大约在 15:16（参见图 4），这是一个常见情况，当一个虚拟机由于等待物理 CPU 共享计算资源而没有运行时会发生。&lt;/p&gt;
&lt;p&gt;*&lt;strong&gt;最大 CPU 核心负载：&lt;/strong&gt; 这个指标通常是指在虚拟机内或主机上所有虚拟机中观察到的单个 CPU 核心的最高利用率百分比。它表示在给定时刻一个特定的 CPU 核心有多重地被利用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总 CPU 核心负载：&lt;/strong&gt; 此指标表示主机机器上所有可用 CPU 核心的整体 CPU 利用率。它考虑了所有 CPU 核心的综合使用情况，提供了运行在主机上的所有虚拟机使用了多少 CPU 容量的综合视图。&lt;/p&gt;
&lt;p&gt;以下是裸机集群的 CPU 利用率测试结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图表显示裸机集群的-cpu-平均利用率为-4375&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图表显示，裸机集群的 CPU 平均利用率为 43.75%&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a_hu12673580296188909068.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a_hu8368303906492050588.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a_hu6304644511949318152.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a_hu12673580296188909068.webp&#34;
               width=&#34;760&#34;
               height=&#34;160&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图表显示，裸机集群的 CPU 平均利用率为 43.75%
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 6：裸机集群的 CPU 平均利用率为 43.75%。&lt;/p&gt;
&lt;p&gt;平均 CPU 负载约为 43.75%，最大负载为 62.57%，没有窃取时间。因此，就 CPU 性能而言，测试显示裸机集群约为虚拟机集群的两倍有效。&lt;/p&gt;
&lt;h2 id=&#34;ram-延迟&#34;&gt;RAM 延迟&lt;/h2&gt;
&lt;p&gt;对于 RAM 测试，&lt;a href=&#34;https://github.com/akopytov/sysbench&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我们使用了 sysbench&lt;/a&gt; 并通过 RAM 传输了 6400 GB 的数据。以下是执行的写入和读取操作的关键结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-7裸机集群的-ram-大约比虚拟机集群的-ram-快三倍&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a_hu6234669188063511086.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a_hu14670826045507087730.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a_hu4791314928989275549.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a_hu6234669188063511086.webp&#34;
               width=&#34;760&#34;
               height=&#34;355&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍。&lt;/p&gt;
&lt;p&gt;虚拟机集群执行写入操作的平均时间为 174.53 毫秒，而裸机集群相同操作仅需 62.02 毫秒。读取操作分别在 173.75 和 47.33 毫秒内完成。&lt;/p&gt;
&lt;p&gt;这意味着裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍。&lt;/p&gt;
&lt;h2 id=&#34;存储-tps-和延迟&#34;&gt;存储 TPS 和延迟&lt;/h2&gt;
&lt;p&gt;为了测试存储性能，我们运行了一个 PostgreSQL 集群，并使用了 &lt;a href=&#34;https://www.postgresql.org/docs/current/pgbench.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pgbench 基准测试&lt;/a&gt;。我们测量了 TPS（每秒事务数）和延迟。我们还变化了工作负载，测试了相同集群配置下的 8 GB 和 75 GB 数据库。&lt;/p&gt;
&lt;p&gt;以下是这些实例的配置：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-8存储测试的裸机和虚拟机集群配置&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 8：存储测试的裸机和虚拟机集群配置&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a_hu9149180351891864535.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a_hu14613515769141181283.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a_hu17653871652178316450.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a_hu9149180351891864535.webp&#34;
               width=&#34;760&#34;
               height=&#34;210&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 8：存储测试的裸机和虚拟机集群配置
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 8：存储测试的裸机和虚拟机集群配置。&lt;/p&gt;
&lt;h3 id=&#34;存储-tps-结果&#34;&gt;存储 TPS 结果&lt;/h3&gt;
&lt;p&gt;以下是 TPS 比较的平均结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-9裸机集群的存储-tps-值大约是虚拟机集群的两倍&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a_hu4655470512185340449.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a_hu13346581987451801685.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a_hu1318709091714920028.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a_hu4655470512185340449.webp&#34;
               width=&#34;760&#34;
               height=&#34;355&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍。&lt;/p&gt;
&lt;p&gt;在运行 8 GB 数据库时，虚拟机集群显示了 7,359 TPS，而裸机集群为 14,087 TPS。75 GB 数据库的性能结果分别为 4,636 和 12,029 TPS。&lt;/p&gt;
&lt;h3 id=&#34;存储延迟结果&#34;&gt;存储延迟结果&lt;/h3&gt;
&lt;p&gt;以下是延迟测试的平均结果：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图表显示8-gb-测试中裸机集群的存储延迟约为虚拟机集群的一半在-75-gb-测试中几乎是其三倍&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图表显示，8 GB 测试中裸机集群的存储延迟约为虚拟机集群的一半，在 75 GB 测试中几乎是其三倍&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10_hu17444463236007598524.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10_hu15242248684357858536.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10_hu1005150464826649085.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10_hu17444463236007598524.webp&#34;
               width=&#34;760&#34;
               height=&#34;355&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图表显示，8 GB 测试中裸机集群的存储延迟约为虚拟机集群的一半，在 75 GB 测试中几乎是其三倍
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 10：裸机在存储延迟方面优于虚拟机。&lt;/p&gt;
&lt;p&gt;在运行 8 GB 数据库时，虚拟机集群的延迟为 34.78 毫秒，而裸机集群的延迟为 18.17 毫秒。对于 75 GB 数据库，延迟分别为 55.21 毫秒和 21.28 毫秒。&lt;/p&gt;
&lt;p&gt;对于 8 GB 数据库，裸机集群的存储性能约为虚拟机集群的两倍。对于 75 GB 数据库，裸机集群相对于虚拟机集群的优势更加明显。&lt;/p&gt;
&lt;h2 id=&#34;网络带宽和延迟&#34;&gt;网络带宽和延迟&lt;/h2&gt;
&lt;p&gt;为了测试网络性能，我们使用了 &lt;a href=&#34;https://github.com/kubernetes/perf-tests/tree/master/network/benchmarks/netperf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;netperf 基准测试&lt;/a&gt;，其中 MSS（最大段大小）从 1 到 65,536 不等。MSS 中的“段”元素是在网络上传输的一种 IP 数据包捆绑。因此，MSS 越大，传输的流量就越多。&lt;/p&gt;
&lt;p&gt;我们在两个物理节点上部署了三个工作节点：Worker 1 和 Worker 2 位于第一个节点上，而 Worker 3 位于第二个节点上。然后，我们测试了所有三个工作节点之间的网络性能。在所有情况下，结果趋势都相似 — 裸机优于虚拟机。&lt;/p&gt;
&lt;p&gt;最有趣的测试是物理距离最远的测试之一，即 Worker 1/Worker 2（位于第一个节点上）与 Worker 3（位于第二个节点上）之间的距离，当流量在第一个和第二个物理节点之间传输时。我们可以将这看作是所有测试中最具挑战性的条件。图 10 和图 11 显示了此测试的结果。图 10 显示了 MSS 值为 1、2、4 和 8 时的网络带宽比较：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-11裸机集群的网络带宽比虚拟机集群的网络带宽大五倍&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11_hu4326784236451675919.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11_hu16763944113206073775.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11_hu15909013285789106783.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11_hu4326784236451675919.webp&#34;
               width=&#34;760&#34;
               height=&#34;346&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍。&lt;/p&gt;
&lt;p&gt;虚拟机集群的带宽范围从 MSS=1 时的 862 KB/秒到 MSS=8 时的 6.52 MB/秒，而裸机集群的带宽在相同的 MSS 值范围内从 4.17 MB/秒到 31 MB/秒不等。平均而言，裸机集群的带宽比虚拟机集群的带宽大五倍。&lt;/p&gt;
&lt;p&gt;图 12 显示了使用相同 MSS 值的网络延迟比较：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-图-12裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍&#34; srcset=&#34;
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12_hu3925527354444535559.webp 400w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12_hu10723088195961781842.webp 760w,
               /blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12_hu848740201447840396.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12_hu3925527354444535559.webp&#34;
               width=&#34;760&#34;
               height=&#34;346&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍。&lt;/p&gt;
&lt;p&gt;正如我们所见，当使用 MSS=8 时，虚拟机集群的延迟约为 145 微秒（us），而裸机的延迟为 24.5 微秒。此外，在裸机集群的情况下，随着 MSS 的增加，延迟增长较慢。&lt;/p&gt;
&lt;p&gt;对于所有测试，请注意我们报告的是&lt;em&gt;内部&lt;/em&gt;集群网络的网络性能比较。我们在一个网络中的节点之间测量了带宽和延迟，位于一个位置。如果我们使用不同位置的节点，这将增加互联网延迟，这是不稳定的，并且可能因提供商而异。我们保持了合成纯净的条件；这可能无法在实际环境中复制。但是，一般趋势可以预期会被重现。&lt;/p&gt;
&lt;h2 id=&#34;裸机性能优势意味着什么&#34;&gt;裸机性能优势意味着什么&lt;/h2&gt;
&lt;p&gt;更好的裸机性能相对于虚拟机提供了两个简单但关键的优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://thenewstack.io/how-do-applications-run-on-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;部署在裸机工作节点上的应用程序&lt;/a&gt;运行和响应速度比部署在虚拟机上的应用程序更快。&lt;/li&gt;
&lt;li&gt;因此，当选择裸机时，客户在使用您的产品时将有更好的体验。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们的测试结果证实了一个普遍的期望，即裸机对于需要高性能和低延迟的计算密集型工作负载（例如数据库、AI/ML 模型和其他类型的实时应用程序）更为适用。虚拟机则更适合不需要高计算和低延迟敏感性的工作负载，如 Web 服务器、网站和开发环境。如果高性能和低延迟对于您的用户至关重要，并直接影响您的业务，您应该考虑在 Kubernetes 集群中使用裸机。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;我们的测试证实了裸机工作节点优于虚拟机工作节点的假设。即裸机比起虚拟机：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 CPU 速度和利用率方面高三倍&lt;/li&gt;
&lt;li&gt;RAM 延迟是虚拟机的1/3&lt;/li&gt;
&lt;li&gt;存储性能高两倍多&lt;/li&gt;
&lt;li&gt;网络延迟是虚拟机的1/5&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>使用 OpenTelemetry 提升 CI/CD 管道的可观察性</title>
      <link>https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/</link>
      <pubDate>Tue, 12 Dec 2023 14:30:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/how-to-observe-your-ci-cd-pipelines-with-opentelemetry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/how-to-observe-your-ci-cd-pipelines-with-opentelemetry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：这篇文章介绍了 OpenTelemetry 这个开源框架，它可以帮助你生成、收集换和导出 CI/CD 管道的遥测数据，以实现性能、可靠性、安全性等方面的度量、监控、告警、分析等功能。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如今的软件比 20 多年前的软件复杂得多，这带来了在故障排除代码时面临新挑战。幸运的是，通过将可观测性引入我们的系统，我们在理解应用程序的性能如何以及问题发生在何处方面取得了相当大的进展。&lt;/p&gt;
&lt;p&gt;然而，不仅软件发生了演变 - 创建和开发软件的过程也发生了变化。&lt;a href=&#34;https://roadmap.sh/devops&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DevOps&lt;/a&gt;引入了&lt;a href=&#34;https://thenewstack.io/a-primer-continuous-integration-and-continuous-delivery-ci-cd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CI/CD的概念&lt;/a&gt;。随着交付周期从每月、每季度，到现在每周甚至一天多次，我们正在全面采用自动化来进行软件交付。&lt;/p&gt;
&lt;p&gt;不幸的是，与应用程序软件相比，&lt;a href=&#34;https://thenewstack.io/ci-cd/&#34; title=&#34;CI/CD pipelines&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CI/CD流水线&lt;/a&gt;的可观测性进展不大。考虑到这些流水线是软件交付流程的基础，这令人惊讶：如果你没有可见性，那么当出现问题且无法将软件投入生产时，你该如何排除问题？&lt;/p&gt;
&lt;p&gt;这正是本文将重点讨论的内容：CI/CD 流水线的可观测性。首先，我们将定义一些概念；然后，我们将深入探讨观察流水线的重要性以及如何使其可观测；最后，我们将讨论一些尚未解决的挑战。&lt;/p&gt;
&lt;h2 id=&#34;关键概念&#34;&gt;关键概念&lt;/h2&gt;
&lt;p&gt;以下是一些需要了解的定义：&lt;/p&gt;
&lt;h3 id=&#34;可观测性&#34;&gt;可观测性&lt;/h3&gt;
&lt;p&gt;有关&lt;a href=&#34;https://thenewstack.io/observability/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;可观测性&lt;/a&gt;有多种定义，因此我们将其缩小为我们最喜欢的定义：&lt;/p&gt;
&lt;p&gt;可观测性，或简称 o11y（发音为“ollie”），允许你通过不了解系统内部运作方式就能从外部了解系统。有趣的是：“o11y”中的数字 11 代表了“可观测性”一词中的字母“o”和“y”之间的字符数。&lt;/p&gt;
&lt;p&gt;这意味着即使你不了解系统的所有细节业务逻辑，系统仍会发出足够的信息，使你能够通过跟踪线索来回答：“为什么会发生这种情况？”但是，如果你的系统不发出信息，那么你就无法进行观察。你如何获取这些信息呢？一种方式是使用 OpenTelemetry。&lt;/p&gt;
&lt;h3 id=&#34;opentelemetry&#34;&gt;OpenTelemetry&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/introducing-opentelemetry-in-your-organization-3-steps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenTelemetry（OTel）&lt;/a&gt;是一个用于生成、收集、转换和导出遥测数据的开源可观测性框架。它提供了一组 API、软件开发工具包（SDK）、仪器库和工具，帮助你完成这些任务。自 2019 年正式成立以来，它已成为应用程序仪器和遥测生成和收集的事实标准，被包括&lt;a href=&#34;https://innovation.ebayinc.com/tech/engineering/why-and-how-ebay-pivoted-to-opentelemetry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eBay&lt;/a&gt;和&lt;a href=&#34;https://www.infoq.com/presentations/opentelemetry-observability/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Skyscanner&lt;/a&gt;在内的公司使用。&lt;/p&gt;
&lt;p&gt;其最大的好处之一是不受供应商锁定的限制。你可以为应用程序添加遥测一次，并将遥测发送到最适合你的后端。它还提供一些非常酷的工具，例如 Collector。&lt;/p&gt;
&lt;p&gt;Collector 是一个供应商中立的服务，用于接收、转换和导出数据到一个或多个可观测性后端。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-otel-collector-组件的图示&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;OTel Collector 组件的图示&#34; srcset=&#34;
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/1_hu7262192281352069676.webp 400w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/1_hu6483044422482279029.webp 760w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/1_hu5063103419020521095.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/1_hu7262192281352069676.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      OTel Collector 组件的图示
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Collector 由四个主要组件组成，这些组件访问遥测：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Receivers&lt;/strong&gt; 接收数据，无论是来自你的应用程序代码还是基础架构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Processors&lt;/strong&gt; 转换数据。处理器可以执行诸如模糊化数据、添加属性、删除属性或过滤数据等操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exporters&lt;/strong&gt; 将数据转换为与你选择的可观测性后端兼容的格式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connectors&lt;/strong&gt; 允许你连接两个流水线。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以将 OTel Collector 视为数据管道。&lt;/p&gt;
&lt;h3 id=&#34;cicd-流水线&#34;&gt;CI/CD 流水线&lt;/h3&gt;
&lt;p&gt;CI/CD 是一种自动化的软件交付方法，依赖于两个关键实践：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连续集成（CI）是指在进行代码更改时构建、打包和测试软件。&lt;/li&gt;
&lt;li&gt;连续交付（CD）是指立即将该软件包部署到生产环境中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cicd-流水线-gif其中有只猫在其中移动&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;CI/CD 流水线 GIF，其中有只猫在其中移动&#34;
           src=&#34;https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/2.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      CI/CD 流水线 GIF，其中有只猫在其中移动
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;自动化的流水线通过允许你更快地向客户提供新功能、修复错误和一般更新来实现快速的产品迭代。它们消除了手动错误的风险，并标准化了对开发人员的反馈循环。&lt;/p&gt;
&lt;h2 id=&#34;为何-cicd-流水线的可观测性很重要&#34;&gt;为何 CI/CD 流水线的可观测性很重要&lt;/h2&gt;
&lt;p&gt;当你的流水线健康时，你的团队可以持续编写、构建、测试和部署代码和配置更改到生产环境。你还可以改进或实现开发敏捷性，这意味着你可以更改运营方式并最小化确定这些修改是否对应用程序的健康产生了积极或消极影响所需的时间。&lt;/p&gt;
&lt;p&gt;相反，当你的流水线不健康时，你可能会遇到以下一种或多种问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;部署缓慢&lt;/strong&gt;：修复错误可能不够快，以制止用户的不满，问题可能会变得严重。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测试问题&lt;/strong&gt;：不得不等待测试完成，或没有足够的时间来测试不同的配置，可能会导致延迟的部署和难以在用户群中实现足够的应用程序性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;技术债务&lt;/strong&gt;：难以确定底层问题可能导致技术债务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-处于燃烧房间中的猫说一切正常&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;处于燃烧房间中的猫说：“一切正常。”&#34; srcset=&#34;
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/3_hu15397063269427768368.webp 400w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/3_hu2726092990639650845.webp 760w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/3_hu9447434243229437912.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/3_hu15397063269427768368.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      处于燃烧房间中的猫说：“一切正常。”
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;流水线是-devops-工程师的生产系统&#34;&gt;流水线是 DevOps 工程师的生产系统&lt;/h3&gt;
&lt;p&gt;虽然流水线可能不是外部用户与之互动的生产环境，但它们绝对是内部用户 - 例如，软件工程师和&lt;a href=&#34;https://thenewstack.io/our-2023-site-reliability-engineering-wish-list/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;站点可靠性工程师&lt;/a&gt;（SRE）- 与之互动的生产环境。能够观察你的生产环境意味着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;避免不必要的长周期时间或更改的引导时间，这会影响提交进入生产所需的时间。&lt;/li&gt;
&lt;li&gt;减少推出新功能和错误修复的等待时间。&lt;/li&gt;
&lt;li&gt;缩短用户等待时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;代码可能会失败&#34;&gt;代码可能会失败&lt;/h3&gt;
&lt;p&gt;CI/CD 流水线由定义其工作方式的代码运行，尽管你付出了最大的努力，代码仍然可能会失败。使应用程序代码可观测有助于你在遇到生产问题时理清头绪。同样，了解你的流水线可以帮助你了解它们失败时发生了什么。&lt;/p&gt;
&lt;h3 id=&#34;故障排除更容易&#34;&gt;故障排除更容易&lt;/h3&gt;
&lt;p&gt;具有可观测的流水线有助于回答以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么失败了？&lt;/li&gt;
&lt;li&gt;为什么失败了？&lt;/li&gt;
&lt;li&gt;是否曾经失败过？&lt;/li&gt;
&lt;li&gt;最常发生了什么失败？&lt;/li&gt;
&lt;li&gt;流水线的正常运行时间是多少？&lt;/li&gt;
&lt;li&gt;是否存在任何瓶颈？如果有，它们是什么？&lt;/li&gt;
&lt;li&gt;你能够缩短修复流水线问题的导向时间吗？&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;想要收集什么样的数据&#34;&gt;想要收集什么样的数据？&lt;/h3&gt;
&lt;p&gt;要回答这些问题，你需要收集有关你的流水线的信息。但是这些信息应该是什么呢？捕获诸如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分支名称。&lt;/li&gt;
&lt;li&gt;提交的安全哈希算法（SHA）。&lt;/li&gt;
&lt;li&gt;机器 IP。&lt;/li&gt;
&lt;li&gt;运行类型（按计划执行，由合并/推送触发）。&lt;/li&gt;
&lt;li&gt;失败的步骤。&lt;/li&gt;
&lt;li&gt;步骤持续时间。&lt;/li&gt;
&lt;li&gt;构建编号。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何观察流水线&#34;&gt;如何观察流水线&lt;/h2&gt;
&lt;p&gt;请记住，当系统发出足够的信息来回答问题：“为什么会发生这种情况？”时，系统就是可观测的。首先，你需要一种方法来发出这些信息；然后，你需要一个发送信息的地方；最后，你需要分析信息并找出需要修复的问题。&lt;/p&gt;
&lt;p&gt;这就是 OpenTelemetry 的用武之地。你可以在系统中实施 OpenTelemetry，以发出你需要实现系统可观测性的信息。与用于应用程序的方式一样，你也可以将其用于 CI/CD 流水线！仍然需要将生成的遥测数据发送到后端进行分析，但我们将专注于第一个部分，即仪器化。&lt;/p&gt;
&lt;h3 id=&#34;使用-opentelemetry&#34;&gt;使用 OpenTelemetry&lt;/h3&gt;
&lt;p&gt;对于仪器化 CI/CD 流水线来说，OpenTelemetry 是一个很合理的选择，因为许多人已经在应用程序中使用它进行仪器化；在过去的几年中，采用和实施逐渐增加。&lt;/p&gt;
&lt;h3 id=&#34;有哪些选项&#34;&gt;有哪些选项？&lt;/h3&gt;
&lt;p&gt;目前，情况有些复杂。存在以下选项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;商业 SaaS 监控解决方案，如&lt;a href=&#34;https://www.datadoghq.com/product/ci-cd-monitoring/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Datadog&lt;/a&gt;和&lt;a href=&#34;https://www.splunk.com/en_us/blog/learn/ci-cd-devops-analytics.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Splunk&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;供应商创建的工具，你可以将其插入现有的 CI/CD 工具中，以帮助实现 CI/CD 可观测性（例如，&lt;a href=&#34;https://github.com/honeycombio/buildevents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Honeycomb buildevents&lt;/a&gt;、&lt;a href=&#34;https://docs.newrelic.com/docs/codestream/how-use-codestream/cicd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;New Relic 的 Codestream 与 CircleCI 集成&lt;/a&gt;和&lt;a href=&#34;https://docs.newrelic.com/docs/change-tracking/ci-cd/change-tracking-github-actions/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Actions 的更改跟踪&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;自制的 GitHub actions（请参阅&lt;a href=&#34;https://github.com/inception-health/otel-export-trace-action&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;、&lt;a href=&#34;https://words.boten.ca/GitHub-Action-to-OTLP/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;和&lt;a href=&#34;https://cloud-native.slack.com/archives/C0598R66XAP/p1698393723861129&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;的示例），以在 CI/CD 流水线中启用可观测性。&lt;/li&gt;
&lt;li&gt;自制的 &lt;a href=&#34;https://github.com/DavidS/circleci-hook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CircleCI OTel webhook&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;自制的 &lt;a href=&#34;https://cloud-native.slack.com/archives/C0598R66XAP/p1698408390701199&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Drone CI OTel webhook&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;将 OpenTelemetry 原生集成到 &lt;a href=&#34;https://plugins.jenkins.io/opentelemetry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jenkins&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/tektoncd/community/blob/main/teps/0124-distributed-tracing-for-tasks-and-pipelines.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tekton&lt;/a&gt; 中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你还可以将这些工具集成到你的 CI/CD 流水线中；它们会发出 OpenTelemetry 信号，从而帮助使你的流水线可观测：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-java-contrib/blob/main/maven-extension/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maven 构建 OTel 扩展&lt;/a&gt;发出 Java 构建的分布式跟踪。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ansible.com/ansible/latest/collections/community/general/opentelemetry_callback.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ansible OpenTelemetry 回调&lt;/a&gt;跟踪 Ansible playbooks。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dynatrace-oss/junit-jupiter-open-telemetry-extension&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dynatrace 的 JUnit Jupiter OpenTelemetry 扩展&lt;/a&gt;是用于通过 OpenTelemetry 收集 JUnit 测试执行数据的 Gradle 插件。还有一个&lt;a href=&#34;https://github.com/dynatrace-oss/junit-jupiter-open-telemetry-extension/packages/1061205&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maven 版本&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pypi.org/project/pytest-otel/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pytest-otel&lt;/a&gt;记录执行的 Python 测试的分布式跟踪。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/equinix-labs/otel-cli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;otel-cli&lt;/a&gt;是用 Go 编写的命令行界面（CLI）工具，可使 shell 脚本发出跟踪信号。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Filelog 接收器&lt;/a&gt;（OTel Collector）从文件中读取和解析日志。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/gitproviderreceiver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Git 提供商接收器&lt;/a&gt;（OTel Collector）从 Git 供应商处获取数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;可观测的流水线示例&#34;&gt;可观测的流水线示例&lt;/h2&gt;
&lt;p&gt;以下图表显示了如何使用上述提到的一些工具实现流水线可观测性。假设你正在构建和部署一个 Java 应用程序。你正在使用 Jenkins 来编排构建和部署过程。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-启用了-otel-的-jenkins-cicd-流水线&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;启用了 OTel 的 Jenkins CI/CD 流水线&#34; srcset=&#34;
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/4_hu6243664876965793228.webp 400w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/4_hu7759320642397304465.webp 760w,
               /blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/4_hu226794652791245591.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/how-to-observe-your-ci-cd-pipelines-with-opentelemetry/4_hu6243664876965793228.webp&#34;
               width=&#34;760&#34;
               height=&#34;333&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      启用了 OTel 的 Jenkins CI/CD 流水线
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Jenkins CI/CD 流水线可以通过&lt;a href=&#34;https://plugins.jenkins.io/opentelemetry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jenkins OTel 插件&lt;/a&gt;发出遥测信号。&lt;/li&gt;
&lt;li&gt;在构建阶段中：
&lt;ul&gt;
&lt;li&gt;你可以使用&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-java-contrib/blob/main/maven-extension/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maven OTel 扩展&lt;/a&gt;发出 Java 构建的分布式跟踪。&lt;/li&gt;
&lt;li&gt;如果你的构建包括 shell 脚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本，你可以使用&lt;a href=&#34;https://github.com/equinix-labs/otel-cli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;otel-cli&lt;/a&gt;工具来使你的 shell 脚本能够发出跟踪信号。
3. 在测试阶段中，&lt;a href=&#34;https://github.com/dynatrace-oss/junit-jupiter-open-telemetry-extension/packages/1061205&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maven 的 JUnit Jupiter 插件&lt;/a&gt;允许你通过 OpenTelemetry 收集 JUnit 测试执行数据。
4. 在打包阶段中，使用 Artifactory 来打包你的应用程序，你可以将其日志发送给 OTel Collector，通过&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/filelogreceiver/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Filelog 接收器&lt;/a&gt;进行解析，该接收器会从文件中读取和解析日志。
5. 在部署阶段，使用 Ansible 来编排你的部署，&lt;a href=&#34;https://docs.ansible.com/ansible/latest/collections/community/general/opentelemetry_callback.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ansible OpenTelemetry 回调&lt;/a&gt;会将跟踪添加到你的 Ansible playbooks 中。如果你的 Ansible playbook 还使用 shell 脚本，它可以利用&lt;a href=&#34;https://github.com/equinix-labs/otel-cli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;otel-cli&lt;/a&gt;工具，使你的 shell 脚本发出额外的跟踪数据。
6. 各种插件发出的信号被 OTel Collector 捕获。可以使用标准的&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver/otlpreceiver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OTLP 接收器&lt;/a&gt;来接收遥测数据，以及&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/gitproviderreceiver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Git 提供商接收器&lt;/a&gt;和&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/filelogreceiver/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Filelog 接收器&lt;/a&gt;。然后，Collector 将遥测信号发送到可观测性后端。
7. 一旦你的数据到达可观测性后端，你可以查看和查询数据，设置警报等等。&lt;/p&gt;
&lt;h2 id=&#34;实现可观测流水线的挑战&#34;&gt;实现可观测流水线的挑战&lt;/h2&gt;
&lt;p&gt;虽然使用 OpenTelemetry 实现 CI/CD 流水线可观测性是有道理的，但缺乏标准化，工具情况有点混乱。&lt;/p&gt;
&lt;p&gt;OpenTelemetry 并未集成到大多数 CI/CD 工具中。虽然有人希望将观察能力添加到诸如 GitLab 和 GitHub Actions 等 CI/CD 工具中，但这些倡议进展缓慢。例如，尽管&lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab/-/issues/338943&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitLab 有关使用 OTel 进行流水线可观测性的请求&lt;/a&gt;存在活动，但该请求已经开放了两年。&lt;a href=&#34;https://github.com/open-telemetry/oteps/pull/223&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;有关 CI/CD 流水线可观测性的 OTel 提案&lt;/a&gt;于 2023 年 1 月提出，但（截至 2023 年 11 月）自 7 月以来尚未有任何活动。&lt;/p&gt;
&lt;p&gt;因此，如果你想使用这些工具，你将取决于创建自己工具的个人和组织是否愿意维护这些工具。如果他们决定不再维护这些工具，会发生什么呢？&lt;/p&gt;
&lt;h2 id=&#34;了解更多&#34;&gt;了解更多&lt;/h2&gt;
&lt;p&gt;使你的 CI/CD 流水线可观测有助于更有效地排除问题，实现开发敏捷性，并深入了解其内部工作原理，以便你可以调整它们以使其运行更高效。&lt;/p&gt;
&lt;p&gt;健康的流水线意味着你可以连续编写、构建、测试和部署新代码。相反，不健康的流水线可能意味着部署较慢，测试问题和技术债务。&lt;/p&gt;
&lt;p&gt;你可以使用 OpenTelemetry 在流水线中添加可观测性；尽管当前选项有限，但事情正在朝着正确的方向发展，我们对 CI/CD 的未来充满期待！&lt;/p&gt;
&lt;p&gt;进一步阅读：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://logz.io/learn/cicd-observability-jenkins&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;解决慢和不稳定的 CI/CD 流水线始于可观测性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/leveraging-opentelemetry-enhance-ansible-jaeger-tracing-infralovers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;利用 OpenTelemetry 增强 Ansible 的 Jaeger 跟踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.splunk.com/en_us/blog/learn/monitoring-ci-cd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CI/CD 流水线监控：简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;在&lt;a href=&#34;https://communityinviter.com/apps/cloud-native/cncf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Slack&lt;/a&gt;的&lt;a href=&#34;https://cloud-native.slack.com/archives/C0598R66XAP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cicd-o11y&lt;/a&gt;频道中查看更多信息。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>如何在 Docker 容器中运行 GUI 应用程序</title>
      <link>https://cloudnativecn.com/blog/run-gui-applications-as-containers-with-x11docker/</link>
      <pubDate>Tue, 19 Sep 2023 12:03:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/run-gui-applications-as-containers-with-x11docker/</guid>
      <description>&lt;p&gt;摘要：本文介绍了如何在 Docker 容器中运行 GUI 应用程序。通过使用 x11docker 应用程序，可以轻松启动带有桌面环境的 GUI 容器，并提供了许多功能，如 GPU 硬件加速、声音、剪贴板共享等。文章还提供了安装 Docker 运行时引擎和 x11docker 的详细步骤，并演示了使用 VLC 媒体播放器在容器中运行 GUI 应用程序的示例。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/run-gui-applications-as-containers-with-x11docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/run-gui-applications-as-containers-with-x11docker/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作为开发人员，您可能需要使用 GUI 容器进行工作。如果是这种情况，您会很快发现，传统的 Docker 运行时引擎并不支持运行 GUI 应用程序（除非它们是基于 Web 的类型）。当您想要开发容器化的 GUI 应用程序时，您该怎么办呢？&lt;/p&gt;
&lt;p&gt;幸运的是，有许多第三方应用程序可以在桌面上轻松启动 GUI 容器。正如您可能预期的那样，这需要一个桌面环境（否则，您将在更传统的基于服务器的设置上进行开发）。其中一个应用程序叫做 &lt;a href=&#34;https://github.com/mviereck/x11docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;x11docker&lt;/a&gt;。顾名思义，此应用程序与 Linux X 显示服务器配合使用（这意味着您需要一个 Linux 发行版才能使其正常工作）。&lt;/p&gt;
&lt;p&gt;x11docker 应用程序包括以下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 硬件加速&lt;/li&gt;
&lt;li&gt;PulseAudio 或 ALSA 声音&lt;/li&gt;
&lt;li&gt;剪贴板共享&lt;/li&gt;
&lt;li&gt;打印机和摄像头访问&lt;/li&gt;
&lt;li&gt;持久的主目录&lt;/li&gt;
&lt;li&gt;Wayland 支持&lt;/li&gt;
&lt;li&gt;语言区域设置创建&lt;/li&gt;
&lt;li&gt;容器内的多个 init 系统和 DBus&lt;/li&gt;
&lt;li&gt;支持多个容器运行时和后端（包括 Podman）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;您可能会问：“X11 不安全吗？”是的，确实。幸运的是，x11docker 通过使用多个 X 服务器来避免 X 服务器泄漏。因此，您可以放心使用该工具，而不必担心会暴露自己、系统或容器给典型的 X11 服务器弱点。&lt;/p&gt;
&lt;p&gt;需要记住的一件事是，x11docker 创建了一个非特权容器用户。该用户的密码为 x11docker，并限制了容器的功能。因此，某些应用程序可能无法按预期方式运行。例如，当尝试从容器内运行 Tor 浏览器时，它无法访问 /dev/stdout，这意味着容器将无法运行。但并不是所有容器都是如此。我将用 VLC 媒体播放器进行演示，该播放器可以按预期运行。&lt;/p&gt;
&lt;p&gt;接下来，我将向您展示如何在运行中的基于 Ubuntu 的桌面操作系统实例上安装 x11docker。当然，首先您必须安装 Docker 运行时引擎。为此，我将向您展示两种不同的方法。&lt;/p&gt;
&lt;p&gt;准备好了吗？我们开始吧。&lt;/p&gt;
&lt;h2 id=&#34;所需的工具&#34;&gt;所需的工具&lt;/h2&gt;
&lt;p&gt;正如我已经提到的，您需要运行中的基于 Ubuntu 的 Linux 桌面发行版实例。您还需要一个具有 sudo 权限的用户。就这些。&lt;/p&gt;
&lt;h2 id=&#34;安装-docker&#34;&gt;安装 Docker&lt;/h2&gt;
&lt;p&gt;首先，我们将使用传统的方法安装 Docker 运行时引擎。首先要做的是使用以下命令将官方 Docker GPG 添加到系统中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL &amp;lt;https://download.docker.com/linux/ubuntu/gpg&amp;gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来，我们必须添加 Docker 仓库，以便安装软件。使用以下命令完成此操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] &amp;lt;https://download.docker.com/linux/ubuntu&amp;gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;lsb_release -cs&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; stable&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo tee /etc/apt/sources.list.d/docker.list &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;gt&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; /dev/null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;添加仓库后，我们将使用以下命令安装一些依赖项：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用以下命令更新 apt：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在，我们可以使用以下命令安装 Docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install docker-ce docker-ce-cli containerd.io -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了能够在不使用 &lt;em&gt;sudo&lt;/em&gt; 的情况下运行 Docker 命令（这可能存在安全风险），请使用以下命令将您的用户添加到 docker 用户组中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo usermod -aG docker &lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注销并重新登录以使更改生效。&lt;/p&gt;
&lt;p&gt;如果您希望采用快速方式，可以使用以下命令安装 Docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install curl wget uidmap -y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -qO- https://get.docker.com/ &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;要能够以无特权方式运行 Docker，请执行以下命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dockerd-rootless-setuptool.sh install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;如何安装-x11docker&#34;&gt;如何安装 x11docker&lt;/h2&gt;
&lt;p&gt;在安装 x11docker 之前，我们必须安装一些依赖项。可以使用以下命令完成此操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install xpra xserver-xephyr xinit xauth xclip x11-xserver-utils x11-utils -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来，使用以下命令安装 x11docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://raw.githubusercontent.com/mviereck/x11docker/master/x11docker &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo bash -s -- --update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后，您可以使用以下命令更新 x11docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo x11docker --update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;如何使用-x11docker&#34;&gt;如何使用 x11docker&lt;/h2&gt;
&lt;p&gt;安装了 x11docker 之后，就可以开始测试了。让我们使用 VLC 应用程序容器进行测试。首先，使用以下命令拉取镜像：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull jess/vlc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;拉取镜像后，使用以下命令（借助 x11docker）运行 VLC：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;x11docker --pulseaudio --share&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/Videos jess/vlc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;您应该会看到 VLC 窗口打开，准备好供使用（图 1）。它的速度比直接安装在您的桌面上要慢一些，但除此之外，它应该按预期工作。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu5167449153449712213.webp 400w,
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu9169833344889354399.webp 760w,
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu4592457042509244309.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/run-gui-applications-as-containers-with-x11docker/docker_hu5167449153449712213.webp&#34;
               width=&#34;621&#34;
               height=&#34;486&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;当然，如果您是开发人员，这对您帮助不大，因为您想要开发自己的容器。您可以始终创建要使用的映像，对其进行标记，将其推送到您选择的存储库，使用 docker pull 命令将其拉到开发系统上，然后使用 x11docker 部署容器。&lt;/p&gt;
&lt;p&gt;就是这样。现在，您可以通过 x11docker 在 Docker 容器中运行 GUI 应用程序了。借助自己的图像部署自己的定制容器，看看它的工作原理。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WebAssembly 能够取代 Kubernetes 吗？探索其优势和限制</title>
      <link>https://cloudnativecn.com/blog/wasm-vs-kubernetes/</link>
      <pubDate>Mon, 11 Sep 2023 19:03:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/wasm-vs-kubernetes/</guid>
      <description>&lt;p&gt;本文源自：&lt;a href=&#34;https://thenewstack.io/webassembly/yes-webassembly-can-replace-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/webassembly/yes-webassembly-can-replace-kubernetes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：WebAssembly 可以作为一种部署应用程序的方式，可以在服务器操作系统上运行，且在许多不同的硬件环境中表现出色。与 Kubernetes 相比，WebAssembly 的优点在于简易性和安全性。但是，Kubernetes 始终有其用途，它将始终用于编排微服务和容器。因此，对于某些用例来说，WebAssembly 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 WebAssembly 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;是的，WebAssembly 可以解决 Kubernetes 的一些问题。&lt;/p&gt;
&lt;p&gt;WebAssembly 或 Wasm 被证明是一种在 Web 浏览器上运行代码的非常实用的方式，它可以作为编译器。它已经作为一种语言运行得非常好，以至于世界万维网联盟（W3C）在 2019 年将其命名为 Web 标准，成为第四个 Web 标准，与 HTML、CSS 和 JavaScript 一起。&lt;/p&gt;
&lt;p&gt;主要的 Web 浏览器，包括 Mozilla、Chrome、Internet Explorer 等，都兼容 Wasm，用于编写代码和创建 Web 浏览器应用程序的使用越来越普遍。除了 Web 工作马车 JavaScript 外，Wasm 还可以容纳其他语言，包括 Go、.NET、C++、Java、PHP、Rust 和 Python。&lt;/p&gt;
&lt;p&gt;Adobe依赖于Wasm/WASI平台在浏览器上直接运行C++代码，这是其中一个更有趣的用例。这使得用户可以在浏览器上直接运行Adobe的Photoshop和Acrobat，从而无需在用户的计算机上下载这些软件工具进行工作。&lt;/p&gt;
&lt;p&gt;最终，开发人员意识到 Wasm 也可以在服务器操作系统上运行，现在它的使用范围扩展到硬件平台。它在许多不同的硬件环境中表现出色，从服务器端到边缘部署和物联网设备，或者任何可以直接在 CPU 上运行代码的地方。代码打包在整洁的 Wasm 可执行文件中，可以将其与容器或甚至可以与较少配置的代码和目标运行的迷你操作系统进行比较。无论在哪里部署代码，应用程序都比仅限于 Web 浏览器环境更加广泛。&lt;/p&gt;
&lt;p&gt;在许多方面，Wasm 的功能可以与一个“大杂烩”多语言编译器相比。然而，与编译器相比，同一二进制可执行文件的 Wasm 可以针对多个平台进行目标和运行，而无需在 Wasm 代码和目标设备上进行配置。&lt;/p&gt;
&lt;p&gt;因此，与编译器相比，Wasm 在完美针对多个目标运行二进制可执行文件时显然比较优越。而在这种情况下，单个二进制可执行文件可以针对多个目标运行，而无需重新配置：这就是 Wasm 的优美之处。&lt;/p&gt;
&lt;p&gt;“Wasm 终于让我们在不涉及开发人员的情况下在服务器、云和边缘设备之间移动代码。这将最终结束开发人员花费大量时间担心调整他们的代码以及为不同的目标平台提供支持的时代，”Enterprise Management Associates（EMA）的分析师 Torsten Volk 告诉 The New Stack。“Wasm 的工作是在所有这些平台上提供一致的运行时。”&lt;/p&gt;
&lt;p&gt;因此，Wasm 可以在某些情况下为 Kubernetes 提供很好的替代方案。与 Kubernetes 相比的主要优点是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简易性&lt;/strong&gt;。在部署应用程序时，即使将应用程序分发到不同的终端，也会有许多明显缺少的步骤。Cosmonic 的 PaaS 版本可以用几个命令行在图形界面中部署应用程序。当使用 Fermyon 和 Fastly 的 Compute@Edge 时，情况也是如此。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安全性&lt;/strong&gt;。在 Kubernetes 这种高度分布式的环境中，安全性是一个真正的问题，并且问题点的详尽列表太长，这里不再赘述。微服务之间的互连性意味着，在一个 Pod 中有数百个入口点中获得访问权限的攻击者可能会对组织的整个基础架构造成严重破坏。&lt;a href=&#34;https://thenewstack.io/kubernetes-secrets-management-3-approaches-9-best-practices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;秘密管理&lt;/a&gt;是另一个问题，并且与名称一样，在容器中指定谁可以访问它们也存在困难。&lt;/p&gt;
&lt;p&gt;Wasm 的可移植性和一致性可以使安全性和合规性更易于管理（再次强调，它在 CPU 级别的二进制格式中运行）。此外，Wasm 结构的简单性意味着代码在几乎直接到达端点的封闭沙箱环境中发布。Wasm 并非没有漏洞可以利用。只是相对于 Kubernetes，它的漏洞利用可能性更少。&lt;/p&gt;
&lt;h2 id=&#34;但它们并不是同一件事情&#34;&gt;但它们并不是同一件事情&lt;/h2&gt;
&lt;p&gt;Wasm 提供了巨大的机会，并且可能会作为一种部署应用程序的方式，在未来几个月和几年中，我们将看到供应商变得更加有创造力，以便用户可以利用它。相比之下，那些预测 Wasm 最终将吃掉 Kubernetes 的午餐并完全取代它的人，可以说是错过了重点。不可能说会发生什么，以及其他用于在云环境中部署和管理高度分布式应用程序的技术可能最终取代 Kubernetes。但是，它高度不可能是 Wasm。&lt;/p&gt;
&lt;p&gt;这是因为 Kubernetes 始终有其用途。它将始终用于编排微服务，以及当然还有容器。它也可以被认为实际上就是 Wasm 将在其中运行的东西，并且其支持者已经说过 Wasm 非常适合在 Kubernetes 环境中运行。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&#34;https://thenewstack.io/webassembly/serverless-webassembly-for-browser-developers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wasm 是为开发人员提供无需编写和维护大量基础设施 YAML 的无服务器运行时&lt;/a&gt;。Wasm 为应用程序代码提供了一组标准 API，以便访问关键的运行时服务，例如 SQL 或 NoSQL、Kafka 消息传递或代码调试，”Volk 说。“但是，然后 Wasm 依赖于资源编排层，可以由 Kubernetes 或任何其他调度器提供，以提供这些服务所需的基础设施资源。这些资源可以以容器、虚拟机、裸机或一些未曾想到的花哨未来技术的形式交付。”&lt;/p&gt;
&lt;p&gt;然而，并非所有人都认为 Kubernetes 作为容器编排的能力将无限期地保持其首选。许多 Wasm 领域的人都倾向于 HashiCorp 的 Nomad 调度器。的确，Fermyon 已经放弃了 Krustlet（Wasm-on-Kubernetes），并将重点转向 HashiCorp Nomad 作为其调度器。Butcher 说：“Nomad 在调度容器方面与 Kubernetes 相当，但具有一个至关重要的附加功能：它可以调度非容器工作负载。在 Fermyon 中，我们能够使 Nomad 调度和执行 WebAssembly 应用程序，而无需编写任何自定义代码。”&lt;/p&gt;
&lt;p&gt;与此同时，Kubernetes 开发人员需要在低级别上&lt;a href=&#34;https://thenewstack.io/webassembly/what-is-webassembly-and-why-do-you-need-it/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接受 WebAssembly&lt;/a&gt;，并更改内置的、容器特定的假设，Butcher 说。微软是第一家真正拥抱这个概念的公司，它的&lt;a href=&#34;https://github.com/containerd/runwasi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;runwasi&lt;/a&gt;项目是 WebAssembly 如何在 Kubernetes 内部执行的示例，Butcher 说。&lt;/p&gt;
&lt;p&gt;“runwasi 项目仅仅是 Kubernetes 需要经历的一系列转型中的第一步，如果它不想被 Nomad 和 Wasm 超越，它的开发人员和维护人员需要快速采取行动。”Butcher 说。“Kubernetes 的游戏要输，但如果它不想被 Nomad 和 Wasm 取代，它们需要迅速采取行动。”&lt;/p&gt;
&lt;h2 id=&#34;存在的威胁&#34;&gt;存在的威胁&lt;/h2&gt;
&lt;p&gt;WebAssembly 对于 Docker 以及容器构成了一种存在的威胁，尽管在超越 Kubernetes 方面，WebAssembly 的简单性、可移植性和安全性等优势使其成为弥补 Docker 缺陷的良好选择，特别是对于边缘和分布式应用。然而，Butcher 指出，Docker 在以下两种应用程序提供环境时表现出色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;长时间运行的过程，如数据库和消息队列，这些过程需要强大的 I/O 和内存管理能力。&lt;/li&gt;
&lt;li&gt;遗留（传统）代码，该代码在应用程序中保留状态并大量使用线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Butcher 说：“我对 Docker 的看法是，它在市场上有一个强大且不可撼动的地位，WebAssembly 不太可能取代它。但是，当涉及到微服务和 Web 应用程序后端时，我认为 WebAssembly 有望削减 Docker 的使用。”&lt;/p&gt;
&lt;p&gt;因此，对于某些用例来说，Wasm 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 Wasm 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>创建高效 Kubernetes 策略的 7 个步骤</title>
      <link>https://cloudnativecn.com/blog/7-steps-to-highly-effective-kubernetes-policies/</link>
      <pubDate>Mon, 11 Sep 2023 09:03:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/7-steps-to-highly-effective-kubernetes-policies/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/7-steps-to-highly-effective-kubernetes-policies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/7-steps-to-highly-effective-kubernetes-policies/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：本文介绍了 Kubernetes 策略的七个步骤，包括基线、修复标签和注释、迁移到受限制的 Pod Security 标准、压制误报、加入常见加固指南、插入并播放、添加自定义规则以应对未预料的特殊情况。通过实施这些步骤，可以逐步减少配置错误和漏洞的数量，实现认证、合规和长期安全目标。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;你刚刚开始了一份新工作，在这个工作中，你第一次有责任操作和管理 Kubernetes 基础设施。你对更深入地了解云原生充满了热情，但同时也非常担心。&lt;/p&gt;
&lt;p&gt;是的，你关注的是编写符合命名和资源使用控制最佳实践的安全应用程序的最佳方法，但是关于已经部署到生产环境中的所有其他内容呢？你打开一个新的工具来查看正在发生的情况，发现有 100 个高或严重的 CVE 和 YAML 配置问题。你关闭标签页告诉自己，你以后会处理所有这些问题的。&lt;/p&gt;
&lt;p&gt;你会吗？&lt;/p&gt;
&lt;p&gt;也许最有雄心壮志和无所畏惧的人会，但问题在于云原生社区喜欢谈论安全、标准化和“左移”，但这些对话都无法减轻因安全、资源、语法和工具问题而产生的不安全感。没有一个开发范式或工具似乎发现了在不压垮人的情况下让错误配置可见的正确方式。&lt;/p&gt;
&lt;p&gt;就像我们可能面对的所有待办事项列表一样，无论是工作还是家务，我们的大脑只能有效地处理有限数量的问题。太多问题了，我们就会迷失在上下文切换和优先处理不完整的临时解决方案之间。我们需要更好的方法来限制范围（即分类），设置里程碑，最终使安全工作可管理。&lt;/p&gt;
&lt;p&gt;是时候忽略问题的数量，专注于交互地塑造，然后强制执行你的组织使用已建立策略的方式，以产生影响——无需产生不安全感。&lt;/p&gt;
&lt;h2 id=&#34;云原生策略的历史&#34;&gt;云原生策略的历史&lt;/h2&gt;
&lt;p&gt;从 Kubernetes 的第一天开始，YAML 配置就是构建完整集群和运行应用程序的基石。作为开发人员应用程序代码和运维工程师维护集群之间的必要桥梁，它们不仅难以正确获取，而且还是 Kubernetes 中大多数部署/服务级别问题的根源。更有甚者，没有人——既不是开发人员，也不是运维工程师——想独自对此负责。&lt;/p&gt;
&lt;p&gt;策略作为一种自动化的方式进入了云原生空间，用于编写和审批为生产环境编写的 YAML 配置。如果没有一个人或团队想要根据内部样式指南手动检查每个配置，那么策略可以慢慢塑造团队解决安全、资源使用和云原生最佳实践中的常见配置错误的方式。更不用说任何唯一应用程序的规则或习语了。&lt;/p&gt;
&lt;p&gt;Kubernetes 中策略的挑战在于它对如何、何时和为什么执行它们是不可知的。你可以用多种方式编写规则，在软件开发生命周期（SDLC）的不同点执行它们，并出于不同的原因使用它们。&lt;/p&gt;
&lt;p&gt;在此混乱中，没有比 Pod 安全策略（PSP）更好的例子了，它在 2016 年 v1.3 中进入 Kubernetes 生态系统。PSP 的设计目的是控制 pod 的操作方式并拒绝任何不符合要求的配置。例如，它允许 K8s 管理员防止开发人员在任何地方运行特权 pod，从而实质上将低级别的 Linux 安全决策与开发生命周期分离开来。&lt;/p&gt;
&lt;p&gt;PSP 从未离开 beta 阶段，有几个很好的理由。这些政策仅在人或进程请求创建 pod 时应用，这意味着没有办法对 PSP 进行改进或默认启用。Kubernetes 团队承认 PSP 使意外授予过于广泛的权限变得太容易了，除了&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?feature=shared&amp;amp;t=970&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;其他困难&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Kubernetes 安全领域的 PSP 时代充满了风险，这启发了一个新的发布周期管理规则：任何 Kubernetes 项目不能超过两个发布周期处于 beta 状态，必须成为稳定的或者标记为[弃用](&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&lt;/a&gt; &lt;a href=&#34;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&lt;/a&gt;)和删除。&lt;/p&gt;
&lt;p&gt;另一方面，PSP 使 Kubernetes 安全领域朝着积极的方向发展：通过将 Kubernetes 安全策略的创建和实例化分离，PSP 开辟了一个新的外部接入控制器和策略执行工具生态系统，例如&lt;a href=&#34;https://kyverno.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kyverno&lt;/a&gt;、&lt;a href=&#34;https://open-policy-agent.github.io/gatekeeper/website/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gatekeeper&lt;/a&gt;和&lt;a href=&#34;https://monokle.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monokle&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们用这些工具摆脱了 PSP 的束缚，并用 Pod Security Standard（PSS）替换了它。一会我们再来谈这个巨大的区别。&lt;/p&gt;
&lt;h2 id=&#34;基于阶段的-kubernetes-策略方法&#34;&gt;基于阶段的 Kubernetes 策略方法&lt;/h2&gt;
&lt;p&gt;在确定了策略创建和实例化之间的解耦后，您现在可以在不管您选择哪些工具的情况下，在您的集群、环境和团队之间应用一致的策略语言。您也可以随时更改您用于创建和实例化的工具，并在您的集群中获得可靠的结果。&lt;/p&gt;
&lt;p&gt;创建通常发生在集成开发环境（IDE）中，这意味着您可以继续使用您当前最喜欢的语言来使用规则特定的语言，如&lt;a href=&#34;https://monokle.io/learn/what-is-opa-for-the-kubernetes-connoisseur-its-as-essential-as-salt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Policy Agent (OPA)&lt;/a&gt;、Kyverno 的声明性语法或 Go 或 TypeScript 等编程语言。&lt;/p&gt;
&lt;p&gt;实例化和强制执行可以在软件开发生命周期的不同部分进行。正如我们在我们之前的&lt;a href=&#34;https://medium.com/kubeshop-i/kubernetes-yaml-policies-101-649a23780371&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;101 级帖子&lt;/a&gt;中看到的那样，您可以在配置生命周期的一个或多个点应用验证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过开发人员的命令行界面（CLI）或 IDE 直接预提交&lt;/li&gt;
&lt;li&gt;通过您的CI/CD流水线进行预部署&lt;/li&gt;
&lt;li&gt;通过像 Kyverno 或 Gatekeeper 这样的&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接入控制器&lt;/a&gt;进行后部署，或者&lt;/li&gt;
&lt;li&gt;在集群中检查部署状态是否仍符合您的策略标准。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;策略的实例化、验证和强制执行越晚，危险的错误配置就越容易滑入生产环境，发现和修复任何发现的错误配置的原始来源所需的工作也越多。您可以在几个阶段实例化和强制执行策略，但越早越好——这正是 Monokle 擅长的，具有强大的预提交和预部署验证支持。&lt;/p&gt;
&lt;p&gt;有了这个场景，以及对 Kubernetes 策略景观的理解，您可以开始消除您面前的误配置。&lt;/p&gt;
&lt;h3 id=&#34;步骤-1实施-pod-security-标准&#34;&gt;步骤 1：实施 Pod Security 标准&lt;/h3&gt;
&lt;p&gt;让我们从前面提到的 PSS 开始。Kubernetes 现在描述了&lt;a href=&#34;https://kubernetes.io/docs/concepts/security/pod-security-standards/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;三个包容性策略&lt;/a&gt;，您可以快速在整个集群中实施和执行。 “特权”策略完全不受限制，应该仅保留给由管理员管理的系统和基础设施工作负载。&lt;/p&gt;
&lt;p&gt;您应该从实例化“基线”策略开始，它允许最小规格的 Pod，这是大多数新接触 Kubernetes 的开发人员开始的地方：&lt;/p&gt;
&lt;p&gt;从基线开始的好处是，您无需修改所有现有的 Dockerfile 和 Kubernetes 配置即可防止已知的权限升级。会有一些例外情况，稍后我会谈到。&lt;/p&gt;
&lt;p&gt;在命名空间级别上创建和实例化这个策略级别是相对简单的：&lt;/p&gt;
&lt;p&gt;您肯定会有一些特殊的服务需要比基线允许的访问权限更多，例如用于收集日志和可观察性的&lt;a href=&#34;https://grafana.com/docs/loki/latest/clients/promtail/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Promtail 代理&lt;/a&gt;。在这些情况下，您需要在特权策略下运行那些命名空间。您需要跟进该供应商的安全改进，以限制您的风险。&lt;/p&gt;
&lt;p&gt;通过强制执行 Pod Security 标准的基线水平来处理大多数配置，并允许一些特权配置，然后修复违反这些策略的任何误配置，您就完成了下一个策略里程碑。&lt;/p&gt;
&lt;h3 id=&#34;步骤-2修复标签和注释&#34;&gt;步骤 2：修复标签和注释&lt;/h3&gt;
&lt;p&gt;标签用于标识资源进行分组或过滤，而注释则用于重要但不用于识别的上下文。如果您的头脑仍在旋转，来自 Ambassador Labs 的 Richard Li 的&lt;a href=&#34;https://blog.getambassador.io/kubernetes-labels-vs-annotations-95fc47196b6d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一个方便的定义&lt;/a&gt;可能会帮助：“标签是为 Kubernetes 而设计的，而注释是为人类而设计的。”&lt;/p&gt;
&lt;p&gt;标签应仅用于其预定目的，即使在这种情况下，您在何处以及如何应用它们时也要小心。过去，&lt;a href=&#34;https://sysdig.com/blog/exposed-prometheus-exploit-kubernetes-kubeconeu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;攻击者已使用标签&lt;/a&gt;深入探索 Kubernetes 集群的架构，包括哪些节点运行单个 Pod，而不留下运行的查询的日志。&lt;/p&gt;
&lt;p&gt;同样的想法也适用于注释：虽然它们是为人类而设计的，但它们经常被用于&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/issues/8503&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;获取凭证&lt;/a&gt;，进而获得访问更多秘密的权限。如果您使用注释来描述应在出现问题的情况下联系的人员，请知道您正在为社交工程攻击创建额外的软目标。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3迁移到受限制的-pss&#34;&gt;步骤 3：迁移到受限制的 PSS&lt;/h3&gt;
&lt;p&gt;虽然基线是可允许但相对安全的，但“受限制”Pod Security 标准采用了目前加固 Pod 的最佳实践。正如 Red Hat 的 Mo Khan&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?t=1951&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾经描述&lt;/a&gt;的那样，受限制的标准确保“您能做的最糟糕的事情是毁掉自己”，而不是您的集群。&lt;/p&gt;
&lt;p&gt;使用受限制的标准，开发人员必须编写在只读模式下运行的应用程序，仅启用 Pod 运行所需的 Linux 功能，不能在任何时候升级特权等。&lt;/p&gt;
&lt;p&gt;我建议从基线开始并稍后迁移到受限制，作为单独的里程碑，因为后者几乎总是需要对现有的 Dockerfile 和 Kubernetes 配置进行主动更改。一旦您实例化并强制执行了受限制策略，您的配置将需要遵守这些策略，否则它们将被您的验证器或接入控制器拒绝。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3a压制而不是忽略不可避免的误报&#34;&gt;步骤 3a：压制而不是忽略不可避免的误报&lt;/h3&gt;
&lt;p&gt;在完成基线和受限制的里程碑时，您正在接近策略管理的更成熟（和复杂）水平。为了确保每个人都在当前策略里程碑方面保持一致，您应该开始处理虚假阳性或必须显式允许的配置，尽管违反了受限制的 PSS。&lt;/p&gt;
&lt;p&gt;在忽略规则或抑制规则之间进行选择时，始终选择抑制规则。这需要一个可审计的操作，具有日志或配置更改，以将例外情况编码为已建立的策略框架。您可以在源中添加抑制规则，直接添加到您的 K8s 配置中或在外部添加，其中开发人员请求其运维同行重新配置其验证器或接入控制器，以允许“误配置”通过。&lt;/p&gt;
&lt;p&gt;在 Monokle 中，您可以将抑制直接添加到您的配置中作为注释，使用&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;静态分析结果交换格式（SARIF）规范&lt;/a&gt;所称的&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/os/sarif-v2.1.0-os.html#_Toc34317739&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;理由&lt;/a&gt;：&lt;/p&gt;
&lt;h3 id=&#34;第-4-步加入常见加固指南&#34;&gt;第 4 步：加入常见加固指南&lt;/h3&gt;
&lt;p&gt;在这一步中，您已经超越了已有的 Kubernetes 安全框架，这意味着您需要更多地积极构建和努力实现自己的里程碑。&lt;/p&gt;
&lt;p&gt;美国国家安全局（NSA）和网络安全和基础设施安全局（CISA）有一份受欢迎的&lt;a href=&#34;https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 加固指南&lt;/a&gt;，其中详细介绍了不仅是 Pod 级别的改进措施，如有效地使用不可变容器文件系统，还包括网络分离、审计日志和威胁检测。&lt;/p&gt;
&lt;h3 id=&#34;第-5-步插入并播放&#34;&gt;第 5 步：插入并播放&lt;/h3&gt;
&lt;p&gt;在实施了一些或所有已有的加固指南之后，每个新的策略都涉及选择、信任和权衡。花些时间在谷歌或 StackOverflow 上，你就会发现很多推荐的插入和播放策略。&lt;/p&gt;
&lt;p&gt;你可以从众包策略中受益，其中许多来自于那些有着更独特经验的人，但请记住，虽然规则可能是出于良好意图的，但你并不了解推荐者的优先事项或操作上下文。他们知道如何实现某些“高挂水果”政策，因为他们不得不这样做，而不是因为这些政策普遍有价值。&lt;/p&gt;
&lt;p&gt;目前正在进行的辩论是是否以及如何严格限制容器的资源需求。对于请求限制也是如此。不配置限制可能会引入安全风险，但如果严重限制 Pod，它们可能无法正常运行。&lt;/p&gt;
&lt;h3 id=&#34;第-6-步添加自定义规则以应对未预料的特殊情况&#34;&gt;第 6 步：添加自定义规则以应对未预料的特殊情况&lt;/h3&gt;
&lt;p&gt;现在，你已经到了 Kubernetes 策略的远端，远离了导致生产负面影响的 20％的错误配置和漏洞。但即使现在，即使已经实施了所有的最佳实践和集体云原生知识，你仍然无法免疫不会意地引发事故或停机的错误配置 - 安全和稳定的奇妙未知未知。&lt;/p&gt;
&lt;p&gt;一个好的经验法则是，如果一个奇特的（错）配置在生产中引起了两次问题，那么就该将其编码为一条自定义规则，在开发过程中强制执行，或由准入控制器强制执行。它太重要了，不能仅在内部悄悄地记录下来，希望开发人员阅读它，在彼此的拉取请求审查中注意到它并捕获它。&lt;/p&gt;
&lt;p&gt;一旦编码到您现有的策略中，自定义规则就成为了您尽可能接近开发人员执行的防护栏杆。如果你可以在开发人员提交工作之前就用验证到达开发人员，Monokle Cloud 就可以无缝地执行这一点，使用自定义插件和您本地运行的开发服务器，那么您可以节省整个组织大量的重复工作和调整他们的拇指等待 CI/CD 管道无可避免地失败时他们可以构建新功能或修复错误。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果您实施了以上所述的所有框架和里程碑，并对您的 Dockerfile 和 Kubernetes 配置进行了所有必要的更改以满足这些新策略，那么您可能会发现您的 90 个主要漏洞清单已经减少到了一个更易管理的数量。&lt;/p&gt;
&lt;p&gt;您正在看到我们逐步塑造和执行 Kubernetes 策略的方法的价值。您与新策略和规则的影响互动得越多，就像 Monokle 在提交之前唯一做到的那样，就越容易在不压垮自己或其他人的情况下逐步迈出步伐。&lt;/p&gt;
&lt;p&gt;您甚至可能会自豪地宣称，您的 Kubernetes 环境完全没有配置错误。这是一种胜利，毫无疑问，但这不是保证 - 总会有新的 Kubernetes 版本、新的应用程序和新的最佳实践融入到您已经完成的工作中。利用框架和加固指南的优势在于，您有更好的共同基础来谈论您在认证、合规和长期安全目标方面的影响。&lt;/p&gt;
&lt;p&gt;对于非专家来说，哪种听起来更有说服力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;您将 CVE 数量从 90 个降至 X 个，&lt;/li&gt;
&lt;li&gt;还是您完全符合美国国家安全局的 Kubernetes 加固指南？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们越早不再担心数字，而是更多地关注共同里程碑，在应用程序生命周期的早期（理想情况下是 pre-commit！）尽早执行，我们就能找到每个云原生策略的可持续甜蜜点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes 故障排除智慧的演变</title>
      <link>https://cloudnativecn.com/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/</link>
      <pubDate>Sun, 10 Sep 2023 19:03:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/</guid>
      <description>&lt;p&gt;摘要：本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI/ML 模型和可观察性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观察性的一致认识的必要性。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文译自：https://thenewstack.io/can-chatgpt-save-collective-kubernetes-troubleshooting/&lt;/p&gt;
&lt;p&gt;数十年前，系统管理员们开始在互联网上分享他们每天面临的技术问题。他们进行了长时间、充满活力且富有价值的讨论，探讨如何调查和解决问题的根本原因，然后详细说明最终对他们有效的解决方案。&lt;/p&gt;
&lt;p&gt;这股洪流从未停歇，只是改变了流向。如今，这些讨论仍在 Stack Overflow、Reddit 以及企业工程博客上进行。每一次讨论都是对全球 IT 系统故障排除经验的宝贵贡献。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;也从根本上改变了这种流向。与几十年来困扰系统管理员和 IT 人员的虚拟机（VM）和单体应用程序相比，&lt;a href=&#34;https://thenewstack.io/microservices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务架构&lt;/a&gt;要复杂得多。由于 Kubernetes 缺乏数据持久性，往往无法对规模化的 K8s 错误进行本地重现。即使能够捕获，观测数据也会在多个平台上分散，而资源和依赖关系的相互关联关系也难以捕捉。&lt;/p&gt;
&lt;p&gt;现在，凭直觉并不一定足够。您需要知道如何调试集群以获得下一步的线索。&lt;/p&gt;
&lt;p&gt;这种复杂性意味着公开的故障排除讨论比以往任何时候都更为重要，但现在我们开始看到这股宝贵的洪流不是被重定向，而是完全被堵住了。你在谷歌上看到了这一点。任何与 Kubernetes 相关问题的搜索都会出现一半以上的付费广告和至少一页 SEO 驱动的文章，这些文章缺乏技术深度。&lt;a href=&#34;https://thenewstack.io/stack-overflow-adds-ai-will-the-community-respond/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow&lt;/a&gt; 正在失去其作为技术人员首选问答资源的主导地位，Reddit 在过去几年中也陷入了争议。&lt;/p&gt;
&lt;p&gt;现在，每个 Kubernetes 的 DevOps 平台都在建立最后一个堤坝：将您的故障排除知识集中在其平台上，并用&lt;a href=&#34;https://thenewstack.io/70-percent-of-developers-using-or-will-use-ai-says-stack-overflow-survey/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;人工智能（AI）和机器学习（ML）&lt;/a&gt;取而代之，直到整个堆栈对于甚至是最有经验的云原生工程师来说都成为一个黑盒。当发生这种情况时，您失去了逐个探测、排除故障和修复系统的能力。这种趋势将曾经是众包故障排除技能洪流变成了过去所能提供的仅仅是一滴水。&lt;/p&gt;
&lt;p&gt;当我们依赖于平台时，故障排除技术的集体智慧就会消失。&lt;/p&gt;
&lt;h2 id=&#34;故障排除智慧的传承&#34;&gt;故障排除智慧的传承&lt;/h2&gt;
&lt;p&gt;起初，系统管理员依靠实体书籍进行技术文档和整体最佳实践的实施。随着互联网在 80 年代和 90 年代的普及，这些人通常通过&lt;a href=&#34;https://today.duke.edu/2010/05/usenet.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Usenet&lt;/a&gt;与同行进行交流，并在像 comp.lang.* 这样的新闻组中提出工作中的技术问题，这类新闻组类似于我们今天所知的论坛的简化版本。&lt;/p&gt;
&lt;p&gt;随着互联网的普及迅速，并几乎完全改变了故障排除智慧的洪流。工程师和管理员们不再聚集在新闻组中，而是涌向包括 Experts Exchange 在内的数千个论坛，该论坛于 1996 年上线。在积累了大量的问题和答案之后，Experts Exchange 团队将所有答案都放在了每年 250 美元的付费墙后面，这使得无数宝贵的讨论无法公开获取，最终导致了该网站的影响力下降。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.joelonsoftware.com/2018/04/06/the-stack-overflow-age/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow 随后出现&lt;/a&gt;，再次向公众开放了这些讨论，并通过声望点数对讨论进行游戏化，这些声望点数可以通过提供见解和解决方案来获得。其他用户随后对“最佳”解决方案进行投票和验证，这有助于其他搜索者快速找到答案。Stack Overflow 的游戏化、自我管理和社区使其成为了洪流式故障排除知识的唯一渠道。&lt;/p&gt;
&lt;p&gt;但是，就像其他时代一样，没有什么好事能永远持续下去。近 10 年来，人们一直在预测&lt;a href=&#34;https://johnslegers.medium.com/the-decline-of-stack-overflow-7cb69faa575d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Stack Overflow 的衰落”&lt;/a&gt;，并指出由于其具有攻击性的性质和由拥有最多声望点数的人进行管理的结构，它“讨厌新用户”。虽然 Stack Overflow 的影响力和流行度确实下降了，但 Reddit 的开发/工程专注的 subreddit 填补了这个空白，它仍然是公开可访问的故障排除知识的最大存储库。&lt;/p&gt;
&lt;p&gt;特别是对于 Kubernetes 和云原生社区来说，这仍然是一个重要的资源，因为它们仍然在经历重大的增长阵痛。而这是一种宝贵的资源，因为如果您认为现在的 Kubernetes 已经很复杂了&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-的复杂性问题&#34;&gt;Kubernetes 的复杂性问题&lt;/h2&gt;
&lt;p&gt;在一篇关于“直观调试”失败的精彩文章中，软件交付顾问 Pete Hodgson 认为，构建和交付软件的现代架构（如 Kubernetes 和微服务）比以往任何时候都更加复杂。他写道：“对于我们大多数人来说，为服务器命名为希腊神话角色，并通过 ssh 进入服务器运行&lt;code&gt;tail&lt;/code&gt;和&lt;code&gt;top&lt;/code&gt;的日子已经一去不复返了。”但是，“这种转变是有代价的……传统的理解和故障排除生产环境的方法在这个新世界中已经行不通了。”&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cynefin-模型&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cynefin 模型&#34; srcset=&#34;
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hu7678611328878471593.webp 400w,
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hu931055034156845125.webp 760w,
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hu10537070282739028136.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hu7678611328878471593.webp&#34;
               width=&#34;760&#34;
               height=&#34;676&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cynefin 模型
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Cynefin 模型。来源：维基百科&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hodgson 使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Cynefin_framework&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cynefin 模型&lt;/a&gt;来说明软件架构过去是复杂的，因为有足够的经验，人们可以理解故障排除和解决方案之间的因果关系。&lt;/p&gt;
&lt;p&gt;他认为，分布式微服务架构是复杂的，即使经验丰富的人对根本原因以及如何进行故障排除也只有“有限的直觉”。他们必须花更多时间通过可观察性数据提出问题和回答问题，最终假设可能出错的原因。&lt;/p&gt;
&lt;p&gt;如果我们同意 Hodgson 的前提 - Kubernetes 本质上是复杂的，并且在响应之前需要花费更多的时间分析问题，那么与 Kubernetes 一起工作的工程师学会了哪些问题最重要，然后用可观察性数据回答，以进行最佳的下一步行动，似乎是至关重要的。&lt;/p&gt;
&lt;p&gt;这正是新一代以 AI 驱动的故障排除平台所提供的智慧。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-故障排除的两种路径&#34;&gt;Kubernetes 故障排除的两种路径&lt;/h2&gt;
&lt;p&gt;多年来，像 OpenAI 这样的公司一直在根据 Stack Overflow、Reddit 等公开数据进行抓取和训练模型，这意味着这些 AI 模型可以访问大量的系统和应用知识，包括 Kubernetes。还有一些人意识到组织的可观察性数据是训练 AI/ML 模型分析新场景的宝贵资源。&lt;/p&gt;
&lt;p&gt;他们都在问同一个问题：我们如何利用关于 Kubernetes 的现有数据来简化搜索最佳解决方案的过程？他们正在构建的产品采取非常不同的路径。&lt;/p&gt;
&lt;h3 id=&#34;第一种增强操作员的分析工作&#34;&gt;第一种：增强操作员的分析工作&lt;/h3&gt;
&lt;p&gt;这些工具自动化和简化对公开在线发布的大量故障排除知识的访问。它们不会取代进行适当故障排除或&lt;a href=&#34;https://aws.amazon.com/opensearch-service/resources/root-cause-analysis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;根本原因分析&lt;/a&gt;（RCA）所需的人类直觉和创造力，而是有条不紊地自动化操作员查找相关信息的方式。&lt;/p&gt;
&lt;p&gt;例如，如果一个刚接触 Kubernetes 的开发人员在运行&lt;code&gt;kubectl get pods&lt;/code&gt;时发现&lt;code&gt;CrashLoopBackOff&lt;/code&gt;状态导致他们无法部署应用程序，他们可以查询一个 AI 驱动的工具以获得建议，比如运行&lt;code&gt;kubectl describe $POD&lt;/code&gt;或&lt;code&gt;kubectl logs $POD&lt;/code&gt;。这些步骤可能会进一步引导开发人员使用&lt;code&gt;kubectl describe $DEPLOYMENT&lt;/code&gt;来调查相关的部署情况。&lt;/p&gt;
&lt;p&gt;在&lt;a href=&#34;https://botkube.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Botkube&lt;/a&gt;，我们对使用 AI 在大量故障排除智慧的基础上自动化这个来回查询的概念非常感兴趣。用户应该能够直接在 Slack 中提问，如“我如何排除这个无法正常工作的服务？”并收到 ChatGPT 撰写的回答。在一次公司范围的黑客马拉松活动中，我们着手实施这一概念，为我们的协作故障排除平台构建了一个新的插件。&lt;/p&gt;
&lt;p&gt;通过&lt;a href=&#34;https://botkube.io/blog/use-chatgpt-to-troubleshoot-kubernetes-errors-with-botkubes-doctor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doctor&lt;/a&gt;，您可以利用大量的故障排除知识，通过 Botkube 作为您的 Kubernetes 集群和消息/协作平台之间的桥梁，无需在 Stack Overflow 或 Google 搜索广告中漫游，这对于新手 Kubernetes 开发人员和操作员特别有用。&lt;/p&gt;
&lt;p&gt;该插件还通过生成一个带有&lt;strong&gt;获取帮助&lt;/strong&gt;按钮的 Slack 消息进一步自动化，用于任何错误或异常，然后查询 ChatGPT 以获取可行的解决方案和下一步操作。您甚至可以将 Doctor 插件的结果导入其他操作或集成，以简化您主动使用现有广泛的 Kubernetes 故障排除知识来更直观地调试和感知问题的方式。&lt;/p&gt;
&lt;h3 id=&#34;第二种将操作员从故障排除中排除&#34;&gt;第二种：将操作员从故障排除中排除&lt;/h3&gt;
&lt;p&gt;这些工具不关心公开知识的泛滥。如果它们可以基于实际的可观察性数据训练通用的 AI/ML 模型，然后根据您的特定架构进行微调，它们可以试图完全剔除人为操作员在根本原因分析和故障修复中的作用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.causely.io/platform/causely-for-kubernetes-applications/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Causely&lt;/a&gt;就是这样一家初创公司，他们并不回避使用 AI 来“消除人为故障排除”的愿景。该平台连接到您现有的可观察性数据，并处理它们以微调因果关系模型，理论上可直接进行修复步骤 - 无需探测或使用&lt;code&gt;kubectl&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果说有时候有一个 Kubernetes 神灵听起来很诱人，那我可能会撒谎，但我对像 Causely 这样的工具夺走运维工作并不担心。我担心的是在 Causely 引领的未来中，我们宝贵的故障排除知识会发生什么。&lt;/p&gt;
&lt;h3 id=&#34;这两种路径之间的差距数据&#34;&gt;这两种路径之间的差距：数据&lt;/h3&gt;
&lt;p&gt;我不是在为“人工智能将取代所有 DevOps 工作”发表言论。我们已经读过太多这样的末日场景，适用于每个小众和行业。我更关心这两种路径之间的差距：用于训练和回答问题或呈现结果的数据是什么？&lt;/p&gt;
&lt;p&gt;第一种路径通常使用现有的公开数据。尽管有关 AI 公司爬取这些站点进行训练数据的担忧-Reddit 和 Twitter，但这些数据的开放性仍然提供了一个激励循环，以保持开发人员和工程师继续在 Reddit、Stack Overflow 和其他平台上共享知识的持续泛滥。&lt;/p&gt;
&lt;p&gt;云原生社区通常也倾向于共享技术知识，认同共享技术知识和一个“涨潮（Kubernetes 故障排除技巧的涨潮）抬高所有船（压力巨大的 Kubernetes 工程师）”的想法。&lt;/p&gt;
&lt;p&gt;第二条路径看起来更为暗淡。随着以 AI 驱动的 DevOps 平台的兴起，越来越多的故障排除知识被锁定在这些仪表板和驱动平台的专有 AI 模型中。我们都同意，Kubernetes 基础架构将继续变得更加复杂，而不是更简单，这意味着随着时间的推移，我们对节点、Pod 和容器之间发生的情况的理解将变得更少。&lt;/p&gt;
&lt;p&gt;当我们停止互相分析问题和感知解决方案时，我们变得依赖于平台。这对每个人来说都是一条失败的道路，除了平台之外。&lt;/p&gt;
&lt;h3 id=&#34;我们如何不失去或失去得更少&#34;&gt;我们如何不失去（或失去得更少）？&lt;/h3&gt;
&lt;p&gt;我们能做的最好的事情是继续在线上发布关于我们在 Kubernetes 和其他领域的故障排除经验的惊人内容，比如“&lt;a href=&#34;https://learnk8s.io/troubleshooting-deployments&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;关于故障排除 Kubernetes 部署的视觉指南&lt;/a&gt;”；通过游戏化创造教育性应用程序，比如&lt;a href=&#34;https://sadservers.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SadServers&lt;/a&gt;；在故障排除系统时采取我们最喜欢的第一步，比如“&lt;a href=&#34;https://rachelbythebay.com/w/2018/03/26/w/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;为什么在排除未知机器问题时我通常首先运行‘w’&lt;/a&gt;”；并进行详细的事后分析，详细描述了探测、感知和应对潜在灾难性情况的压力故事，比如&lt;a href=&#34;https://mail.tarsnap.com/tarsnap-announce/msg00050.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023 年 7 月的 Tarsnap 故障&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们还可以超越技术解决方案，比如讨论我们如何在紧张的故障排除场景中管理和支持同事，或者在组织范围内建立对可观察性的一致认识。&lt;/p&gt;
&lt;p&gt;尽管它们目前面临困境，但 Stack Overflow 和 Reddit 将继续是讨论故障排除和寻求答案的可靠渠道。如果它们最终与 Usenet 和 Experts Exchange 齐名，它们可能会被其他可公开获得的替代品所取代。&lt;/p&gt;
&lt;p&gt;无论何时何地以何种方式发生，我希望您能加入我们在 Botkube 和全新的 Doctor 插件中，为在 Kubernetes 中协作解决复杂问题构建新的渠道。&lt;/p&gt;
&lt;p&gt;无论 AI 驱动的 DevOps 平台是否继续基于抓取的公共 Kubernetes 数据训练新模型，只要我们不自愿地将好奇心、冒险精神和解决问题的能力全部放入这些黑匣子中，就会始终有一条新路径，让宝贵的故障排除知识源源不断地流动。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>将 AI 应用于 WebAssembly 还为时过早吗？</title>
      <link>https://cloudnativecn.com/blog/is-it-too-early-to-leverage-ai-for-webassembly/</link>
      <pubDate>Thu, 07 Sep 2023 21:03:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/is-it-too-early-to-leverage-ai-for-webassembly/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：Fermyon Technologies 认为，将 AI 应用于 WebAssembly 并不为时过早。WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。Fermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了企业级 AI 应用程序成本高的问题。这是一种共生关系。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;人工智能及其在 IT、软件开发和运营方面的应用刚开始发挥作用，预示着人类角色将如何在近期和长期内演变，特别是在较小的规模上，WebAssembly 代表着一种正在引起重大关注的技术，同时证明了其可行性，但成功的商业模型尚未实现，主要是由于最终端点的缺乏标准化。与此同时，至少有一家供应商 Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。&lt;/p&gt;
&lt;p&gt;那么，AI 如何潜在地帮助 Wasm 的开发和采用，这是否为时过早？正如 VMware CTO 办公室的高级工程师 Angel M De Miguel Meana 所指出的那样，自从 ChatGPT 推出以来，AI 生态系统已经发生了巨大的变化，WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。由于 Wasm 生态系统仍在兴起，因此在早期阶段集成 AI 将有助于推动新的和现有的与 AI 相关的标准。这是一种共生关系。&lt;/p&gt;
&lt;h2 id=&#34;完美的匹配&#34;&gt;完美的匹配&lt;/h2&gt;
&lt;p&gt;Fermyon Technologies 的联合创始人兼首席执行官 Matt Butcher 告诉 The New Stack：“我们成立 Fermyon 的目标是打造下一代无服务器平台。AI 显然是这一下一代的一部分。在我们的行业中，我们经常看到革命性的技术一起成长：Java 和 Web、云和微服务、Docker 和 Kubernetes。WebAssembly 和 AI 是一对完美的组合。我看到它们一起成长（并变老）。”&lt;/p&gt;
&lt;p&gt;“烘焙”AI 模型，如 LLM（大型语言模型）或转换器，到 WebAssembly 运行时中，是加速采用 WebAssembly 的逻辑下一步，Enterprise Management Associates (EMA) 的分析师 Torsten Volk 告诉 The New Stack。与调用诸如通过 API 的数据库服务类似，编译 WebAssembly 应用程序（二进制文件）可以将其 API 请求发送到 WebAssembly 运行时，该运行时将该调用中继到 AI 模型并将模型响应返回给发起者，Volk 说。&lt;/p&gt;
&lt;p&gt;“一旦我们有一个提供开发人员一个标准 API 的通用组件模型（CCM），访问数据库、AI 模型、GPU、消息传递、身份验证等，这些 API 请求将变得非常强大。CCM 将让开发人员编写相同的代码，在数据中心、云甚至边缘位置的任何类型的服务器上与 AI 模型（例如 GPT 或 Llama）进行通信，只要该服务器拥有足够的硬件资源可用，”Volk 说。“这一切都归结为关键问题，即产业参与者何时会就 CCM 达成一致。同时，WebAssembly 云（如 Fermyon）可以利用 WebAssembly 使 AI 模型在其自己的云基础设施中具有可移植性和可扩展性，无需 CCM，并将一些节省成本传递给客户。”&lt;/p&gt;
&lt;h2 id=&#34;解决问题&#34;&gt;解决问题&lt;/h2&gt;
&lt;p&gt;同时，Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。正如 Butcher 所指出的那样，负责在 LLM（如 LLaMA2）上构建和运行企业 AI 应用程序的开发人员面临着 100 倍计算成本的挑战，即每小时 32 美元及以上的 GPU 访问费用。或者，他们可以使用按需服务，但是启动时间却非常慢。这使得以实惠的方式提供企业级 AI 应用程序变得不切实际。&lt;/p&gt;
&lt;p&gt;Fermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了这个问题，Butcher 说。这一“突破”得益于驱动 Fermyon Cloud 的服务器 WebAssembly 技术，该技术被架构为亚毫秒冷启动和高容量时间分片的计算实例，已被证明可以将计算密度提高 30 倍。“将此运行时配置文件扩展到 GPU 将使 Fermyon Cloud 成为最快的 AI 推理基础设施服务，”Butcher 说。&lt;/p&gt;
&lt;p&gt;Volk 说，这样的推理服务“非常有趣”，因为典型的 WebAssembly 应用程序仅包含几兆字节，而 AI 模型的大小要大得多。这意味着它们不会像传统的 WebAssembly 应用程序那样启动得那么快。“我认为 Fermyon 已经想出了如何使用时间分片为 WebAssembly 应用程序提供 GPU 访问的方法，以便所有这些应用程序都可以通过其 WebAssembly 运行时保留一些时间片来获取所需的 GPU 资源”，Volk 说。“这意味着很多应用程序可以共享一小部分昂贵的 GPU，以按需为其用户提供服务。这有点像分时共享，但不需要强制参加午餐时间的演示。”&lt;/p&gt;
&lt;p&gt;使用 Spin 入门。&lt;/p&gt;
&lt;p&gt;!https://prod-files-secure.s3.us-west-2.amazonaws.com/86575c70-5cc9-4b3e-bee7-d1bb14ba20e3/6bf78916-e34c-4051-86a7-52145cdc372a/4a27b287-capture-decran-2023-09-05-192118.png&lt;/p&gt;
&lt;p&gt;那么，用户如何与 Serverless AI 交互？Fermyon 的 Serverless AI 没有 REST API 或外部服务，它仅构建在 Fermyon 的 Spin 本地和 Fermyon Cloud 中，Butcher 解释说。“在您的代码的任何位置，您都可以将提示传递到 Serverless AI 并获得响应。在这个第一个测试版中，我们包括 LLaMa2 的聊天模型和最近宣布的 Code Llama 代码生成模型，”Butcher 说。“因此，无论您是在总结文本、实现自己的聊天机器人还是编写后端代码生成器，Serverless AI 都可以满足您的需求。我们的目标是使 AI 变得简单，使开发人员可以立即开始利用它来构建新的令人瞩目的无服务器应用程序。”&lt;/p&gt;
&lt;h2 id=&#34;重要意义&#34;&gt;重要意义&lt;/h2&gt;
&lt;p&gt;使用 WebAssembly 来运行工作负载，可以使用 Fermyon Serverless AI 将“GPU 的一小部分”分配给用户应用程序，以“及时”执行 AI 操作，Fermyon CTO 和联合创始人 Radu Matei 在一篇博客文章中写道。 “当操作完成时，我们将该 GPU 的一小部分分配给队列中的另一个应用程序，”Matei 写道。“由于 Fermyon Cloud 中的启动时间为毫秒级，因此我们可以在分配给 GPU 的用户应用程序之间快速切换。如果所有 GPU 分数都在忙于计算数据，我们将在下一个可用的应用程序之前将传入的应用程序排队。”&lt;/p&gt;
&lt;p&gt;这有两个重大的影响，Matei 写道。首先，用户不必等待虚拟机或容器启动并附加到 GPU 上。此外，“我们可以实现更高的资源利用率和效率，”Matei 写道。&lt;/p&gt;
&lt;p&gt;Fermyon 传达的 Serverless AI 的具体特点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是一款开发人员工具和托管服务，专为使用开源 LLM 进行 AI 推理的无服务器应用程序而设计。&lt;/li&gt;
&lt;li&gt;由于我们的核心 WebAssembly 技术，我们的冷启动时间比竞争对手快 100 倍，从几分钟缩短到不到一秒。这使我们能够在相同的时间内（并且使用相同的硬件）执行数百个应用程序（二进制文件），而今天的服务用于运行一个。&lt;/li&gt;
&lt;li&gt;我们为使用 Spin 构建和运行 AI 应用程序提供了本地开发体验，然后将其部署到 Fermyon Cloud 中，以高性能的方式以其他解决方案的一小部分成本提供服务。&lt;/li&gt;
&lt;li&gt;Fermyon Cloud 使用 AI 级别的 GPU 处理每个请求。由于我们的快速启动和高效的时间共享，我们可以在数百个应用程序之间共享单个 GPU。&lt;/li&gt;
&lt;li&gt;我们正在推出免费的私人测试版。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;大希望&#34;&gt;大希望&lt;/h2&gt;
&lt;p&gt;然而，在 Wasm 和 AI 同时达到潜力之前，还有很长的路要走。在 WasmCon 2023 上，Second State 的 CEO 兼联合创始人 Michael Yuan 和 Wasm 的运行时项目以及 WasmEdge 的讨论了一些正在进行的工作。他在与 De Miguel Meana 的谈话中涵盖了这个话题，“开始使用 AI 和 WebAssembly”在 WasmCon 2023 上。&lt;/p&gt;
&lt;p&gt;“在这个领域（AI 和 Wasm）需要做很多生态系统工作。例如，仅拥有推理是不够的，”Yuan 说。“现在的百万美元问题是，当您拥有图像和文本时，如何将其转换为一系列数字，然后在推理之后如何将这些数字转换回可用的格式？”&lt;/p&gt;
&lt;p&gt;预处理和后处理是 Python 今天最大的优势之一，这得益于为这些任务提供的众多库，Yuan 说。将这些预处理和后处理函数合并到 Rust 函数中将是有益的，但需要社区更多的努力来支持其他模块。“这个生态系统有很大的增长潜力，”Yuan 说。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
