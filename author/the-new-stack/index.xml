<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The New Stack | 云原生社区（中国）</title>
    <link>https://cloudnative.to/author/the-new-stack/</link>
      <atom:link href="https://cloudnative.to/author/the-new-stack/index.xml" rel="self" type="application/rss+xml" />
    <description>The New Stack</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://cloudnative.to/author/the-new-stack/avatar_hu1140c20a64fbbcf64929a71e7b5f3aea_8402_270x270_fill_lanczos_center_3.png</url>
      <title>The New Stack</title>
      <link>https://cloudnative.to/author/the-new-stack/</link>
    </image>
    
    <item>
      <title>如何在 Docker 容器中运行 GUI 应用程序</title>
      <link>https://cloudnative.to/blog/run-gui-applications-as-containers-with-x11docker/</link>
      <pubDate>Tue, 19 Sep 2023 12:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/run-gui-applications-as-containers-with-x11docker/</guid>
      <description>&lt;p&gt;摘要：本文介绍了如何在 Docker 容器中运行 GUI 应用程序。通过使用 x11docker 应用程序，可以轻松启动带有桌面环境的 GUI 容器，并提供了许多功能，如 GPU 硬件加速、声音、剪贴板共享等。文章还提供了安装 Docker 运行时引擎和 x11docker 的详细步骤，并演示了使用 VLC 媒体播放器在容器中运行 GUI 应用程序的示例。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/run-gui-applications-as-containers-with-x11docker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/run-gui-applications-as-containers-with-x11docker/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作为开发人员，您可能需要使用 GUI 容器进行工作。如果是这种情况，您会很快发现，传统的 Docker 运行时引擎并不支持运行 GUI 应用程序（除非它们是基于 Web 的类型）。当您想要开发容器化的 GUI 应用程序时，您该怎么办呢？&lt;/p&gt;
&lt;p&gt;幸运的是，有许多第三方应用程序可以在桌面上轻松启动 GUI 容器。正如您可能预期的那样，这需要一个桌面环境（否则，您将在更传统的基于服务器的设置上进行开发）。其中一个应用程序叫做 &lt;a href=&#34;https://github.com/mviereck/x11docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;x11docker&lt;/a&gt;。顾名思义，此应用程序与 Linux X 显示服务器配合使用（这意味着您需要一个 Linux 发行版才能使其正常工作）。&lt;/p&gt;
&lt;p&gt;x11docker 应用程序包括以下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 硬件加速&lt;/li&gt;
&lt;li&gt;PulseAudio 或 ALSA 声音&lt;/li&gt;
&lt;li&gt;剪贴板共享&lt;/li&gt;
&lt;li&gt;打印机和摄像头访问&lt;/li&gt;
&lt;li&gt;持久的主目录&lt;/li&gt;
&lt;li&gt;Wayland 支持&lt;/li&gt;
&lt;li&gt;语言区域设置创建&lt;/li&gt;
&lt;li&gt;容器内的多个 init 系统和 DBus&lt;/li&gt;
&lt;li&gt;支持多个容器运行时和后端（包括 Podman）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;您可能会问：“X11 不安全吗？”是的，确实。幸运的是，x11docker 通过使用多个 X 服务器来避免 X 服务器泄漏。因此，您可以放心使用该工具，而不必担心会暴露自己、系统或容器给典型的 X11 服务器弱点。&lt;/p&gt;
&lt;p&gt;需要记住的一件事是，x11docker 创建了一个非特权容器用户。该用户的密码为 x11docker，并限制了容器的功能。因此，某些应用程序可能无法按预期方式运行。例如，当尝试从容器内运行 Tor 浏览器时，它无法访问 /dev/stdout，这意味着容器将无法运行。但并不是所有容器都是如此。我将用 VLC 媒体播放器进行演示，该播放器可以按预期运行。&lt;/p&gt;
&lt;p&gt;接下来，我将向您展示如何在运行中的基于 Ubuntu 的桌面操作系统实例上安装 x11docker。当然，首先您必须安装 Docker 运行时引擎。为此，我将向您展示两种不同的方法。&lt;/p&gt;
&lt;p&gt;准备好了吗？我们开始吧。&lt;/p&gt;
&lt;h2 id=&#34;所需的工具&#34;&gt;所需的工具&lt;/h2&gt;
&lt;p&gt;正如我已经提到的，您需要运行中的基于 Ubuntu 的 Linux 桌面发行版实例。您还需要一个具有 sudo 权限的用户。就这些。&lt;/p&gt;
&lt;h2 id=&#34;安装-docker&#34;&gt;安装 Docker&lt;/h2&gt;
&lt;p&gt;首先，我们将使用传统的方法安装 Docker 运行时引擎。首先要做的是使用以下命令将官方 Docker GPG 添加到系统中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL &amp;lt;https://download.docker.com/linux/ubuntu/gpg&amp;gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来，我们必须添加 Docker 仓库，以便安装软件。使用以下命令完成此操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] &amp;lt;https://download.docker.com/linux/ubuntu&amp;gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;lsb_release -cs&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; stable&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo tee /etc/apt/sources.list.d/docker.list &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;gt&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; /dev/null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;添加仓库后，我们将使用以下命令安装一些依赖项：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用以下命令更新 apt：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在，我们可以使用以下命令安装 Docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install docker-ce docker-ce-cli containerd.io -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了能够在不使用 &lt;em&gt;sudo&lt;/em&gt; 的情况下运行 Docker 命令（这可能存在安全风险），请使用以下命令将您的用户添加到 docker 用户组中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo usermod -aG docker &lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注销并重新登录以使更改生效。&lt;/p&gt;
&lt;p&gt;如果您希望采用快速方式，可以使用以下命令安装 Docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install curl wget uidmap -y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -qO- https://get.docker.com/ &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;要能够以无特权方式运行 Docker，请执行以下命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dockerd-rootless-setuptool.sh install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;如何安装-x11docker&#34;&gt;如何安装 x11docker&lt;/h2&gt;
&lt;p&gt;在安装 x11docker 之前，我们必须安装一些依赖项。可以使用以下命令完成此操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install xpra xserver-xephyr xinit xauth xclip x11-xserver-utils x11-utils -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来，使用以下命令安装 x11docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://raw.githubusercontent.com/mviereck/x11docker/master/x11docker &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sudo bash -s -- --update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后，您可以使用以下命令更新 x11docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo x11docker --update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;如何使用-x11docker&#34;&gt;如何使用 x11docker&lt;/h2&gt;
&lt;p&gt;安装了 x11docker 之后，就可以开始测试了。让我们使用 VLC 应用程序容器进行测试。首先，使用以下命令拉取镜像：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull jess/vlc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;拉取镜像后，使用以下命令（借助 x11docker）运行 VLC：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;x11docker --pulseaudio --share&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/Videos jess/vlc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;您应该会看到 VLC 窗口打开，准备好供使用（图 1）。它的速度比直接安装在您的桌面上要慢一些，但除此之外，它应该按预期工作。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu7af1eb32b7036660bb546c727cf1eec4_34121_77f74f4bcf8a2271972c2b8bd0f35e59.webp 400w,
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu7af1eb32b7036660bb546c727cf1eec4_34121_cd475a0241c762599f9ec2a3b3dfc621.webp 760w,
               /blog/run-gui-applications-as-containers-with-x11docker/docker_hu7af1eb32b7036660bb546c727cf1eec4_34121_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/run-gui-applications-as-containers-with-x11docker/docker_hu7af1eb32b7036660bb546c727cf1eec4_34121_77f74f4bcf8a2271972c2b8bd0f35e59.webp&#34;
               width=&#34;621&#34;
               height=&#34;486&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;当然，如果您是开发人员，这对您帮助不大，因为您想要开发自己的容器。您可以始终创建要使用的映像，对其进行标记，将其推送到您选择的存储库，使用 docker pull 命令将其拉到开发系统上，然后使用 x11docker 部署容器。&lt;/p&gt;
&lt;p&gt;就是这样。现在，您可以通过 x11docker 在 Docker 容器中运行 GUI 应用程序了。借助自己的图像部署自己的定制容器，看看它的工作原理。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WebAssembly 能够取代 Kubernetes 吗？探索其优势和限制</title>
      <link>https://cloudnative.to/blog/wasm-vs-kubernetes/</link>
      <pubDate>Mon, 11 Sep 2023 19:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/wasm-vs-kubernetes/</guid>
      <description>&lt;p&gt;本文源自：&lt;a href=&#34;https://thenewstack.io/webassembly/yes-webassembly-can-replace-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/webassembly/yes-webassembly-can-replace-kubernetes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：WebAssembly 可以作为一种部署应用程序的方式，可以在服务器操作系统上运行，且在许多不同的硬件环境中表现出色。与 Kubernetes 相比，WebAssembly 的优点在于简易性和安全性。但是，Kubernetes 始终有其用途，它将始终用于编排微服务和容器。因此，对于某些用例来说，WebAssembly 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 WebAssembly 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;是的，WebAssembly 可以解决 Kubernetes 的一些问题。&lt;/p&gt;
&lt;p&gt;WebAssembly 或 Wasm 被证明是一种在 Web 浏览器上运行代码的非常实用的方式，它可以作为编译器。它已经作为一种语言运行得非常好，以至于世界万维网联盟（W3C）在 2019 年将其命名为 Web 标准，成为第四个 Web 标准，与 HTML、CSS 和 JavaScript 一起。&lt;/p&gt;
&lt;p&gt;主要的 Web 浏览器，包括 Mozilla、Chrome、Internet Explorer 等，都兼容 Wasm，用于编写代码和创建 Web 浏览器应用程序的使用越来越普遍。除了 Web 工作马车 JavaScript 外，Wasm 还可以容纳其他语言，包括 Go、.NET、C++、Java、PHP、Rust 和 Python。&lt;/p&gt;
&lt;p&gt;Adobe依赖于Wasm/WASI平台在浏览器上直接运行C++代码，这是其中一个更有趣的用例。这使得用户可以在浏览器上直接运行Adobe的Photoshop和Acrobat，从而无需在用户的计算机上下载这些软件工具进行工作。&lt;/p&gt;
&lt;p&gt;最终，开发人员意识到 Wasm 也可以在服务器操作系统上运行，现在它的使用范围扩展到硬件平台。它在许多不同的硬件环境中表现出色，从服务器端到边缘部署和物联网设备，或者任何可以直接在 CPU 上运行代码的地方。代码打包在整洁的 Wasm 可执行文件中，可以将其与容器或甚至可以与较少配置的代码和目标运行的迷你操作系统进行比较。无论在哪里部署代码，应用程序都比仅限于 Web 浏览器环境更加广泛。&lt;/p&gt;
&lt;p&gt;在许多方面，Wasm 的功能可以与一个“大杂烩”多语言编译器相比。然而，与编译器相比，同一二进制可执行文件的 Wasm 可以针对多个平台进行目标和运行，而无需在 Wasm 代码和目标设备上进行配置。&lt;/p&gt;
&lt;p&gt;因此，与编译器相比，Wasm 在完美针对多个目标运行二进制可执行文件时显然比较优越。而在这种情况下，单个二进制可执行文件可以针对多个目标运行，而无需重新配置：这就是 Wasm 的优美之处。&lt;/p&gt;
&lt;p&gt;“Wasm 终于让我们在不涉及开发人员的情况下在服务器、云和边缘设备之间移动代码。这将最终结束开发人员花费大量时间担心调整他们的代码以及为不同的目标平台提供支持的时代，”Enterprise Management Associates（EMA）的分析师 Torsten Volk 告诉 The New Stack。“Wasm 的工作是在所有这些平台上提供一致的运行时。”&lt;/p&gt;
&lt;p&gt;因此，Wasm 可以在某些情况下为 Kubernetes 提供很好的替代方案。与 Kubernetes 相比的主要优点是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简易性&lt;/strong&gt;。在部署应用程序时，即使将应用程序分发到不同的终端，也会有许多明显缺少的步骤。Cosmonic 的 PaaS 版本可以用几个命令行在图形界面中部署应用程序。当使用 Fermyon 和 Fastly 的 Compute@Edge 时，情况也是如此。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安全性&lt;/strong&gt;。在 Kubernetes 这种高度分布式的环境中，安全性是一个真正的问题，并且问题点的详尽列表太长，这里不再赘述。微服务之间的互连性意味着，在一个 Pod 中有数百个入口点中获得访问权限的攻击者可能会对组织的整个基础架构造成严重破坏。&lt;a href=&#34;https://thenewstack.io/kubernetes-secrets-management-3-approaches-9-best-practices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;秘密管理&lt;/a&gt;是另一个问题，并且与名称一样，在容器中指定谁可以访问它们也存在困难。&lt;/p&gt;
&lt;p&gt;Wasm 的可移植性和一致性可以使安全性和合规性更易于管理（再次强调，它在 CPU 级别的二进制格式中运行）。此外，Wasm 结构的简单性意味着代码在几乎直接到达端点的封闭沙箱环境中发布。Wasm 并非没有漏洞可以利用。只是相对于 Kubernetes，它的漏洞利用可能性更少。&lt;/p&gt;
&lt;h2 id=&#34;但它们并不是同一件事情&#34;&gt;但它们并不是同一件事情&lt;/h2&gt;
&lt;p&gt;Wasm 提供了巨大的机会，并且可能会作为一种部署应用程序的方式，在未来几个月和几年中，我们将看到供应商变得更加有创造力，以便用户可以利用它。相比之下，那些预测 Wasm 最终将吃掉 Kubernetes 的午餐并完全取代它的人，可以说是错过了重点。不可能说会发生什么，以及其他用于在云环境中部署和管理高度分布式应用程序的技术可能最终取代 Kubernetes。但是，它高度不可能是 Wasm。&lt;/p&gt;
&lt;p&gt;这是因为 Kubernetes 始终有其用途。它将始终用于编排微服务，以及当然还有容器。它也可以被认为实际上就是 Wasm 将在其中运行的东西，并且其支持者已经说过 Wasm 非常适合在 Kubernetes 环境中运行。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&#34;https://thenewstack.io/webassembly/serverless-webassembly-for-browser-developers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wasm 是为开发人员提供无需编写和维护大量基础设施 YAML 的无服务器运行时&lt;/a&gt;。Wasm 为应用程序代码提供了一组标准 API，以便访问关键的运行时服务，例如 SQL 或 NoSQL、Kafka 消息传递或代码调试，”Volk 说。“但是，然后 Wasm 依赖于资源编排层，可以由 Kubernetes 或任何其他调度器提供，以提供这些服务所需的基础设施资源。这些资源可以以容器、虚拟机、裸机或一些未曾想到的花哨未来技术的形式交付。”&lt;/p&gt;
&lt;p&gt;然而，并非所有人都认为 Kubernetes 作为容器编排的能力将无限期地保持其首选。许多 Wasm 领域的人都倾向于 HashiCorp 的 Nomad 调度器。的确，Fermyon 已经放弃了 Krustlet（Wasm-on-Kubernetes），并将重点转向 HashiCorp Nomad 作为其调度器。Butcher 说：“Nomad 在调度容器方面与 Kubernetes 相当，但具有一个至关重要的附加功能：它可以调度非容器工作负载。在 Fermyon 中，我们能够使 Nomad 调度和执行 WebAssembly 应用程序，而无需编写任何自定义代码。”&lt;/p&gt;
&lt;p&gt;与此同时，Kubernetes 开发人员需要在低级别上&lt;a href=&#34;https://thenewstack.io/webassembly/what-is-webassembly-and-why-do-you-need-it/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接受 WebAssembly&lt;/a&gt;，并更改内置的、容器特定的假设，Butcher 说。微软是第一家真正拥抱这个概念的公司，它的&lt;a href=&#34;https://github.com/containerd/runwasi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;runwasi&lt;/a&gt;项目是 WebAssembly 如何在 Kubernetes 内部执行的示例，Butcher 说。&lt;/p&gt;
&lt;p&gt;“runwasi 项目仅仅是 Kubernetes 需要经历的一系列转型中的第一步，如果它不想被 Nomad 和 Wasm 超越，它的开发人员和维护人员需要快速采取行动。”Butcher 说。“Kubernetes 的游戏要输，但如果它不想被 Nomad 和 Wasm 取代，它们需要迅速采取行动。”&lt;/p&gt;
&lt;h2 id=&#34;存在的威胁&#34;&gt;存在的威胁&lt;/h2&gt;
&lt;p&gt;WebAssembly 对于 Docker 以及容器构成了一种存在的威胁，尽管在超越 Kubernetes 方面，WebAssembly 的简单性、可移植性和安全性等优势使其成为弥补 Docker 缺陷的良好选择，特别是对于边缘和分布式应用。然而，Butcher 指出，Docker 在以下两种应用程序提供环境时表现出色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;长时间运行的过程，如数据库和消息队列，这些过程需要强大的 I/O 和内存管理能力。&lt;/li&gt;
&lt;li&gt;遗留（传统）代码，该代码在应用程序中保留状态并大量使用线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Butcher 说：“我对 Docker 的看法是，它在市场上有一个强大且不可撼动的地位，WebAssembly 不太可能取代它。但是，当涉及到微服务和 Web 应用程序后端时，我认为 WebAssembly 有望削减 Docker 的使用。”&lt;/p&gt;
&lt;p&gt;因此，对于某些用例来说，Wasm 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 Wasm 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>创建高效 Kubernetes 策略的 7 个步骤</title>
      <link>https://cloudnative.to/blog/7-steps-to-highly-effective-kubernetes-policies/</link>
      <pubDate>Mon, 11 Sep 2023 09:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/7-steps-to-highly-effective-kubernetes-policies/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/7-steps-to-highly-effective-kubernetes-policies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/7-steps-to-highly-effective-kubernetes-policies/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：本文介绍了 Kubernetes 策略的七个步骤，包括基线、修复标签和注释、迁移到受限制的 Pod Security 标准、压制误报、加入常见加固指南、插入并播放、添加自定义规则以应对未预料的特殊情况。通过实施这些步骤，可以逐步减少配置错误和漏洞的数量，实现认证、合规和长期安全目标。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;你刚刚开始了一份新工作，在这个工作中，你第一次有责任操作和管理 Kubernetes 基础设施。你对更深入地了解云原生充满了热情，但同时也非常担心。&lt;/p&gt;
&lt;p&gt;是的，你关注的是编写符合命名和资源使用控制最佳实践的安全应用程序的最佳方法，但是关于已经部署到生产环境中的所有其他内容呢？你打开一个新的工具来查看正在发生的情况，发现有 100 个高或严重的 CVE 和 YAML 配置问题。你关闭标签页告诉自己，你以后会处理所有这些问题的。&lt;/p&gt;
&lt;p&gt;你会吗？&lt;/p&gt;
&lt;p&gt;也许最有雄心壮志和无所畏惧的人会，但问题在于云原生社区喜欢谈论安全、标准化和“左移”，但这些对话都无法减轻因安全、资源、语法和工具问题而产生的不安全感。没有一个开发范式或工具似乎发现了在不压垮人的情况下让错误配置可见的正确方式。&lt;/p&gt;
&lt;p&gt;就像我们可能面对的所有待办事项列表一样，无论是工作还是家务，我们的大脑只能有效地处理有限数量的问题。太多问题了，我们就会迷失在上下文切换和优先处理不完整的临时解决方案之间。我们需要更好的方法来限制范围（即分类），设置里程碑，最终使安全工作可管理。&lt;/p&gt;
&lt;p&gt;是时候忽略问题的数量，专注于交互地塑造，然后强制执行你的组织使用已建立策略的方式，以产生影响——无需产生不安全感。&lt;/p&gt;
&lt;h2 id=&#34;云原生策略的历史&#34;&gt;云原生策略的历史&lt;/h2&gt;
&lt;p&gt;从 Kubernetes 的第一天开始，YAML 配置就是构建完整集群和运行应用程序的基石。作为开发人员应用程序代码和运维工程师维护集群之间的必要桥梁，它们不仅难以正确获取，而且还是 Kubernetes 中大多数部署/服务级别问题的根源。更有甚者，没有人——既不是开发人员，也不是运维工程师——想独自对此负责。&lt;/p&gt;
&lt;p&gt;策略作为一种自动化的方式进入了云原生空间，用于编写和审批为生产环境编写的 YAML 配置。如果没有一个人或团队想要根据内部样式指南手动检查每个配置，那么策略可以慢慢塑造团队解决安全、资源使用和云原生最佳实践中的常见配置错误的方式。更不用说任何唯一应用程序的规则或习语了。&lt;/p&gt;
&lt;p&gt;Kubernetes 中策略的挑战在于它对如何、何时和为什么执行它们是不可知的。你可以用多种方式编写规则，在软件开发生命周期（SDLC）的不同点执行它们，并出于不同的原因使用它们。&lt;/p&gt;
&lt;p&gt;在此混乱中，没有比 Pod 安全策略（PSP）更好的例子了，它在 2016 年 v1.3 中进入 Kubernetes 生态系统。PSP 的设计目的是控制 pod 的操作方式并拒绝任何不符合要求的配置。例如，它允许 K8s 管理员防止开发人员在任何地方运行特权 pod，从而实质上将低级别的 Linux 安全决策与开发生命周期分离开来。&lt;/p&gt;
&lt;p&gt;PSP 从未离开 beta 阶段，有几个很好的理由。这些政策仅在人或进程请求创建 pod 时应用，这意味着没有办法对 PSP 进行改进或默认启用。Kubernetes 团队承认 PSP 使意外授予过于广泛的权限变得太容易了，除了&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?feature=shared&amp;amp;t=970&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;其他困难&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Kubernetes 安全领域的 PSP 时代充满了风险，这启发了一个新的发布周期管理规则：任何 Kubernetes 项目不能超过两个发布周期处于 beta 状态，必须成为稳定的或者标记为[弃用](&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&lt;/a&gt; &lt;a href=&#34;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&lt;/a&gt;)和删除。&lt;/p&gt;
&lt;p&gt;另一方面，PSP 使 Kubernetes 安全领域朝着积极的方向发展：通过将 Kubernetes 安全策略的创建和实例化分离，PSP 开辟了一个新的外部接入控制器和策略执行工具生态系统，例如&lt;a href=&#34;https://kyverno.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kyverno&lt;/a&gt;、&lt;a href=&#34;https://open-policy-agent.github.io/gatekeeper/website/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gatekeeper&lt;/a&gt;和&lt;a href=&#34;https://monokle.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monokle&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们用这些工具摆脱了 PSP 的束缚，并用 Pod Security Standard（PSS）替换了它。一会我们再来谈这个巨大的区别。&lt;/p&gt;
&lt;h2 id=&#34;基于阶段的-kubernetes-策略方法&#34;&gt;基于阶段的 Kubernetes 策略方法&lt;/h2&gt;
&lt;p&gt;在确定了策略创建和实例化之间的解耦后，您现在可以在不管您选择哪些工具的情况下，在您的集群、环境和团队之间应用一致的策略语言。您也可以随时更改您用于创建和实例化的工具，并在您的集群中获得可靠的结果。&lt;/p&gt;
&lt;p&gt;创建通常发生在集成开发环境（IDE）中，这意味着您可以继续使用您当前最喜欢的语言来使用规则特定的语言，如&lt;a href=&#34;https://monokle.io/learn/what-is-opa-for-the-kubernetes-connoisseur-its-as-essential-as-salt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Policy Agent (OPA)&lt;/a&gt;、Kyverno 的声明性语法或 Go 或 TypeScript 等编程语言。&lt;/p&gt;
&lt;p&gt;实例化和强制执行可以在软件开发生命周期的不同部分进行。正如我们在我们之前的&lt;a href=&#34;https://medium.com/kubeshop-i/kubernetes-yaml-policies-101-649a23780371&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;101 级帖子&lt;/a&gt;中看到的那样，您可以在配置生命周期的一个或多个点应用验证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过开发人员的命令行界面（CLI）或 IDE 直接预提交&lt;/li&gt;
&lt;li&gt;通过您的CI/CD流水线进行预部署&lt;/li&gt;
&lt;li&gt;通过像 Kyverno 或 Gatekeeper 这样的&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接入控制器&lt;/a&gt;进行后部署，或者&lt;/li&gt;
&lt;li&gt;在集群中检查部署状态是否仍符合您的策略标准。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;策略的实例化、验证和强制执行越晚，危险的错误配置就越容易滑入生产环境，发现和修复任何发现的错误配置的原始来源所需的工作也越多。您可以在几个阶段实例化和强制执行策略，但越早越好——这正是 Monokle 擅长的，具有强大的预提交和预部署验证支持。&lt;/p&gt;
&lt;p&gt;有了这个场景，以及对 Kubernetes 策略景观的理解，您可以开始消除您面前的误配置。&lt;/p&gt;
&lt;h3 id=&#34;步骤-1实施-pod-security-标准&#34;&gt;步骤 1：实施 Pod Security 标准&lt;/h3&gt;
&lt;p&gt;让我们从前面提到的 PSS 开始。Kubernetes 现在描述了&lt;a href=&#34;https://kubernetes.io/docs/concepts/security/pod-security-standards/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;三个包容性策略&lt;/a&gt;，您可以快速在整个集群中实施和执行。 “特权”策略完全不受限制，应该仅保留给由管理员管理的系统和基础设施工作负载。&lt;/p&gt;
&lt;p&gt;您应该从实例化“基线”策略开始，它允许最小规格的 Pod，这是大多数新接触 Kubernetes 的开发人员开始的地方：&lt;/p&gt;
&lt;p&gt;从基线开始的好处是，您无需修改所有现有的 Dockerfile 和 Kubernetes 配置即可防止已知的权限升级。会有一些例外情况，稍后我会谈到。&lt;/p&gt;
&lt;p&gt;在命名空间级别上创建和实例化这个策略级别是相对简单的：&lt;/p&gt;
&lt;p&gt;您肯定会有一些特殊的服务需要比基线允许的访问权限更多，例如用于收集日志和可观察性的&lt;a href=&#34;https://grafana.com/docs/loki/latest/clients/promtail/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Promtail 代理&lt;/a&gt;。在这些情况下，您需要在特权策略下运行那些命名空间。您需要跟进该供应商的安全改进，以限制您的风险。&lt;/p&gt;
&lt;p&gt;通过强制执行 Pod Security 标准的基线水平来处理大多数配置，并允许一些特权配置，然后修复违反这些策略的任何误配置，您就完成了下一个策略里程碑。&lt;/p&gt;
&lt;h3 id=&#34;步骤-2修复标签和注释&#34;&gt;步骤 2：修复标签和注释&lt;/h3&gt;
&lt;p&gt;标签用于标识资源进行分组或过滤，而注释则用于重要但不用于识别的上下文。如果您的头脑仍在旋转，来自 Ambassador Labs 的 Richard Li 的&lt;a href=&#34;https://blog.getambassador.io/kubernetes-labels-vs-annotations-95fc47196b6d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一个方便的定义&lt;/a&gt;可能会帮助：“标签是为 Kubernetes 而设计的，而注释是为人类而设计的。”&lt;/p&gt;
&lt;p&gt;标签应仅用于其预定目的，即使在这种情况下，您在何处以及如何应用它们时也要小心。过去，&lt;a href=&#34;https://sysdig.com/blog/exposed-prometheus-exploit-kubernetes-kubeconeu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;攻击者已使用标签&lt;/a&gt;深入探索 Kubernetes 集群的架构，包括哪些节点运行单个 Pod，而不留下运行的查询的日志。&lt;/p&gt;
&lt;p&gt;同样的想法也适用于注释：虽然它们是为人类而设计的，但它们经常被用于&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/issues/8503&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;获取凭证&lt;/a&gt;，进而获得访问更多秘密的权限。如果您使用注释来描述应在出现问题的情况下联系的人员，请知道您正在为社交工程攻击创建额外的软目标。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3迁移到受限制的-pss&#34;&gt;步骤 3：迁移到受限制的 PSS&lt;/h3&gt;
&lt;p&gt;虽然基线是可允许但相对安全的，但“受限制”Pod Security 标准采用了目前加固 Pod 的最佳实践。正如 Red Hat 的 Mo Khan&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?t=1951&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾经描述&lt;/a&gt;的那样，受限制的标准确保“您能做的最糟糕的事情是毁掉自己”，而不是您的集群。&lt;/p&gt;
&lt;p&gt;使用受限制的标准，开发人员必须编写在只读模式下运行的应用程序，仅启用 Pod 运行所需的 Linux 功能，不能在任何时候升级特权等。&lt;/p&gt;
&lt;p&gt;我建议从基线开始并稍后迁移到受限制，作为单独的里程碑，因为后者几乎总是需要对现有的 Dockerfile 和 Kubernetes 配置进行主动更改。一旦您实例化并强制执行了受限制策略，您的配置将需要遵守这些策略，否则它们将被您的验证器或接入控制器拒绝。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3a压制而不是忽略不可避免的误报&#34;&gt;步骤 3a：压制而不是忽略不可避免的误报&lt;/h3&gt;
&lt;p&gt;在完成基线和受限制的里程碑时，您正在接近策略管理的更成熟（和复杂）水平。为了确保每个人都在当前策略里程碑方面保持一致，您应该开始处理虚假阳性或必须显式允许的配置，尽管违反了受限制的 PSS。&lt;/p&gt;
&lt;p&gt;在忽略规则或抑制规则之间进行选择时，始终选择抑制规则。这需要一个可审计的操作，具有日志或配置更改，以将例外情况编码为已建立的策略框架。您可以在源中添加抑制规则，直接添加到您的 K8s 配置中或在外部添加，其中开发人员请求其运维同行重新配置其验证器或接入控制器，以允许“误配置”通过。&lt;/p&gt;
&lt;p&gt;在 Monokle 中，您可以将抑制直接添加到您的配置中作为注释，使用&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;静态分析结果交换格式（SARIF）规范&lt;/a&gt;所称的&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/os/sarif-v2.1.0-os.html#_Toc34317739&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;理由&lt;/a&gt;：&lt;/p&gt;
&lt;h3 id=&#34;第-4-步加入常见加固指南&#34;&gt;第 4 步：加入常见加固指南&lt;/h3&gt;
&lt;p&gt;在这一步中，您已经超越了已有的 Kubernetes 安全框架，这意味着您需要更多地积极构建和努力实现自己的里程碑。&lt;/p&gt;
&lt;p&gt;美国国家安全局（NSA）和网络安全和基础设施安全局（CISA）有一份受欢迎的&lt;a href=&#34;https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 加固指南&lt;/a&gt;，其中详细介绍了不仅是 Pod 级别的改进措施，如有效地使用不可变容器文件系统，还包括网络分离、审计日志和威胁检测。&lt;/p&gt;
&lt;h3 id=&#34;第-5-步插入并播放&#34;&gt;第 5 步：插入并播放&lt;/h3&gt;
&lt;p&gt;在实施了一些或所有已有的加固指南之后，每个新的策略都涉及选择、信任和权衡。花些时间在谷歌或 StackOverflow 上，你就会发现很多推荐的插入和播放策略。&lt;/p&gt;
&lt;p&gt;你可以从众包策略中受益，其中许多来自于那些有着更独特经验的人，但请记住，虽然规则可能是出于良好意图的，但你并不了解推荐者的优先事项或操作上下文。他们知道如何实现某些“高挂水果”政策，因为他们不得不这样做，而不是因为这些政策普遍有价值。&lt;/p&gt;
&lt;p&gt;目前正在进行的辩论是是否以及如何严格限制容器的资源需求。对于请求限制也是如此。不配置限制可能会引入安全风险，但如果严重限制 Pod，它们可能无法正常运行。&lt;/p&gt;
&lt;h3 id=&#34;第-6-步添加自定义规则以应对未预料的特殊情况&#34;&gt;第 6 步：添加自定义规则以应对未预料的特殊情况&lt;/h3&gt;
&lt;p&gt;现在，你已经到了 Kubernetes 策略的远端，远离了导致生产负面影响的 20％的错误配置和漏洞。但即使现在，即使已经实施了所有的最佳实践和集体云原生知识，你仍然无法免疫不会意地引发事故或停机的错误配置 - 安全和稳定的奇妙未知未知。&lt;/p&gt;
&lt;p&gt;一个好的经验法则是，如果一个奇特的（错）配置在生产中引起了两次问题，那么就该将其编码为一条自定义规则，在开发过程中强制执行，或由准入控制器强制执行。它太重要了，不能仅在内部悄悄地记录下来，希望开发人员阅读它，在彼此的拉取请求审查中注意到它并捕获它。&lt;/p&gt;
&lt;p&gt;一旦编码到您现有的策略中，自定义规则就成为了您尽可能接近开发人员执行的防护栏杆。如果你可以在开发人员提交工作之前就用验证到达开发人员，Monokle Cloud 就可以无缝地执行这一点，使用自定义插件和您本地运行的开发服务器，那么您可以节省整个组织大量的重复工作和调整他们的拇指等待 CI/CD 管道无可避免地失败时他们可以构建新功能或修复错误。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果您实施了以上所述的所有框架和里程碑，并对您的 Dockerfile 和 Kubernetes 配置进行了所有必要的更改以满足这些新策略，那么您可能会发现您的 90 个主要漏洞清单已经减少到了一个更易管理的数量。&lt;/p&gt;
&lt;p&gt;您正在看到我们逐步塑造和执行 Kubernetes 策略的方法的价值。您与新策略和规则的影响互动得越多，就像 Monokle 在提交之前唯一做到的那样，就越容易在不压垮自己或其他人的情况下逐步迈出步伐。&lt;/p&gt;
&lt;p&gt;您甚至可能会自豪地宣称，您的 Kubernetes 环境完全没有配置错误。这是一种胜利，毫无疑问，但这不是保证 - 总会有新的 Kubernetes 版本、新的应用程序和新的最佳实践融入到您已经完成的工作中。利用框架和加固指南的优势在于，您有更好的共同基础来谈论您在认证、合规和长期安全目标方面的影响。&lt;/p&gt;
&lt;p&gt;对于非专家来说，哪种听起来更有说服力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;您将 CVE 数量从 90 个降至 X 个，&lt;/li&gt;
&lt;li&gt;还是您完全符合美国国家安全局的 Kubernetes 加固指南？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们越早不再担心数字，而是更多地关注共同里程碑，在应用程序生命周期的早期（理想情况下是 pre-commit！）尽早执行，我们就能找到每个云原生策略的可持续甜蜜点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes 故障排除智慧的演变</title>
      <link>https://cloudnative.to/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/</link>
      <pubDate>Sun, 10 Sep 2023 19:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/</guid>
      <description>&lt;p&gt;摘要：本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI/ML 模型和可观察性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观察性的一致认识的必要性。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文译自：https://thenewstack.io/can-chatgpt-save-collective-kubernetes-troubleshooting/&lt;/p&gt;
&lt;p&gt;数十年前，系统管理员们开始在互联网上分享他们每天面临的技术问题。他们进行了长时间、充满活力且富有价值的讨论，探讨如何调查和解决问题的根本原因，然后详细说明最终对他们有效的解决方案。&lt;/p&gt;
&lt;p&gt;这股洪流从未停歇，只是改变了流向。如今，这些讨论仍在 Stack Overflow、Reddit 以及企业工程博客上进行。每一次讨论都是对全球 IT 系统故障排除经验的宝贵贡献。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;也从根本上改变了这种流向。与几十年来困扰系统管理员和 IT 人员的虚拟机（VM）和单体应用程序相比，&lt;a href=&#34;https://thenewstack.io/microservices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务架构&lt;/a&gt;要复杂得多。由于 Kubernetes 缺乏数据持久性，往往无法对规模化的 K8s 错误进行本地重现。即使能够捕获，观测数据也会在多个平台上分散，而资源和依赖关系的相互关联关系也难以捕捉。&lt;/p&gt;
&lt;p&gt;现在，凭直觉并不一定足够。您需要知道如何调试集群以获得下一步的线索。&lt;/p&gt;
&lt;p&gt;这种复杂性意味着公开的故障排除讨论比以往任何时候都更为重要，但现在我们开始看到这股宝贵的洪流不是被重定向，而是完全被堵住了。你在谷歌上看到了这一点。任何与 Kubernetes 相关问题的搜索都会出现一半以上的付费广告和至少一页 SEO 驱动的文章，这些文章缺乏技术深度。&lt;a href=&#34;https://thenewstack.io/stack-overflow-adds-ai-will-the-community-respond/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow&lt;/a&gt; 正在失去其作为技术人员首选问答资源的主导地位，Reddit 在过去几年中也陷入了争议。&lt;/p&gt;
&lt;p&gt;现在，每个 Kubernetes 的 DevOps 平台都在建立最后一个堤坝：将您的故障排除知识集中在其平台上，并用&lt;a href=&#34;https://thenewstack.io/70-percent-of-developers-using-or-will-use-ai-says-stack-overflow-survey/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;人工智能（AI）和机器学习（ML）&lt;/a&gt;取而代之，直到整个堆栈对于甚至是最有经验的云原生工程师来说都成为一个黑盒。当发生这种情况时，您失去了逐个探测、排除故障和修复系统的能力。这种趋势将曾经是众包故障排除技能洪流变成了过去所能提供的仅仅是一滴水。&lt;/p&gt;
&lt;p&gt;当我们依赖于平台时，故障排除技术的集体智慧就会消失。&lt;/p&gt;
&lt;h2 id=&#34;故障排除智慧的传承&#34;&gt;故障排除智慧的传承&lt;/h2&gt;
&lt;p&gt;起初，系统管理员依靠实体书籍进行技术文档和整体最佳实践的实施。随着互联网在 80 年代和 90 年代的普及，这些人通常通过&lt;a href=&#34;https://today.duke.edu/2010/05/usenet.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Usenet&lt;/a&gt;与同行进行交流，并在像 comp.lang.* 这样的新闻组中提出工作中的技术问题，这类新闻组类似于我们今天所知的论坛的简化版本。&lt;/p&gt;
&lt;p&gt;随着互联网的普及迅速，并几乎完全改变了故障排除智慧的洪流。工程师和管理员们不再聚集在新闻组中，而是涌向包括 Experts Exchange 在内的数千个论坛，该论坛于 1996 年上线。在积累了大量的问题和答案之后，Experts Exchange 团队将所有答案都放在了每年 250 美元的付费墙后面，这使得无数宝贵的讨论无法公开获取，最终导致了该网站的影响力下降。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.joelonsoftware.com/2018/04/06/the-stack-overflow-age/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow 随后出现&lt;/a&gt;，再次向公众开放了这些讨论，并通过声望点数对讨论进行游戏化，这些声望点数可以通过提供见解和解决方案来获得。其他用户随后对“最佳”解决方案进行投票和验证，这有助于其他搜索者快速找到答案。Stack Overflow 的游戏化、自我管理和社区使其成为了洪流式故障排除知识的唯一渠道。&lt;/p&gt;
&lt;p&gt;但是，就像其他时代一样，没有什么好事能永远持续下去。近 10 年来，人们一直在预测&lt;a href=&#34;https://johnslegers.medium.com/the-decline-of-stack-overflow-7cb69faa575d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Stack Overflow 的衰落”&lt;/a&gt;，并指出由于其具有攻击性的性质和由拥有最多声望点数的人进行管理的结构，它“讨厌新用户”。虽然 Stack Overflow 的影响力和流行度确实下降了，但 Reddit 的开发/工程专注的 subreddit 填补了这个空白，它仍然是公开可访问的故障排除知识的最大存储库。&lt;/p&gt;
&lt;p&gt;特别是对于 Kubernetes 和云原生社区来说，这仍然是一个重要的资源，因为它们仍然在经历重大的增长阵痛。而这是一种宝贵的资源，因为如果您认为现在的 Kubernetes 已经很复杂了&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-的复杂性问题&#34;&gt;Kubernetes 的复杂性问题&lt;/h2&gt;
&lt;p&gt;在一篇关于“直观调试”失败的精彩文章中，软件交付顾问 Pete Hodgson 认为，构建和交付软件的现代架构（如 Kubernetes 和微服务）比以往任何时候都更加复杂。他写道：“对于我们大多数人来说，为服务器命名为希腊神话角色，并通过 ssh 进入服务器运行&lt;code&gt;tail&lt;/code&gt;和&lt;code&gt;top&lt;/code&gt;的日子已经一去不复返了。”但是，“这种转变是有代价的……传统的理解和故障排除生产环境的方法在这个新世界中已经行不通了。”&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cynefin-模型&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cynefin 模型&#34; srcset=&#34;
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hua353e1f3a668859fa4d7a161556969e4_94124_bc813e5da2f806022c76773eb056f8e6.webp 400w,
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hua353e1f3a668859fa4d7a161556969e4_94124_6570ccc58d88a6ef37457e3c8bdedde7.webp 760w,
               /blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hua353e1f3a668859fa4d7a161556969e4_94124_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hua353e1f3a668859fa4d7a161556969e4_94124_bc813e5da2f806022c76773eb056f8e6.webp&#34;
               width=&#34;760&#34;
               height=&#34;676&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cynefin 模型
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Cynefin 模型。来源：维基百科&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hodgson 使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Cynefin_framework&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cynefin 模型&lt;/a&gt;来说明软件架构过去是复杂的，因为有足够的经验，人们可以理解故障排除和解决方案之间的因果关系。&lt;/p&gt;
&lt;p&gt;他认为，分布式微服务架构是复杂的，即使经验丰富的人对根本原因以及如何进行故障排除也只有“有限的直觉”。他们必须花更多时间通过可观察性数据提出问题和回答问题，最终假设可能出错的原因。&lt;/p&gt;
&lt;p&gt;如果我们同意 Hodgson 的前提 - Kubernetes 本质上是复杂的，并且在响应之前需要花费更多的时间分析问题，那么与 Kubernetes 一起工作的工程师学会了哪些问题最重要，然后用可观察性数据回答，以进行最佳的下一步行动，似乎是至关重要的。&lt;/p&gt;
&lt;p&gt;这正是新一代以 AI 驱动的故障排除平台所提供的智慧。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-故障排除的两种路径&#34;&gt;Kubernetes 故障排除的两种路径&lt;/h2&gt;
&lt;p&gt;多年来，像 OpenAI 这样的公司一直在根据 Stack Overflow、Reddit 等公开数据进行抓取和训练模型，这意味着这些 AI 模型可以访问大量的系统和应用知识，包括 Kubernetes。还有一些人意识到组织的可观察性数据是训练 AI/ML 模型分析新场景的宝贵资源。&lt;/p&gt;
&lt;p&gt;他们都在问同一个问题：我们如何利用关于 Kubernetes 的现有数据来简化搜索最佳解决方案的过程？他们正在构建的产品采取非常不同的路径。&lt;/p&gt;
&lt;h3 id=&#34;第一种增强操作员的分析工作&#34;&gt;第一种：增强操作员的分析工作&lt;/h3&gt;
&lt;p&gt;这些工具自动化和简化对公开在线发布的大量故障排除知识的访问。它们不会取代进行适当故障排除或&lt;a href=&#34;https://aws.amazon.com/opensearch-service/resources/root-cause-analysis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;根本原因分析&lt;/a&gt;（RCA）所需的人类直觉和创造力，而是有条不紊地自动化操作员查找相关信息的方式。&lt;/p&gt;
&lt;p&gt;例如，如果一个刚接触 Kubernetes 的开发人员在运行&lt;code&gt;kubectl get pods&lt;/code&gt;时发现&lt;code&gt;CrashLoopBackOff&lt;/code&gt;状态导致他们无法部署应用程序，他们可以查询一个 AI 驱动的工具以获得建议，比如运行&lt;code&gt;kubectl describe $POD&lt;/code&gt;或&lt;code&gt;kubectl logs $POD&lt;/code&gt;。这些步骤可能会进一步引导开发人员使用&lt;code&gt;kubectl describe $DEPLOYMENT&lt;/code&gt;来调查相关的部署情况。&lt;/p&gt;
&lt;p&gt;在&lt;a href=&#34;https://botkube.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Botkube&lt;/a&gt;，我们对使用 AI 在大量故障排除智慧的基础上自动化这个来回查询的概念非常感兴趣。用户应该能够直接在 Slack 中提问，如“我如何排除这个无法正常工作的服务？”并收到 ChatGPT 撰写的回答。在一次公司范围的黑客马拉松活动中，我们着手实施这一概念，为我们的协作故障排除平台构建了一个新的插件。&lt;/p&gt;
&lt;p&gt;通过&lt;a href=&#34;https://botkube.io/blog/use-chatgpt-to-troubleshoot-kubernetes-errors-with-botkubes-doctor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doctor&lt;/a&gt;，您可以利用大量的故障排除知识，通过 Botkube 作为您的 Kubernetes 集群和消息/协作平台之间的桥梁，无需在 Stack Overflow 或 Google 搜索广告中漫游，这对于新手 Kubernetes 开发人员和操作员特别有用。&lt;/p&gt;
&lt;p&gt;该插件还通过生成一个带有&lt;strong&gt;获取帮助&lt;/strong&gt;按钮的 Slack 消息进一步自动化，用于任何错误或异常，然后查询 ChatGPT 以获取可行的解决方案和下一步操作。您甚至可以将 Doctor 插件的结果导入其他操作或集成，以简化您主动使用现有广泛的 Kubernetes 故障排除知识来更直观地调试和感知问题的方式。&lt;/p&gt;
&lt;h3 id=&#34;第二种将操作员从故障排除中排除&#34;&gt;第二种：将操作员从故障排除中排除&lt;/h3&gt;
&lt;p&gt;这些工具不关心公开知识的泛滥。如果它们可以基于实际的可观察性数据训练通用的 AI/ML 模型，然后根据您的特定架构进行微调，它们可以试图完全剔除人为操作员在根本原因分析和故障修复中的作用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.causely.io/platform/causely-for-kubernetes-applications/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Causely&lt;/a&gt;就是这样一家初创公司，他们并不回避使用 AI 来“消除人为故障排除”的愿景。该平台连接到您现有的可观察性数据，并处理它们以微调因果关系模型，理论上可直接进行修复步骤 - 无需探测或使用&lt;code&gt;kubectl&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果说有时候有一个 Kubernetes 神灵听起来很诱人，那我可能会撒谎，但我对像 Causely 这样的工具夺走运维工作并不担心。我担心的是在 Causely 引领的未来中，我们宝贵的故障排除知识会发生什么。&lt;/p&gt;
&lt;h3 id=&#34;这两种路径之间的差距数据&#34;&gt;这两种路径之间的差距：数据&lt;/h3&gt;
&lt;p&gt;我不是在为“人工智能将取代所有 DevOps 工作”发表言论。我们已经读过太多这样的末日场景，适用于每个小众和行业。我更关心这两种路径之间的差距：用于训练和回答问题或呈现结果的数据是什么？&lt;/p&gt;
&lt;p&gt;第一种路径通常使用现有的公开数据。尽管有关 AI 公司爬取这些站点进行训练数据的担忧-Reddit 和 Twitter，但这些数据的开放性仍然提供了一个激励循环，以保持开发人员和工程师继续在 Reddit、Stack Overflow 和其他平台上共享知识的持续泛滥。&lt;/p&gt;
&lt;p&gt;云原生社区通常也倾向于共享技术知识，认同共享技术知识和一个“涨潮（Kubernetes 故障排除技巧的涨潮）抬高所有船（压力巨大的 Kubernetes 工程师）”的想法。&lt;/p&gt;
&lt;p&gt;第二条路径看起来更为暗淡。随着以 AI 驱动的 DevOps 平台的兴起，越来越多的故障排除知识被锁定在这些仪表板和驱动平台的专有 AI 模型中。我们都同意，Kubernetes 基础架构将继续变得更加复杂，而不是更简单，这意味着随着时间的推移，我们对节点、Pod 和容器之间发生的情况的理解将变得更少。&lt;/p&gt;
&lt;p&gt;当我们停止互相分析问题和感知解决方案时，我们变得依赖于平台。这对每个人来说都是一条失败的道路，除了平台之外。&lt;/p&gt;
&lt;h3 id=&#34;我们如何不失去或失去得更少&#34;&gt;我们如何不失去（或失去得更少）？&lt;/h3&gt;
&lt;p&gt;我们能做的最好的事情是继续在线上发布关于我们在 Kubernetes 和其他领域的故障排除经验的惊人内容，比如“&lt;a href=&#34;https://learnk8s.io/troubleshooting-deployments&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;关于故障排除 Kubernetes 部署的视觉指南&lt;/a&gt;”；通过游戏化创造教育性应用程序，比如&lt;a href=&#34;https://sadservers.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SadServers&lt;/a&gt;；在故障排除系统时采取我们最喜欢的第一步，比如“&lt;a href=&#34;https://rachelbythebay.com/w/2018/03/26/w/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;为什么在排除未知机器问题时我通常首先运行‘w’&lt;/a&gt;”；并进行详细的事后分析，详细描述了探测、感知和应对潜在灾难性情况的压力故事，比如&lt;a href=&#34;https://mail.tarsnap.com/tarsnap-announce/msg00050.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023 年 7 月的 Tarsnap 故障&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们还可以超越技术解决方案，比如讨论我们如何在紧张的故障排除场景中管理和支持同事，或者在组织范围内建立对可观察性的一致认识。&lt;/p&gt;
&lt;p&gt;尽管它们目前面临困境，但 Stack Overflow 和 Reddit 将继续是讨论故障排除和寻求答案的可靠渠道。如果它们最终与 Usenet 和 Experts Exchange 齐名，它们可能会被其他可公开获得的替代品所取代。&lt;/p&gt;
&lt;p&gt;无论何时何地以何种方式发生，我希望您能加入我们在 Botkube 和全新的 Doctor 插件中，为在 Kubernetes 中协作解决复杂问题构建新的渠道。&lt;/p&gt;
&lt;p&gt;无论 AI 驱动的 DevOps 平台是否继续基于抓取的公共 Kubernetes 数据训练新模型，只要我们不自愿地将好奇心、冒险精神和解决问题的能力全部放入这些黑匣子中，就会始终有一条新路径，让宝贵的故障排除知识源源不断地流动。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>将 AI 应用于 WebAssembly 还为时过早吗？</title>
      <link>https://cloudnative.to/blog/is-it-too-early-to-leverage-ai-for-webassembly/</link>
      <pubDate>Thu, 07 Sep 2023 21:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/is-it-too-early-to-leverage-ai-for-webassembly/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：Fermyon Technologies 认为，将 AI 应用于 WebAssembly 并不为时过早。WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。Fermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了企业级 AI 应用程序成本高的问题。这是一种共生关系。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;人工智能及其在 IT、软件开发和运营方面的应用刚开始发挥作用，预示着人类角色将如何在近期和长期内演变，特别是在较小的规模上，WebAssembly 代表着一种正在引起重大关注的技术，同时证明了其可行性，但成功的商业模型尚未实现，主要是由于最终端点的缺乏标准化。与此同时，至少有一家供应商 Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。&lt;/p&gt;
&lt;p&gt;那么，AI 如何潜在地帮助 Wasm 的开发和采用，这是否为时过早？正如 VMware CTO 办公室的高级工程师 Angel M De Miguel Meana 所指出的那样，自从 ChatGPT 推出以来，AI 生态系统已经发生了巨大的变化，WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。由于 Wasm 生态系统仍在兴起，因此在早期阶段集成 AI 将有助于推动新的和现有的与 AI 相关的标准。这是一种共生关系。&lt;/p&gt;
&lt;h2 id=&#34;完美的匹配&#34;&gt;完美的匹配&lt;/h2&gt;
&lt;p&gt;Fermyon Technologies 的联合创始人兼首席执行官 Matt Butcher 告诉 The New Stack：“我们成立 Fermyon 的目标是打造下一代无服务器平台。AI 显然是这一下一代的一部分。在我们的行业中，我们经常看到革命性的技术一起成长：Java 和 Web、云和微服务、Docker 和 Kubernetes。WebAssembly 和 AI 是一对完美的组合。我看到它们一起成长（并变老）。”&lt;/p&gt;
&lt;p&gt;“烘焙”AI 模型，如 LLM（大型语言模型）或转换器，到 WebAssembly 运行时中，是加速采用 WebAssembly 的逻辑下一步，Enterprise Management Associates (EMA) 的分析师 Torsten Volk 告诉 The New Stack。与调用诸如通过 API 的数据库服务类似，编译 WebAssembly 应用程序（二进制文件）可以将其 API 请求发送到 WebAssembly 运行时，该运行时将该调用中继到 AI 模型并将模型响应返回给发起者，Volk 说。&lt;/p&gt;
&lt;p&gt;“一旦我们有一个提供开发人员一个标准 API 的通用组件模型（CCM），访问数据库、AI 模型、GPU、消息传递、身份验证等，这些 API 请求将变得非常强大。CCM 将让开发人员编写相同的代码，在数据中心、云甚至边缘位置的任何类型的服务器上与 AI 模型（例如 GPT 或 Llama）进行通信，只要该服务器拥有足够的硬件资源可用，”Volk 说。“这一切都归结为关键问题，即产业参与者何时会就 CCM 达成一致。同时，WebAssembly 云（如 Fermyon）可以利用 WebAssembly 使 AI 模型在其自己的云基础设施中具有可移植性和可扩展性，无需 CCM，并将一些节省成本传递给客户。”&lt;/p&gt;
&lt;h2 id=&#34;解决问题&#34;&gt;解决问题&lt;/h2&gt;
&lt;p&gt;同时，Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。正如 Butcher 所指出的那样，负责在 LLM（如 LLaMA2）上构建和运行企业 AI 应用程序的开发人员面临着 100 倍计算成本的挑战，即每小时 32 美元及以上的 GPU 访问费用。或者，他们可以使用按需服务，但是启动时间却非常慢。这使得以实惠的方式提供企业级 AI 应用程序变得不切实际。&lt;/p&gt;
&lt;p&gt;Fermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了这个问题，Butcher 说。这一“突破”得益于驱动 Fermyon Cloud 的服务器 WebAssembly 技术，该技术被架构为亚毫秒冷启动和高容量时间分片的计算实例，已被证明可以将计算密度提高 30 倍。“将此运行时配置文件扩展到 GPU 将使 Fermyon Cloud 成为最快的 AI 推理基础设施服务，”Butcher 说。&lt;/p&gt;
&lt;p&gt;Volk 说，这样的推理服务“非常有趣”，因为典型的 WebAssembly 应用程序仅包含几兆字节，而 AI 模型的大小要大得多。这意味着它们不会像传统的 WebAssembly 应用程序那样启动得那么快。“我认为 Fermyon 已经想出了如何使用时间分片为 WebAssembly 应用程序提供 GPU 访问的方法，以便所有这些应用程序都可以通过其 WebAssembly 运行时保留一些时间片来获取所需的 GPU 资源”，Volk 说。“这意味着很多应用程序可以共享一小部分昂贵的 GPU，以按需为其用户提供服务。这有点像分时共享，但不需要强制参加午餐时间的演示。”&lt;/p&gt;
&lt;p&gt;使用 Spin 入门。&lt;/p&gt;
&lt;p&gt;!https://prod-files-secure.s3.us-west-2.amazonaws.com/86575c70-5cc9-4b3e-bee7-d1bb14ba20e3/6bf78916-e34c-4051-86a7-52145cdc372a/4a27b287-capture-decran-2023-09-05-192118.png&lt;/p&gt;
&lt;p&gt;那么，用户如何与 Serverless AI 交互？Fermyon 的 Serverless AI 没有 REST API 或外部服务，它仅构建在 Fermyon 的 Spin 本地和 Fermyon Cloud 中，Butcher 解释说。“在您的代码的任何位置，您都可以将提示传递到 Serverless AI 并获得响应。在这个第一个测试版中，我们包括 LLaMa2 的聊天模型和最近宣布的 Code Llama 代码生成模型，”Butcher 说。“因此，无论您是在总结文本、实现自己的聊天机器人还是编写后端代码生成器，Serverless AI 都可以满足您的需求。我们的目标是使 AI 变得简单，使开发人员可以立即开始利用它来构建新的令人瞩目的无服务器应用程序。”&lt;/p&gt;
&lt;h2 id=&#34;重要意义&#34;&gt;重要意义&lt;/h2&gt;
&lt;p&gt;使用 WebAssembly 来运行工作负载，可以使用 Fermyon Serverless AI 将“GPU 的一小部分”分配给用户应用程序，以“及时”执行 AI 操作，Fermyon CTO 和联合创始人 Radu Matei 在一篇博客文章中写道。 “当操作完成时，我们将该 GPU 的一小部分分配给队列中的另一个应用程序，”Matei 写道。“由于 Fermyon Cloud 中的启动时间为毫秒级，因此我们可以在分配给 GPU 的用户应用程序之间快速切换。如果所有 GPU 分数都在忙于计算数据，我们将在下一个可用的应用程序之前将传入的应用程序排队。”&lt;/p&gt;
&lt;p&gt;这有两个重大的影响，Matei 写道。首先，用户不必等待虚拟机或容器启动并附加到 GPU 上。此外，“我们可以实现更高的资源利用率和效率，”Matei 写道。&lt;/p&gt;
&lt;p&gt;Fermyon 传达的 Serverless AI 的具体特点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是一款开发人员工具和托管服务，专为使用开源 LLM 进行 AI 推理的无服务器应用程序而设计。&lt;/li&gt;
&lt;li&gt;由于我们的核心 WebAssembly 技术，我们的冷启动时间比竞争对手快 100 倍，从几分钟缩短到不到一秒。这使我们能够在相同的时间内（并且使用相同的硬件）执行数百个应用程序（二进制文件），而今天的服务用于运行一个。&lt;/li&gt;
&lt;li&gt;我们为使用 Spin 构建和运行 AI 应用程序提供了本地开发体验，然后将其部署到 Fermyon Cloud 中，以高性能的方式以其他解决方案的一小部分成本提供服务。&lt;/li&gt;
&lt;li&gt;Fermyon Cloud 使用 AI 级别的 GPU 处理每个请求。由于我们的快速启动和高效的时间共享，我们可以在数百个应用程序之间共享单个 GPU。&lt;/li&gt;
&lt;li&gt;我们正在推出免费的私人测试版。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;大希望&#34;&gt;大希望&lt;/h2&gt;
&lt;p&gt;然而，在 Wasm 和 AI 同时达到潜力之前，还有很长的路要走。在 WasmCon 2023 上，Second State 的 CEO 兼联合创始人 Michael Yuan 和 Wasm 的运行时项目以及 WasmEdge 的讨论了一些正在进行的工作。他在与 De Miguel Meana 的谈话中涵盖了这个话题，“开始使用 AI 和 WebAssembly”在 WasmCon 2023 上。&lt;/p&gt;
&lt;p&gt;“在这个领域（AI 和 Wasm）需要做很多生态系统工作。例如，仅拥有推理是不够的，”Yuan 说。“现在的百万美元问题是，当您拥有图像和文本时，如何将其转换为一系列数字，然后在推理之后如何将这些数字转换回可用的格式？”&lt;/p&gt;
&lt;p&gt;预处理和后处理是 Python 今天最大的优势之一，这得益于为这些任务提供的众多库，Yuan 说。将这些预处理和后处理函数合并到 Rust 函数中将是有益的，但需要社区更多的努力来支持其他模块。“这个生态系统有很大的增长潜力，”Yuan 说。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
