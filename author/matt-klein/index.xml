<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matt Klein | 云原生社区（中国）</title>
    <link>https://cloudnative.to/author/matt-klein/</link>
      <atom:link href="https://cloudnative.to/author/matt-klein/index.xml" rel="self" type="application/rss+xml" />
    <description>Matt Klein</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://cloudnative.to/author/matt-klein/avatar_hua55550e6532f142b60895d906d8ec485_27449_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Matt Klein</title>
      <link>https://cloudnative.to/author/matt-klein/</link>
    </image>
    
    <item>
      <title>网络代理 Envoy 开源五周年，创始人 Matt Klein 亲述开源心路历程及经验教训</title>
      <link>https://cloudnative.to/blog/envoy-oss-5-year/</link>
      <pubDate>Wed, 15 Sep 2021 10:41:54 +0800</pubDate>
      <guid>https://cloudnative.to/blog/envoy-oss-5-year/</guid>
      <description>&lt;p&gt;译者注：本文译自 Envoy 代理的创始人 Matt Klein 于昨晚在个人博客上发布的文章 &lt;a href=&#34;https://mattklein123.dev/2021/09/14/5-years-envoy-oss/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;5 year of Envoy OSS&lt;/a&gt;。他在 Twitter 因为自己的程序 bug 造成重大事故而离职，后加入 Lyft，在开源 Envoy 之前几乎没有贡献和管理开源项目的经验，这篇文章分享了他个人及 Envoy 开源的心路历程，在投身开源 Envoy 还是为雇主 Lyft 效命，该如何抉择？看完本文，相信对于开源项目的维护者、创业者及投资人都会大有收获。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;今天是 &lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy Proxy 开源&lt;/a&gt;的 &lt;a href=&#34;https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;5 周年&lt;/a&gt;。毫不夸张地说，在专业方面，过去的 5 年是一个史诗般的过山车，我的情绪介于兴奋、自豪、焦虑、尴尬、无聊、倦怠之间。我想分享一下这个项目的前传和历史，以及我在发展大型开源软件项目的过程中所学到的一些经验教训。&lt;/p&gt;
&lt;h2 id=&#34;前传和历史&#34;&gt;前传和历史&lt;/h2&gt;
&lt;h3 id=&#34;前传&#34;&gt;前传&lt;/h3&gt;
&lt;p&gt;除了一些小的弯路，我在技术行业二十年的职业生涯一直专注于底层系统：嵌入式系统，操作系统，虚拟化，文件系统，以及最近的分布式系统网络。我的分布式系统网络之旅始于 2010 年初在亚马逊，我有幸帮助开发了第一批高性能计算（HPC）EC2 实例类型。我学到了大量的底层高性能计算机网络知识，尽管我对分布式系统的概念接触有限。&lt;/p&gt;
&lt;p&gt;2012 年，我加入了 Twitter，在经历了几次错误的开始后，我最终加入了边缘网络团队。这是我第一次真正接触到分布式系统应用网络概念。我领导了一个新的 HTTP 边缘代理的开发，称为 Twitter 流式聚合器（TSA），它在 2013 年首次推出，以扩大 Twitter 的“firehose”API（流式所有推文）的交付。在 2014 年世界杯前夕，我们决定将 TSA 作为一个通用的 HTTP/HTTP2/TLS 边缘代理，在靠近巴西赛事的存在点（POPs）推出。这样做的主要原因是不可能在 POP 的少量主机托管机架上部署现有的基于 JVM 的资源匮乏的边缘代理。项目周期特别紧张，我的团队成功地完成了一届没有事故的世界杯。（我还清楚地记得有一段时间，当软件崩溃时，不管是什么时候，我都会给自己打上一页，修复错误，然后重新进行金丝雀部署，继续测试）。在 Twitter 工作期间，我还接触到了该公司通过 Finagle 库进行服务间网络通信的方式，并取得了巨大成功。&lt;/p&gt;
&lt;p&gt;2015 年元旦前后，我在 Twitter 的日子里，因为我写的一个 bug，TSA 系统故障导致数百万 Twitter 的安卓用户被下线，这将是我在 Twitter 工作的尾声。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-oss-5-year/008i3skNly1guh3vblu9xj60tu0eu76p02_hubd4583d756fbe27b6a689d8708ccd16d_92801_fc52990c8ab82d8af72a364d6d6af14e.webp 400w,
               /blog/envoy-oss-5-year/008i3skNly1guh3vblu9xj60tu0eu76p02_hubd4583d756fbe27b6a689d8708ccd16d_92801_74a8f51698dde13b778fee25ce6303f7.webp 760w,
               /blog/envoy-oss-5-year/008i3skNly1guh3vblu9xj60tu0eu76p02_hubd4583d756fbe27b6a689d8708ccd16d_92801_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-oss-5-year/008i3skNly1guh3vblu9xj60tu0eu76p02_hubd4583d756fbe27b6a689d8708ccd16d_92801_fc52990c8ab82d8af72a364d6d6af14e.webp&#34;
               width=&#34;760&#34;
               height=&#34;378&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;加入-lyft-和创建lyft-代理&#34;&gt;加入 Lyft 和创建“Lyft 代理”&lt;/h3&gt;
&lt;p&gt;我在 2015 年春天离开了 Twitter，部分原因是下线事件的影响，部分原因是对没有得到晋升的挫败感，部分原因是想尝试新的东西。我跟着我的老板从 Twitter 到了 Lyft，还有我在 Twitter 的其他同事。&lt;/p&gt;
&lt;p&gt;当我加入 Lyft 时，公司规模相对较小（少于 100 名工程师），并且正在努力从单体架构迁移到微服务架构。我已经&lt;a href=&#34;https://mattklein123.dev/appearances/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;多次&lt;/a&gt;谈到了 Envoy 的这部分历程，所以我不会再重述，在此简短的总结下，Lyft 遇到了所有典型的微服务迁移问题，主要是源于网络和可观察性。此外，Lyft 已经是“多面手”（使用多种语言和框架），所以使用基于库的解决方案来解决这些问题似乎不切实际。因此，根据我以前建立 TSA 的经验和观察服务间通信在 Twitter 的工作方式，由于得到在 Lyft 的前 Twitter 同事们的信任，我提议建立一个新的应用网络系统，称为“Lyft 代理”。&lt;/p&gt;
&lt;p&gt;经过一些激烈的讨论，包括新的代理是否应该用 Python 构建（是的，真的），我们就项目的大致轮廓达成一致，并决定使用 C++ 作为实现语言。在当时，C++ 似乎是唯一合理的选择。今天我还会选择 C++ 吗？然而，如今已经不是 2015 年初了。&lt;/p&gt;
&lt;p&gt;如果不说“Envoy&amp;quot; 这个名字的由来，这部分的历史就不完整了。我们正在为这个项目建立最初的开发脚手架的时候，一个有远见的同事（Ryan Lane）说，我们不能把这个新项目叫做“Lyft 代理”，我们必须选择一个更好的名字。我总是很实际，就去找辞典，查了一下“代理”，然后决定用 Envoy 作为新名字。&lt;/p&gt;
&lt;h3 id=&#34;在-lyft-上线&#34;&gt;在 Lyft 上线&lt;/h3&gt;
&lt;p&gt;直到 2015 年夏天，我才开始认真地研究 Envoy 的源代码。那几个月是我职业生涯中最有趣的几个月。我们应该珍惜这段初创时期，因为它不会持续很久。我花了很长时间，争取在合理的时间内（根据我的定义，这种类型的项目需要 3-4 个月的时间）做出能给 Lyft 带来价值的东西。俗话说，Lyft 给了我大量的绳子来吊死自己，而我致力于确保这种吊死不会发生。&lt;/p&gt;
&lt;p&gt;当然，我的效率主要归功于刚从压缩的开发时间表和许多错误（主要是我自己的）中走出来，在 Twitter 的 TSA。我知道哪些错误是不能犯的，哪些抽象是需要的，哪些测试有效，哪些无效，等等。&lt;/p&gt;
&lt;p&gt;2015 年秋天准备投入生产的 Envoy 的最初版本只包含了该项目今天所包含的功能和复杂性的一小部分。它不支持 TLS，只支持 HTTP/1，并且有极其简单的路由和弹性功能。它所拥有的是你今天所看到的东西的骨架。在这个项目的历史上，很少有重大的重构，主要是因为，正如我之前所说的，我知道将要发生什么，以及为了支持这些功能，需要有哪些抽象。Envoy 从一开始就拥有一流的可观察性输出，以指标和日志的形式。在 2021 年，这种类型的网络可观察性是桌面上的赌注（这在很大程度上要归功于 Envoy 的成功），但在当时却不是这样。&lt;/p&gt;
&lt;p&gt;Envoy 最初是作为边缘代理在 Lyft 上线的，位于提供 TLS 终止的 AWS ELB 后面。到 2015 年秋末，Envoy 为 Lyft 的 100% 流量提供服务，该系统产生的边缘仪表盘立即得到了回报（例如，提供 API 调用百分点延迟直方图，每个终端的成功率和请求率等）。&lt;/p&gt;
&lt;p&gt;在最初推出后不久，另一位 Twitter 同事（Bill Gallagher）加入了我的项目，我们迅速增加了一些功能，如 TLS 终止、HTTP/2 支持、更多路由和负载平衡功能等。&lt;/p&gt;
&lt;p&gt;与此同时，Lyft 基于 Envoy 的“服务网格 &amp;quot; 也开始成形了。首先，Envoy 被部署在 PHP 单片机旁边，以取代 HAProxy 及其一些固有的运维问题（例如，当时 HAProxy 仍然是单线程的），以帮助 MongoDB 的代理。可以毫不夸张地说，Envoy 的早期开发有很大一部分是针对 MongoDB 的稳定性（负载均衡、速率限制、可观察性等）。&lt;/p&gt;
&lt;p&gt;基于 Envoy 的边缘机群和单体之间的直接观察能力的好处是非常明显的。不久之后，我们在一些高 RPS 分解的微服务旁边部署了 Envoy，以帮助排除网络问题。这方面的价值也得到了证明。随着时间的推移，我们超越了对可观察性的关注，增加了帮助系统可靠性的功能，如直接连接和服务发现（跳过内部 ELB）、异常值检测、健康检查、重试、断路等。Lyft 的基于负载的重大事件的数量从每 1-2 周一次慢慢减少。当然，Envoy 不能将所有此类事件的减少归功于此，但它提供的网络抽象确实有很大的帮助。&lt;/p&gt;
&lt;p&gt;2016 年初，我们决定推动一个 100% 覆盖的服务网格。最初，我们认为这将是一个艰难的过程，需要自上而下的授权。在实践中，&lt;strong&gt;团队报名参加了迁移，因为他们将得到的好处是显而易见的&lt;/strong&gt;。“胡萝卜 &amp;ldquo;式的迁移几乎总是成功的。而“大棒&amp;rdquo; 式的迁移则很少成功，或者即使成功了，也会在组织内留下眼泪和愤怒。&lt;/p&gt;
&lt;p&gt;到 2016 年中期，Envoy 被用于 Lyft 的所有网络通信，包括边缘服务、服务间通信、数据库、外部合作伙伴等。无论从哪个角度来看，该项目都取得了巨大的成功，帮助 Lyft 完成了微服务的迁移，提高了整体的可靠性，并对网络进行了抽象，使大多数工程师不需要了解真实的系统拓扑结构。此后，Bill 离开了这个项目，在 Lyft 从事其他工作，接替他的是 Roman Dzhabarov 和 Constance Caramanolis 加入我的团队。我们的小团队为整个 Lyft 开发和运维 Envoy。&lt;/p&gt;
&lt;h3 id=&#34;开放源码&#34;&gt;开放源码&lt;/h3&gt;
&lt;p&gt;到 2016 年夏天，我们开始认真讨论开源 Envoy 的问题。早期的 Lyft 员工对开源和它为公司所做的事情很欣赏。很明显，Envoy 并不是 Lyft 的主要业务，那么为什么不把它放在那里并给予回报呢？我可以坦率地说，我们都带着不同的目标和期望来对待开放源代码的过程，以及对项目获得巨大成功后会发生什么感到非常天真。&lt;/p&gt;
&lt;p&gt;在加入 Envoy 之前，我已经使用了相当多的开源软件，但我几乎没有开源贡献的经验，也没有维护者的经验。（虽然我在 Linux 内核中有过&lt;a href=&#34;https://github.com/torvalds/linux/commit/00370b8f8dd6e3171b8202f9c5187a5f73e99497&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一次提交&lt;/a&gt;！）开源 Envoy 似乎是一个很好的机会，可以扩展我的技能组合，学习新的东西，可能会促进我的职业生涯，坦率地说，我不希望有一个 TSA v3 在第三家公司出现。对于 Lyft 来说，Envoy 是一个重要的工程项目，领导层认为，开放源代码将使 Lyft 作为一个工程组织具有可信度，并有助于招聘工作。正如我之前所说，我们所有人都对创建成功的开源，更重要的是在它获得成功的情况下培育它所需要的东西感到天真。&lt;/p&gt;
&lt;p&gt;但是，我们决定给它一个机会。我们在 2016 年夏天花了很大一部分时间来编写文档（Jose Nino 在这个时候加入了团队，他的第一个任务就是阅读并帮助改进所有的文档），清理存储库，使其 &amp;quot; 不那么尴尬”，制作网站，发布博文等等。我真的很感谢这段时间里我在 Lyft 的同事，他们不仅支持我们，还帮助我们完成了无数的任务，包括网站设计、logo 等等。即使在这个早期阶段，我们也觉得第一印象很重要，如果我们要在开源领域有所作为，就必须通过高质量的文档、网站等给人留下良好的第一印象。&lt;/p&gt;
&lt;p&gt;在此期间，我们还利用我们的行业关系，与 Lyft 的一些“同行公司”（湾区的“独角兽 &amp;quot; 互联网创业公司）会面，向他们展示我们在 Envoy 方面所做的工作，并获得他们的反馈，我们认为如果我们在正式开源前成功获得一个启动合作伙伴，这将是对项目的一个重大帮助。所有这些会议都非常友好，总的来说，所有与我们会面的公司都对我们所取得的成就印象深刻。但是，事后看来，他们都表示，以他们的小型基础设施团队，不可能马上采用 Envoy。他们祝愿我们在开放源代码方面取得最好的成绩，并说他们以后会回来看看。我们不禁对这些会议的结果感到沮丧，但我们还是向前推进了。&lt;/p&gt;
&lt;p&gt;2015 年 8 月，我与谷歌进行了第一次友好的会面。一个 Lyft 的同事（Chris Burnett）在一个 gRPC 聚会上发言，提到了 Envoy，因为它与 Envoy 的 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/other_protocols/grpc#grpc-bridging&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gRPC 桥接&lt;/a&gt;支持有关。我不知道的是，谷歌在发现 Envoy 的时候，正准备在 NGINX 的基础上推出 Istio。一次会议引出了另一次会议，然后是更多的会议，在 Envoy 开源之前，大量的谷歌员工已经看到了源代码和文档。(稍后会有更多关于这方面的内容）。&lt;/p&gt;
&lt;p&gt;到 9 月初，我们已经准备好了，并将开源日定为 9 月 14 日。总的来说，我是一个（过度？）自信的人，但在我的生活中，有几次我对自己成功的能力有很大的焦虑。我立即想到的是：开始上高中，开始上大学，以及大学毕业后在微软工作。而开源的 Envoy 就是其中之一。我记得我被公众的反应吓坏了。人们会怎么说？反馈会是积极的还是恶毒的？虽然我们在开源时是一个小团队，但我仍然写了 90% 或更多的代码，并且觉得把它放到公共领域是对我自己和我的能力的一种反映。&lt;/p&gt;
&lt;p&gt;如期而至，&lt;a href=&#34;https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt; 在 2016 年 9 月 14 日 &lt;a href=&#34;https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;成为开源产品&lt;/a&gt;。我记得我和妻子一起庆祝，并说了一些话。“如果我们能让其他公司像 Lyft 一样使用 Envoy，我就会很高兴。”&lt;/p&gt;
&lt;p&gt;对开放源码发布的反应几乎是普遍的积极。令我们惊讶的是，几乎是立刻，我们开始听到大公司的声音，而不是小公司。在几周内，我们与苹果、微软进行了交谈，与谷歌的对话也不断加快。大公司在现有的解决方案中存在问题，并且有大量的团队准备投入到解决这些问题的工作中。具有讽刺意味的是（至少在 Twitter 的观点中），C++ 在这里是一种帮助，而不是一种阻碍。这些大公司都已经拥有充足的 C/C++ 开发资源，以及他们想要整合的现有库，等等。对他们来说，C++ 是一个卖点。&lt;/p&gt;
&lt;p&gt;在这段时间里，毫不奇怪，我们与谷歌的人有最多的互动。最初主要是构建 Istio 的团队，但渐渐地，我们与 Anna Berenberg 花了更多时间，她现在是谷歌的杰出工程师，领导各种网络和负载均衡工作。这种关系将产生 &amp;quot; 喷气燃料”，在 2017 年初真正启动该项目。&lt;/p&gt;
&lt;h3 id=&#34;开始起飞&#34;&gt;开始起飞&lt;/h3&gt;
&lt;p&gt;到了 2017 年初，很明显，Envoy 的开发正在加速。谷歌承诺用 Envoy 取代 NGINX，用于 Istio（最终在 2017 年春季推出），对项目的未来来说更重要的是，Anna 的大型团队致力于 GCP 云负载均衡功能，他们开始向使用 Envoy 的各种云负载均衡产品以及内部用例（这在这个时期都是非常秘密的，但现在已经众所周知）。&lt;/p&gt;
&lt;p&gt;我将永远记得与谷歌互动的那段时间是我职业生涯中最紧张的时期之一。说实话，那感觉就像一个收购（审讯）过程。我记得长长的会议和电子邮件线程，以证明我们的技术决定，“面试 &amp;ldquo;中，谷歌试图确定我们是否会成为一个好的开源项目合作伙伴，等等。当时我们很痛苦地发现，这次&amp;rdquo; 收购 &amp;quot; 将使 Envoy 进入一个我们自己永远无法实现的轨道，所以我们尽一切努力使它获得成功，最终也获得了成功。而且，在过去 4 年多的时间里，我们与谷歌的合作确实是一种杰出的伙伴关系。早期的谷歌云工程师最终成为维护者，Harvey Tuch 和 Alyssa Wilk，为项目带来了大量的人才，包括技术上的，以及对开源和社区的支持。我对他们的感激之情溢于言表，没有他们，项目就不会有今天的成就。多年来为该项目做出贡献的其他谷歌工程师（现在有很多），除了普遍是优秀的社区管理者之外，还为该项目增加了大量的工程力量，否则该项目就不会有。我当然对最初的谷歌合作关系有顾虑（技术和理念上的分歧，等等），但我可以诚实地说，这些顾虑都没有成为现实。&lt;/p&gt;
&lt;p&gt;除了确保 Istio 和 GCP 团队与谷歌合作的成功之外，我们还花了大量时间与其他公司和维护者合作并加入他们，其中许多人对项目产生了巨大的影响，至今仍作为维护者、贡献者或用户大量参与。如果没有这些早期的社区成员，这个项目就不会有今天，我也非常感谢他们对项目的信任。&lt;/p&gt;
&lt;p&gt;同时，随着项目的不断深入，我开始收到大量投资者对 Envoy 的兴趣。有强烈的愿望让我离开 Lyft，围绕这个项目开一家公司。我&lt;a href=&#34;https://medium.com/@mattklein123/optimizing-impact-why-i-will-not-start-an-envoy-platform-company-8904286658cb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;写过这部分的旅程&lt;/a&gt;，所以我不会在这里重述，留在 Lyft 我会有大量的时间和精力来处理所有这些互动。正如链接的文章所描述的，我最终决定留在 Lyft，不开公司，以支持 Envoy 的持续成功。&lt;/p&gt;
&lt;p&gt;与此同时，我仍然在 Lyft 工作，正如我将在后面进一步讨论的那样，我越来越多地从事两份工作。我的第一份工作是在内部领导网络团队，并在运营上支持 Lyft 的 Envoy。我的第二份工作是作为 Envoy 的公众形象，包括 OSS 领导，代码审查，修复错误，编写可以促进项目的功能，在会议上发言，帮助其他公司采用和部署 Envoy，等等。我开始变得过于分散，并出现了倦怠的迹象。然而，到了 2017 年年中，不可否认的事实是，Envoy 的发展轨迹是大大的“向上和向右”。各大公司、“同行公司”、垂直产品和服务等的采用率继续攀升。&lt;/p&gt;
&lt;h3 id=&#34;捐赠给-cncf-且感到倦怠&#34;&gt;捐赠给 CNCF 且感到倦怠&lt;/h3&gt;
&lt;p&gt;到 2017 年秋天，有两件事是清楚的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Envoy 已经超出了 Lyft OSS 设备所能提供的范围。该项目需要法律、公共关系、营销、活动组织等方面的帮助。&lt;/li&gt;
&lt;li&gt;我很快就完全倦怠了，需要找出一条可持续发展的道路。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决第一点，我们最终同意考虑将 Envoy 转交到 CNCF。数月来，CNCF 一直在追求该项目，但似乎从来没有任何令人信服的理由来加入。到 2017 年底，很明显，CNCF 的资源即使不是净收益，也至少对项目是中性的。我们开始了提交程序，并最终在我们最初开放项目资源的几乎整整一年后&lt;a href=&#34;https://eng.lyft.com/envoy-joins-the-cncf-dc18baefbc22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;加入了该基金会&lt;/a&gt;。我很感谢 Alexis Richardson 和 Chris Aniszczyk 在这个过程中对项目的指导。&lt;/p&gt;
&lt;p&gt;第二点则要复杂得多。从根本上说，我的工作时间超过了我的工作能力，有效地跨越了两个不同的工作。此外，我正在期待我的第一个孩子，预产期在 2018 年初，随着到来的日期越来越近，这让我越来越焦虑。到这个时候，我已经很清楚，我在设定期望和界限方面做得不够好，不知道自己能够为 Lyft 提供什么，同时也没有从行业的角度关注 Envoy 的持续增长。在 Lyft，我越来越放任自流，陷入人际关系的争吵，在为更多的初级团队成员提供指导和领导方面，没有达到我这个级别的期望。&lt;/p&gt;
&lt;p&gt;简而言之，我当时正处于崩溃的边缘，最终我选择了 Envoy 而不是 Lyft，这对我的 Lyft 同事造成了伤害。我想，如果我在 2017 年初至年中对我的工作量与 Lyft 的领导层更加透明，我可能会避免一些最糟糕的结果，但不幸的现实是，&lt;strong&gt;为开源软件行业的工作提供资源，而这些工作对雇主没有立即明显的作用，这是一个复杂的努力&lt;/strong&gt;。它可能会更顺利，也可能不会。在任何情况下，虽然我对一些我本可以处理得更好的人际关系问题感到遗憾，但无论好坏，&lt;strong&gt;我都不后悔把精力放在 Envoy 上。我优先考虑的是 Envoy，而不是 Lyft，我做了我认为当时必须做的事情，以使它成功&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;可持续发展道路&#34;&gt;可持续发展道路&lt;/h3&gt;
&lt;p&gt;我的第一个孩子在 2018 年 2 月出生，Lyft 极其慷慨的陪产假政策为我提供了休息和放空自己的时间。我从 Lyft 获得了一些空间，并开始更深入地思考我想要什么以及什么对我来说是可持续的。&lt;/p&gt;
&lt;p&gt;当我休完陪产假回来后，我与 Lyft 领导层明确表示，我不能再参与 Lyft 的 Envoy 的 &amp;ldquo;日常&amp;rdquo; 运维。相反，由于 2017 年底的一些后果，基础设施团队也希望与我分开一些。由于这个原因，&lt;strong&gt;我大幅后退，实际上完全停止了在 Lyft 的基础设施工作&lt;/strong&gt;，在 2018 年年中至年末的 Lyft Bikes 和 Scooters 初始版本中编写固件网络代码。这是一个了不起的团队努力，在压缩的时间范围内得到了一些东西，我真的很喜欢在几个月内做一些完全不同的事情。&lt;/p&gt;
&lt;p&gt;2018 年也是我积极开始琢磨在 Envoy OSS 社区中 &amp;ldquo;取代自己&amp;rdquo; 的那一年。我花了大量的时间（并将继续花大量的时间）来培养维护者、新的贡献者，组织第一次专门的 EnvoyCon，等等。任何领导者都应该有一个目标，那就是确保该组织在有一天该领导者退位时能够继续良好地运作。&lt;/p&gt;
&lt;p&gt;到 2018 年底，我的主要职业倦怠风险已经得到解决，我又开始了合理的工作时间，并花了很多时间与我的妻子和儿子在一起，我的时间大致在 Envoy OSS 工作和 Lyft 的一般基础设施领导之间各占一半。明确地说，Envoy 的成功带来的特权使我能够在 Lyft 的工作生活中取得这种平衡。随着时间的推移，随着我的行业地位的提高，我的影响力也在同步增加，这使得我更容易按照自己的意愿设定就业条款。没有多少人有这样的运气，我明白我是多么幸运，能够“突破“倦怠墙的另一边而不必离开我的工作。&lt;/p&gt;
&lt;h3 id=&#34;envoy-长大了&#34;&gt;Envoy 长大了&lt;/h3&gt;
&lt;p&gt;自 2019 年以来，因为新冠疫情，我在 Lyft 的基础设施领导和 OSS 领导之间继续保持着我上面描述的五五开的比例。当然也有单调和渴望不同的时候（从历史上看，我是一个习惯性换工作的人，6.5 年是迄今为止我在一件事情上工作的最长时间），但总的来说，我很高兴看到 Envoy 从一个“新秀 &amp;quot; 变成更多的“少年”。我不再专注于做我所能想到的一切，使 Envoy 获得巨大的成功，因为坦率地说，Envoy 是一个巨大的成功，已经席卷了市场，并改变了用户对应用负载均衡工具的期望。相反，我更关注项目的可持续性。我们是在做长期的工作，这些天我觉得自己更像一个 CEO，看减员人数、优先级、预算编制、安全问题等等。这并不是说这不是有用的工作；它显然是有用的，它只是与早期的工作不同，早期的工作技术性更强，节奏更快。&lt;/p&gt;
&lt;p&gt;截止到 2021 年末，我对 Envoy 最引以为豪的事情是，在我看来，这个社区已经可以自我维持了。我们有一群令人难以置信的维护者、贡献者和用户，他们对项目的成功充满热情，并在使 Envoy 成为今天的样子中发挥了作用。这确实是一个团队的努力。&lt;/p&gt;
&lt;h2 id=&#34;经验教训&#34;&gt;经验教训&lt;/h2&gt;
&lt;p&gt;过去的 5 年是一个史诗般的旅程。虽然我觉得我在技术上学到的东西相对较少，但我在领导力、社区建设和所有其他非技术性的东西方面都得到了成长和学习，这些都是建立一个成功的企业，无论是企业还是一个主要的开源成功故事。以下是我对一些主要学习内容的简短总结。&lt;/p&gt;
&lt;h3 id=&#34;成功的开源软件就像创办一个企业&#34;&gt;成功的开源软件就像创办一个企业&lt;/h3&gt;
&lt;p&gt;也许有争议的是，&lt;strong&gt;我认为如果一个人有目标要创建一个非常成功的开源软件项目，他们需要把它想成一个企业&lt;/strong&gt;。除了核心技术之外，创业还涉及很多因素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;招聘（在开源软件中，这意味着招聘贡献者和维护者）&lt;/li&gt;
&lt;li&gt;获取客户（在开源软件中，这被转化为用户）&lt;/li&gt;
&lt;li&gt;文档和技术写作&lt;/li&gt;
&lt;li&gt;公共关系&lt;/li&gt;
&lt;li&gt;市场营销&lt;/li&gt;
&lt;li&gt;法律（商标、许可等）&lt;/li&gt;
&lt;li&gt;人力资源（在开源软件中，这将转化为解决社区纠纷和制定文化）&lt;/li&gt;
&lt;li&gt;资金（在开源软件中，这转化为辅助费用，如 CI、为维护者找到允许他们在项目中部分或全部时间工作的工作，等等）&lt;/li&gt;
&lt;li&gt;总的说来，就是领导和方向的确定。资源有限，有很多事情可以做。企业 / 项目需要专注于最重要的事情，以实现产品的市场适应性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;直观地说，我知道这一点，在最初为 Envoy 进行开源努力时，我积极地追求上述所有的领域，努力使项目从开始发展到今天的规模。上述列表中的每一项都很关键，如果没有所有这些，一个项目是不可能成功的，尤其是在技术领域有很多资金雄厚的公司竞争对手的情况下。&lt;/p&gt;
&lt;p&gt;我强烈鼓励那些考虑进行大规模开源工作的人提前在上述领域进行投资，以便在第一天就给人留下最佳印象。此外，新的开源项目应该准备在项目成长并开始看到采用时，在上述领域进行更多的投资。&lt;/p&gt;
&lt;p&gt;毫不奇怪，这些天我在 Envoy 上做的编码工作相对较少。我在项目上的时间主要是管理项目的所有非技术方面（上述列表中的所有内容，甚至更多！），并确保事情按计划进行。我所做的大多数编码项目都是“清洁 &amp;quot; 的幕后项目，对项目有好处，但没有什么乐趣，也不可能激励其他贡献者（当然，我对他们每天的工作没有发言权，我有动力让他们尽可能的开心，这样他们就不会离开）。&lt;/p&gt;
&lt;h3 id=&#34;终端用户驱动的开源软件是一种结构性优势&#34;&gt;终端用户驱动的开源软件是一种结构性优势&lt;/h3&gt;
&lt;p&gt;这些天来，很多“大的开源软件”，特别是在基础设施领域，是由大公司和风险投资支持的初创公司资助的。我不会绕到关于开源软件的困难经济的讨论，因为我&lt;a href=&#34;https://medium.com/@mattklein123/the-broken-economics-of-oss-5a1b31fc0182&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;已经写过了&lt;/a&gt;。我想说的是，&lt;strong&gt;我坚信终端用户的开源软件比企业和风险投资支持的开源软件有很大的优势&lt;/strong&gt;：最初的客户几乎肯定会从软件中获得价值，否则软件就不会得到资助。这种与客户一起建立东西的良性循环是非常强大的。它几乎普遍导致了更好的结果：软件更可靠、更专注、功能更少。有很多由最终用户驱动的开源软件的例子，然后取得了巨大的商业成功。鉴于坚实的基础和内在的产品市场适应性，这对我来说并不奇怪。我希望看到比今天更多的最终用户驱动的开源软件，尽管我认识到经济上是困难的。对于那些有机会的人来说，请向这种类型的软件所具有的结构性优势靠拢！&lt;/p&gt;
&lt;h3 id=&#34;不要跟风要跟随客户&#34;&gt;不要跟风，要跟随客户&lt;/h3&gt;
&lt;p&gt;这也许是 &amp;ldquo;成功的开源软件就像创业&amp;rdquo; 和 &amp;ldquo;最终用户驱动的开源软件是一种结构性优势&amp;rdquo; 的必然结果，但我无法强调坚持不懈地关注客户的实际需求而不是炒作周期所认为的客户需求是多么关键。例如，&lt;strong&gt;多年来，人们一直在嘲笑 Envoy 是用 C++ 编写的，这引起了无数的笑话&lt;/strong&gt;。我喜欢 C++ 吗？不，不是很喜欢。它是否在 2015 年完成了工作，并吸引了最初的一批主要用户？肯定是的。这是一个关注客户和市场的例子，而不是屈服于没有实际“商业 &amp;quot; 影响的炒作。如果一个人把开源软件当做一个企业，就会立刻明白，&lt;strong&gt;以客户和市场为中心是取得巨大成功的唯一途径&lt;/strong&gt;。在 Envoy，我花了大量的时间为终端用户争论，以确保我们建立的东西能让所有人受益，而不仅仅是一小部分小众用户。&lt;/p&gt;
&lt;h3 id=&#34;可扩展性是至关重要的&#34;&gt;可扩展性是至关重要的&lt;/h3&gt;
&lt;p&gt;跟着客户走往往会导致客户的要求不能很好地融入项目的架构中。从开源软件的角度来看，失去对项目主要目标的关注会导致功能蔓延、软件无法维护和维护人员负担过重。同时，说“不 &amp;quot; 也是失去潜在用户的一个保证。&lt;/p&gt;
&lt;p&gt;对于 Envoy，我想确保我们至少可以说“是的，但是……&amp;quot;，即提供一个强大的可扩展性模型，让用户可以满足他们的需求，而不需要将每一个改动和功能都推到上游。这种策略已经多次得到回报，它减轻了维护者的负担，让用户能够解决他们自己的问题，更重要的是，将 Envoy 推向了我在最初设计该软件时从未想象过的用例。&lt;/p&gt;
&lt;p&gt;可扩展性，特别是对于开源软件的构建模块，是至关重要的。&lt;/p&gt;
&lt;h3 id=&#34;质量问题&#34;&gt;质量问题&lt;/h3&gt;
&lt;p&gt;跟随客户的另一个推论是，质量确实很重要。用户希望软件易于操作，相对来说没有错误，关心安全，等等。曾几何时很多人会觉得因为开源软件是 &amp;quot; 免费的”，所以质量就得不到保证。这在理论上也许是正确的，但实际上，在一个项目对软件质量认真对待之前，用户不会大量地聚集在一个软件上。因为获得用户是一个飞轮，可以获得更多的用户（特别是当从早期采用者转向晚期采用者时），所以确保为整个软件质量编列时间预算就更加关键了。&lt;/p&gt;
&lt;p&gt;关于 Envoy，我一直有一个 &amp;ldquo;零碰撞&amp;rdquo; 的理念。任何崩溃都会被调查和修复，无论多么不频繁的错误。这种对稳定性和质量的关注不会被忽视。&lt;/p&gt;
&lt;h3 id=&#34;社区是扩大规模的唯一途径&#34;&gt;社区是扩大规模的唯一途径&lt;/h3&gt;
&lt;p&gt;这很明显，但我还是要说：社区是扩展开源软件的唯一途径。这是一个由维护者、贡献者和用户组成的社区。此外，社区的&lt;strong&gt;基调&lt;/strong&gt;在项目开始时就已经确定，而且极难改变。人类倾向于遵循规范。一旦规范被确定下来，无论规范是什么，与这些规范不一致的人都会被避开。因此，&lt;strong&gt;项目最初的公共基调对于设定其长期的社区轨迹极为关键&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当我们把 Envoy 做成开源软件时，我在 GitHub 上投入了大量的精力与人们一起工作，使用建设性和欢迎性的语言。总的来说，我尽我所能让 Envoy 成为一个受欢迎的地方，让人们愿意来贡献自己的力量，无论是维护、偶尔的贡献，还是用户帮助其他用户。&lt;/p&gt;
&lt;p&gt;在 Envoy 所取得的所有不同类型的成功中，到目前为止，给我带来最多个人满足感的部分是，有相当多的人告诉我，他们已经发誓不再使用开源软件，尤其是基础设施开源软件，因为他们觉得大多数项目中的人对彼此感觉都很糟糕。相反的，他们喜欢为 Envoy 做贡献，因为这个社区是如此的尊重和欢迎彼此。这需要大量的努力和纪律，尤其是在项目的早期，才能达到这样的结果，而这已经得到了众多的回报。&lt;/p&gt;
&lt;p&gt;不要低估从一开始就确定项目的文化和基调的复合效应。&lt;/p&gt;
&lt;h3 id=&#34;混合商业和开源软件的利益是非常困难的&#34;&gt;混合商业和开源软件的利益是非常困难的&lt;/h3&gt;
&lt;p&gt;已经有很多关于开源软件的困难经济学的文章（&lt;a href=&#34;https://medium.com/@mattklein123/the-broken-economics-of-oss-5a1b31fc0182&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;包括我自己的文章&lt;/a&gt;，我在上面提到的）。我只想说，&lt;strong&gt;试图将商业上的成功和开放源码的成功结合起来是非常困难的，主要是因为这些成功往往是相互矛盾的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我相信，Envoy 通过其强大的 API 和可扩展性系统穿透了这个矛盾。从本质上讲，Envoy 已经成为一个工具，现在被大量的垂直产品和服务所使用。这就产生了一个社区，该社区充满了选择在一个共同的基底上合作的公司，即使是通过在扩展 / API / 控制平面 / UI/UX 层上的创新，推出相互竞争的上层产品。&lt;/p&gt;
&lt;p&gt;任何成功的开源项目都会看到大量的商业 / 投资人的兴趣。如果一个项目的目标是保持一个充满活力的社区，同时又能取得商业上的成功（我认为这对整个项目的成功是必要的，因为钱必须来自某处），&lt;strong&gt;那么预先考虑如何将核心层和商业层分开是极其重要的&lt;/strong&gt;。这样做的实用性和策略会因项目和技术的不同而不同，但我相信专注于强大的 API / 扩展性的分割是一个富有成效的策略。&lt;/p&gt;
&lt;h3 id=&#34;基金会是很棘手的&#34;&gt;基金会是很棘手的&lt;/h3&gt;
&lt;p&gt;在现代的开源讨论中，有很多关于基金会的作用的讨论。我不打算对这一话题做大量的评论，&lt;strong&gt;但我的主要建议是不要被基金会和它们可能提供的理论利益所干扰&lt;/strong&gt;。相反，要积极地关注产品的市场适应性，生产高质量的软件，并为用户提供价值。如果这些事情得以实现，其余的事情就会自然而然地发生。&lt;/p&gt;
&lt;p&gt;对于非常成功的项目来说，基金会，更确切地说，中立的商标持有地，是非常有用的，所以我肯定会在那个时候考虑加入一个。随着项目的成熟，Envoy 从成为 CNCF 的一部分所获得的价值也在不断增加。CNCF 雇佣了开源软件律师、营销人员、公共关系人员、一流的活动人员等等。这些额外的资源在“经营业务 &amp;quot; 方面是非常宝贵的。&lt;/p&gt;
&lt;h3 id=&#34;提前考虑治理问题&#34;&gt;提前考虑治理问题&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-oss-5-year/008i3skNly1guh3vqvywcj60tw0h8go702_hu0ad3db969701db278470f1096ccc2d23_98159_f83781e7a3c63610a8a7259c955caa40.webp 400w,
               /blog/envoy-oss-5-year/008i3skNly1guh3vqvywcj60tw0h8go702_hu0ad3db969701db278470f1096ccc2d23_98159_fb5cf63e9bd26cd29a785680cbbc767e.webp 760w,
               /blog/envoy-oss-5-year/008i3skNly1guh3vqvywcj60tw0h8go702_hu0ad3db969701db278470f1096ccc2d23_98159_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-oss-5-year/008i3skNly1guh3vqvywcj60tw0h8go702_hu0ad3db969701db278470f1096ccc2d23_98159_f83781e7a3c63610a8a7259c955caa40.webp&#34;
               width=&#34;760&#34;
               height=&#34;438&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
开源治理是&lt;strong&gt;非常&lt;/strong&gt;困难的。就其本质而言，开放源代码是无政府的，没有明确的领导结构。没有一个适合所有项目的治理方法，每个项目都必须找到自己的前进方向，可以通过“BDFL”/CEO 类型的模式、指导委员会、类似 Apache PMC 的程序等。所有的治理模式都有优点和缺点，并且有不同的失败模式。&lt;/p&gt;
&lt;p&gt;最重要的是，在项目变得庞大和成功之前，先认真思考治理问题。写下一套规则和规范，特别是花时间记录项目的冲突解决过程。&lt;/p&gt;
&lt;p&gt;同时也要意识到，根据我在上面关于社区规范如何在早期设定的评论，早期的项目维护者将对整个对话和冲突解决的风格产生巨大的影响，就像公司的早期员工对公司的文化产生巨大的影响一样。&lt;/p&gt;
&lt;p&gt;在我的印象中，我们在 Envoy 内部非常幸运，没有发生过任何重大分歧，出现的问题也可以迅速友好地解决。在项目的历史上，我们从来没有需要援引&lt;a href=&#34;https://github.com/envoyproxy/envoy/blob/main/GOVERNANCE.md#conflict-resolution-and-voting&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;维护者投票程序来解决冲突&lt;/a&gt;。在我看来，这是一个巨大的成就，也是对所有维护者的素质和专业性的证明，尤其是考虑到该项目已经变得如此受欢迎，以及围绕它的所有商业利益。&lt;/p&gt;
&lt;h3 id=&#34;对开源贡献的期望是至关重要的&#34;&gt;对开源贡献的期望是至关重要的&lt;/h3&gt;
&lt;p&gt;我在上面提到过这个问题，但我自己的职业倦怠很大程度上是由于我没有很好地与我的雇主就我需要花多少时间来管理 Envoy 的开源增长设定合理的期望。我不会撒谎说，进行这样的对话就能神奇地使雇主为某人腾出大量时间来从事开源工作，特别是那些可能不直接适用于其日常工作的项目。话虽如此，我确信对所有参与的人来说，对开源过程有公开和诚实的期望是非常重要的。以下是在开源项目之前或开始以开源身份工作之前要问的合理问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雇员应该问他们的雇主，为什么他们要开放源代码？&lt;/li&gt;
&lt;li&gt;雇主应该问他们的员工，为什么他们要开放源代码？(这个问题的答案和前一个问题的答案不同是完全合理的，但应该在公开场合讨论)。&lt;/li&gt;
&lt;li&gt;雇员应该问他们的雇主，如果项目成功了，会发生什么？该项目将有哪些资源可用？员工将有多少时间可以在通用的开源软件问题上工作，目的是直接推动项目的发展？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;雇主和雇员之间不匹配的期望是未来怨恨和倦怠的根本原因。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;代理容易api-难&#34;&gt;代理容易，API 难&lt;/h3&gt;
&lt;p&gt;对一些人来说，Envoy 提供的底层网络代理机制似乎是这个项目的复杂部分。事实证明，与为 Envoy 发展一个稳定的 API 生态系统所做的工作相比，代理部分（在我看来）相对简单。平衡人类和计算机消费的 API 人体工程学，保持不同版本的稳定性，发展 API 以支持其他客户端，如 gRPC，指定协议语义以使 Envoy 能够与数百（可能是数千）个不同的管理服务器对话，等等，都是非常复杂的。我为团队在这一领域取得的成就感到骄傲（特别要感谢推动这一工作的 Harvey），即使在这一过程中出现了一些错误（比如从 API 的 V2 版本强制迁移到 V3 版本）。&lt;/p&gt;
&lt;p&gt;如果一个软件提供了一个 API，而且更重要的是希望这个 API 成为其他系统的关键组件，那么不要低估提供一个稳定和符合人体工程学的 API 的成本和复杂性。反过来说，&lt;strong&gt;强大的 API 是一个生态系统飞轮的重要组成部分&lt;/strong&gt;，会以此产生更多的产品和用户，所以在我看来，这些努力是非常值得的。&lt;/p&gt;
&lt;h3 id=&#34;不要忽视职业倦怠&#34;&gt;不要忽视职业倦怠&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;如果一个人想成就大事业，我不相信他可以 100% 实现良好的工作生活平衡&lt;/strong&gt;。现实情况是，任何成功都是由现有的特权 / 机会、一个好的想法、良好的执行力和大量的运气（包括在正确的时间出现在正确的地点）组成的。所有这些东西都在 Envoy 中发挥作用，我不会假装我没有把自己搞得很累，特别是在 2017 年。我也会重新做一遍 2017 年的工作，因为从我的角度来看，我做了我必须做的事情，使项目获得成功。(有时我想，如果我已经有了孩子，Envoy 是否还会诞生。我不确定它是否会发生，但这是一个更长的谈话主题！)&lt;/p&gt;
&lt;p&gt;综上所述，我在 2017 年描述的那种史诗般的推动力只能持续这么久，直到一个人崩溃。我鼓励大家不断反思自己的工作生活平衡，并为自己找出一条可持续发展的道路。每个人的情况都不同，我不能提供任何一个避免职业倦怠的建议，但我认为反思是一个好的开始，也是我自己不得不努力的事情。&lt;/p&gt;
&lt;h2 id=&#34;感谢&#34;&gt;感谢&lt;/h2&gt;
&lt;p&gt;在过去 6 年半的时间里，在 Envoy 上工作，其中 5 年是作为开源软件，这是我职业生涯中的亮点。这个项目的成功确实是一个团队的努力，我一个人是不可能完成的，我为我们所有人（维护者、贡献者和用户）共同完成的事情感到非常自豪。在这个项目上工作的维护者和贡献者是我所共事过的最好的工程师群体，他们才华横溢，他们就职在不同公司，位于不同的地理位置，这真是开源的理论潜力在实践中的体现。作为一个团队，我们已经产生了世界性的影响，改变了用户对软件负载均衡系统的期望，同时也建立了一个充满活力和热情的社区。在我最疯狂的梦想中，我从未想过这个项目会成为今天的样子。&lt;/p&gt;
&lt;p&gt;对我来说，未来会发生什么就不那么清楚了。正如我上面所说的，我的重点已经转移到了可持续性上。我想确保，如果有一天我离开了，这个项目将保持健康。尽管如此，这一天还没有到来，我期待着在可预见的未来帮助领导项目前进，希望能取得更大的成功和采用。向前迈进！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Envoy 架构师 Matt Klein 对 Envoy 线程模型的简介</title>
      <link>https://cloudnative.to/blog/envoy-threading-model/</link>
      <pubDate>Wed, 20 Feb 2019 20:17:12 +0800</pubDate>
      <guid>https://cloudnative.to/blog/envoy-threading-model/</guid>
      <description>&lt;p&gt;本文为翻译文章，&lt;a href=&#34;https://blog.envoyproxy.io/envoy-threading-model-a8d44b922310&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;点击查看原文&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;编者注：原文于 2017 年 7 月 30 日发布于 Envoy 博客上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关于 Envoy 代码库的底层技术文档目前相当稀少。为了纠正这个问题，我打算做一系列关于各种子系统的博客文章。由于这是第一篇文章，请让我知道您的想法以及您希望了解的其他主题。&lt;/p&gt;
&lt;p&gt;我经常看到的关于 Envoy 的最常见技术问题之一就是要求从底层描述 Envoy 使用的线程模型。这篇文章将介绍 Envoy 如何将连接映射到线程，以及内部使用的线程本地存储（TLS）系统的描述，以使代码极其并行且性能更高。&lt;/p&gt;
&lt;h3 id=&#34;线程模型概览&#34;&gt;线程模型概览&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-threading-model/5f3e3349gy1g0c5di41ayj218g10ewm0_hu6a1f461f502160abd5b7fd669a13ac13_338619_a6aecc934b9b9d12f30315f022073103.webp 400w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5di41ayj218g10ewm0_hu6a1f461f502160abd5b7fd669a13ac13_338619_9f572755087c5f3767c25e805bde786d.webp 760w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5di41ayj218g10ewm0_hu6a1f461f502160abd5b7fd669a13ac13_338619_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-threading-model/5f3e3349gy1g0c5di41ayj218g10ewm0_hu6a1f461f502160abd5b7fd669a13ac13_338619_a6aecc934b9b9d12f30315f022073103.webp&#34;
               width=&#34;760&#34;
               height=&#34;623&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Envoy 使用三种不同类型的线程，如上图所示。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Main：此线程负责服务器启动和关闭，所有 &lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/dynamic_configuration.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS API&lt;/a&gt; 处理（包括 &lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/service_discovery.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DNS&lt;/a&gt;，&lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/health_checking.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行状况检查&lt;/a&gt; 和常规 &lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/cluster_manager.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;集群管理&lt;/a&gt;），&lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/runtime.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行时&lt;/a&gt;，统计刷新，管理和一般进程管理（信号，&lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/hot_restart.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;热启动&lt;/a&gt; 等）。在此线程上发生的所有事情都是异步的并且是“非阻塞的”。通常，主线程协调所有不需要大量 CPU 来完成的关键过程功能。这允许将大多数管理代码编写为单线程编写。&lt;/li&gt;
&lt;li&gt;Worker：默认情况下，Envoy 为系统中的每个硬件线程生成一个工作线程。（这可以通过 &lt;a href=&#34;https://lyft.github.io/envoy/docs/operations/cli.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ndash;concurrency&lt;/a&gt; &lt;a href=&#34;https://lyft.github.io/envoy/docs/operations/cli.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;选项&lt;/a&gt; 控制）。每个工作线程运行一个“非阻塞”事件循环，负责监听每个监听器（当前没有监听器分片），接受新连接，为连接实例化过滤器堆栈，以及处理所有 IO 的生命周期。连接。同样，这允许将大多数连接处理代码写成好像是单线程的。&lt;/li&gt;
&lt;li&gt;文件刷新器：Envoy 写入的每个文件（主要是访问日志）当前都有一个独立的阻塞刷新线程。这是因为即使使用 O_NONBLOCK 写入文件系统缓存文件有时也会阻塞（哎）。当工作线程需要写入文件时，数据实际上被移入内存缓冲区，最终通过文件刷新线程刷新。这是代码的一个区域，技术上所有 worker 都可以阻止同一个锁尝试填充内存缓冲区。还有一些其他的将在下面进一步讨论。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;连接处理&#34;&gt;连接处理&lt;/h3&gt;
&lt;p&gt;如上所述，所有工作线程都会在没有任何分片的情况下监听所有监听器。因此，内核用于智能地将接受的套接字分派给工作线程。现代内核一般都很擅长这个；他们使用诸如 IO 优先级提升之类的功能来尝试填充线程的工作，然后开始使用同时监听同一套接字的其他线程，以及不使用单个自旋锁来处理每个接受。&lt;/p&gt;
&lt;p&gt;一旦连接被 worker 接受，它就永远不会离开那个 worker。所有进一步的连接处理都在工作线程内完全处理，包括任何转发行为。这有一些重要的含义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Envoy 中的所有连接池都是每个工作线程。因此，尽管 HTTP / 2 连接池一次只与每个上游主机建立一个连接，但如果有四个工作站，则每个上游主机在稳定状态下将有四个 HTTP/2 连接。&lt;/li&gt;
&lt;li&gt;Envoy 以这种方式工作的原因是因为通过将所有代码保存在单个工作线程中，几乎所有代码都可以在没有锁的情况下编写，就像它是单线程一样。这种设计使得大多数代码更易于编写，并且可以非常好地扩展到几乎无限数量的 worker。&lt;/li&gt;
&lt;li&gt;然而，一个主要的问题是，从内存和连接池效率的角度来看，调整并发选项实际上非常重要。拥有比所需更多的 worker 将浪费内存，创建更多空闲连接，并导致更低的连接池命中率。在 Lyft，我们的 sidecar Envoy 以非常低的并发性运行，因此性能大致与他们旁边的服务相匹配。我们只以最大并发性运行我们的边缘 Envoy。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;什么是非阻塞&#34;&gt;什么是非阻塞&lt;/h3&gt;
&lt;p&gt;到目前为止，在讨论主线程和工作线程如何操作时，已经多次使用术语“非阻塞”。所有代码都是在假设没有任何阻塞的情况下编写的。然而，这并不完全正确（完全是这样的吗？）。Envoy 确实采用了一些进程宽锁：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如前所述，如果正在写入访问日志，则所有工作程序在填充内存访问日志缓冲区之前都会获取相同的锁。锁定保持时间应该非常低，但是这种锁可以在高并发性和高吞吐量下竞争。&lt;/li&gt;
&lt;li&gt;Envoy 采用了一个非常复杂的系统来处理线程本地的统计数据。这将是一个单独的帖子的主题。但是，我将简要提一下，作为线程本地统计处理的一部分，有时需要获取对中央“stat store”的锁定。这种锁定不应该高度争用。&lt;/li&gt;
&lt;li&gt;主线程需要定期与所有工作线程协调。这是通过从主线程“发布”到工作线程（有时从工作线程返回到主线程）来完成的。发布需要锁定，以便将发布的消息放入队列中以便以后发送。这些锁永远不应该高度争用，但它们仍然可以在技术上阻止。&lt;/li&gt;
&lt;li&gt;当 Envoy 将自己记录到标准错误时，它会获取进程范围的锁定。一般来说，Envoy 本地记录被认为是表现糟糕的，所以没有多少考虑改善这一点。&lt;/li&gt;
&lt;li&gt;还有一些其他随机锁，但它们都不在性能关键路径中，永远不应该争用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;线程本地存储&#34;&gt;线程本地存储&lt;/h3&gt;
&lt;p&gt;由于 Envoy 将主线程职责与工作线程职责分开，因此需要在主线程上完成复杂处理，然后以高度并发的方式使每个工作线程可用。本节介绍了 Envoy 的高级线程本地存储（TLS）系统。在下一节中，我将描述如何使用它来处理集群管理。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-threading-model/5f3e3349gy1g0c5bd3l63j218g0n1wjh_huc1ddf4668440e64d7b9b89b6d99e6421_221662_5e5845bbb5f91de8e65f28fd22955450.webp 400w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5bd3l63j218g0n1wjh_huc1ddf4668440e64d7b9b89b6d99e6421_221662_5c3be151d5bb613603b792dea651bb07.webp 760w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5bd3l63j218g0n1wjh_huc1ddf4668440e64d7b9b89b6d99e6421_221662_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-threading-model/5f3e3349gy1g0c5bd3l63j218g0n1wjh_huc1ddf4668440e64d7b9b89b6d99e6421_221662_5e5845bbb5f91de8e65f28fd22955450.webp&#34;
               width=&#34;760&#34;
               height=&#34;394&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;如已经描述的那样，主线程基本上处理 Envoy 过程中的所有管理 / 控制平面功能。 （控制平面在这里有点过载但是当在 Envoy 进程中考虑并与工人做的转发进行比较时，似乎是合适的）。主线程进程执行某些工作是一种常见模式，然后需要使用该工作的结果更新每个工作线程，并且工作线程不需要在每次访问时获取锁定。&lt;/p&gt;
&lt;p&gt;Envoy 的 TLS 系统的工作原理如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在主线程上运行的代码可以分配进程范围的 TLS 槽。虽然是抽象的，但实际上，这是一个允许 O（1）访问的向量索引。&lt;/li&gt;
&lt;li&gt;主线程可以将任意数据设置到其槽中。完成此操作后，数据将作为正常事件循环事件发布到每个工作程序中。&lt;/li&gt;
&lt;li&gt;工作线程可以从其 TLS 槽读取，并将检索那里可用的任何线程本地数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然非常简单，但这是一个非常强大的范例，与 RCU 锁定概念非常相似。 （实质上，工作线程在工作时从不会看到 TLS 插槽中的数据发生任何变化。更改只发生在工作事件之间的静止期间）。Envoy 以两种不同的方式使用它：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过在没有任何锁定的情况下访问每个 worker 存储不同的数据&lt;/li&gt;
&lt;li&gt;通过将共享指针存储到每个 worker 的只读全局数据。因此，每个工作者都具有对在工作时不能递减的数据的引用计数。只有当所有 worker 都已停顿并加载新的共享数据时，旧数据才会被销毁。这与 RCU 相同。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;集群线程更新&#34;&gt;集群线程更新&lt;/h3&gt;
&lt;p&gt;在本节中，我将描述 TLS 如何用于集群管理。集群管理包括 xDS API 处理和 / 或 DNS 以及运行状况检查。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-threading-model/5f3e3349gy1g0c5dx3j34j20ir0agwgn_hu1a5043fcb7b09b19f3c5940457c0432c_77746_afa78d838b957126923cdaee22a3fc98.webp 400w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5dx3j34j20ir0agwgn_hu1a5043fcb7b09b19f3c5940457c0432c_77746_325b90d4a652089e0c1d52fea2695d5d.webp 760w,
               /blog/envoy-threading-model/5f3e3349gy1g0c5dx3j34j20ir0agwgn_hu1a5043fcb7b09b19f3c5940457c0432c_77746_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-threading-model/5f3e3349gy1g0c5dx3j34j20ir0agwgn_hu1a5043fcb7b09b19f3c5940457c0432c_77746_afa78d838b957126923cdaee22a3fc98.webp&#34;
               width=&#34;675&#34;
               height=&#34;376&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上图显示了涉及以下组件和步骤的总体流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;集群管理器是 Envoy 内部的组件，用于管理所有已知的上游集群，CDS API，SDS / EDS API，DNS 和活动（带外）运行状况检查。它负责创建每个上游集群的最终一致视图，其中包括已发现的主机以及运行状况。&lt;/li&gt;
&lt;li&gt;运行状况检查程序执行活动运行状况检查，并将运行状况更改报告回集群管理器。&lt;/li&gt;
&lt;li&gt;执行 CDS / SDS / EDS / DNS 以确定集群成员资格。状态更改将报告回集群管理器。&lt;/li&gt;
&lt;li&gt;每个工作线程都在不断运行事件循环。&lt;/li&gt;
&lt;li&gt;当集群管理器确定集群的状态已更改时，它会创建集群状态的新只读快照，并将其发布到每个工作线程。&lt;/li&gt;
&lt;li&gt;在下一个静止期间，工作线程将更新分配的 TLS 插槽中的快照。&lt;/li&gt;
&lt;li&gt;在需要确定要负载均衡的主机的 IO 事件期间，负载均衡器将在 TLS 插槽中查询主机信息。没有获得锁定来执行此操作。 （另请注意，TLS 还可以在更新时触发事件，以便负载平衡器和其他组件可以重新计算高速缓存，数据结构等。这超出了本文的范围，但在代码中的各个位置使用）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过使用先前描述的过程，Envoy 能够处理每个请求而不需要任何锁定（除了之前描述的那些）。除了 TLS 代码本身的复杂性之外，大多数代码都不需要理解线程如何工作，并且可以编写为单线程。这使得大多数代码更容易编写，并产生出色的性能。&lt;/p&gt;
&lt;h3 id=&#34;其他使用-tls-的子系统&#34;&gt;其他使用 TLS 的子系统&lt;/h3&gt;
&lt;p&gt;TLS 和 RCU 在 Envoy 中广泛使用。其他一些例子包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运行时（功能标志）覆盖查找：在主线程上计算当前功能标志覆盖映射。然后使用 RCU 语义为每个工作程序提供只读快照。&lt;/li&gt;
&lt;li&gt;路由表交换：对于 RDS 提供的路由表，路由表在主线程上实例化。然后使用 RCU 语义为每个工作程序提供只读快照。这使得路由表交换有效地原子化。&lt;/li&gt;
&lt;li&gt;HTTP 日期标头缓存：事实证明，在每个请求上计算 HTTP 日期标头（当每个核心执行～25K + RPS 时）非常昂贵。Envoy 大约每半秒计算一次日期标题，并通过 TLS 和 RCU 将其提供给每个 worker。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有其他情况，但前面的例子应该提供 TLS 所用事物的良好品味。&lt;/p&gt;
&lt;h3 id=&#34;已知的性能陷阱&#34;&gt;已知的性能陷阱&lt;/h3&gt;
&lt;p&gt;虽然 Envoy 整体表现相当不错，但是当它以非常高的并发性和吞吐量使用时，有一些已知领域需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正如本文中已经描述的那样，当前所有工作者在写入访问日志的内存缓冲区时都会获得锁定。在高并发性和高吞吐量的情况下，当写入最终文件时，将需要以按顺序交付为代价对每个 worker 批量访问日志进行批处理。或者，访问日志可以成为每个工作线程。&lt;/li&gt;
&lt;li&gt;尽管统计信息已经过非常优化，但在非常高的并发性和吞吐量下，个别统计信息可能存在原子争用。对此的解决方案是每个工人计数器，定期冲洗到中央计数器。这将在后续文章中讨论。&lt;/li&gt;
&lt;li&gt;如果 Envoy 部署在几乎没有需要大量资源来处理的连接的场景中，现有架构将无法正常运行。这是因为无法保证连接在 worker 之间均匀分布。这可以通过实现工作者连接平衡来解决，其中 worker 能够将连接转发给另一个 worker 进行处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;
&lt;p&gt;Envoy 的线程模型旨在支持编程的简单性和大规模并行性，但如果调整不当可能会浪费内存和连接使用。该模型允许它在非常高的 worker 数量和吞吐量下表现良好。&lt;/p&gt;
&lt;p&gt;正如我在 &lt;a href=&#34;https://twitter.com/mattklein123/status/872291252695293952&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter&lt;/a&gt; 上简要提到的那样，该设计也适合在 DPDK 之类的完整用户模式网络堆栈上运行，这可能导致商用服务器在执行完整的 L7 处理时每秒处理数百万个请求。看看未来几年建成什么会非常有趣。&lt;/p&gt;
&lt;p&gt;最后一个快速评论：我多次被问到为什么我们为 Envoy 选择 C++。原因仍然是它仍然是唯一广泛部署的生产级语言，使用该语言中可以构建本文中描述的架构。C++ 当然不适合所有项目，甚至许多项目，但对于某些用例，它仍然是完成工作的唯一工具。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Envoy 中的数据统计</title>
      <link>https://cloudnative.to/blog/envoy-stats/</link>
      <pubDate>Fri, 07 Dec 2018 12:52:58 +0800</pubDate>
      <guid>https://cloudnative.to/blog/envoy-stats/</guid>
      <description>&lt;p&gt;这是我在&lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;架构系列中的第 3 篇文章。这篇文章基于以前关于 Envoy 的&lt;a href=&#34;https://medium.com/@mattklein123/envoy-threading-model-a8d44b922310&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;线程模型&lt;/a&gt;和&lt;a href=&#34;https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;热重启&lt;/a&gt;功能的帖子。如果您还没有阅读这些帖子，请先阅读。需要指出的是，随着预演的结束，我们现在可以进入更有趣的话题！&lt;/p&gt;
&lt;h2 id=&#34;统计概述&#34;&gt;统计概述&lt;/h2&gt;
&lt;p&gt;到目前为止，Envoy 所做的最重要的事情是为分布式系统的可观测性提供了一个健壮的平台。这包括统计数据、日志记录和分布式跟踪。这篇文章将集中在统计数据和 Envoy 是如何实现允许高容量的同时保持卓越性能的。Envoy 目前支持三种不同的统计数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Counter（计数器）&lt;/strong&gt;：只能增加不会减少的无符号整数。例如，总请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gauge（计量）&lt;/strong&gt;：可以同时增加和减少的无符号整数。例如，目前有效的请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timer/hitogram（计时器/直方图）&lt;/strong&gt;：无符号整数，最终将产生汇总百分位值。Envoy 不区分计时器（通常以毫秒为单位）和原始直方图（可以是任何单位）。例如，上游请求时间（以毫秒为单位）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Envoy 目前不支持任何浮点统计数据。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-stats/006tNbRwly1fxv00zgfu2j30m804ugmh_huf7f3688ffc51e6a27ba202f38813ac41_29421_2316e4a37a0bdc18a04b3884de8511b5.webp 400w,
               /blog/envoy-stats/006tNbRwly1fxv00zgfu2j30m804ugmh_huf7f3688ffc51e6a27ba202f38813ac41_29421_ec4e37070856cdbf03605b9dba8675c7.webp 760w,
               /blog/envoy-stats/006tNbRwly1fxv00zgfu2j30m804ugmh_huf7f3688ffc51e6a27ba202f38813ac41_29421_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-stats/006tNbRwly1fxv00zgfu2j30m804ugmh_huf7f3688ffc51e6a27ba202f38813ac41_29421_2316e4a37a0bdc18a04b3884de8511b5.webp&#34;
               width=&#34;760&#34;
               height=&#34;165&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;center&gt;Envoy 生成很多对调试分布式系统有用的数据！&lt;/center&gt;
## 统计子系统目标
&lt;p&gt;Envoy 统计子系统的总体目标如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;粗略的线性吞吐量：可以与任意数量的工作线程一起扩展。另一种说法是：在稳定状态下，使用 stats 时应该没有跨线程争用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在使用热重启时，状态应该在逻辑上保持一致。这意味着即使有两个 Envoy 进程在运行，当逻辑上认为是单个进程时，所有计数器、量规和直方图都应该是一致的。（有关这方面的更多信息，请参阅&lt;a href=&#34;https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;热重启&lt;/a&gt;这篇文章）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计数据应该包含在作用域内并作为一个组释放。作用域是具有公共前缀的统计数据的逻辑分组。例如：&lt;code&gt;http.admin.*&lt;/code&gt;。这一点很重要，因为 Envoy 具有动态性。Envoy 支持各种&lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;管理 API&lt;/a&gt;，如监听器发现服务（LDS）和集群发现服务（CDS）API。为了不耗尽内存，Envoy 需要清理不再使用的统计数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计范围应该能够重叠和正确的引用计数。这意味着如果作用域 A 使用一个名为&lt;code&gt;foo.bar.baz&lt;/code&gt;的属性，作用域 B 也使用&lt;code&gt;foo.bar.baz&lt;/code&gt;属性，那么&lt;code&gt;foo.bar.baz&lt;/code&gt;的属性的引用计数应该是 2。这对于热重启（两个进程将在一段时间内写入相同的统计数据）和动态管理 API（在一段时间内，更新的监听器或集群将引用与旧监听器或集群相同的统计数据）都是必需的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计数据子系统应该能够很好地执行直到数据平面处理开始时才知道的统计信息。许多统计数据本质上是“固定的”，可以在加载配置或动态 API 重新配置数据平面时创建（例如，&lt;code&gt;cluster.foo.upstream_rq_5xx&lt;/code&gt;）。这些都是低频事件。其他统计信息，例如详细的 HTTP 响应代码度量（例如，&lt;code&gt;cluster.foo.upstream_rq_503&lt;/code&gt;），在数据开始流动之前都不知道。使用“动态”的统计数据永远不会像使用“固定”的统计数据那样快，但是即使在处理每个内核每秒数千个请求的 10 次时，性能仍然应该是足够的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为一个整体，上述目标需要一个复杂的系统来满足。我们现在将深入研究这个系统是如何工作的。&lt;/p&gt;
&lt;h2 id=&#34;数据架构&#34;&gt;数据架构&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-stats/006tNbRwly1fxv13dqf7mj30m808zwf9_hubd6d9c259526179c1e2a6513193b119b_26676_3a9ee800366a75d9dccb41cd84cae387.webp 400w,
               /blog/envoy-stats/006tNbRwly1fxv13dqf7mj30m808zwf9_hubd6d9c259526179c1e2a6513193b119b_26676_d46dcaeab96f31575cc584f5622c159d.webp 760w,
               /blog/envoy-stats/006tNbRwly1fxv13dqf7mj30m808zwf9_hubd6d9c259526179c1e2a6513193b119b_26676_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-stats/006tNbRwly1fxv13dqf7mj30m808zwf9_hubd6d9c259526179c1e2a6513193b119b_26676_3a9ee800366a75d9dccb41cd84cae387.webp&#34;
               width=&#34;760&#34;
               height=&#34;307&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;center&gt;图 1：高级统计架构，蓝色统计数据显示了一个作用域分组。&lt;/center&gt;
**图 1**显示了 Envoy 数据统计子系统的高级架构。它由以下几个部分组成。
&lt;h3 id=&#34;存储&#34;&gt;存储&lt;/h3&gt;
&lt;p&gt;stat 存储是 Envoy 内部的一个单例对象，并提供了一个简单的接口，通过该接口，其余代码可以获得作用域、计数器、计量和直方图的句柄。调用代码负责维护所有创建的作用域的所有权语义。当作用域被销毁时，所有包含的统计数据的引用计数都会减少 1。如果任何统计数据达到 0 引用计数，它们将被释放。&lt;/p&gt;
&lt;h3 id=&#34;统计数据&#34;&gt;统计数据&lt;/h3&gt;
&lt;p&gt;如前所述，统计数据包括计数器、量规和直方图。从终端用户的角度来看，这些接口使用起来非常简单。例如，计数器和计量都包括&lt;code&gt;inc()&lt;/code&gt;和&lt;code&gt;dec()&lt;/code&gt;方法，而只有计量包括&lt;code&gt;set()&lt;/code&gt;方法。程序员看不到任何潜在的存储复杂性。&lt;/p&gt;
&lt;h3 id=&#34;flusher&#34;&gt;Flusher&lt;/h3&gt;
&lt;p&gt;为了获得高性能，使用原子 CPU 指令在内部缓冲所有的状态变化。在可配置的间隔内，所有计数器和计量都被冲到 flusher 中。注意，在当前的架构中，直方图值直接发送到接收器。下面将更详细地描述这一点。Flusher 在 main 线程中运行。&lt;/p&gt;
&lt;h3 id=&#34;sink&#34;&gt;Sink&lt;/h3&gt;
&lt;p&gt;统计数据接收器是一个接口，它接受通用的统计数据并将其转换为特定于后端的连线格式。所有接收器都使用 TLS，这样在刷新输出时就不会出现争用。然而，在实践中，目前只有主线会冲掉计数器和量规。所有线程都刷新直方图。&lt;/p&gt;
&lt;p&gt;目前 Envoy 只支持 TCP 和 UDP &lt;a href=&#34;https://github.com/b/statsd_spec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;statsd&lt;/a&gt;协议。statsd 是一种非常简单但得到广泛支持的传输格式。在未来，很可能会实现其他本地统计数据接收器，如&lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prometheus&lt;/a&gt;、&lt;a href=&#34;https://www.wavefront.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wavefront&lt;/a&gt;和 &lt;a href=&#34;https://www.influxdata.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;InfluxDB&lt;/a&gt;。还要注意 Envoy 目前不支持维度或标签统计。这将在下面的工作部分中进一步讨论。&lt;/p&gt;
&lt;h3 id=&#34;admin&#34;&gt;Admin&lt;/h3&gt;
&lt;p&gt;从操作的角度来看，能够实时地到达一个节点并转储当前状态是非常有用的。Envoy 可以通过&lt;code&gt;/stats&lt;/code&gt;&lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;管理端点&lt;/a&gt;实现此功能。管理端点直接查看存储库以加载所有计数器和计量并打印它们。这个端点目前不输出任何直方图数据。这同样是由于在当前的实现中直方图值是直接写入接收器的，因此存储不知道它们。&lt;/p&gt;
&lt;h3 id=&#34;直方图的架构&#34;&gt;直方图的架构&lt;/h3&gt;
&lt;p&gt;正如已经多次提到的，Envoy 目前不维护进程内直方图数据。除了开发效率之外，没有什么特别的原因；Lyft 使用的 statsd 摄取管道提供了自己的直方图支持，并希望直方图值直接发送到它。因此，直方图值目前不能通过管理端点查看。未来我们很可能直接在 Envoy 内部实现&lt;a href=&#34;http://hdrhistogram.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HDR 直方图&lt;/a&gt;。这一点将在下面进一步讨论。&lt;/p&gt;
&lt;h3 id=&#34;线程本地热重启的能力存储&#34;&gt;线程本地热重启的能力存储&lt;/h3&gt;
&lt;p&gt;以上所有的背景都完成了，现在是时候深入到有趣的部分：实践中是如何工作的？&lt;/p&gt;
&lt;h4 id=&#34;统计项&#34;&gt;统计项&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-stats/006tNbRwly1fxv1793dqqj30m8028glv_hu30f54fd114145af92b3751f8bbeeff3f_12826_2688680706d293061cc3c081fc16d272.webp 400w,
               /blog/envoy-stats/006tNbRwly1fxv1793dqqj30m8028glv_hu30f54fd114145af92b3751f8bbeeff3f_12826_4bff9b9938a4fe08022694ceb4df6cab.webp 760w,
               /blog/envoy-stats/006tNbRwly1fxv1793dqqj30m8028glv_hu30f54fd114145af92b3751f8bbeeff3f_12826_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-stats/006tNbRwly1fxv1793dqqj30m8028glv_hu30f54fd114145af92b3751f8bbeeff3f_12826_2688680706d293061cc3c081fc16d272.webp&#34;
               width=&#34;760&#34;
               height=&#34;76&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;center&gt;图 2：共享内存中单独的计数器/计量统计项&lt;/center&gt;
正如我们在[热重启文章](https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5)中已经讨论过的那样，最终，所有统计数据都存储在共享内存中，以便可以在所有进程中使用它们。**图 2**显示了单个 stat 条目。它由以下几个部分组成：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt;：完全解析的属性名，例如&lt;code&gt;http.admin.downstream_cx_active&lt;/code&gt;。目前限制为 128 个字符。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value&lt;/strong&gt;：属性的当前值。该数据包含量具的当前值和计数器的当前总价值。所有的数据写操作都使用原子操作，所以它们在多线程环境下是安全的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pending increment&lt;/strong&gt;：此数据仅供计数器使用。除了值之外，每个增量都是原子式的。之所以这样做，是因为大多数统计数据接收器想要获取刷新之间的增量而不是总数。因此，在冲洗期间计数器是锁住的。挂起的增量被写入计数器，然后归零。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flags&lt;/strong&gt;：目前只支持标志&lt;code&gt;used&lt;/code&gt;。这表示如果统计数据被写过，那么代码能够区分零和从未写过。Envoy 不会刷新从来没有使用过的统计数据，以避免压倒性的统计后端很少使用的统计数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ref count&lt;/strong&gt;：Ref count 允许重叠范围（可能在多个进程中）使用相同的底层统计数据。只有当 ref 计数为 0 时，才释放统计数据内存供将来使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;存储-1&#34;&gt;存储&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/envoy-stats/006tNbRwly1fxv1e9mvjdj30m80f1gn7_hua48cded1631941f90fc93c54c64de2c0_48455_41c5df4852e4d032baa2bd60ee0eaf81.webp 400w,
               /blog/envoy-stats/006tNbRwly1fxv1e9mvjdj30m80f1gn7_hua48cded1631941f90fc93c54c64de2c0_48455_c8f1906fac059b2c8fc28debad23c953.webp 760w,
               /blog/envoy-stats/006tNbRwly1fxv1e9mvjdj30m80f1gn7_hua48cded1631941f90fc93c54c64de2c0_48455_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/envoy-stats/006tNbRwly1fxv1e9mvjdj30m80f1gn7_hua48cded1631941f90fc93c54c64de2c0_48455_41c5df4852e4d032baa2bd60ee0eaf81.webp&#34;
               width=&#34;760&#34;
               height=&#34;514&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;center&gt;图 3:线程本地热重启支持的存储体系结构&lt;/center&gt;
**图 3** 显示了 Envoy 内部使用的线程本地 stat 存储的设计。这个版本的商店满足了之前发布的所有设计目标。现在我们将详细介绍它的工作原理。
&lt;ol&gt;
&lt;li&gt;该存储是单例存储，整个 Envoy 流程都使用它。所有的范围、计数器和标准引用都是从这个单例中心存储库获得的。（本节将不介绍直方图，因为目前直方图不重要，直接刷新到 TLS 统计数据接收器）。&lt;/li&gt;
&lt;li&gt;当线程试图通过作用域获取计数器或量规时，它首先在作用域 TLS 缓存中按名称查找计数器或量规。如果在缓存中找到了统计数据，它将立即返回给调用者，而不需要任何锁定。如果没有找到该属性，则必须从范围中央缓存中获取该属性。&lt;/li&gt;
&lt;li&gt;范围中央缓存通过标准进程范围内的互斥锁锁定（在稳定状态下，它不应该被高度竞争，因为统计信息将在范围 TLS 缓存中找到）。如果在中心缓存中找到了统计数据，那么它将返回到 TLS 缓存，在那里存储它以供以后无锁查找。如果在中央缓存中没有找到该属性，则必须从共享内存中分配该属性。&lt;/li&gt;
&lt;li&gt;共享内存包含一系列固定的个人统计条目（图 2）。Envoy 包含一个非常基本的分配器，搜索统计条目名称相同的槽 (支持热重启和重叠范围) 或一个空位置，选择初始化槽如果目前空，增加引用计数，并返回它。这是在热重启期间跨进程统计数据的工作方式。两个进程都将从共享内存中分配一个统计数据条目槽，但是其中一个进程最终将引用计数增加到两个（相同的进程在重叠作用域创建期间发生）。如果在共享内存中找不到空间，Envoy 将增加一个“panic”属性并返回一个特殊的溢出属性槽，以便进程可以在降级状态下继续运行。一旦一个统计数据槽被分配，它就被包装在一个进程本地数据结构中，存储在范围中心缓存中，存储在范围 TLS 缓存中，然后最终返回给调用者。&lt;/li&gt;
&lt;li&gt;回想一下，stat 子系统的目标之一是使作用域安全可删除。作用域是全局对象，由主线程和单例存储管理。删除作用域时，不同线程上的作用域 TLS 缓存可能持有对单个统计数据的引用。为了说明这一点，“作用域缓存刷新”事件通过 TLS 发送到每个线程。线程使用&lt;a href=&#34;https://medium.com/@mattklein123/envoy-threading-model-a8d44b922310&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;线程模型文章&lt;/a&gt;中描述的类似 RCU 的行为释放所有对作用域统计的引用。一旦计数器或表的最后一次引用计数被减少，共享内存统计项插槽也被释放。这是通过在统计数据条目插槽上减少引用计数来完成的。如果这个引用计数现在为零，那么这个槽就被完全释放了，并且可以被任何进程用于一个新的状态。如果前面的描述有点混乱，总结一下：Envoy 中的所有统计数据都由两个引用计数控制。第一个引用计数用于进程内 TLS 缓存的状态，第二个引用用于多个进程共享的备份状态入口槽。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;回顾一下，让我们看看上面的设计如何满足所有的原始目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线性吞吐量&lt;/strong&gt;：在稳定状态下，所有的统计数据分配都通过作用域 TLS 缓存进行。对于大量的工作线程来说这要求不能加锁。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在热重新启动期间逻辑上是一致的&lt;/strong&gt;：最终，所有同名的数据在共享内存中使用相同的备份存储。这在流程之间创建了逻辑一致性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统计数据包含在一个作用域内，可以作为一个组释放，也可以重叠&lt;/strong&gt;：作用域具有完全独立的中央缓存和 TLS 缓存，以及独立的每个统计数据引用计数。一个作用域可以被移除，并且它的所有统计数据的引用计数将会减少，并且可能会被释放。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;足够的动态统计数据性能&lt;/strong&gt;：通过范围 TLS 缓存查找动态统计数据并使用 O(1) 哈希表。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;未来的工作&#34;&gt;未来的工作&lt;/h2&gt;
&lt;p&gt;虽然 Envoystats 子系统工作得很好，但是有几个方面在未来可以改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;维度/标记状态:&lt;/strong&gt; 大多数更新的状态后端支持维度/标记，而不仅仅是一个扁平的层次命名空间。在特使统计数据的某些区域中，这是很有用的。短期而言，我们可能会添加全球标记支持，作为支持它的后端（如Prometheus、Wavefront和流感数据库）的第一步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;线程本地原子缓存：&lt;/strong&gt; 在 worker 数量和吞吐量极高的情况下，单个 stat 值上的原子争用将成为一个问题。这可以通过移动到 TLS 计数器和压力表来解决，这些计数器和压力表在冲洗之前被聚集到中央存储中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内置的 HDR 直方图：&lt;/strong&gt; 由于几个原因（管理输出、基于异常值的延迟检测和没有内置直方图支持的接收器），向 Envoy 添加直接的 HDR 直方图支持将非常有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;额外的静态接收器：&lt;/strong&gt; 如前所述，我们希望直接支持更多的后端，如 Prometheus、Wavefront、InfluxDB 等。幸运的是，接收器接口很简单，添加新的实现并不困难。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;为了满足上述目标，Envoy 的数据统计子系统的设计是新颖的。到目前为止，它在实践中表现得非常好，对于其他用例来说，扩展起来应该相对容易。&lt;/p&gt;
&lt;h2 id=&#34;代码链接&#34;&gt;代码链接&lt;/h2&gt;
&lt;p&gt;本文中涉及到的一些接口及实现的头文件请参考下面链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy/blob/master/include/envoy/stats/stats.h&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/envoyproxy/envoy/blob/master/include/envoy/stats/stats.h&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy/tree/master/source/common/stats&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/envoyproxy/envoy/tree/master/source/common/stats&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Service Mesh 中的通用数据平面 API 设计</title>
      <link>https://cloudnative.to/blog/the-universal-data-plane-api/</link>
      <pubDate>Thu, 21 Jun 2018 16:11:03 +0800</pubDate>
      <guid>https://cloudnative.to/blog/the-universal-data-plane-api/</guid>
      <description>&lt;p&gt;正如我之前所说的，在如此短的时间内，&lt;a href=&#34;https://lyft.github.io/envoy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt; 带来的兴奋既神奇又震撼人心。我经常问自己：envoy 的哪些方面导致了我们所看到的异常的社区增长？虽然 Envoy 具有很多引人注目的特征，但最终我认为有三个主要特征在共同推动：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;性能&lt;/strong&gt;：在具备大量特性的同时，Envoy 提供极高的吞吐量和低尾部延迟差异，而 CPU 和 RAM 消耗却相对较少。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：Envoy 在 L4 和 L7 都提供了丰富的可插拔过滤器能力，使用户可以轻松添加 开源版本中没有的功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API 可配置性&lt;/strong&gt;：或许最重要的是，Envoy 提供了一组可以通过控制平面服务实现的&lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/dynamic_configuration.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;管理 API&lt;/a&gt; 。如果控制平面实现所有的 API，则可以使用通用引导配置在整个基础架构上运行 Envoy。所有进一步的配置更改通过管理服务器以无缝方式动态传送，因此 Envoy 从不需要重新启动。这使得 Envoy 成为通用数据平面，当它与一个足够复杂的控制平面相结合时，会极大的降低整体运维的复杂性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有代理具备超高性能。也有代理具备高度的可扩展性和动态可配置性。在我看来，性能、可扩展性和动态可配置性的&lt;em&gt;结合&lt;/em&gt; 才使得 Envoy 如此的引人注目。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我将概述 Envoy 动态配置 API 背后的历史和动机，讨论从 v1 到 v2 的演变，最后，鼓励更多的负载均衡，代理和控制平面社区来考虑在其产品中支持这些 API。&lt;/p&gt;
&lt;h2 id=&#34;envoy-api-v1-的历史&#34;&gt;Envoy API v1 的历史&lt;/h2&gt;
&lt;p&gt;Envoy 最初的设计目标之一是实现&lt;a href=&#34;https://lyft.github.io/envoy/docs/intro/arch_overview/service_discovery.html#on-eventually-consistent-service-discovery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;最终一致的服务发现&lt;/a&gt;系统。为此，我们开发了一个非常简单的&lt;a href=&#34;https://github.com/lyft/discovery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;发现服务&lt;/a&gt;和 &lt;a href=&#34;https://lyft.github.io/envoy/docs/configuration/cluster_manager/sds_api.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Discovery Service (SDS) REST API&lt;/a&gt;，用来返回上游集群成员。该 API 克服了基于 DNS 的服务发现的一些限制（记录限制、缺少额外元数据等），并使我们能够快速实现高可靠性。&lt;/p&gt;
&lt;p&gt;Envoy 开源初期，我们收到了很多关于支持其他服务发现系统的要求，如 Consul、Kubernetes、Marathon、DNS SRV 等。我担心我们对这些系统直接支持的缺失会限制 Envoy 的使用范围而不被人所接纳。添加新的发现适配器的代码编写并不困难，我希望有关方面能够实施新的适配器。而过去一年实际发生是什么？没有一个新的适配器被贡献到代码中，但我们看到了令人难以置信的接受度。为什么？&lt;/p&gt;
&lt;p&gt;事实证明，几乎每个人都以自己的方式来实现 SDS API。API 本身是微不足道的，但我不认为这是人们实现它的唯一原因。另一个原因是，离数据平面越远，事情自然就会开始变得更牢固。Envoy 的消费者通常希望最终服务发现能够集成到特定的工作流程中。API 的简单性使得其可以轻松集成到几乎任何控制平面系统中。甚至像 Consul 系统的用户（参见示例 &lt;a href=&#34;https://verizon.github.io/nelson/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nelson&lt;/a&gt;）也发现中间 API 可以对成员和命名做更智能的处理。因此，即使在如此早期的阶段，我们也看到了对&lt;em&gt;通用数据平面 API&lt;/em&gt; 的渴望：一个简单的 API，从控制平面中抽象出数据平面。&lt;/p&gt;
&lt;p&gt;在过去的一年中，Envoy 添加了多个 v1/REST 管理 API。他们包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://lyft.github.io/envoy/docs/configuration/cluster_manager/cds.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;集群发现服务（CDS）&lt;/a&gt;：使用此 API，Envoy 可以动态地添加/更新/删除所有上游集群（每个集群本身都有自己的服务/端点发现）。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lyft.github.io/envoy/docs/configuration/http_conn_man/rds.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;路由发现服务（RDS）&lt;/a&gt;：使用此 API，Envoy 可以动态地添加/更新 HTTP 路由表。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lyft.github.io/envoy/docs/configuration/listeners/lds.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;监听器发现服务（LDS）&lt;/a&gt;：使用此 API，Envoy 可以动态地添加/更新/删除全体监听器，包括其完整的 L4 和 L7 过滤器堆栈。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当控制平面实现 SDS/CDS/RDS/LDS 时，几乎 Envoy 的所有方面都可以在运行时动态配置。&lt;a href=&#34;https://istio.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt; 和 &lt;a href=&#34;https://verizon.github.io/nelson/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nelson&lt;/a&gt; 都是控制平面的例子，他们在 V1 API 上构建，具备极其丰富的功能。通过使用相对简单的 REST API，Envoy 可以快速迭代性能和数据平面功能，同时仍支持各种不同的控制平面方案。此时，通用数据平面概念正成为现实。&lt;/p&gt;
&lt;h2 id=&#34;v1-api-的缺点和-v2-的引入&#34;&gt;v1 API 的缺点和 v2 的引入&lt;/h2&gt;
&lt;p&gt;v1 API 仅使用 JSON/REST，本质上是轮询。这有几个缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尽管 Envoy 在内部使用的是 JSON 模式，但 API 本身并不是强类型，而且安全实现它们的通用服务器也很难。&lt;/li&gt;
&lt;li&gt;虽然轮询工作在实践中是很正常的用法，但更强大的控制平面更喜欢 streaming API，当其就绪后，可以将更新推送给每个 Envoy。这可以将更新传播时间从 30-60 秒降低到 250-500 毫秒，即使在极其庞大的部署中也是如此。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在过去几个月与 Google 的紧密合作中，我们一直在努力研究一组我们称之为 v2 的新 API。v2 API 具有以下属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新的 API 模式使用 &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;proto3&lt;/a&gt; 指定，并同时以 gRPC 和 REST + JSON/YAML 端点实现。另外，它们被定义在一个名为 &lt;a href=&#34;https://github.com/lyft/envoy-api&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;envoy-api&lt;/a&gt; 的新的专用源代码仓库中。proto3 的使用意味着这些 API 是强类型的，同时仍然通过 proto3 的 JSON/YAML 表示来支持 JSON/YAML 变体。专用存储仓库的使用意味着项目可以更容易的使用 API 并用 gRPC 支持的所有语言生成存根（实际上，对于希望使用它的用户，我们将继续支持基于 REST 的 JSON/YAML 变体）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;译者注：&lt;a href=&#34;https://github.com/lyft/envoy-api&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;envoy-api&lt;/a&gt; 仓库在 Envoy 加入 CNCF 后改为 &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;envoyproxy/data-plane-api&lt;/a&gt; 仓库，问题后面有提到。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;v2 API 是 v1 的演进，而不是革命，它是 v1 功能的超集。v1 用户会发现 v2 非常接近他们已经在使用的 API。实际上，我们一直以可以继续永久支持 v1（尽管是最终被冻结的功能集）的方式在 Envoy 中实现 v2。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不透明的元数据已被添加到各种 API 响应中，这将极大的增强可扩展性。例如，HTTP 路由中的元数据，附加到上游端点和自定义负载均衡器的元数据，以用来构建站点特有的基于标签的路由。我们的目标是可以在默认的 OSS 发行版之上&lt;a href=&#34;https://github.com/lyft/envoy-filter-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;轻松插入丰富的功能&lt;/a&gt;。未来将有更强大的关于编写 Envoy 扩展的文档。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于使用 v2 gRPC（vs. JSON/REST）的 API 消费者，双向流会有一些有趣的增强，我将在下面进行更多讨论。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2 API 由以下部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Endpoint Discovery Service (EDS)：这是 v1 SDS API 的替代品。SDS 是一个不幸的名字选择，所以我们正在 v2 中修复这个问题。此外，gRPC 的双向流性质将允许将负载/健康信息报告回管理服务器，为将来的全局负载均衡功能开启大门。&lt;/li&gt;
&lt;li&gt;Cluster Discovery Service (CDS)：和 v1 没有实质性变化。&lt;/li&gt;
&lt;li&gt;Route Discovery Service (RDS)：和 v1 没有实质性变化。&lt;/li&gt;
&lt;li&gt;Listener Discovery Service (LDS)：和 v1 的唯一主要变化是：我们现在允许监听器定义多个并发过滤栈，这些过滤栈可以基于一组监听器路由规则（例如，SNI，源/目的地 IP 匹配等）来选择。这是处理“原始目的地”策略路由的更简洁的方式，这种路由是透明数据平面解决方案（如 Istio）所需要的。&lt;/li&gt;
&lt;li&gt;Health Discovery Service (HDS)：该 API 将允许 Envoy 成为分布式健康检查网络的成员。中央健康检查服务可以使用一组 Envoy 作为健康检查终点并将状态报告回来，从而缓解 N²健康检查问题，这个问题指的是其间的每个 Envoy 都可能需要对每个其他 Envoy 进行健康检查。&lt;/li&gt;
&lt;li&gt;Aggregated Discovery Service (ADS)：总的来说，Envoy 的设计是最终一致的。这意味着默认情况下，每个管理 API 都并发运行，并且不会相互交互。在某些情况下，一次一个管理服务器处理单个 Envoy 的所有更新是有益的（例如，如果需要对更新进行排序以避免流量下降）。此 API 允许通过单个管理服务器的单个 gRPC 双向流对所有其他 API 进行编组，从而实现确定性排序。&lt;/li&gt;
&lt;li&gt;Key Discovery Service (KDS)：该 API 尚未定义，但我们将添加一个专用的 API 来传递 TLS 密钥材料。这将解耦通过 LDS/CDS 发送主要监听器、集群配置和通过专用密钥管理系统发送秘钥素材。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;译者注：目前 xds 中没有 kds 的定义，但是有一个 Secret Discovery Service，应该是这个 kds 的改名。以上 API 请参考 &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/tree/master/envoy/api/v2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/envoyproxy/data-plane-api/tree/master/envoy/api/v2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;总的来说，我们称所有上述 API 为 &lt;code&gt;xDS&lt;/code&gt;。从 JSON/REST 到 proto3 API 的过渡非常令人兴奋，良好类型的 proto3 API 可以更容易使用，我认为这将进一步提高 API 本身以及 Envoy 的接受度。&lt;/p&gt;
&lt;h2 id=&#34;多代理多控制平面的-api&#34;&gt;多代理多控制平面的 API？&lt;/h2&gt;
&lt;p&gt;服务网格/负载均衡领域现在非常活跃。代理包括 Envoy、&lt;a href=&#34;https://linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linkerd&lt;/a&gt;、&lt;a href=&#34;https://www.nginx.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NGINX&lt;/a&gt;、&lt;a href=&#34;https://www.haproxy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HAProxy&lt;/a&gt;、&lt;a href=&#34;https://traefik.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Traefik&lt;/a&gt;，来自所有主要云提供商的软件负载均衡器，以及传统硬件供应商（如 F5 和思科）的物理设备。随着众多解决方案的出现，如 &lt;a href=&#34;https://istio.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;、&lt;a href=&#34;https://verizon.github.io/nelson/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nelson&lt;/a&gt;，集成云解决方案以及许多供应商即将推出的产品等，控制平面领域也在不断升温。&lt;/p&gt;
&lt;p&gt;特别讨论一下 Istio，Linkerd 已经宣布对它的支持，这意味着至少在某种程度上它已经实现了 v1 Envoy API。其他人可能会跟随。在这个数据平面和控制平面快速发展的新世界中，我们将看到组件的混合和匹配；数据平面将与许多控制平面一起工作，反之亦然。我们是否可以让业界受益于一种通用 API，让这种混合和匹配更容易实现？这会有什么帮助？&lt;/p&gt;
&lt;p&gt;在我看来，在接下来的几年中，数据平面本身将大部分商品化。大部分创新（和商业机会扩展）实际上将成为控制平面的一部分。使用 v2 Envoy API，控制平面功能的范围可以会从使用 N² 健康检查的扁平端点命名空间扩展到一个非常丰富的全局负载均衡系统，该系统可进行自动构造子集、负载装卸和均衡、分布式局部健康检查、区域感知路由、基于百分比的自动部署和回滚等。供应商将在提供无缝的微服务运维环境方面展开竞争，而对路由的自动化控制将是其竞争中的主要部分。&lt;/p&gt;
&lt;p&gt;在这个新的世界中，数据平台可以用来与控制平面进行通讯的通用 API 对每个参与者都是一个胜利。控制平面提供商可以将它们的服务提供给实现该 API 的任何数据平面。数据平面可以在功能，性能，规模和健壮性方面展开竞争。此外，解耦允许控制平面提供商提供 SaaS 解决方案，而不需要同时拥有数据平面部署，这是一个主要的痛点。&lt;/p&gt;
&lt;h2 id=&#34;envoy-api-合作邀请&#34;&gt;Envoy API 合作邀请&lt;/h2&gt;
&lt;p&gt;虽然很难知道未来几年会发生什么，但我们对 Envoy 及其相关 API 的采用感到非常兴奋。我们看到了通用的数据平面 API 的价值所在：可以桥接不同系统。根据这些原则，我们邀请更大的数据平面和控制平面供应商以及用户与我们在 &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;envoy-api&lt;/em&gt;&lt;/a&gt; 存储仓库中进行协作（请注意，当 Envoy 进入 CNCF 并转换到专用的 envoyproxy GitHub 组织时，我们将重命名该存储仓库为 data-plane-api）。我们不保证我们将添加所有可能的功能，但我们希望看到其他系统使用这些 API 并帮助我们改进它们以满足他们自己的需求。我们的观点是，数据平面的商品化将为最终用户带来巨大收益，这有助于控制平面领域提高迭代和竞争速度，未来几年大部分创新将会发生在控制平面。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;英文原文发布于 2017 年 9 月 6 日，本文发出时 Envoy 已经进入了 CNCF，成为了官方项目，Envoy 原来的代码都已经被重构和迁移，本文中提到的很多链接都已过时，请大家参考 Envoy 官网 &lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/&lt;/a&gt;，也可以查看 Envoy 官方文档中文版 &lt;a href=&#34;https://servicemesher.github.io/envoy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://servicemesher.github.io/envoy/&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
