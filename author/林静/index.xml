<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>林静 | 云原生社区（中国）</title>
    <link>https://cloudnative.to/author/%E6%9E%97%E9%9D%99/</link>
      <atom:link href="https://cloudnative.to/author/%E6%9E%97%E9%9D%99/index.xml" rel="self" type="application/rss+xml" />
    <description>林静</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Tue, 27 Dec 2022 12:00:00 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/author/%E6%9E%97%E9%9D%99/avatar_hu17762776515273144913.jpg</url>
      <title>林静</title>
      <link>https://cloudnative.to/author/%E6%9E%97%E9%9D%99/</link>
    </image>
    
    <item>
      <title>是时候思考 Kubernetes 出向流量安全了</title>
      <link>https://cloudnative.to/blog/egress-for-k8s/</link>
      <pubDate>Tue, 27 Dec 2022 12:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/egress-for-k8s/</guid>
      <description>&lt;h2 id=&#34;为何要进行-egress-流量策略管控&#34;&gt;为何要进行 Egress 流量策略管控&lt;/h2&gt;
&lt;p&gt;2021 年 CNCF 调查显示，全球将 kubernetes 用在生产环境的用户占比已达 59.77%，欧洲用户更是达到了 68.98%。用户正越来越多的将生产业务迁移到 kubernetes 环境下。Gartner 2021 Hype Cycle for Cloud Security 也显示了容器与 Kubernetes 安全已处在”slope of Enlightenment”阶段。这说明保护 kubernetes 里的应用服务正变的越来越重要。&lt;/p&gt;
&lt;p&gt;当我们去审视运行在 kubernetes 中的大量微服务时，我们可以看到微服务安全具有典型的微边界以及需要进行持续性安全工程的特点。我们需要以每个微服务为边界进行保护，无论是其运行时，还是南北和东西流量。需要每个微服务单元在编码之初就开始着手安全考虑，进行安全左移，安全的防护设施、方法、策略应与开发者和 kubernetes 平台运维者适配。还需要有能力洞察所有的流量事件，采集所有运行时日志、事件等数据，通过持续性的安全工程系统对这些数据进行分析，聚合出规则并反馈到安全的策略设定中。&lt;/p&gt;
&lt;p&gt;kubernetes 里的微服务不会只在集群内部封闭运行，它需要访问集群外部应用、数据库、第三方 API 服务、互联网服务等。出向流量里可能包含业务需要的外部访问，开源组件更新的访问，甚至可能是被入侵的应用向 C2 连接的流量。因此，必须对 kubernetes 中的微服务主动外出流量进行管控，确保其安全合规。在以云原生架构为核心技术驱动的数字化转型下，企业会大量采用开源技术，而这可能是最容易引入安全风险的地方，无论是否有明确的开源准入机制，企业都应足够重视这些开源产品可能的主动外访服务，将其管控好，确保安全。&lt;/p&gt;
&lt;p&gt;管理 kubernetes 中的出向流量策略，看似简单的需求，要想做好却并不是一件容易的事。本文将和您一起分析 kubernetes 出向策略的挑战，并针对当前常见解决方案的优缺点进行分析，思考企业应如何做好 kubernetes 出向流量策略管控。&lt;/p&gt;
&lt;h2 id=&#34;存在的挑战&#34;&gt;存在的挑战&lt;/h2&gt;
&lt;h3 id=&#34;动态&#34;&gt;动态&lt;/h3&gt;
&lt;p&gt;从技术角度看，这是第一个存在的挑战。在 kubernetes 环境下，微服务单元的 pods 将是高度动态的、分散的。IP、网段和物理位置将会随时发生变化。因此直接采用 IP 等特征进行静态化策略设定将是一件不可能的事情。策略必须依赖于其它抽象的应用标签、服务名或命名空间等进行，并能做到动态感知变化。&lt;/p&gt;
&lt;h3 id=&#34;粒度&#34;&gt;粒度&lt;/h3&gt;
&lt;p&gt;传统应用环境下，对一个应用出向流量策略的管控一般来说只需要对该应用所涉及的少量部署进行策略设定即可。然而在微服务加容器化的环境下，一个应用可能会有许多的微服务组成，而一个微服务又包含许多 pods。不同的微服务单元会需要不同的出向策略规则，比如 payment 需要连接第三方外部接口，而评论服务则不需要主动访问第三方服务。这意味着策略设定的粒度需要精细到每个微服务单元，并确保管控了所有相关的 pods。可以看出，策略管控粒度更细、工作量更大、复杂性更高。&lt;/p&gt;
&lt;h3 id=&#34;协同&#34;&gt;协同&lt;/h3&gt;
&lt;p&gt;当我们要为不同的微服务单元部署出向策略时候，谁应该为此负责，应用开发部门？应用部署与运维部门？kubernetes 的 platformOps 部门？或是安全部门？我们以安全左移的思想去看待这件事时，显然应用部门应该考虑他的微服务是否需要主动外访，需要访问哪些外部服务。然而，如果由应用开发人员负责，是不是平台或安全部门就可以放手不管？显然不是，应用开发人员最多是为其所负责的应用设定安全策略，与应用无关的全局性基础安全策略，如何快速补救应用开发人员设定的错误策略，这些依然需要由其他团队来负责。而要想开发部门能够践行安全左移的思想，那么 PlatformOps 或安全部门则必须提供友好的工具并将安全策略的设定集成到 DevSecOps 的 pipeline 当中，如果工具或方法导致开发效率下降，开发人员将不乐意去使用。所以，这不是某一个部门的独立工作，需要多团队的协作来确保安全。&lt;/p&gt;
&lt;h3 id=&#34;数据驱动&#34;&gt;数据驱动&lt;/h3&gt;
&lt;p&gt;正如文章开始所述，安全是一个持续工程化的工作，意味着任何出向访问行为与事件都应被记录到安全工程系统中进行分析，以确保足够的可见性和洞察。出向安全管控不仅仅是一个简单策略设定，需具有完整日志、行为、事件输出的能力。&lt;/p&gt;
&lt;h2 id=&#34;业界方案分析&#34;&gt;业界方案分析&lt;/h2&gt;
&lt;p&gt;接下来，我们来逐一分析当前业界关于出向策略管控的解决方案，首先我们将其分为 6 大类方案，然后再逐一分析：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Category&lt;/th&gt;
          &lt;th&gt;Solutions or products&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Platform based&lt;/td&gt;
          &lt;td&gt;Kubernetes Network policy&lt;br&gt;Openshift EgressIP&lt;br&gt;Openshift Egress Router pod&lt;br&gt;Openshift Egress Firewall&lt;br&gt;Openshift EgressNetworkPolicy&lt;/td&gt;
          &lt;td&gt;A specific feature of a platform provider&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CNI based&lt;/td&gt;
          &lt;td&gt;Calico Egress pod&lt;br&gt;Calico Enhanced Network policy&lt;br&gt;Cilium Enhanced Network policy&lt;br&gt;Kube-ovn&lt;/td&gt;
          &lt;td&gt;The capability of CNI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Service Mesh&lt;/td&gt;
          &lt;td&gt;NGINX Service Mesh&lt;br&gt;Istio&lt;/td&gt;
          &lt;td&gt;A function of Service Mesh&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Micro segmentation&lt;/td&gt;
          &lt;td&gt;PrismaNeu&lt;br&gt;Vector&lt;/td&gt;
          &lt;td&gt;From ZTA perspective or use enforcer container to control egress&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Fusion&lt;/td&gt;
          &lt;td&gt;F5 CES(Container Egress Service)&lt;br&gt;Fortinet&lt;/td&gt;
          &lt;td&gt;Use k8s native method to integrate exist security assets to k8s&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Others&lt;/td&gt;
          &lt;td&gt;DNS interception&lt;br&gt;Proxy pod&lt;/td&gt;
          &lt;td&gt;Intercept coredns or use a proxy pod as forward proxy&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;platform-based&#34;&gt;Platform based&lt;/h3&gt;
&lt;p&gt;kubernetes 自带的 Network policy，这是最容易想到的关于出向安全策略管控方法。它是 k8s 的自身能力，对于开发者或 PlatformOps 人员来说具有天然的亲和性，能够很好的适应安全左移的思想。但 Network policy 需 CNI 支持。其它一些缺点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有集群全局性的策略能力，不同 namespace 下要维护独立的 policy&lt;/li&gt;
&lt;li&gt;没有以 k8s svc 名称为条件的选择能力（可改为选 pod 标签，但不灵活）&lt;/li&gt;
&lt;li&gt;无显式拒绝能力，通过策略的隔离性特点，然后施加具体的白名单&lt;/li&gt;
&lt;li&gt;规则无优先级概念&lt;/li&gt;
&lt;li&gt;无明确的集群外访规则，外部目标服务只能依靠宽泛的 ipblock&lt;/li&gt;
&lt;li&gt;纯四层，无七层的控制能力&lt;/li&gt;
&lt;li&gt;无策略执行调试能力&lt;/li&gt;
&lt;li&gt;无策略执行日志&lt;/li&gt;
&lt;li&gt;Networkpolicy 的“隔离性”特点使得维护工作变得及其麻烦，例如，本身只想控制其对互联网的访问，但因为隔离性，就不得不额外维护该 pod 在集群内的所有出向（东西向）访问&lt;/li&gt;
&lt;li&gt;不能解决 k8s 与外部安全设备协同问题。试想一下，Network policy 做了规则控制后，那么外部的安全设备就可以为该集群打开一个默认通行的规则吗？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Openshift，在 Egress 方面有四个特性与之有关，分别是标准的 Network Policy，Egress IP，Egress Router，Egress Firewall 以及 Egress NetworkPolicy。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network Policy，当 Openshift 使用 OVN-Kubernetes 作为 CNI 时完全支持，而传统的 Openshift SDN CNI 则仅是部分支持。与标准的 kubernetes 并无不同，其优缺点这里不再做额外分析。&lt;/li&gt;
&lt;li&gt;EgressIP，是用来实现 Pods 流量离开集群时候使用确定性源 IP 的一种功能。当使用 Openshift SDN CNI 时，该功能将 Egress IP 应用到指定的 nodes 上作为 secondary IP，并用于 SNAT。当使用 OVN-kubernetes CNI 时候，则通过 OVS 为具体的 pods 执行 snat 规则。使用 EgressIP，本身并不是出向安全策略管控的直接方法，但是借助为不同的 namespace 指定确定的源 IP，这样可以在集群外部的安全设备上部署一些策略来执行控制。显而易见，这种策略控制方式比较粗放，无法做到对不同服务的精细化粒度。如果 pods 分散在不同的 nodes 上，则还会存在 pods 出集群流量要先在不同 nodes 之间穿越问题，增加了额外的延迟。此外，EgressIP 还必须与 nodes 的主网络地址同属相同网段，且一个 node 不可以拥有一个以上的 EgressIP。EgressIP 也不支持公有云以及 Redhat Openstack Platform。&lt;/li&gt;
&lt;li&gt;Egress Router Pod，它是一种特殊的 pod，拥有两个网卡，使用 MacVlan 技术将其中一个容器网卡与外部网络直接连通。所有 pods 出集群流量都会经过该 pod。根据不同的 CNI（SDN 或 OVN-kubernetes）, 具有的功能也不同，在 OVN-kubernetes CNI 下仅支持重定向操作。一般来说这并不适合大规模使用，从 Egress 安全策略设定角度，这也依然无法区分不同服务，且集中的 Egress pod 容易成为性能瓶颈。&lt;/li&gt;
&lt;li&gt;EgressFirewall，它实际是 OVN-kubernetes 的特性。容许为某个 project 或 namespace 设置出向访问规则，可以基于协议，端口，IP，DNS 等维度。协议仅支持 TCP，UDP，SCTP 三种，无法支持其它协议控制。它只容许基于 namespace 级别设定，一个 namespace 中只容许设置一个规则文件，无法为集群内的不同 service 来设定不同的 Egress 规则。同时它限制每个 namespace/project 最大 8000 条规则。也不支持可观测或事件。&lt;/li&gt;
&lt;li&gt;Egress NetworkPolicy，与 EgressFirewall 功能类似，当采用 Openshift SDN CNI 时候支持该 CRD。但是 Egress NetworkPolicy 具有更多的限制性，例如每个 namespace/project 最大支持 1000 条规则，且必须打开 nework policy 或 multitennat 模式。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cni-based&#34;&gt;CNI based&lt;/h3&gt;
&lt;p&gt;以 Calico 和 Cilium 为典型代表的 CNI，在标准 k8s Network Policy 上扩展了部分能力，主要表现在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持全局策略（Calico，Cilium）&lt;/li&gt;
&lt;li&gt;DNS-based 策略支持（Calico 企业，Cilium)&lt;/li&gt;
&lt;li&gt;L7 仅 HTTP 协议扩展（Calico，Cilium）&lt;/li&gt;
&lt;li&gt;Log（Calico，Cilium）&lt;/li&gt;
&lt;li&gt;扩展策略的应用对象到 pod 以外，例如 node 等（Calico，Cilium）&lt;/li&gt;
&lt;li&gt;层次化策略，角色化边界设定（Calico 企业）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要实现这些能力，企业首先需使用这些 CNI。部分企业特性，例如层次化策略与角色设定、DNS 支持等需要额外购买服务。这会造成用户 CNI 技术锁定，不利于多云场景部署。Calico 在中国也没有服务销售，这些都会阻碍客户体验。在 CNI 上采取复杂的安全策略，会导致在集群内部创建大量复杂的规则，造成排错困难，运维成本增大。大量的规则，也可能会导致网络性能下降。&lt;/p&gt;
&lt;p&gt;对于 Calico Egress Pod，是一个特殊的 pod，拥有固定的可路由的 SNAT 地址，当 Egress 流量从该专用 pod 流出时，携带了专用固定地址，这容许外部防火墙等安全设备基于该固定地址进行策略设定。其行为上与 Openshift 的 Egress Router pod 类似，从 Egress 安全策略设定角度，它无法为不同服务执行细粒度的安全策略设定或成为性能瓶颈。&lt;/p&gt;
&lt;h3 id=&#34;service-mesh&#34;&gt;Service Mesh&lt;/h3&gt;
&lt;p&gt;Service Mesh 并不是 Egress 流量管控的专门方案，因此要通过 Service Mesh 实现 Egress 的管控意味着首先需要部署整体 Service Mesh 方案，比如 Istio。如果仅仅是为了实现 Egress 的管控，这样的方案会显得较重。Service Mesh 所支持的协议范围也较少，这对于企业的安全策略来说还不足够。&lt;/p&gt;
&lt;p&gt;在 Istio 中，当设置 meshConfig.outboundTrafficPolicy.mode 为 REGISTRY_ONLY 后，可以通过 sidecar 结合 ServiceEntry 资源实现外部服务访问的白名单。也可以通过结合 Egress Gateway 将流量导向到专门的 Egress Gateway。相比于 ServiceEntry 方法，Egress Gateway 则结合了 VirtualService 和 DestinationRule 来实现更多的控制，配合 AuthorizationPolicy 则可以控制粒度更细一些。&lt;/p&gt;
&lt;p&gt;无论哪种方式，都必须依赖 sidecar 进行流量的劫持，如果有威胁绕开或破坏了 sidecar，则意味着有害访问可以直接绕开管控，这个安全问题在 Istio 的文档中被反复提及。所以本质上来说它不是一个很好的 Egress 流量管控方案。同时，Service Mesh 的思维更多是面向开发者（尽管它常常体现的是平台层面的能力），所以我们依然需要回答这样一个问题：当开发者设置了外部服务访问白名单后，集群外部是否就可以信任开发者这样的设置，外部安全设备是否就可以设置为容许集群的任意外部访问？&lt;/p&gt;
&lt;h3 id=&#34;micro-segmentation&#34;&gt;Micro Segmentation&lt;/h3&gt;
&lt;p&gt;微分段一般是 Zero Trust Architecture (ZTA) 领域热衷的概念，通过技一些技术（如 TC，IPtables，DPI）对底层流量进行探查、操纵与控制，实现对容器内进程、容器间通信、容器与集群外的通信的可视化与策略控制。一般来说会在集群的各个主机上安装 DaemonSet 类容器实现对底层流量的探查。此类方案可以基于较细的粒度进行 Egress 策略控制，例如对哪些应用相关 pods 通过哪些协议访问哪些外部服务，亦可选择诸如 Service account 或 Label 等要素。对于应用层加密数据，如果是 Istio 环境则可通过探查 sidecar 与应用容器之间流量实现明文探查；如果是应用容器自身直接加密则无法实现探查，但可以通过结合 DNS 解析、SNI 实现一定程度上的策略管控。&lt;/p&gt;
&lt;h3 id=&#34;fusion&#34;&gt;Fusion&lt;/h3&gt;
&lt;p&gt;上述的多种类型方案，主要切入点是在集群内。在客户的实际生产环境中，kubernetes 集群是一种资源性对象，从企业整体安全角度来看，外部安全设备依然有必要对 kubernetes 集群的出向流量进行管控。让外部安全设备与 kubernetes 集群融合，其难点在于，传统安全设备不是直接面向 kubernetes 设计。高动态性、IP 无关性会成为传统设备进行 kubernetes 出向流量管控的难点。但这并不是无法解决的技术难题，如果外部安全设备具有较好的 API 接口，通过专门设计的控制器则可以解决上述技术难题。这样，外部安全防护的措施便可以应用到 kubernetes 集群上来，形成完整的纵深防御体系。同时可以保护企业已有投资，节约成本。通过面向 kubernetes 的自定义资源类型设计，负责外部安全设备的团队也因此可以介入到 kubernetes 集群的整体安全工作中来，避免了团队的割裂。&lt;/p&gt;
&lt;p&gt;F5 的 Application Firewall Manager (AFM) 通过专用的免费控制器（CES）实现了以 kubernetes 原生自定义资源（CRD）方式进行 Egress 策略的控制，并实现了安全规则与角色的层次化设定，让安全设备管理员融合到了 kubernetes 平台。借助 AFM 的能力，可实现 Egress 流量的高级访问规则、限流、协议检查、日志与事件可视化等。&lt;/p&gt;
&lt;p&gt;Fortinet 自身以及与 Calico 企业版联合，也实现了与 kubernetes 的集成，但其主要特点是将 kubernetes 资源对象转化并写入 Fortinet 的地址组中，其管理视角依然是防火墙管理员视角，而不是 kubernetes native 方式。&lt;/p&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;p&gt;Proxy pod 是一种普通的正向代理，应用使用该代理实现对外部业务的访问。此种方式一般仅适合小规模场景，不适合大规模集群及复杂业务。DNS interception，其原理是通过 patch coredns，如果应用访问 ExternalService 对象中设定的外部服务，则将请求引导到一个专用的 proxy pod 上（例如 Envoy 等）实现对流量的处理。该方案同样不适合大规模场景。&lt;/p&gt;
&lt;p&gt;在完成对上述 6 类 Egress 流量管控方案的分析后，让我们来总结和对比一下这些方案的优缺点：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-方案特性比较&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;方案特性比较&#34; srcset=&#34;
               /blog/egress-for-k8s/solutions-comparison_hu9170336069257629228.webp 400w,
               /blog/egress-for-k8s/solutions-comparison_hu4707590452245805263.webp 760w,
               /blog/egress-for-k8s/solutions-comparison_hu17144274194584100008.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/egress-for-k8s/solutions-comparison_hu9170336069257629228.webp&#34;
               width=&#34;760&#34;
               height=&#34;236&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      方案特性比较
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;可以看出 Network Policy 虽然是一个 kubernetes 原生的方式，但显然并不适合于集群 Egress 流量的管控。CNI 类产品有了一定的增强，但是在协议检测、企业级支持方面还是不够。微分段类产品具有相对完整的能力，但是微分段是一个整体性的解决方案，仅仅使用微分段实现集群出向流量的管控会显得投入较大，且微分段的产品一般底层技术较为复杂，运维难度较高。将外部安全设施融入到 kubernetes 当中实现出向流量管控的解决方法更加适合企业，无论是功能特性还是运维复杂度都比较适合，更加重要的是，该类方案将企业的传统安全资产与现代应用架构进行了结合，让不同部门能够紧密协同，形成纵深防御体系。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;我们往往重视 Ingress 的能力，而忽视了 Egress 流量的安全管控。但无论从安全还是合规的角度，Egress 流量都应加强管控。当漏洞已经侵入应用后，Egress 流量管控往往是最后一个保护的关口。在上当前众多方案中，大部分的方案是基于 kubernetes 内的 Network Policy 实现，有的依赖于特定的 CNI，有的依赖于特定的编排平台。但当我们从企业的整体安全架构去考虑时，将外部安全设备引入到 kubernetes 安全体系当中一件非常必要的事情，只有这样才能实现真正的全面防御。而当我们讨论 DevSecOps 时，需要让开发、平台、安全乃至网络这些不同团队同时参与到整体安全工作中，实现跨团队的紧密协作。关于 F5 CES 方案是如何实现 kubernetes Egress 流量安全管控，以及如何实现不同团队紧密协作，请看考 &lt;a href=&#34;https://github.com/f5devcentral/container-egress-service&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github CES 项目&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>应用交付老兵眼中的 Envoy, 云原生时代下的思考</title>
      <link>https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/</guid>
      <description>&lt;p&gt;本文作者：林静，F5 软件方向解决方案架构师，历任 F5 Global Service ENE，APAC Professional Service 顾问，技术专家。拥有超过 10 多年的应用交付领域工作经验，秉承持续学习和反馈的理念，致力于现代应用体系下的应用服务研究。CNCF Kubernetes CKA 664 号认证获得者，中国首位 F5 Security Solution Expert 认证获得者。&lt;/p&gt;
&lt;p&gt;感谢邱世达对本文的审校。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;Envoy，使者，使节，代表！就像其单词含义本身一样，带着一种权威感，一种全代理的神圣感。结合其本身用途与角色，真是“人如其名”，不禁为 Lyft 点赞，不知是得到了哪位大师的指点来起这个名字。在当前火热的微服务时代下，Envoy 是个绝对的明星，用众人皆知来形容可以说一点也不为过。曾有人问我如何看 Envoy 以及在云原生时代下是否 Envoy 将取代 F5 取代 NGINX，作为一个经历了两次应用交付技术领域更迭浪潮的老兵，在本文中我将来浅谈一下 Envoy，以及试图从个人角度来理解与回答一下这个问题。为什么说浅谈一下，这真的不是谦虚，而是客观上真的没有那么深入的大规模长时间使用和研究 Envoy 的所有技术细节，因此我将结合我的从业经历与经验来对 Envoy 做一个浅谈。&lt;/p&gt;
&lt;h2 id=&#34;星光熠熠的-envoy&#34;&gt;星光熠熠的 Envoy&lt;/h2&gt;
&lt;p&gt;首先我们看一下 Envoy 官方是如何介绍 Envoy 的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ENVOY IS AN OPEN SOURCE EDGE AND SERVICE PROXY, DESIGNED FOR CLOUD-NATIVE APPLICATIONS
&lt;em&gt;Envoy 是一个开源的边缘以及服务代理，为云原生应用而生。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从网站首页的这一段描述可以清晰的看出官方对 Envoy 的定义，简单来说就是云原生时代下东西南北流量的代理。Lfyt 公司是微服务应用架构的先导者，在大量的微服务类布道文章中我们都可以看到 Lfyt 的身影，在从单体应用大规模转向微服务架构后，一个严重的问题摆在了开发与架构人员面前，一方面 Lyft 的服务采用了多种语言开发，而采用类库来解决分布式架构下的各种问题需要进行大量的语言适配以及对代码的侵入，另一方面 Lyft 的业务都是部署在 AWS 上的，大量依赖 AWS 的 ELB 以及 EC2，但是 ELB 以及 AWS 在当时所提供的服务间流量管控、洞察与问题排除都不能满足 Lyft 的需求，正是基于这样的背景，Lfyt 于 2015 年 5 月开始了 Envoy 的开发，最早是作为一个边缘代理进行部署并开始替代 ELB，随后开始作为 sidecar 方式进行大规模部署。2016 年 9 月 14 日，Lyft 在其博客上正式对外宣布了这一项目： &lt;a href=&#34;https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy C++ L7 代理与通信总线&lt;/a&gt;。一时间 Envoy 得到了大量的关注，Google 等公司开始贡献到这个项目里，并在一年后的 2017 年 9 月将项目捐献给 CNCF。有了 Lyft 这样一个好妈，又过继给了 CNCF 这样一个富爸，再加上同父异母的 Istio 明星兄弟的加持，可以说 Envoy 一时风光无两，赚足了眼球与开发者的支持，仅一年多点时间便从 CNCF 毕业了。&lt;/p&gt;
&lt;p&gt;容器技术助推了企业实践 Devops 与进行微服务改造，k8s 容器编排平台则让企业能够更加自信的将更多业务从传统架构迁移到基于容器的现代基础架构之上，k8s 解决了容器编排、应用发布等问题，但是当服务之间的通信从以前的内存之间调用变成了基于 TCP 的网络通信后，网络对应用服务的影响变得更加巨大与不确定，基于传统的应用架构的运维手段无法适应与解决巨大且复杂的服务间通信洞察、排错，为了解决这样的问题，sevice mesh 应用而生，并迅速成为关注的热。Istio 项目则是此生态中最重要的玩家，Istio 的架构是一个典型的管理平面与数据分离的架构，在数据平面的选择上是开放的，但是 Istio 默认选择了 Envoy 作为数据平面。两大人气明星强强联手，让几乎同一时期的 linkerd 变得黯然失色。而在这个时间点，NGINX 同样也曾短暂的进行了 Nginmesh 项目，试图让 NGINX 作为 Istio 的数据平面，但最终在 2018 年底放弃了，为什么会放弃，这个本文后面会提到。&lt;/p&gt;
&lt;p&gt;当前除了 Istio 选择 Envoy 作为数据平面外，以 Envoy 为基础的项目还有很多，例如 k8s 的多个 Ingress Controller 项目：Gloo, Contur, Ambassador。Istio 自身的 Ingress gateway 与 Egress gateway 同样选择的是 Envoy。来看下其官方首页列出的 Envoy 用户，说星光熠熠一点也不为过。注意列表里的 F5，是不是很有意思。
















&lt;figure  id=&#34;figure-envoy-end-user&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-end-user&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-endusers_hu6799052598184233798.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-endusers_hu9333259974859487410.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-endusers_hu16641209702176892386.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-endusers_hu6799052598184233798.webp&#34;
               width=&#34;744&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-end-user
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;（Envoy 最终用户列表）&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;后浪为时代而生&#34;&gt;后浪：为时代而生&lt;/h2&gt;
&lt;p&gt;下面我将从技术方面来看看为何 Envoy 能够得到社区的如此重视。将从以下几个方面来总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;技术特征&lt;/li&gt;
&lt;li&gt;部署架构&lt;/li&gt;
&lt;li&gt;软件架构&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;技术特征&#34;&gt;技术特征&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;接口化与 API&lt;/li&gt;
&lt;li&gt;动态性&lt;/li&gt;
&lt;li&gt;扩展性&lt;/li&gt;
&lt;li&gt;可观测性&lt;/li&gt;
&lt;li&gt;现代性&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;接口化与-api&#34;&gt;接口化与 API&lt;/h4&gt;
&lt;p&gt;当我第一次打开 Envoy 的配置时候，我的第一感觉是，天啊，这样一个产品用户该怎么配置和使用。先来直观的感受下，在一个并不复杂的实验环境下，一个 Envoy 的实际配置文件行数竟然达到了 20000 行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ curl http://127.0.0.1:15000/config_dump &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; wc -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 Dload  Upload   Total   Spent    Left  Speed
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;  634k    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;  634k    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;  10.1M      &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; --:--:-- --:--:-- --:--:-- 10.1M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;20550&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;尽管这是 Istio 环境下的动态配置，虽然还有方式去优化使得实际配置量减少，或者说当完全使用静态配置方式进行配置的时候我们不会做如此大量的配置，但是当我们看到以下实际的配置结构输出就会感觉到对于这样一个软件，如果以普通方式进行配置与维护显然是不切实际的，其配置完全 json 结构化，并拥有大量的描述性配置，相对于 NGINX 等这些反向代理软件来说，其配置结构实在是过于复杂。
















&lt;figure  id=&#34;figure-复杂的配置结构&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;复杂的配置结构&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-json_hu12345293659231668235.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-json_hu13896660061195703221.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-json_hu5883515376925480868.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-json_hu12345293659231668235.webp&#34;
               width=&#34;760&#34;
               height=&#34;604&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      复杂的配置结构
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(复杂的配置结构)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;显然，Envoy 的设计天生就不是为手工而设，因此 Envoy 设计了大量的 xDS 协议接口，需要用户自行设计一个 xDS 的服务端实现对所有配置处理，Envoy 支持 gRPC 或者 REST 与服务端进行通信从而更新自身的配置。xDS 是 Envoy DS（discover service）协议的统称，具体可分为 Listener DS（LDS), Route DS (RDS), Cluster DS (CDS), Endpoint DS (EDS), 此外还有 Secret DS，为了保证配置一致性的聚合 DS-ADS 等，更多的 xDS 可 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/operations/dynamic_configuration&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;查看这里&lt;/a&gt;。这些接口用于自动化产生各种具体不同的配置对象。可以看出，这是一个高度动态性的运行时配置，要想用好它则必须开发一个具有足够能力的 server 端，显然这不是传统反向代理软件的设计思维。
















&lt;figure  id=&#34;figure-envoyxds&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoyxDS&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-xds_hu17194649248433441388.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-xds_hu1724380229423217509.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-xds_hu10481698885558496977.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-xds_hu17194649248433441388.webp&#34;
               width=&#34;760&#34;
               height=&#34;372&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoyxDS
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;动态性&#34;&gt;动态性&lt;/h4&gt;
&lt;p&gt;正如前面所述，Envoy 的配置高度依赖接口自动化产生各种配置，这些配置是可以进行 Runtime 修改而无需 reload 文件，在现代应用架构中，一个服务端点的生命周期都变得更短，其运行的不确定性或弹性都变得更大，所以能够对配置进行 runtime 修改而无需重新 reload 配置文件这个能力在现代应用架构中显得尤其珍贵，这正是 Istio 选择 Envoy 作为数据平面的一个重要考虑。Envoy 同时还具备热重启能力，这使得在升级或必须进行重启的时候变得更加优雅，已有连接能够得到更多的保护。&lt;/p&gt;
&lt;p&gt;在 Istio 场景下，Envoy 的容器里运行两个进程，一个叫 pilot-agent，一个是 envoy-proxy 本身，pilot-agent 负责管理与启动 Envoy，并产生一个位于 /etc/istio/proxy/ 下的 envoy-rev0.json 初始配置文件，这个文件里定义了 Envoy 应该如何与 pilot server 进行通信以获取配置，利用该配置文件最终启动 Envoy 进程。但是 Envoy 最终运行的配置并不仅仅是 envoy-rev0.json 里的内容，它包含上文所说的通过 xDS 协议发现的所有动态配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ps -ef
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;UID         PID   PPID  C STIME TTY          TIME CMD
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istio-p+      &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;      &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; Jun25 ?        00:00:33 /usr/local/bin/pilot-agent proxy sidecar --domain istio-bookinfo.svc.cluster.local --serviceCluster productpage.istio-bookinfo --proxyLogLevel&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;warning --proxyComp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istio-p+     &lt;span class=&#34;m&#34;&gt;14&lt;/span&gt;      &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; Jun25 ?        00:05:31 /usr/local/bin/envoy -c etc/istio/proxy/envoy-rev0.json --restart-epoch &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; --drain-time-s &lt;span class=&#34;m&#34;&gt;45&lt;/span&gt; --parent-shutdown-time-s &lt;span class=&#34;m&#34;&gt;60&lt;/span&gt; --service-cluster productpage.istio-bookin
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istio-p+    &lt;span class=&#34;m&#34;&gt;142&lt;/span&gt;      &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; 15:38 pts/0    00:00:00 sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istio-p+    &lt;span class=&#34;m&#34;&gt;148&lt;/span&gt;    &lt;span class=&#34;m&#34;&gt;142&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; 15:38 pts/0    00:00:00 ps -ef
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在下图的 envoy 整体配置 dump 中可以看到包含了 bootstrap 的内容以及其它静态以及动态配置：
















&lt;figure  id=&#34;figure-envoy-config-dump&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-config-dump&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-dump-config-json-struc.jpg_hu13874550445880783603.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-dump-config-json-struc.jpg_hu17084928965450479500.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-dump-config-json-struc.jpg_hu6647357983719312421.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-dump-config-json-struc.jpg_hu13874550445880783603.webp&#34;
               width=&#34;760&#34;
               height=&#34;737&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-config-dump
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(Envoy 配置结构)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;结合下图可以看出基本的 Envoy 配置结构及其逻辑，无论是入口 listener（类似 F5 的 VS 以及部分 profile 配置，NGINX 的 listener 以及部分 Server 段落配置）还是路由控制逻辑（类似 F5 LTM policy，NGINX 的各种 Locations 匹配等），还是 Clusters（类似 F5 pool，NGINX 的 upstream）、Endpoints（类似 F5 pool member，NGINX 的 upstream 里的 server），乃至 SSL 证书完全可以通过接口从服务侧自动化的发现过来
















&lt;figure  id=&#34;figure-envoy-objects&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-objects&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-basic-objects-logic_hu17508484752428090924.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-basic-objects-logic_hu2293302292580566092.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-basic-objects-logic_hu530924156425972181.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-basic-objects-logic_hu17508484752428090924.webp&#34;
               width=&#34;760&#34;
               height=&#34;625&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-objects
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;扩展性&#34;&gt;扩展性&lt;/h4&gt;
&lt;p&gt;Envoy 的配置中可以看到大量的 filter，这些都是其扩展性的表现，Envoy 学习了 F5 以及 NGINX 的架构，大量使用插件式，使得开发者可以更加容易的开发。从 listener 开始就支持使用 filter，支持开发者开发 L3,L4,L7 的插件从而实现对协议扩展与更多控制。&lt;/p&gt;
&lt;p&gt;在实际中，企业在 C++ 的开发储备方面可能远不如 JavaScript 等这样的语言多，因此 Envoy 还支持 Lua 以及 Webassembly 扩展，这一方面使得无需经常重新编译二进制并重启，另一方面降低了企业插件开发难度，让企业可以使用更多兼容 Webassembly 的语言进行插件编写，然后编译为 Webassenmbly 机器码实现高效的运行。目前来说 Envoy 以及 Istio 利用 Webassembly 做扩展还在早期阶段，走向成熟还需一段时间。
















&lt;figure  id=&#34;figure-envoy-traffic-logic&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-traffic-logic&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/concept-envoy-filter_hu4093514552564540010.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/concept-envoy-filter_hu15445197559158407684.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/concept-envoy-filter_hu13780114289574066355.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/concept-envoy-filter_hu4093514552564540010.webp&#34;
               width=&#34;760&#34;
               height=&#34;567&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-traffic-logic
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/envoy.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.servicemesher.com/istio-handbook/concepts/envoy.html&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;从上面的图可以看出，这样的请求处理结构非常的接近于 F5 TMOS 系统的设计思想，也在一定程度上与 NGINX 类似。连接、请求在不同的协议层面与阶段对应不同的处理组件，而这些组件本身是可扩展的、可编程的，进而实现对数据流的灵活编程控制。&lt;/p&gt;
&lt;h4 id=&#34;可观测性&#34;&gt;可观测性&lt;/h4&gt;
&lt;p&gt;说 Envoy 生来具备云原生的特质，其中一大特点就是对可观测性的重视，可以看到可观测的三大组件：&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/observability/observability&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;logs，metrics，tracing&lt;/a&gt; 默认都被 Envoy 所支持。&lt;/p&gt;
&lt;p&gt;Envoy 容许用户以灵活的方式在灵活的位置定义灵活的日志格式，这些变化可以通过动态配置下发从而实现立即生效，并容许定义对日志的采样等。在 Metrics 则提供了能够与 Prometheus 进行集成的诸多指标，值得一提的是 Envoy 容许 filter 本身来扩充这些指标，例如在限流或者验证等 filter 中容许插件本身定义属于自己的指标从而帮助用户更好的使用和量化插件的运行状态。在 Tracing 方面 Envoy 支持向 zipkin，jaeger，datadog，lightStep 等第三方集成，Envoy 能够生产统一的请求 ID 并在整个网络结构中保持传播，同时也支持外部的 x-client-trace-id，从而实现对微服务之间关系拓扑的描述。
















&lt;figure  id=&#34;figure-envoy-kiali&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-kiali&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-kiali_hu15363982539604589223.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-kiali_hu2711396859096628456.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-kiali_hu2263674761946026666.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-kiali_hu15363982539604589223.webp&#34;
               width=&#34;760&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-kiali
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Envoy 生成的每个 span 包含以下数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过设置 &lt;code&gt;--service-cluster&lt;/code&gt; 的原始服务集群信息。&lt;/li&gt;
&lt;li&gt;请求的开始时间和持续时间。&lt;/li&gt;
&lt;li&gt;通过设置 &lt;code&gt;--service-node&lt;/code&gt; 的原始主机信息。&lt;/li&gt;
&lt;li&gt;通过 &lt;code&gt;x-envoy-downstream-service-cluster&lt;/code&gt; 标头设置的下游集群。&lt;/li&gt;
&lt;li&gt;HTTP 请求 URL，方法，协议和用户代理。&lt;/li&gt;
&lt;li&gt;通过 &lt;code&gt;custom_tags&lt;/code&gt; 设置的其他自定义标签。&lt;/li&gt;
&lt;li&gt;上游集群名称和地址。&lt;/li&gt;
&lt;li&gt;HTTP 响应状态代码。&lt;/li&gt;
&lt;li&gt;GRPC 响应状态和消息（如果可用）。&lt;/li&gt;
&lt;li&gt;HTTP 状态为 5xx 或 GRPC 状态不是“OK”时的错误标记。&lt;/li&gt;
&lt;li&gt;跟踪特定于系统的元数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;现代性&#34;&gt;现代性&lt;/h4&gt;
&lt;p&gt;其实，说 Envoy 具有现代性显然是正确的废话，Envoy 天生为现代应用架构而生，这里主要是想从几个我们最容易能够感受到的方面来说明一下。首先是其特殊的结构设计，在 Envoy 里它支持利用 iptables 截取流量并做透明处理，其本身能够利用 getsockopt () 实现对 NAT 条目中原始目的信息的提取，并在 listener 监听上容许在从被跳转的端口 listener 中跳跃到实际能匹配原始目的信息的非绑定型 listener，尽管从反向代理角度看这就有点像 F5 的 VS 内部跳转，NGINX 的 subrequest，但是其最大的特点和能力在于对连接的透明性，这在 Pod sidecar 模式的部署中显得尤其重要，具体原理可参考 &lt;a href=&#34;https://www.cnadn.net/post/2945.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;对于现代应用最爱的灰度发布，流量镜像，断路器，全局限流等等功能，其在配置上也非常的简洁，这一点尽管 F5/NGINX 等软件也能完成类似的工作，但在原生性上以及配置的难易程度上 Envoy 具有更大优势。&lt;/p&gt;
&lt;p&gt;现代性的另一个表现就是对协议的支持，看看以下支持的协议，熟悉应用交付、反向代理软件的同学可能会情不自禁的表示赞叹，而这些协议的支持更从另一方面表现了 Envoy 作为更加面向开发者和 SRE 的一个特质。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gRPC&lt;/li&gt;
&lt;li&gt;HTTP2&lt;/li&gt;
&lt;li&gt;MongoDB&lt;/li&gt;
&lt;li&gt;DynamoDB&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;li&gt;Postgres&lt;/li&gt;
&lt;li&gt;Kafka&lt;/li&gt;
&lt;li&gt;Dubbo&lt;/li&gt;
&lt;li&gt;Thrift&lt;/li&gt;
&lt;li&gt;ZooKeeper&lt;/li&gt;
&lt;li&gt;RockeMQ&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;部署架构&#34;&gt;部署架构&lt;/h3&gt;
&lt;p&gt;在了解完 Envoy 的技术特征后，再来从部署架构角度看 Envoy。&lt;/p&gt;
&lt;p&gt;完整 Sidecar 模型部署，这是 Envoy 最大的部署特征，services 之间的通信完全转化为 Envoy 代理之间的通信，从而实现将诸多非业务功能从服务代码中移出到外部代理组件，Envoy 负责网络通信控制与流量的可观测。也可以部署为简化的 sidecar，其仅充当 service 入站方向的代理，无需额外的流量操纵，这个结构在我对外阐述的基于 NGINX 实现业务可观测性中所使用
















&lt;figure  id=&#34;figure-envoy-topo-1&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-topo-1&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t1_hu159581803290427262.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t1_hu2347861568232987227.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t1_hu7348400294503735087.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t1_hu159581803290427262.webp&#34;
               width=&#34;752&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-topo-1
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hub 型，这与 NGINX 的 MRA 中的 Router-mesh 型理念相同，所有服务使用一个集中的 Envoy 进行通信，这种部署结构一般适用于中小型服务，可通过与服务注册的适配将服务流量导向到 Envoy
















&lt;figure  id=&#34;figure-envoy-topo-hub&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-topo-hub&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t2_hu18312775189791689686.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t2_hu11835949750609221899.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t2_hu15766074068280843372.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t2_hu18312775189791689686.webp&#34;
               width=&#34;760&#34;
               height=&#34;583&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-topo-hub
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Envoy 也可以作为 Ingress edge 网关或 Egress 网关，在这种场景下一般 Envoy 多用于 Ingress controller 或 API 网关，可以看到很多的此类实现喜欢使用 Envoy 作为底层，例如 Gloo, Ambassador 等
















&lt;figure  id=&#34;figure-envoy-topo-in-out&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-topo-in-out&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t3_hu1773807307099282407.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t3_hu842029865509798659.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t3_hu8013796444600578267.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t3_hu1773807307099282407.webp&#34;
               width=&#34;760&#34;
               height=&#34;280&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-topo-in-out
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;下面这个部署结构应该是大家比较熟悉的，Envoy 作为一个 Edge 网关，并同时部署额外一层微服务网关（或代理平台层）
















&lt;figure  id=&#34;figure-envoy-topo-in-out&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-topo-in-out&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t5_hu1936851840588938202.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t5_hu119509308977035490.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t5_hu2443935117029988189.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t5_hu1936851840588938202.webp&#34;
               width=&#34;760&#34;
               height=&#34;369&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-topo-in-out
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;最后，这是将所有形态的 Envoy 部署集中到了一起，这种架构可能会在服务从传统架构向微服务架构迁移过程的中间形态
















&lt;figure  id=&#34;figure-envoy-topo-all&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-topo-all&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t4_hu2364443506448237643.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t4_hu3754208821841297438.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t4_hu6838388449447446672.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t4_hu2364443506448237643.webp&#34;
               width=&#34;760&#34;
               height=&#34;277&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-topo-all
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;最后，来看一下 Istio 里是如何使用 Envoy 的
















&lt;figure  id=&#34;figure-envoy-istio&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-istio&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t6_hu11559339029152836716.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t6_hu7131722740097625662.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t6_hu9010717358913844271.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t6_hu11559339029152836716.webp&#34;
               width=&#34;665&#34;
               height=&#34;539&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-istio
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;em&gt;(图片来自网络)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;总结来看，由于 Envoy 的跨平台性，使其具有和 NGINX 一样的灵活部署结构，但是实际上部署结构往往与最终的配置实现机制有着强关系，软件的能力能否适应在此结构下的灵活与简单的配置实现是最终考验。客观的讲，在这方面 Envoy 更具有优势。&lt;/p&gt;
&lt;h3 id=&#34;软件架构&#34;&gt;软件架构&lt;/h3&gt;
&lt;p&gt;Envoy 采用了单进程多线程的设计结构，主线程负责配置更新，进程信号处理等。请求则是由多个 worker 线程来处理，为了简化与避免处理复杂，一个连接始终由一个线程处理，这样可尽量减少线程间的数据共享而引发的一些锁操作。Envoy 尽可能的避免线程之间的状态共享，为此设计了 Thread Local Store 机制。在日志的写入上，实际上是 worker 线程写入到内存缓存，最后再由文件刷新线程来负责写入到磁盘，这样可以在一定程度上提高效率。整体上来说，Envoy 在设计时候还是比较偏重于简化复杂性，并强调灵活性，因此与 NGINX 不同它并没有把对性能的追求放在第一位，这一点在 Envoy 的相关官方博客里可以得到验证。
















&lt;figure  id=&#34;figure-envoy-threads&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-threads&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-thread_hu8998616320433349220.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-thread_hu3481010438107405610.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-thread_hu7702547937363026934.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-thread_hu8998616320433349220.webp&#34;
               width=&#34;760&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-threads
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图片来自 &lt;a href=&#34;https://blog.envoyproxy.io/envoy-threading-model-a8d44b922310&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.envoyproxy.io/envoy-threading-model-a8d44b922310&lt;/a&gt;*&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与 NGINX 类似，Envoy 整体是异步非阻塞的设计，采用的是事件驱动方式。每个线程都负责每一个 listener，可以采用 SO_REUSEPORT 也可以共享 socket，NGINX 也有类似的机制。
















&lt;figure  id=&#34;figure-envoy-listener&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy-listener&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/t7_hu3243275592188465019.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/t7_hu6600005741263487193.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/t7_hu754460369682746272.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/t7_hu3243275592188465019.webp&#34;
               width=&#34;760&#34;
               height=&#34;364&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy-listener
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图片来自 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request#request-flow&lt;/a&gt;*&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当请求由 listener 监听并开始处理后，根据配置连接将会被后续的 L3、4、7 等多个 filter 进行处理。
















&lt;figure  id=&#34;figure-envoy-proxy-arch&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;envoy proxy arch&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-arch_hu2575397981111876452.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-arch_hu6051004337005723172.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/envoy-arch_hu6559516165323358465.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/envoy-arch_hu2575397981111876452.webp&#34;
               width=&#34;760&#34;
               height=&#34;558&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      envoy proxy arch
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图片取自 jimmysong.io*&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前浪宝刀未老&#34;&gt;前浪：宝刀未老&lt;/h2&gt;
&lt;p&gt;在了解完 Envoy 的技术特性及其架构后，我们再回到此文的原点。Envoy 从出生就带着现代应用架构的基因，是不是说对于 NGINX/F5 等这些前浪就落伍了呢。&lt;/p&gt;
&lt;p&gt;记得 NGINX 的作者 Igor 在 F5 中国 520 大会上曾这样对大家介绍 NGINX 为何如此成功。他说，他没有想到会如此成功，究其原因是他在正确的时间点开发了一个正确的软件。我们知道，在 2003 年左右那个时期，还谈不上什么分布式架构、微服务，那时候主要要解决的是单机性能问题，正是基于这样的背景，NGINX 无论从架构设计还是代码质量都严格苛求于性能。在功能上，NGINX 本来是一款 Web Server 软件，L7 反向代理则是其能力的延伸，而 L4 代理能力的增加则更晚，鉴于这样的背景，从现代应用架构角度来看，确实有一些能力是较难覆盖的。同样，Envoy 诞生和发展于现代应用架构时代，正如 Envoy 自我阐述，其参考了大量已有的软硬件反向代理、负载均衡产品，从上面的技术分析中也可以看出 Envoy 有很多 NGINX 以及 F5 架构理念，可以说 Envoy 从成熟的反向代理产品中吸取了诸多精华，并在设计时候充分考虑现代应用架构的需求，它也是一个在正确的时间的一个正确软件。&lt;/p&gt;
&lt;p&gt;微服务架构下，很多问题都变成了如何控制服务之间的通信与流量洞察，这是典型的应用交付领域，作为这个领域的前浪一方面需积极拥抱和适应新时代的应用架构，一方面需要创新并继续引领新的方向。历史上这个领域发生了两次技术革新，第一次是在 2006 年左右，当时一度关于“负载均衡已死”话题被炒爆，实质是当时市场开始发生变换，大家不再满足于简单的负载均衡，需求衍生到应用安全、网络优化、应用优化、接入控制、流量控制等更多复杂的场景，应用交付概念开始被提出，可以说在 2006 年前，市场的主要概念和技术方向是以四层交换机为核心理念的负载均衡技术，大部分玩家是传统网络厂商，思维与概念都是以网络交换为基础，而 F5 就像一个奇怪的家伙，产品设计思想完全在另一个维度之上，自 2004 年就开始发布的 TMOS V9 操作系统自此开始引领市场，此后 10 年，无人超越。第二次技术革新发生在 2016 年左右，受云、微服务的影响，软件化、轻量化变为市场主流，同时 Devops 思想意味着使用者角色发生了变化，传统的面向网络运维人员的设计开始变得难以满足市场需求。以 F5 为主导的这个领域在市场上也发生了新的变化，Gartner 不再对应用交付领域发布魔力象限分析，转而形成以 Guide 方式的指导。
















&lt;figure  id=&#34;figure-f5stock&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;F5stock&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/F5-stock_hu13402485614848195609.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/F5-stock_hu4383365262005013346.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/F5-stock_hu15303605360851371632.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/F5-stock_hu13402485614848195609.webp&#34;
               width=&#34;760&#34;
               height=&#34;317&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      F5stock
    &lt;/figcaption&gt;&lt;/figure&gt;

*F5 股价走势图 *&lt;/p&gt;
&lt;p&gt;看当下，历史总是惊人的相似。&lt;/p&gt;
&lt;p&gt;现代应用架构飞速发展，大量应用开始微服务化，但从业务访问的整体链条来看，Envoy 还不能解决所有问题，例如应用安全防护，复杂的企业协议，以及不同的组织关系导致的不同需求。可以看到以 F5/NGINX 为代表的应用交付产品在 Devops 大潮下也开始积极的实现产品融入，F5 发布了完整的自动化工具链，从产品的 bootstrap 到网络配置、到应用服务配置，到最后的监控遥测都已经形成了完整的接口，并采用声明式接口来将产品管理提升到更高角色人群与管理系统中。NGINX 同样构建了自身的 API 以及 Controller 平面，对外提供声明式 API 接口，开发者可以更好的利用接口融入自身的控制平面。这些变化都是为了让开发者或者 SRE 能够更好的使用 F5/NGINX, 详细可以参考我的《从传统 ADC 迈向 Cloud Native ADC》&lt;a href=&#34;https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1593224168&amp;amp;ver=2425&amp;amp;signature=znUdlLDdpbGGxWX7pZhH2uSVq1SAdQuloO09HIXssdQ15nRtWVOIgzlYTFmjOIUsDrqghPbSZM6vQI45TIqmINQKjposI7AfJ6jKQaEXm9KD4tEV5Bk9AF0RGuKvVuHI&amp;amp;new=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;系列文章&lt;/a&gt;。
















&lt;figure  id=&#34;figure-slides3&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;slides3&#34; srcset=&#34;
               /blog/thoughts-to-envoy-from-adn-perspective/slides-3_hu12596873232693964475.webp 400w,
               /blog/thoughts-to-envoy-from-adn-perspective/slides-3_hu8400035856560163137.webp 760w,
               /blog/thoughts-to-envoy-from-adn-perspective/slides-3_hu16642826745871050820.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/thoughts-to-envoy-from-adn-perspective/slides-3_hu12596873232693964475.webp&#34;
               width=&#34;760&#34;
               height=&#34;447&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      slides3
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;F5 在收购 NGINX 与 Shape 之后，提出了新的 view，将充分利用可广泛触达的数据平面能力，借助 AI 进一步挖掘数据潜能帮助用户更好的掌握和了解应用行为、性能，为业务运营提出参考，并反馈到组件配置与运行管理，从而形成闭环。&lt;/p&gt;
&lt;p&gt;现代应用交付依然不能缺少一个重要场景，那就是应用安全，尽管 Istio 等产品在安全通信，身份，策略方面做了不少的尝试，但是应用安全本身则比较缺乏，F5 作为 WAF 安全领域的领导厂商，通过将安全能力转移到 NGINX 上形成了新的 NGINX APP Protect，利用其跨平台的能力帮助用户更好的管理微服务场景下的应用安全能力，帮助企业更好的落地 DevSecOps。&lt;/p&gt;
&lt;p&gt;如果将 Envoy 的那些技术特征与 F5 进行对比的话，我们可以看到 F5 一定程度上欠缺在扩展性与现代性上，F5 具有较好的编程控制能力，但是相对于更大的插件开发来说是不足的，这和现代性往往可以联系到一起看，比如想针对某个很新的协议做一个类似 Envoy 的复杂 7 层 filter 是无法实现的，尽管 iRule 或者 iRuleLX 可以一定程度上做一些事情。然而无论怎样，最终 F5 的产品形态本身决定了 F5 的 BIGIP 是无法完全跨平台的，因为它无法以容器来运行。值得期待的是，这样的形态限制将会被 F5 下一代 TMOS 系统打破。&lt;/p&gt;
&lt;p&gt;Service Mesh 是当前热门的技术方向，F5 基于 Istio 打造了企业级的 Aspen Mesh 服务网格产品，帮助企业更好、更容易的部署和使用 Istio。Aspen mesh 团队成员进入仅有 7 个位置的的 Istio Technical Oversight Committee，负责 Istio 的 RFCs/Designs/APIs 等方面的重要职责。尽管 Istio 在 service mesh 领域拥有绝对的生态与热度，但这并不表示 Istio 是唯一的选择，在很多时候客户可能希望采用一种更加简洁的 Service Mesh 去实现大部分所需功能而不是去部署一整套复杂的 Istio 方案，基于 NGINX 组件打造的 NGINX Service Mesh (NSM) 将为用户带来新的选择，一个更加简单易用的 Service Mesh 产品，这是我们在文章最开始提到 NGINX 终止 Nginmesh 的原因。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;技术发展是一个必然的过程，2006 年从传统的负载均衡技术演变为应用交付，除了负载均衡之外，引入安全、访问控制、接入控制、流量控制等诸多方面。2016 年左右，这个领域再次发生新的技术变革，大量新生代反向代理开源软件的出现对传统应用交付类产品产生了一次新的冲击，积极适应与改变并创新是制胜的关键。Envoy 作为新代表有着优秀的能力，但它也不是解决所有问题的银弹，Envoy 拥有更陡峭的学习曲线以及更高开发成本与维护成本，对于企业来说应根据实际情况选择合适的解决方案与产品来解决架构中的不同问题，避免追赶潮流而让自己陷入陷阱。&lt;/p&gt;
&lt;p&gt;F5 则更加需要让开发人员了解 TMOS 系统所拥有的巨大潜能（特别是下一代产品在架构以及形态上的颠覆），了解其优秀全代理架构以及可以在任意层面进行的编程控制，让开发者、SRE 以 F5 TMOS 作为一种能力平台和中间件进行开发，更好的利用 F5 自身已经拥有的应用交付能力来快速实现自身需求。&lt;/p&gt;
&lt;p&gt;最后，再次引用 Envoy 官方网站首页的一句话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正如微服务从业者很快意识到的那样，当转移到分布式体系结构时出现的大多数操作问题最终都基于两个方面：网络和可观察性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而保证更可靠的网络交付与更好的可观察性正是前浪们的强项。创新吧，前浪。&lt;/p&gt;
&lt;p&gt;写在最后：
无论技术如何更迭，人的因素依旧是核心，不论企业自身还是厂商，在这样一轮技术浪潮中都应具备足够的技术储备，就像传统金融行业通过建立科技公司寻求转变一样，厂商同样需要转型，F5 中国的 SE 几乎 100% 的通过了 CKA 认证，无论相对比例还是绝对数量在业界应该是惟一了，转型不只在产品，更在于思想。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
