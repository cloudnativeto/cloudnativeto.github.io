<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI | 云原生社区（中国）</title>
    <link>https://cloudnativecn.com/category/ai/</link>
      <atom:link href="https://cloudnativecn.com/category/ai/index.xml" rel="self" type="application/rss+xml" />
    <description>AI</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Fri, 18 Apr 2025 09:30:08 +0800</lastBuildDate>
    <image>
      <url>https://cloudnativecn.com/media/sharing.png</url>
      <title>AI</title>
      <link>https://cloudnativecn.com/category/ai/</link>
    </image>
    
    <item>
      <title>什么是 AI Agent？简要介绍与构建指南</title>
      <link>https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/</link>
      <pubDate>Fri, 18 Apr 2025 09:30:08 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/</guid>
      <description>&lt;p&gt;&lt;strong&gt;下一件大事？&lt;/strong&gt; Gartner 认为 AI Agent 将引领未来。OpenAI、Nvidia 和 Microsoft 都在下注，就连在 AI 领域一直比较低调的 Salesforce 也开始布局。&lt;/p&gt;
&lt;p&gt;这一趋势确实正在快速起飞。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f1_hu6511902177471666923.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f1_hu6407050605857690753.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f1_hu13668997699999675077.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f1_hu6511902177471666923.webp&#34;
               width=&#34;760&#34;
               height=&#34;260&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;“AI Agents” 在 Google Trends 上的搜索趋势（来源：trends.google.com）&lt;/p&gt;
&lt;h2 id=&#34;什么是-ai-agent关键词是-agency&#34;&gt;什么是 AI Agent？关键词是 “Agency”&lt;/h2&gt;
&lt;p&gt;不同于传统的生成式 AI 系统，Agent 不只是回应用户输入，而是能够&lt;strong&gt;自主处理一个复杂流程&lt;/strong&gt;，比如处理一个保险理赔请求：理解邮件内容、图像、PDF 文件，从客户数据库提取信息，比对条款、与客户沟通并等待对方回复（哪怕是几天后）——整个过程中不丢失上下文。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它能自主完成这些操作&lt;/strong&gt;，无需人类实时干预。&lt;/p&gt;
&lt;h2 id=&#34;咖啡机与咖啡师的比喻&#34;&gt;咖啡机与咖啡师的比喻&lt;/h2&gt;
&lt;p&gt;相比 Copilot 这类工具“辅助”员工，&lt;strong&gt;AI Agent 更像是一位可以独立上岗的“数字员工”&lt;/strong&gt;，可实现高程度的流程自动化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;想象一下&lt;/strong&gt;，一个 AI 能够承担当前由人类员工或整个部门完成的复杂任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;策划、设计、执行、评估并优化一场 &lt;strong&gt;营销活动&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;与物流公司、客户和仓库沟通以&lt;strong&gt;追踪遗失的货物&lt;/strong&gt;，若找不到可发起索赔&lt;/li&gt;
&lt;li&gt;每天&lt;strong&gt;监控商标注册数据库&lt;/strong&gt;，发现潜在冲突后自动提起异议&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;汇总 ESG 报告所需数据&lt;/strong&gt;，主动向员工发起询问并校验信息准确性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前的 AI 模型只能在流程中“协助”，而不能主导。&lt;strong&gt;AI Agent 则能完成整个流程的执行&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f2_hu7005329819237701757.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f2_hu14055442940085759594.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f2_hu3240225224215173109.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f2_hu7005329819237701757.webp&#34;
               width=&#34;760&#34;
               height=&#34;472&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;如上图所示，传统生成式 AI 协助团队完成流程（黄色），AI Agent 能从头到尾执行整个任务（橙色）。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果把传统模型比作高端咖啡机，Agent 则是咖啡师&lt;/strong&gt;。咖啡师不仅能做咖啡，还能招呼客人、点单、收银、洗杯子，甚至打烊关店。而咖啡机永远无法独自运营一家咖啡馆。&lt;/p&gt;
&lt;h2 id=&#34;为什么-agent-能胜任这些任务&#34;&gt;为什么 Agent 能胜任这些任务？&lt;/h2&gt;
&lt;p&gt;Agent 擅长在复杂流程中&lt;strong&gt;掌控多个子流程&lt;/strong&gt;，能自主判断下一步应该执行什么任务。如果遇到问题，它知道该向谁请求帮助（缺咖啡豆就找老板，机器故障就联系售后）。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f3_hu14605325461640235722.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f3_hu2110732695597566784.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f3_hu8930354378423729038.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f3_hu14605325461640235722.webp&#34;
               width=&#34;614&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;AI Agent 与传统生成式 AI 的比较。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;h2 id=&#34;一位-ai-员工的构成解剖&#34;&gt;一位 AI 员工的构成解剖&lt;/h2&gt;
&lt;p&gt;现在开始动手构建一个 AI Agent，基于上述保险理赔流程，我们来看每一步的设计。&lt;/p&gt;
&lt;p&gt;我们的目标是构建业务架构与流程设计。由于篇幅原因，本篇不涉及具体代码实现。&lt;/p&gt;
&lt;h3 id=&#34;第一步分类并进入处理通道&#34;&gt;第一步：分类并进入处理通道&lt;/h3&gt;
&lt;p&gt;流程从客户发送邮件报案开始。Agent 需要先&lt;strong&gt;分析邮件内容，识别客户的意图&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一旦分类完成，Agent 会将请求路由至正确的处理通道。通常这远不止是 function calling，而是涉及流程路径的选择与多个步骤的执行。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f4_hu15216092587147984036.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f4_hu3829888902256977319.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f4_hu8748466306381553867.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f4_hu15216092587147984036.webp&#34;
               width=&#34;659&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;AI Agent 的第一步：对邮件进行分类并分发至对应处理路径。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;h3 id=&#34;第二步提取数据&#34;&gt;第二步：提取数据&lt;/h3&gt;
&lt;p&gt;下一步，Agent 将&lt;strong&gt;非结构化数据转化为结构化数据&lt;/strong&gt;，以实现安全、系统、规范的处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分类是将文本归入某个类别&lt;/li&gt;
&lt;li&gt;而抽取是“读懂”数据并提取其中的关键信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;模型并不会直接“复制粘贴”，而是生成带格式的结果，例如将“(718) 123–45678”转换为“+1 718 123 45678”。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f5_hu15412797075567924946.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f5_hu547757857634892682.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f5_hu3480875470495157515.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f5_hu15412797075567924946.webp&#34;
               width=&#34;464&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;数据提取可以来自邮件文本、附件图片、PDF等。通常是多模型协作，包含 LLM、OCR 等模块。&lt;/p&gt;
&lt;p&gt;示例输入（非结构化）：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Hi,

I would like to report a damage and ask you to compensate me...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出（结构化 JSON）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Deepak&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;surname&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Jamal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;123 Main Street, 10008 New York City, NY&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;phone&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;+1 718 123 45678&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;contract_no&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;HC12-223873923&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;claim_description&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;...&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;第三步调用外部系统并持久化上下文&#34;&gt;第三步：调用外部系统并持久化上下文&lt;/h3&gt;
&lt;p&gt;普通生成式 AI 通常只能在会话中处理信息，Agent 则&lt;strong&gt;需要访问并更新数据库与企业系统中的数据&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查询合同号是否存在&lt;/li&gt;
&lt;li&gt;将处理状态写入客服工单系统&lt;/li&gt;
&lt;li&gt;向客户或外部方索要补充信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f6_hu11329655967911579183.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f6_hu6272794820619617351.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f6_hu10520864855883170393.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f6_hu11329655967911579183.webp&#34;
               width=&#34;556&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图示：调用系统服务并实现上下文持久化。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;h3 id=&#34;第四步判断rag推理与置信度&#34;&gt;第四步：判断、RAG、推理与置信度&lt;/h3&gt;
&lt;p&gt;行政流程的核心是&lt;strong&gt;基于规则做判断&lt;/strong&gt;。这就需要引入 RAG（检索增强生成），通过向量数据库找出条款内容。&lt;/p&gt;
&lt;p&gt;在判断前，我们引导模型“思考过程”，即 prompt 要求其先解释自己的推理过程。&lt;/p&gt;
&lt;p&gt;好处包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给客户一个合理解释&lt;/li&gt;
&lt;li&gt;帮助数据科学家分析模型是否“瞎猜”&lt;/li&gt;
&lt;li&gt;判断模型的结果是否有理可循&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设置“置信度阈值”也很关键：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若置信度低，交给人工处理&lt;/li&gt;
&lt;li&gt;若置信度高，可全自动处理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;阈值的设置影响系统的安全性与自动化程度之间的平衡。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f7_hu17341882381196661932.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f7_hu14471712264540132646.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f7_hu10375699246047860855.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f7_hu17341882381196661932.webp&#34;
               width=&#34;740&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;AI Agent 的判断流程。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;p&gt;至此，如果你实现了以上 2~3 个步骤，你就构建了一个初级 Agent。&lt;/p&gt;
&lt;p&gt;你可以使用 crewAI、langGraph、langFlow 等框架，也可以直接用 Python 编写。&lt;/p&gt;
&lt;p&gt;根据实践，这种 Agent 可承担理赔部门 70%~90% 的工作量。这是传统生成式 AI 无法完成的。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f8_hu9117535578301768422.webp 400w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f8_hu16416981768750289903.webp 760w,
               /blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f8_hu8624009177302542594.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/what-are-ai-agents-step-by-step-guide-to-build-your-own/f8_hu9117535578301768422.webp&#34;
               width=&#34;760&#34;
               height=&#34;430&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;AI Agent 的三大法则（致敬 Asimov 的机器人三定律）。图片来源：Maximilian Vogel&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的团队刚刚上线了一个大型物流系统，预计未来几个月我们将继续深耕 Agent 系统的开发。&lt;/p&gt;
&lt;p&gt;祝你成功打造属于自己的 AI Agent！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>平台工程师的 LLM 入门指南</title>
      <link>https://cloudnativecn.com/blog/a-gentle-introduction-to-llms-for-platform-engineers/</link>
      <pubDate>Tue, 15 Apr 2025 11:33:31 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/a-gentle-introduction-to-llms-for-platform-engineers/</guid>
      <description>&lt;p&gt;技术世界日新月异。如今最火的莫过于 AI。作为平台工程师，我们本身已经身处技术栈的洪流之中：容器、Kubernetes、Prometheus、Istio、ArgoCD、Zipkin、Backstage.io …… 技术名词一个接一个，每一个都复杂、抽象且需要深入理解。现在又来了个 AI，让人头大。大多数平台工程师根本没有时间或精力去琢磨什么是 LLM、大模型，更别说在系统中落地使用。&lt;/p&gt;
&lt;p&gt;但现实是：AI 正悄然渗透进平台工程的世界。我们终将需要理解和掌握它。本文尝试用通俗易懂的方式，帮助平台工程师快速建立起对 LLM（大语言模型）的基础认知，并思考它在云原生领域中的应用场景。&lt;/p&gt;
&lt;h2 id=&#34;1-ai-是智能助手而不是天外来物&#34;&gt;1. AI 是“智能助手”而不是“天外来物”&lt;/h2&gt;
&lt;p&gt;你可能用过 Siri，也可能在酒店网站上与机器人客服打过交道。大多数情况下，它们都让人失望——要么不理解你的问题，要么机械地回复固定答案。它们多数基于传统的机器学习或预设规则，无法真正理解你的意图。&lt;/p&gt;
&lt;p&gt;相比之下，现代的 LLM（如 ChatGPT）已经可以处理极为复杂的语言输入，甚至能根据上下文推理、总结信息，和人类进行近乎自然的对话。&lt;/p&gt;
&lt;p&gt;但问题来了：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对平台工程师来说，LLM 到底是什么？它跟传统 API、控制器、CI/CD 流水线有什么关系？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;别急，我们从一个核心问题讲起——“它能做什么”。&lt;/p&gt;
&lt;h2 id=&#34;2-llm-能做什么像人一样理解文档和日志&#34;&gt;2. LLM 能做什么：像人一样理解文档和日志&lt;/h2&gt;
&lt;p&gt;设想一个企业内部的聊天助手，帮助员工快速了解公司的规范、流程、产品特点。当客户提出技术问题时，员工可以通过这个助手快速定位问题、给出答案。这种助手背后就是一个被企业文档、知识库、过往案例、甚至源码“喂养”过的 LLM。&lt;/p&gt;
&lt;p&gt;对比一下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;功能&lt;/th&gt;
          &lt;th&gt;人工&lt;/th&gt;
          &lt;th&gt;LLM&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;阅读全部文档&lt;/td&gt;
          &lt;td&gt;慢&lt;/td&gt;
          &lt;td&gt;快&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;理解概念&lt;/td&gt;
          &lt;td&gt;可&lt;/td&gt;
          &lt;td&gt;可&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;回答问题&lt;/td&gt;
          &lt;td&gt;慢&lt;/td&gt;
          &lt;td&gt;快&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;LLM 的强大之处，在于它可以“吞掉”TB 级别的数据，然后从中提炼出概念与模式。听起来是不是像搜索引擎？不，它远远超过了搜索引擎。&lt;/p&gt;
&lt;h2 id=&#34;3-不只是搜索是理解&#34;&gt;3. 不只是搜索，是“理解”&lt;/h2&gt;
&lt;p&gt;传统搜索引擎依赖关键词匹配，比如你搜索“database timeout”，它只会返回包含这些词的文档。如果真实错误日志写的是“SQL connection lost”，你就查不到了。&lt;/p&gt;
&lt;p&gt;而 LLM 能理解“database timeout”与“SQL连接丢失”、“查询超时”、“数据库网络延迟”之间的语义联系。它不仅能从日志、trace 和文档中抓出相关内容，还能像一个资深工程师一样，总结出可能原因。&lt;/p&gt;
&lt;p&gt;这才是 LLM 的本事：&lt;strong&gt;不仅能搜索，还能理解、总结、推理。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;4-使用自然语言交互甚至可以生成代码&#34;&gt;4. 使用自然语言交互（甚至可以生成代码）&lt;/h2&gt;
&lt;p&gt;LLM 可以像人类一样理解自然语言，还能用自然语言输出答案。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;问：引擎故障灯亮了，启动时有咔哒声，怎么回事？
答：可能是电池电量不足或启动电机故障……（给出详细分析）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;更惊人的是，它还能生成代码、撰写文档、总结聊天记录、处理用户请求……它甚至可以读懂老旧系统的接口文档，然后自动生成集成代码！&lt;/p&gt;
&lt;p&gt;对于平台工程师而言，LLM 可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;帮你总结应用日志&lt;/li&gt;
&lt;li&gt;快速生成 Kubernetes YAML 或 Terraform 模板&lt;/li&gt;
&lt;li&gt;自动生成 CI/CD 流水线步骤说明&lt;/li&gt;
&lt;li&gt;撰写插件或脚本（例如 ArgoCD 的 Plugin、Backstage 的 Template）&lt;/li&gt;
&lt;li&gt;甚至为 SRE 分析告警和异常根因&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-如何接入-llm熟悉的-http-接口&#34;&gt;5. 如何接入 LLM？熟悉的 HTTP 接口！&lt;/h2&gt;
&lt;p&gt;最棒的是，LLM 通常通过 HTTP API 暴露服务。&lt;/p&gt;
&lt;p&gt;平台工程师早就熟悉这个套路了：写一个 HTTP 请求，传入 JSON，接收 JSON 响应。&lt;/p&gt;
&lt;p&gt;来看个例子，调用 OpenAI API 查询 Siri 是如何工作的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl https://api.openai.com/v1/chat/completions &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Authorization: Bearer &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;      {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#34;content&amp;#34;: &amp;#34;Do you know how Siri works?&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;      }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  }&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;返回内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;chatcmpl-Avpw5BwQ4HypBRJFpqg3pPeeqDRwS&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo-0125&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;choices&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Um... I mean... does it though?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;usage&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;prompt_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;completion_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;107&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;total_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;121&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你会注意到几个要点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求是一个标准的 HTTP API 调用&lt;/li&gt;
&lt;li&gt;请求体是自然语言，响应也是自然语言&lt;/li&gt;
&lt;li&gt;响应中包含 token 数量（因为使用 LLM 通常按 token 计费）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，作为平台工程师，你可以用 API Gateway 做调用限流、配额管理、成本控制，还可以做安全网关。&lt;/p&gt;
&lt;h2 id=&#34;6-背后的原理其实很简单但也很神奇&#34;&gt;6. 背后的原理其实很简单（但也很神奇）&lt;/h2&gt;
&lt;p&gt;虽然 LLM 看起来很“神”，但它的核心原理其实很简单：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;接收一串单词（tokens），然后预测下一个最可能的词。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The cow jumped over the ___” → “moon”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就是这么简单的过程，重复进行数百次，就组成了一个完整回答。&lt;/p&gt;
&lt;p&gt;这个过程背后依赖大量训练数据和昂贵的硬件，但核心机制就是概率预测。&lt;/p&gt;
&lt;p&gt;推荐阅读： 👉 &lt;a href=&#34;https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How LLMs work explained without math&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;7-注意事项不是银弹也有风险&#34;&gt;7. 注意事项：不是银弹，也有风险&lt;/h2&gt;
&lt;p&gt;LLM 带来了新的能力，也伴随着新的风险，尤其在平台工程中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;准确性&lt;/strong&gt;：LLM 可能自信满满地说错话，在合规或运维场景中可能带来严重问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据隐私&lt;/strong&gt;：若使用的是 SaaS 模型，输入的数据可能泄露（例如 OpenAI）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成本控制&lt;/strong&gt;：token 计费方式容易产生隐性费用，建议用网关管理配额&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应质量&lt;/strong&gt;：LLM 的输出不是文档原文，可能偏离主题或引入“幻觉”&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;品牌风险&lt;/strong&gt;：若未设置过滤机制，LLM 输出可能引发不当或带偏见内容&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;依赖过重&lt;/strong&gt;：部分用户过度依赖模型输出，忽略人工判断与验证&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合规问题&lt;/strong&gt;：如 GDPR、HIPAA 等法规限制使用 AI 处理敏感数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建议设立审计机制、明确边界、设定使用准则。&lt;/p&gt;
&lt;h2 id=&#34;结语llm-是平台工程师的又一个工具&#34;&gt;结语：LLM 是平台工程师的又一个工具&lt;/h2&gt;
&lt;p&gt;LLM 不是什么魔法，它是一个模式识别系统，用海量数据训练而成，具备强大的语义理解和生成能力。&lt;/p&gt;
&lt;p&gt;对平台工程师而言，它就像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;另一种“自动化”&lt;/li&gt;
&lt;li&gt;一种“超能运维助手”&lt;/li&gt;
&lt;li&gt;一种“文档理解引擎”&lt;/li&gt;
&lt;li&gt;一种“智能 CI/CD 脚本生成器”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以用它来增强现有平台的能力，提高团队效率，提升用户支持体验。
但你也需要理性对待它的局限，持续试验、迭代和评估其在你平台中的最佳用法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI 正在来到平台工程的世界——拥抱它，不如先理解它。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>MCP 到底是什么，为什么每个人都在谈论它？</title>
      <link>https://cloudnativecn.com/blog/what-the-heck-is-mcp-and-why-is-everyone-talking-about-it/</link>
      <pubDate>Mon, 14 Apr 2025 10:37:31 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/what-the-heck-is-mcp-and-why-is-everyone-talking-about-it/</guid>
      <description>&lt;p&gt;本文译自：&lt;a href=&#34;https://github.blog/ai-and-ml/llms/what-the-heck-is-mcp-and-why-is-everyone-talking-about-it/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What the heck is MCP and why is everyone talking about it?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在大模型（LLM）相关的讨论中，最近“&lt;strong&gt;MCP（模型上下文协议，Model Context Protocol）&lt;/strong&gt;”这个词频频出现，几乎成了热门话题。但真正讲清楚它是什么的，反而不多。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一句话总结：MCP 是一个开放标准，用来连接大模型与外部的数据和工具。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文带你快速了解它的来龙去脉。&lt;/p&gt;
&lt;h2 id=&#34;llm-的上下文难题&#34;&gt;LLM 的上下文难题&lt;/h2&gt;
&lt;p&gt;大模型擅长生成内容，但一旦你问它一些训练数据之外的内容，它要么&lt;strong&gt;胡诌&lt;/strong&gt;（幻觉），要么说“我不知道”。&lt;/p&gt;
&lt;p&gt;这时，我们就需要在 Prompt 里提供“上下文信息”——无论是你的代码仓库、文档、数据源还是配置项，这些上下文对构建真正有用的 AI agent 来说是必不可少的。&lt;/p&gt;
&lt;p&gt;目前主流做法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 Prompt 中尽可能精细地嵌入上下文&lt;/li&gt;
&lt;li&gt;借助额外工具注入上下文，比如 GitHub Copilot 的 &lt;a href=&#34;https://code.visualstudio.com/docs/copilot/workspace-context&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@workspace&lt;/a&gt;，会把代码库中的信息传递给 LLM&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种方式虽然很酷，但&lt;strong&gt;实现复杂、跨 API 和服务集成时更是困难重重&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;解决方案mcpmodel-context-protocol&#34;&gt;解决方案：MCP（Model Context Protocol）&lt;/h2&gt;
&lt;p&gt;2023 年 11 月，Anthropic &lt;a href=&#34;https://www.anthropic.com/news/model-context-protocol&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;开源了 MCP 协议&lt;/a&gt;，它是一个用于连接大模型和工具的数据交换标准。&lt;/p&gt;
&lt;p&gt;MCP 就像“你睡觉的样子”——起初慢慢发展，后来突然爆火。随着越来越多的组织采纳 MCP，它的价值也在迅速上升。&lt;/p&gt;
&lt;p&gt;✨ &lt;strong&gt;MCP 是模型无关的（model-agnostic）&lt;/strong&gt;，意味着任何厂商、平台或个人开发者都可以实现自己的 MCP 兼容系统。这种开放性让它在 AI 工具生态中大受欢迎。&lt;/p&gt;
&lt;p&gt;从云原生社区的角度看，它类似于我们熟悉的 &lt;a href=&#34;https://microsoft.github.io/language-server-protocol/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Language Server Protocol（LSP）&lt;/a&gt;。LSP 诞生于 2016 年，标准化了代码编辑器和语言之间的通信方式，使编辑器对语言的支持变得“开箱即用”。&lt;/p&gt;
&lt;p&gt;如今，&lt;strong&gt;MCP 正在复刻这一成功路径，只不过对象变成了 AI 工具链。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;mcp-意味着什么&#34;&gt;MCP 意味着什么？&lt;/h2&gt;
&lt;p&gt;它让：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大厂 🏢&lt;/li&gt;
&lt;li&gt;初创团队 🚀&lt;/li&gt;
&lt;li&gt;独立开发者 👩‍💻&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都能在自己的系统中&lt;strong&gt;快速集成上下文能力&lt;/strong&gt;，从而构建功能更强大的 AI 应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它降低了 AI 工具链的集成门槛，提升了开发体验和用户体验&lt;/strong&gt;，在开放标准领域，MCP 有望成为“新一代基础设施”。&lt;/p&gt;
&lt;h2 id=&#34;github-正在行动&#34;&gt;GitHub 正在行动&lt;/h2&gt;
&lt;p&gt;GitHub 不只是聊 MCP，我们也在贡献！&lt;/p&gt;
&lt;p&gt;我们最近发布了一个官方开源项目：&lt;a href=&#34;https://github.com/github/github-mcp-server&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub MCP Server&lt;/a&gt;，它可以与 GitHub API 无缝集成，开发者可以基于它构建自动化和上下文增强工具。&lt;/p&gt;
&lt;p&gt;📢 查看 &lt;a href=&#34;https://github.blog/changelog/2025-04-04-github-mcp-server-public-preview/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方公告&lt;/a&gt;，或加入 &lt;a href=&#34;https://github.com/orgs/community/discussions/categories/announcements&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub 社区讨论&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;如何参与-mcp-社区&#34;&gt;如何参与 MCP 社区？&lt;/h2&gt;
&lt;p&gt;非常欢迎你加入 MCP 社区并贡献力量，下面是一些推荐资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://modelcontextprotocol.io/introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MCP 官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/modelcontextprotocol/servers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MCP 示例实现仓库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://spec.modelcontextprotocol.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MCP 协议规范&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://code.visualstudio.com/api/language-extensions/language-server-extension-guide#why-language-server&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LSP 背景资料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，也别忘了：MCP 已可与 Agent 模式结合使用。是时候动手打造你的 AI 工具链了！&lt;/p&gt;
&lt;h2 id=&#34;-云原生视角总结&#34;&gt;🚀 云原生视角总结&lt;/h2&gt;
&lt;p&gt;MCP 是一个符合云原生价值观的协议标准：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;开放&lt;/strong&gt;：人人可用，人人可贡献&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可组合&lt;/strong&gt;：可以集成到任何 AI 系统&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可移植&lt;/strong&gt;：不绑定任何平台或模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生态驱动&lt;/strong&gt;：标准的普及带动工具和平台共同进化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它的崛起像当年的 Kubernetes、gRPC、LSP —— 正在为 AI 时代构建“可插拔”基础设施。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>了解 Llama 3：迄今最强大的免费开源大模型从概念到使用</title>
      <link>https://cloudnativecn.com/blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/</link>
      <pubDate>Mon, 01 Jul 2024 09:33:23 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/</guid>
      <description>&lt;p&gt;Meta 公司最近发布了 &lt;a href=&#34;https://ai.meta.com/blog/meta-llama-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Llama 3&lt;/a&gt;，这是其最新一代尖端开源大型语言模型（LLM）。基于其前身的基础之上，Llama 3 旨在提升 Llama 2 作为与 ChatGPT 竞争的重要开源产品的能力，如文章 &lt;a href=&#34;https://www.unite.ai/llama-2-a-deep-dive-into-the-open-source-challenger-to-chatgpt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Llama 2: 深入探索开源挑战者 ChatGPT&lt;/a&gt; 中全面回顾的那样。&lt;/p&gt;
&lt;p&gt;在本文中，我们将讨论 Llama 3 背后的核心概念，探索其创新架构和训练过程，并提供关于如何负责任地访问、使用和部署这一开创性模型的实际指导。无论你是研究人员、开发者还是 AI 爱好者，这篇文章都将为你提供利用 Llama 3 为你的项目和应用赋能的知识和资源。&lt;/p&gt;
&lt;h2 id=&#34;llama-的演变从-llama-2-到-llama-3&#34;&gt;Llama 的演变：从 Llama 2 到 Llama 3&lt;/h2&gt;
&lt;p&gt;Meta 的 CEO，Mark Zuckerberg，在 &lt;a href=&#34;https://www.threads.net/@zuck/post/C56MFEKxl-x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Threads.net&lt;/a&gt; 上宣布了 Llama 3 的首次亮相，这是 Meta AI 开发的最新 AI 模型。这个尖端模型现在已开源，旨在提升 Meta 的各种产品，包括 Messenger 和 Instagram。Zuckerberg 强调，Llama 3 使 Meta AI 成为最先进的&lt;a href=&#34;https://about.fb.com/news/2024/04/meta-ai-assistant-built-with-llama-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;免费可用的 AI 助手&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在我们讨论 Llama 3 的具体细节之前，让我们简要回顾一下它的前身，Llama 2。Llama 2 于 2022 年推出，是开源 LLM 领域的一个重要里程碑，提供了一个强大而高效的模型，可以在消费者硬件上运行。&lt;/p&gt;
&lt;p&gt;然而，尽管 Llama 2 取得了显著的成就，但它也有其局限性。用户报告了一些问题，如错误拒绝（模型拒绝回答无害的提示）、有限的帮助性，以及在推理和代码生成等领域的改进空间。&lt;/p&gt;
&lt;p&gt;进入 Llama 3：Meta 对这些挑战和社区的反馈做出了回应。通过 Llama 3，Meta 设定了与当今市场上顶级专有模型相媲美的最佳开源模型的目标，同时也优先考虑了负责任的开发和部署实践。&lt;/p&gt;
&lt;h2 id=&#34;llama-3架构和训练&#34;&gt;Llama 3：架构和训练&lt;/h2&gt;
&lt;p&gt;Llama 3 的一项关键创新是其分词器，特点是显著扩展的词汇表，&lt;strong&gt;128,256 个 token&lt;/strong&gt;（从 Llama 2 的 32,000 个增加）。这更大的词汇表允许更有效的文本编码，无论是输入还是输出，可能导致更强的多语言能力和整体性能的提升。&lt;/p&gt;
&lt;p&gt;Llama 3 还采用了&lt;strong&gt;分组查询注意力&lt;/strong&gt;（GQA），这是一种提高可扩展性的有效表示技术，有助于模型更有效地处理更长的上下文。&lt;strong&gt;8B&lt;/strong&gt; 版本的 Llama 3 使用了 GQA，而&lt;strong&gt;8B&lt;/strong&gt; 和 &lt;strong&gt;70B&lt;/strong&gt; 模型都可以处理长达 &lt;strong&gt;8,192 个 token&lt;/strong&gt;的序列。&lt;/p&gt;
&lt;h3 id=&#34;训练数据和扩展&#34;&gt;训练数据和扩展&lt;/h3&gt;
&lt;p&gt;用于 Llama 3 的训练数据是其性能提升的关键因素。Meta 精心策划了一个包含超过 &lt;strong&gt;15 万亿&lt;/strong&gt; token 的庞大数据集，来自公开可获得的在线来源，是用于 Llama 2 的数据集的七倍。这个数据集还包括了超过 5% 的高质量非英语数据，涵盖了 &lt;strong&gt;30 多种语言&lt;/strong&gt;，为未来的多语言应用做准备。&lt;/p&gt;
&lt;p&gt;为了确保数据质量，Meta 采用了先进的过滤技术，包括启发式过滤器、NSFW 过滤器、语义去重和训练在 Llama 2 上预测数据质量的文本分类器。团队还进行了广泛的实验，以确定预训练的最佳数据来源组合，确保 Llama 3 在广泛的用例上表现良好，包括琐事、STEM、编码和历史知识。&lt;/p&gt;
&lt;p&gt;放大预训练是 Llama 3 开发的另一个关键方面。Meta 开发了缩放法则，使他们能够在实际训练之前预测其最大模型在关键任务上的性能，如代码生成。这些信息指导了关于数据组合和计算分配的决策，最终导致了更有效和有效的培训。&lt;/p&gt;
&lt;p&gt;Llama 3 最大的模型是在两个定制构建的 24,000 GPU 集群上训练的，利用数据并行、模型并行和流水线并行技术的组合。Meta 的先进训练堆栈自动化了错误检测、处理和维护，最大化了 GPU 的运行时间，使训练效率比 Llama 2 提高了大约三倍。&lt;/p&gt;
&lt;h3 id=&#34;指令微调和性能&#34;&gt;指令微调和性能&lt;/h3&gt;
&lt;p&gt;为了充分发挥 Llama 3 在聊天和对话应用中的潜力，Meta 创新了其指令微调方法。其方法结合了&lt;strong&gt;监督微调&lt;/strong&gt;（SFT）、拒绝抽样、&lt;strong&gt;近端政策优化&lt;/strong&gt;（PPO）和&lt;strong&gt;直接偏好优化&lt;/strong&gt;（DPO）。&lt;/p&gt;
&lt;p&gt;SFT 中使用的提示质量和在 PPO 和 DPO 中使用的偏好排名在对齐模型的性能中起着关键作用。Meta 的团队精心策划了这些数据，并对由人类注释者提供的注释进行了多轮质量保证。&lt;/p&gt;
&lt;p&gt;通过 PPO 和 DPO 对偏好排名进行训练还显著提高了 Llama 3 在推理和编码任务上的性能。Meta 发现，即使模型在直接回答推理问题时遇到困难，它仍然可能产生正确的推理迹象。通过偏好排名的训练，模型学会了如何从这些迹象中选择正确的答案。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-对比结果&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;对比结果&#34; srcset=&#34;
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f2_hu1078991893979778142.webp 400w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f2_hu5794619480392154546.webp 760w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f2_hu13233647470042596874.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f2_hu1078991893979778142.webp&#34;
               width=&#34;760&#34;
               height=&#34;617&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      对比结果
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;成果显而易见：Llama 3 在常见的行业基准测试中表现优于许多可用的开源聊天模型，为 LLM 的 8B 和 70B 参数级别建立了新的最佳性能。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f3_hu13002368666571729442.webp 400w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f3_hu10874792885244218593.webp 760w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f3_hu623210716393878442.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f3_hu13002368666571729442.webp&#34;
               width=&#34;760&#34;
               height=&#34;467&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;负责任的开发和安全考虑&#34;&gt;负责任的开发和安全考虑&lt;/h2&gt;
&lt;p&gt;在追求尖端性能的同时，Meta 也优先考虑了负责任的开发和部署实践，用于 Llama 3。该公司采用了系统级方法，将 Llama 3 模型视为更广泛生态系统的一部分，使开发者能够设计和定制模型以满足其特定用例和安全要求。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f4_hu7484193510083323431.webp 400w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f4_hu15430403253064485765.webp 760w,
               /blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f4_hu13946329183677072181.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/f4_hu7484193510083323431.webp&#34;
               width=&#34;760&#34;
               height=&#34;300&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Meta 进行了广泛的红队演习，执行了对抗评估，并实施了安全缓解技术，以降低其指令调优模型中的残余风险。然而，该公司承认可能仍会存在残余风险，并建议开发者在其特定用例的背景下评估这些风险。&lt;/p&gt;
&lt;p&gt;为支持负责任的部署，Meta 更新了其负责任使用指南，为开发者提供了一个全面的资源，以实施模型和系统级安全最佳实践，用于他们的应用。该指南涵盖了内容审查、风险评估和使用安全工具（如 Llama Guard 2 和 Code Shield）等主题。&lt;/p&gt;
&lt;p&gt;Llama Guard 2，基于 MLCommons 分类法构建，旨在对 LLM 输入（提示）和响应进行分类，检测可能被视为不安全或有害的内容。CyberSecEval 2 在其前身的基础上增加了措施，以防止模型的代码解释器被滥用、攻击性网络安全能力和对提示注入攻击的易感性。&lt;/p&gt;
&lt;p&gt;Code Shield 是 Llama 3 新推出的一个介绍，增加了推断时间的不安全代码过滤，减轻了不安全代码建议、代码解释器滥用和安全命令执行等风险。&lt;/p&gt;
&lt;h2 id=&#34;访问和使用-llama-3&#34;&gt;访问和使用 Llama 3&lt;/h2&gt;
&lt;p&gt;随着 Meta AI 的 Llama 3 发布，已推出了几种开源工具，可在各种操作系统上进行本地部署，包括 Mac、Windows 和 Linux。本节详细介绍了三个值得注意的工具：Ollama、Open WebUI 和 LM Studio，每个工具都提供了利用 Llama 3 功能的独特功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ollama&lt;/strong&gt;：适用于 Mac、Linux 和 Windows，&lt;a href=&#34;https://ollama.com/download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ollama&lt;/a&gt; 简化了在个人计算机上操作 Llama 3 和其他大型语言模型的过程，即使是那些硬件较弱的设备也是如此。它包括一个包管理器，便于模型管理，并支持跨平台的下载和运行模型的命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open WebUI with Docker&lt;/strong&gt;：这个工具提供了一个用户友好的、基于 &lt;a href=&#34;https://docs.docker.com/desktop/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt; 的界面，兼容 Mac、Linux 和 Windows。它与 Ollama 注册表中的模型无缝集成，允许用户在本地 Web 界面内部署和交互，例如 Llama 3。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;：面向 Mac、Linux 和 Windows 的用户，&lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LM Studio&lt;/a&gt; 支持一系列模型，基于 llama.cpp 项目构建。它提供了一个聊天界面，便于直接与各种模型进行交互，包括 Llama 3 8B Instruct 模型。&lt;/p&gt;
&lt;p&gt;这些工具确保用户可以在个人设备上高效利用 Llama 3，满足技术技能和需求的不同范围。每个平台都提供了设置和模型交互的分步过程，使先进的人工智能更加易于开发者和爱好者接触。&lt;/p&gt;
&lt;h2 id=&#34;大规模部署-llama-3&#34;&gt;大规模部署 Llama 3&lt;/h2&gt;
&lt;p&gt;除了直接提供模型权重外，Meta 还与各种云提供商、模型 API 服务和硬件平台合作，实现 Llama 3 的无缝部署。&lt;/p&gt;
&lt;p&gt;Llama 3 的一大优势是其改进的 token 效率，这要归功于新的分词器。基准测试显示，与 Llama 2 相比，Llama 3 需要的 token 减少了 &lt;strong&gt;15%&lt;/strong&gt;，从而实现了更快、更经济的推断。&lt;/p&gt;
&lt;p&gt;Grouped Query Attention (GQA) 的整合在 Llama 3 的 8B 版本中有助于保持与 Llama 2 的 7B 版本相当的推断效率，尽管参数数量增加了。&lt;/p&gt;
&lt;p&gt;为简化部署流程，Meta 提供了 Llama Recipes 代码库，其中包含开源代码和微调、部署、模型评估等示例。这个代码库为开发者提供了一个宝贵的资源，帮助他们利用 Llama 3 的能力来应用到他们的应用中。&lt;/p&gt;
&lt;p&gt;对于那些有兴趣探索 Llama 3 性能的人来说，Meta 已经将其最新模型整合到 Meta AI 中，这是一个以 Llama 3 技术构建的领先人工智能助手。用户可以通过各种 Meta 应用程序，如 Facebook、Instagram、WhatsApp、Messenger 和 Web 与 Meta AI 进行交互，以完成任务、学习、创造和与他们关心的事物建立联系。&lt;/p&gt;
&lt;h2 id=&#34;llama-3-接下来会怎样&#34;&gt;Llama 3 接下来会怎样？&lt;/h2&gt;
&lt;p&gt;尽管 8B 和 70B 模型标志着 Llama 3 发布的开始，但 Meta 对这款开创性 LLM 的未来有雄心勃勃的计划。&lt;/p&gt;
&lt;p&gt;在未来几个月，我们可以期待看到新功能的引入，包括多模态（能够处理和生成不同数据模态，如图像和视频）、多语言支持（支持多种语言）和更长的上下文窗口，以提高在需要广泛上下文的任务上的性能。&lt;/p&gt;
&lt;p&gt;此外，Meta 计划发布更大的模型大小，包括目前正在训练中的超过 4000 亿参数的模型，这些模型在性能和能力方面展现出了有前途的趋势。&lt;/p&gt;
&lt;p&gt;为了进一步推进该领域的发展，Meta 还将发布关于 Llama 3 的详细研究论文，与广泛的 AI 社区分享其发现和见解。&lt;/p&gt;
&lt;p&gt;作为即将推出的内容的预览，Meta 分享了一些其最大 LLM 模型在各种基准上的早期性能快照。尽管这些结果是基于早期检查点的，并且可能会发生变化，但它们提供了一个激动人心的展望，展示了 Llama 3 的未来潜力。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;Llama 3 代表了开源大型语言模型演变的一个重要里程碑，推动了性能、能力和负责任开发实践的边界。凭借其创新架构、庞大的训练数据集和尖端的微调技术，Llama 3 为 LLM 的 8B 和 70B 参数级别建立了新的最佳性能基准。&lt;/p&gt;
&lt;p&gt;然而，Llama 3 不仅仅是一个强大的语言模型；它还体现了 Meta 致力于培养一个开放和负责任的 AI 生态系统的承诺。通过提供全面的资源、安全工具和最佳实践，Meta 授权开发者充分利用 Llama 3 的潜力，同时确保根据其特定用例和受众的需求实现负责任的部署。&lt;/p&gt;
&lt;p&gt;随着 Llama 3 之旅的继续，随着新的能力、模型大小和研究发现的出现，AI 社区热切期待从这款开创性 LLM 中涌现出的创新应用和突破。&lt;/p&gt;
&lt;p&gt;无论你是一名推动自然语言处理边界的研究人员、一名构建下一代智能应用的开发者还是对最新进展感到好奇的 AI 爱好者，Llama 3 都承诺成为你工具箱中的强大工具，开启新的大门并解锁一系列可能性。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>给初学生成式 AI（GenAI）的开发人员的 7 条最佳实践</title>
      <link>https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/</link>
      <pubDate>Wed, 20 Dec 2023 11:30:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/</guid>
      <description>&lt;h2 id=&#34;编者按&#34;&gt;编者按&lt;/h2&gt;
&lt;p&gt;本文译自：&lt;a href=&#34;https://thenewstack.io/7-best-practices-for-developers-getting-started-with-genai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://thenewstack.io/7-best-practices-for-developers-getting-started-with-genai/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;编辑评论：这是一篇非常有价值的文章，向开发者展示了生成式 AI 的潜力和应用。生成式 AI 是一种利用大型语言模型来生成和转换文本的技术，它可以帮助开发者解决一些复杂的问题，如代码生成，文档编写，内容创作等。生成式 AI 也是一种云原生的技术，它需要大量的计算资源和数据，以及高效的部署和管理方式。文章提供了一些实用的工具和平台，如 GitHub Copilot，Bard，ChatGPT 等，让开发者可以轻松地尝试和使用生成式 AI。文章还给出了一些注意事项和建议，如保护数据隐私，验证输出质量，避免滥用等，让开发者可以负责任地使用生成式 AI。我认为这篇文章是一个很好的入门指南，让开发者可以了解和利用生成式 AI 来打造创新的云原生应用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文&lt;/h2&gt;
&lt;p&gt;通过一点经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习任何新技术一样，最好的方法就是动手实践。&lt;/p&gt;
&lt;p&gt;随着可访问的生成式人工智能进入主流，以及由此产生的通过简单语言转化整个人类知识的能力，每个企业都在竭力将人工智能整合到其技术体系中。对于开发人员来说，压力很大，但也有着令人兴奋的无限可能性。&lt;/p&gt;
&lt;p&gt;如果你有一些经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习自 HTML 诞生以来的每一项新技术一样。让我们看看你可以采取的七个步骤，以开始建立 GenAI 的基础，并最终逐步发展成一个完全运作、可扩展的应用程序。&lt;/p&gt;
&lt;h2 id=&#34;1-玩转现有的-genai-工具&#34;&gt;1. 玩转现有的 GenAI 工具&lt;/h2&gt;
&lt;p&gt;入门 GenAI 的最佳方法是实践，而且门槛非常低。市场上现在有许多免费选项，比如 Bard、ChatGPT、Bing 和 Anthropic，有很多可以学习的选择。&lt;/p&gt;
&lt;p&gt;尝试使用 GenAI 工具和代码生成解决方案进行实验（并鼓励你的团队进行实验），例如&lt;a href=&#34;https://github.com/features/copilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Copilot&lt;/a&gt;，它集成到每个流行的 IDE 中，充当一对程序员。Copilot 提供程序员建议，帮助解决代码问题，并生成整个函数，使学习和适应&lt;a href=&#34;https://us.resources.cio.com/resources/the-data-streaming-platform-key-to-ai-initiatives-4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GenAI&lt;/a&gt;变得更快更容易。&lt;/p&gt;
&lt;p&gt;当你首次使用这些现成的工具时，要小心使用专有或敏感的公司数据，即使只是提供给工具一个提示也要小心。Gen AI 供应商可能会存储并使用你的数据用于将来的训练运行，这是公司数据政策和信息安全协议的重大违规行为。确保你及时直接地向你的团队传达这一黄金规则。&lt;/p&gt;
&lt;h2 id=&#34;2-了解从-genai-中可以获得什么&#34;&gt;2. 了解从 GenAI 中可以获得什么&lt;/h2&gt;
&lt;p&gt;一旦你开始尝试 GenAI，你将很快了解到不同提示会产生什么类型的输出。大多数 GenAI 工具可以生成各种格式的文本，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;生成&lt;/strong&gt;新的故事、想法、文章或任意长度的文本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转换&lt;/strong&gt;现有文本为不同格式，如 JSON、Markdown 或 CSV。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;翻译&lt;/strong&gt;文本成不同语言。&lt;/li&gt;
&lt;li&gt;以聊天的方式&lt;strong&gt;对话&lt;/strong&gt;来回。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;审查&lt;/strong&gt;文本以展示特定元素。&lt;/li&gt;
&lt;li&gt;将长篇内容&lt;strong&gt;汇总&lt;/strong&gt;以获取洞察。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分析&lt;/strong&gt;文本的情感。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;任何人都可以生成这些类型的生成文本结果，无需编程技能。只需键入提示，文本就会产生。然而，大型语言模型（LLM）经过的培训越多，即它摄取的语言碎片越多，随着时间的推移，它在生成、更改和分析文本方面就会变得更加准确。&lt;/p&gt;
&lt;h2 id=&#34;3-学习提示工程&#34;&gt;3. 学习提示工程&lt;/h2&gt;
&lt;p&gt;部署 GenAI 的良好方法之一是掌握编写提示的技巧，这既是一门艺术又是一门科学。虽然提示工程师是一个实际的职位描述，但它也是任何希望提高他们使用 AI 的人的好绰号。优秀的提示工程师知道如何开发、完善和优化文本提示，以获得最佳结果并提高整个 AI 系统的性能。&lt;/p&gt;
&lt;p&gt;提示工程不需要特定的学位或背景，但从事这项工作的人需要擅长清晰解释事物。这是重要的，因为所有可用的 LLM 都是无状态的，这意味着没有长期记忆，每次交互只存在于小会话中。&lt;/p&gt;
&lt;p&gt;在提示工程中，以下三个因素变得重要：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;上下文&lt;/strong&gt;：你提出的问题、聊天历史记录和你设置的参数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;知识&lt;/strong&gt;：LLM 已经接受的培训内容以及你通过提示提供的新信息的结合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;形式&lt;/strong&gt;：你期望以何种方式生成信息的语气。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上下文、知识和形式的结合塑造了 GenAI 的大量知识存储成为你希望获得的响应类型。&lt;/p&gt;
&lt;h2 id=&#34;4-探索其他-genai-提示方法&#34;&gt;4. 探索其他 GenAI 提示方法&lt;/h2&gt;
&lt;p&gt;到目前为止，我们一直在谈论零-shot 提示，这基本上意味着提出一个带有一些上下文的问题。如果你从这种方法中没有得到期望的结果，还有四种提示 GenAI 的方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;单次提示&lt;/strong&gt;：提供你正在寻找的输出类型的示例。如果你想要特定类型的格式，例如[标题]和[4 个要点]，这将特别有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;少量提示&lt;/strong&gt;：这类似于单次提示，但你会提供三到五个示例而不仅仅是一个。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“让我们一步一步地思考”&lt;/strong&gt;：这种技巧对 LLM 和对人都同样有效。如果你有一个包含多个部分的复杂问题，请在末尾输入此短语，等待 LLM 分解问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;思路链提示&lt;/strong&gt;：对于涉及复杂算术或其他推理任务的问题，思路链提示会指示工具“展示其工作方式”并解释其如何得出答案。以下是可能的示例：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14801736640312961138.webp 400w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14731880502347286634.webp 760w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu5759154962722220918.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/f1_hu14801736640312961138.webp&#34;
               width=&#34;760&#34;
               height=&#34;402&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;5-查看其他-genai-工作示例&#34;&gt;5. 查看其他 GenAI 工作示例&lt;/h2&gt;
&lt;p&gt;一旦你熟悉了 GenAI 工具并了解如何编写出色的提示，&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;请查看 OpenAI 发布的一些示例&lt;/a&gt;，了解其他人正在做什么以及可能的其他可能性。随着你的实验，你将更加熟悉聊天界面，并学会如何对其进行微调，以便熟练地缩小响应范围，甚至将响应转换为 CSV 文件或其他类型的表格。&lt;/p&gt;
&lt;p&gt;考虑如何将你的 GenAI 知识应用于你的业务，以简化困难或重复性任务，生成创意并使信息易于让更广泛的受众访问。你可以想象出哪些新的用例？以前不可能的东西现在成为可能了吗？&lt;/p&gt;
&lt;h2 id=&#34;6-集成第三方-genai-工具和-api&#34;&gt;6. 集成第三方 GenAI 工具和 API&lt;/h2&gt;
&lt;p&gt;考虑使用 ChatGPT、Bard 和 Claude 2 等 API 通过 API 使用 LLMs 的角色。这些工具都提供了强大的 API，并有支持文档，因此入门门槛很低。大多数这些 API 是基于使用量的，因此更容易玩弄。&lt;/p&gt;
&lt;p&gt;通常情况下，通过语义搜索和由向量数据库支持的嵌入来将自定义或私有数据集成到 LLM 提示中，你还可以集成自定义或私有数据。通常称为 RAG（检索增强生成）。&lt;/p&gt;
&lt;p&gt;分解这两个术语：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;语义搜索&lt;/strong&gt;：使用词嵌入比较查询的含义与其索引中文档的含义，即使没有完全匹配的单词也能获得更相关的结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;嵌入&lt;/strong&gt;：将对象（如单词、句子或整个文档）的数值表示转化为多维空间。这使得评估不同实体之间的关系成为可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下是这可能看起来的一个示例：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu1009306822241985111.webp 400w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu11470018464599431523.webp 760w,
               /blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu17865044914941909841.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/7-best-practices-for-developers-getting-started-with-genai/f2_hu1009306822241985111.webp&#34;
               width=&#34;760&#34;
               height=&#34;608&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这幅图展示了“猫”和“狗”的概念比它们与“人”或“蜘蛛”的概念更接近，“车辆汽车”则是最远的，是概念中最不相关的。（&lt;a href=&#34;https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/#connecting-knowledge-base-to-gpt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里有更多关于如何使用语义搜索和嵌入的信息&lt;/a&gt;。）&lt;/p&gt;
&lt;h2 id=&#34;7-从头开始训练自己的模型&#34;&gt;7. 从头开始训练自己的模型&lt;/h2&gt;
&lt;p&gt;这最后的建议实际上不太像建议，更像是一个“可选的下一步”。训练自己的 GenAI 模型并不适合每个人，但如果你：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拥有独特而有价值的知识库。&lt;/li&gt;
&lt;li&gt;想要执行商业 LLM 无法完成的某些任务。&lt;/li&gt;
&lt;li&gt;发现商业 LLM 的推理成本在商业上没有意义。&lt;/li&gt;
&lt;li&gt;有特定的安全要求，需要托管自己的 LLM 数据，并且不愿通过第三方 API 传递数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;训练自己的模型的一种方法是使用开源模型，例如 Llama 2、Mosaic MPT-7B、Falcon 或 Vicuna，其中许多还提供了商业使用许可证。这些通常根据它们具有的参数数量进行标记：7B、13B、40B 等。 “B”代表模型的参数数目，以及它可以处理和存储的信息量。数字越高，模型就越复杂和复杂，但训练和运行成本也越高。如果你的用例不复杂，并且如果你计划在性能相当强大的现代笔记本电脑上运行模型，那么具有较低参数的模型是开始的最佳且最经济的方法。&lt;/p&gt;
&lt;p&gt;中大型组织可能会选择从头开始构建和训练一个 LLM 模型。这是一条非常昂贵、资源密集且耗时的 AI 之路。你需要难以招聘的技术人才，并具备长时间迭代的机会，因此对大多数组织来说，这条路线不现实。&lt;/p&gt;
&lt;h3 id=&#34;微调-llm&#34;&gt;微调 LLM&lt;/h3&gt;
&lt;p&gt;一些组织选择中间路径：微调基本开源 LLM 以实现模型预训练能力之外的特定功能。如果你希望以你品牌独特的声音创建虚拟助手或基于真实客户购买构建的推荐系统，那么这是一个很好的选择。这些模型会随着你纳入排名靠前的用户交互而不断地训练自己。事实上，&lt;a href=&#34;https://voicebot.ai/2023/08/23/openai-brings-fine-tuning-to-gpt-3-5-turbo-and-gpt-4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open AI 报告&lt;/a&gt;，使用此模型，可以将提示长度缩短多达 90%，同时保持性能不变。此外，Open AI 的商业 API 的最新增强功能使其与驱动 ChatGPT 和 Bing AI 的模型一样强大和易于访问。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>微软零成本收购 OpenAI？——OpenAI 的错位与微软的收益</title>
      <link>https://cloudnativecn.com/blog/openais-misalignment-and-microsofts-gain/</link>
      <pubDate>Tue, 21 Nov 2023 14:40:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/openais-misalignment-and-microsofts-gain/</guid>
      <description>&lt;p&gt;上个周末的 OpenAI“宫斗”大戏相信大家都知晓了，今天正巧看到 Ben Thompson 的这篇总结文章，感觉不错，分享给大家。&lt;/p&gt;
&lt;p&gt;关于作者：Ben Thompson（本·汤普森）是一位知名的科技和商业评论家，他是 Stratechery（《战略》）博客的创始人和作者。Stratechery 是一家专注于科技产业和商业策略分析的网站，汤普森在博客中深入剖析科技公司、产品、行业趋势和商业模式。他的文章通常涵盖了互联网、数字媒体、云计算、人工智能等领域的重要话题。&lt;/p&gt;
&lt;p&gt;Ben Thompson 因其深刻的洞察力和独特的分析方法而闻名，他的文章常常引发行业内外的广泛讨论。他的分析不仅关注技术本身，还关注技术如何塑造和影响商业和社会。由于其博客的高质量内容，他已经建立了一支忠实的读者群，并成为了科技产业和商业领域的重要声音之一。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;下文译自：&lt;a href=&#34;https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：
这篇文章分析了 OpenAI 的使命与商业模式之间的不一致，以及 Microsoft 如何从中受益。文章认为，OpenAI 的 GPT-3 模型是一种强大的通用人工智能，但是它的许可协议限制了它的应用范围。Microsoft 作为 OpenAI 的合作伙伴和投资者，拥有 GPT-3 的独家许可权，可以将其用于自己的产品和服务，从而获得竞争优势。&lt;/p&gt;
&lt;p&gt;正如您所预期的那样，我已经在脑海中和页面上撰写了几个版本的这篇文章，因为&lt;a href=&#34;https://twitter.com/benthompson/status/1726514608234746003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我职业生涯中最不同寻常的周末&lt;/a&gt;已经开始。简要总结如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;周五，时任 CEO Sam Altman 被 OpenAI 的董事会解雇；接着，OpenAI 总裁 Greg Brockman 被免去董事会职务，并随后辞职。&lt;/li&gt;
&lt;li&gt;周末期间，有传闻称 Altman 正在谈判回归，然后 OpenAI 聘请了前 Twitch CEO Emmett Shear 担任 CEO。&lt;/li&gt;
&lt;li&gt;最后，在周日深夜，&lt;a href=&#34;https://twitter.com/satyanadella/status/1726509045803336122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Satya Nadella 通过推文宣布&lt;/a&gt;，Altman 和 Brockman 以及他们的“同事”将加入 Microsoft。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很显然，对于 Microsoft 来说，这是一个非凡的成果。该公司已经获得了&lt;a href=&#34;https://www.wsj.com/articles/microsoft-and-openai-forge-awkward-partnership-as-techs-new-power-couple-3092de51&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;所有 OpenAI 知识产权的永久许可证&lt;/a&gt;（&lt;a href=&#34;https://openai.com/our-structure#:~:text=the%20board%20determines%20when%20we%27ve%20attained%20AGI.%20Again%2C%20by%20AGI%20we%20mean%20a%20highly%20autonomous%20system%20that%20outperforms%20humans%20at%20most%20economically%20valuable%20work.%20Such%20a%20system%20is%20excluded%20from%20IP%20licenses%20and%20other%20commercial%20terms%20with%20Microsoft%2C%20which%20only%20apply%20to%20pre%2DAGI%20technology.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;除通用人工智能之外&lt;/a&gt;)，包括源代码和模型权重；问题是，如果 OpenAI 遭受了人才流失的威胁，Altman 和 Brockman 被解雇，它是否有足够的才能来利用那些知识产权。实际上，他们将拥有足够多的人才，似乎很有可能流向 Microsoft；你可以这样说，Microsoft 刚刚以零风险和零成本收购了 OpenAI。&lt;/p&gt;
&lt;p&gt;注：微软与 OpenAI 的最初协议还禁止微软基于 OpenAI 技术单独开发通用人工智能（AGI）；据我了解，这一条款已在最近的协议中被删除&lt;/p&gt;
&lt;p&gt;与此同时，对于 OpenAI 来说，这是一个损失，因为它在金钱和计算资源上依赖于总部位于雷德蒙德的 Microsoft 公司：OpenAI 员工在人工智能方面的工作要么因为永久许可证属于 Microsoft，要么因为员工加入了 Altman 的团队而成为 Microsoft 的直接财产。OpenAI 的王牌是 ChatGPT，它正在朝着技术的至高境界迈进——一个大规模的消费者平台——但是如果周末的报道可信，OpenAI 的董事会可能已经对 ChapGPT 给公司带来的激励产生了疑虑（后文详述）。&lt;/p&gt;
&lt;p&gt;然而，最大的损失是一个必然的损失：即除了盈利公司，任何其他组织形式都不是正确的公司组织方式。&lt;/p&gt;
&lt;h2 id=&#34;openai-的非营利模式&#34;&gt;OpenAI 的非营利模式&lt;/h2&gt;
&lt;p&gt;OpenAI 成立于 2015 年，是一家被称为“非营利智能研究公司”的组织。从他们的&lt;a href=&#34;https://openai.com/blog/introducing-openai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;最初博客文章&lt;/a&gt;中可以得知：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenAI 是一家非营利人工智能研究公司。我们的目标是以最有可能造福整个人类的方式推进数字智能，不受需要产生财务回报的限制。由于我们的研究不受财务义务的制约，我们可以更好地专注于对人类产生积极影响。我们认为人工智能应该是个体人类意愿的延伸，在自由的精神中尽可能广泛和均匀地分布。这个冒险的结果是不确定的，工作是困难的，但我们认为目标和结构是正确的。我们希望这对领域最优秀的人来说是最重要的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于 OpenAI 的创始人，特别是 Altman 和 Elon Musk 的动机，我曾经有过相当怀疑；我在一篇&lt;a href=&#34;https://stratechery.com/2015/openai-artificial-intelligence-and-data-data-and-recruiting/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;每日更新&lt;/a&gt;中写到：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Elon Musk 和 Sam Altman 分别领导着特斯拉和 YCombinator 等组织，这些组织看起来很像我刚刚描述的那两个受到 Google 和 Facebook 数据优势威胁的公司的例子，他们与 OpenAI 做到了这一点，还有使整个事情成为非营利性组织的额外动机；我说“动机”是因为成为非营利性组织几乎肯定更多地与我在开头强调的那句话有关：“我们希望这对领域中最优秀的人来说最重要。”换句话说，OpenAI 也许没有最好的数据，但至少它有一个可能帮助理想主义研究人员晚上睡得更香的使命结构。OpenAI 可能有助于平衡特斯拉和 YCombinator 的竞争局势，我猜我们应该相信这是一个愉快的巧合。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;无论 Altman 和 Musk 的动机如何，将 OpenAI 建立为非营利性组织的决定并不仅仅是口头上的；该公司是一个 501(c)(3) 组织；您可以在&lt;a href=&#34;https://projects.propublica.org/nonprofits/organizations/810861541&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;查看他们的年度 IRS 申报。Form 990 上的第一个问题要求组织“简要描述组织的使命或最重要的活动”；&lt;a href=&#34;https://projects.propublica.org/nonprofits/organizations/810861541/201703459349300445/full&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2016 年的第一份申报&lt;/a&gt;中写道：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenAI 的目标是以最有可能使整个人类受益的方式推进数字智能，不受产生财务回报的需求限制。我们认为人工智能技术将有助于塑造 21 世纪，我们希望帮助世界构建安全的人工智能技术，并确保人工智能的利益尽可能广泛均衡地分布。我们试图作为更大社区的一部分构建人工智能，并希望在此过程中公开分享我们的计划和能力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;两年后，“公开分享我们的计划和能力”的承诺消失了；三年后，“推进数字智能”的目标被替换为“构建通用人工智能”。&lt;/p&gt;
&lt;p&gt;2018 年，根据今年早些时候的一份 Semafor 报告，马斯克试图接管该公司，但被拒绝了；他离开了董事会，并且更为关键的是，停止了对 OpenAI 的运营支持。这导致了第二个关键背景信息：面对需要支付大量计算资源的需求，现在坚决掌控 OpenAI 的 Altman 创建了 OpenAI Global, LLC，这是一家有上限的营利性公司，微软是少数股东。这是 OpenAI 当前结构的图像来自&lt;a href=&#34;https://openai.com/our-structure&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;他们的网站&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-openai-的公司结构&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;OpenAI 的公司结构&#34; srcset=&#34;
               /blog/openais-misalignment-and-microsofts-gain/openai-2_hu5409524645142908902.webp 400w,
               /blog/openais-misalignment-and-microsofts-gain/openai-2_hu4922875475911230746.webp 760w,
               /blog/openais-misalignment-and-microsofts-gain/openai-2_hu10391124918716492126.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/openais-misalignment-and-microsofts-gain/openai-2_hu5409524645142908902.webp&#34;
               width=&#34;640&#34;
               height=&#34;464&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      OpenAI 的公司结构
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OpenAI Global 可以筹集资金，而且对于其投资者来说至关重要的是，它可以盈利，但它仍然在非营利性组织和其使命的监督下运营；OpenAI Global 的经营协议规定：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该公司的存在是为了推进 OpenAI, Inc.确保开发安全的人工通用智能并使其造福全人类的使命。该公司对这一使命以及 OpenAI, Inc.宪章中提出的原则的责任优先于产生利润的任何义务。该公司可能永远不会盈利，也没有义务这样做。该公司可以自由重新投资公司的全部或部分现金流于研究和开发活动和/或相关费用，而无需向成员承担任何义务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;chatgpt-族群&#34;&gt;ChatGPT 族群&lt;/h3&gt;
&lt;p&gt;第三个关键背景信息是最为人熟知的，也推动了这些雄心壮志达到了新的高度：ChatGPT 在 2022 年 11 月底发布，震撼了整个世界。如今，ChatGPT 拥有超过 1 亿的每周用户和超过 10 亿美元的收入；它还从根本上改变了几乎每个大公司和政府关于人工智能的讨论。&lt;/p&gt;
&lt;p&gt;但对我来说，最引人注目的是我上面提到的可能性，即 ChatGPT 成为一个新的重要消费者科技公司的基础，这是最有价值和最难建立的公司类型。我在今年早些时候在&lt;a href=&#34;https://stratechery.com/2023/the-accidental-consumer-tech-company-chatgpt-meta-and-product-market-fit-aggregation-and-apis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《偶然的消费者科技公司》&lt;/a&gt;中写道：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在涉及有意义的消费者科技公司时，实际上产品是最重要的。消费者产品的关键在于高效的客户获取，这意味着口碑和/或网络效应；ChatGPT 实际上没有后者（是的，它会收到反馈），但它拥有大量的前者。事实上，ChatGPT 的出现最让我想到的产品是谷歌：它简直比市场上任何其他产品都要好，这意味着它来自一对大学生并不重要（起源故事有些相似！）。此外，就像谷歌一样，与扎克伯格对硬件的痴迷相反，ChatGPT 非常出色，人们会想方设法使用它。甚至没有一个应用程序！然而，仅仅四个月过去，已经有一个平台了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我所指的平台是&lt;a href=&#34;https://stratechery.com/2023/chatgpt-learns-computing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT 插件&lt;/a&gt;；这是一个令人着迷的概念，其用户界面不太完善，而在八个月后的&lt;a href=&#34;https://stratechery.com/2023/the-openai-keynote/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI 首个开发者日&lt;/a&gt;上，公司宣布了 GPTs，这是他们试图成为一个平台的第二次尝试。与此同时，据报道，Altman 正在探索 OpenAI 监管范围之外的新公司，以构建芯片和硬件，显然没有向董事会报备。这些因素的某种组合，或者可能尚未报道的其他因素，是董事会的最后一根稻草，由首席科学家 Ilya Sutskever 领导，他们在周末罢免了 Altman。&lt;a href=&#34;https://www.theatlantic.com/technology/archive/2023/11/sam-altman-open-ai-chatgpt-chaos/676050/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Atlantic 报道&lt;/a&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Altman 在上周五被 OpenAI 董事会解雇，这是公司两派意识形态的权力斗争的顶点，一派来自硅谷的技术乐观主义，充满了快速商业化的活力；另一方则深受人工智能代表对人类构成存在威胁的担忧，认为必须极度谨慎地控制。多年来，这两派成功地共存，虽然也出现了一些波折。&lt;/p&gt;
&lt;p&gt;根据现任和前员工的说法，几乎一年前的今天，正是 ChatGPT 的发布导致了 OpenAI 陷入全球关注的关键时刻。从外部看，ChatGPT 看起来像有史以来最成功的产品推出之一。它比历史上任何其他消费者应用程序都增长得更快，似乎单凭一己之力重新定义了数百万人对自动化的威胁和机遇的理解。但它使 OpenAI 朝着截然相反的方向发展，加剧了已经存在的意识形态分歧。ChatGPT 为盈利而创造产品的竞争加速了，同时给公司的基础设施和专注于评估和减轻技术风险的员工带来了前所未有的压力。这加剧了 OpenAI 派系之间已经紧张的关系，Altman 在 2019 年的员工电子邮件中称之为“族群”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Altman 的“族群”——将 OpenAI 变得更像传统科技公司的一方——对于科技界的人们，包括我自己，肯定更加熟悉。我甚至在我的文章中关于开发者日演讲的段落中谈到了 OpenAI 的过渡，但不幸的是，我编辑掉了。以下是我写的内容：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;大约在这个时候，我再次开始哀叹&lt;a href=&#34;https://stratechery.com/2022/dall-e-open-to-all-openai-and-openness-openai-opportunities-and-threats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI 奇怪的公司结构&lt;/a&gt;。作为长期关注硅谷的观察者，看到 OpenAI 追随传统的创业公司道路是令人愉快的：公司显然处于迅速扩张阶段，产品经理突然被认为是有用的，因为他们处于找到并交付低悬果实的甜蜜点，而这对于一个尚未拥有时间或壕沟来容忍王国建设和功能蔓延的实体来说是有益的。&lt;/p&gt;
&lt;p&gt;让我犹豫不决的是，目标不是上市，然后退休到游艇上，并向那些在消除极度富有的内疚感方面做得更好的事业提供资金。赚钱并回应股东的要求会控制更多救世主的冲动；当我听说 Altman 不拥有 OpenAI 的任何股权时，这使我更加紧张而不是宽慰。或者也许是因为我不会有 S-1 或 10-K 要分析。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;微软与董事会的对立&#34;&gt;微软与董事会的对立&lt;/h3&gt;
&lt;p&gt;在整个周末，科技界 Twitter 上的讨论大部分集中在董事会为何会烧掉如此多的价值上感到震惊。首先，Altman 是硅谷最有关联的高管之一，是一位多产的筹款人和交易谈判者；其次，一些 OpenAI 员工已经辞职，预计未来几天会有更多人辞职。OpenAI 以前可能有两个派系；可以合理地假设未来只会有一个，由新任 CEO Shear 领导，他将人工智能末日的概率定为&lt;a href=&#34;https://twitter.com/rowancheung/status/1726473420299534491&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;5% 至 50% 之间&lt;/a&gt;，并提倡&lt;a href=&#34;https://twitter.com/eshear/status/1703178063306203397&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;大幅减缓发展&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;然而，事实上是这样的：无论您是否同意 Sutskever/Shear 派的观点，董事会的宪章和责任不是为了赚钱。这不是一家受益人公司，其对股东具有信托责任；事实上，正如我上面所述，OpenAI 的宪章明确规定了它是“无需生成财务回报”。从这个角度来看，董事会实际上正在履行其职责，尽管这似乎有些违反直觉：在董事会认为 Altman 及其派别并没有“构建造福于人类的通用人工智能”的情况下，他们有权解雇他；他们这么做了。&lt;/p&gt;
&lt;p&gt;这涉及到了我对该公司非营利性地位的担忧的讽刺之处：我曾担心 Altman 没有受到赚钱的需要的限制，或者担心由某人负责，而他没有对结果有财务利益，而事实上正是这些因素让他失去了工作。更广泛地说，我的批评不够全面，因为在商业分析的案例中，对无约束权力的哲学关切相形见绌——至少在 OpenAI 成为与之进行交易的根本不稳定的实体方面如此。当然，这涉及到了微软，作为一直支持 Satya Nadella 领导的人，我不得不承认我对公司与 OpenAI 合作的分析存在不足之处。&lt;/p&gt;
&lt;p&gt;微软已经押注了其未来的大部分，这超越了金钱，微软拥有大量的金钱，其中很多尚未支付（或以 Azure 积分形式授予）；OpenAI 的技术已经内建到了微软的许多产品中，从 Windows 到 Office，甚至有些大多数人从未听说过的产品（我看到了你，Dynamics CRM 迷！）。微软还在为 OpenAI 量身定制的基础设施上进行大规模投资，纳德拉一直在宣传专业化的财务优势，而且刚刚发布了一款专门用于运行 OpenAI 模型的定制芯片。现在看来，微软将大量的承诺交给了一个非追求利润的实体，因此不受微软作为投资者和收入驱动因素的约束，这似乎是荒谬的。&lt;/p&gt;
&lt;p&gt;或者说，直到纳德拉在太平洋时间晚上 11:53 发推文如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-satya-nadella-发文宣布-sam-altman-加入微软&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Satya Nadella 发文宣布 Sam Altman 加入微软&#34; srcset=&#34;
               /blog/openais-misalignment-and-microsofts-gain/openai-1_hu6400280948200541092.webp 400w,
               /blog/openais-misalignment-and-microsofts-gain/openai-1_hu6791968672014753677.webp 760w,
               /blog/openais-misalignment-and-microsofts-gain/openai-1_hu17602148903376625195.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/openais-misalignment-and-microsofts-gain/openai-1_hu6400280948200541092.webp&#34;
               width=&#34;640&#34;
               height=&#34;358&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Satya Nadella 发文宣布 Sam Altman 加入微软
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;对我刚才提出的关于微软错误决定与非营利组织合作的论点的反驳是关于人工智能开发的现实，特别是对大量计算资源的需求。正是对这种计算资源的需求导致 OpenAI，其自身禁止进行传统的风险投资交易，向微软交出了知识产权。换句话说，尽管董事会可能拥有非营利公司的宪章，以及一种令人钦佩的愿意行动并坚守信念，但他们最终没有筹码，因为他们不是一家拥有资本以真正独立的公司。最终的结果是，一个以安全开发人工智能为宗旨的实体基本上已经将其所有工作，以及可能很快的时间内的一大部分人才，移交给了地球上最大的盈利实体之一。或者用与人工智能相关的框架来说，OpenAI 的结构最终与实现其所述使命不符。试图通过命令组织激励措施根本无法考虑在动态情况下可能发挥作用的所有可能情况和变量；出于良好的原因，收获自身利益一直是对齐个人和公司的最佳方式。&lt;/p&gt;
&lt;h3 id=&#34;关于-altman-的疑问&#34;&gt;关于 Altman 的疑问&lt;/h3&gt;
&lt;p&gt;董事会的行动还有一个角度值得承认：这很可能是有正当理由的。我支持&lt;a href=&#34;https://www.newcomer.co/p/give-openais-board-some-time-the&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eric Newcomer 在他的同名 Substack 上发表的深思熟虑的专栏文章&lt;/a&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在其&lt;a href=&#34;https://openai.com/blog/openai-announces-leadership-transition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;声明&lt;/a&gt;中，董事会表示他们得出了结论，认为 Altman“在与董事会的沟通中没有始终坦诚”。我们不应该因为糟糕的公开信息传递让我们忽视一个事实，那就是 Altman 失去了董事会的信任，而董事会本应该证明 OpenAI 的诚信&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;据我了解，一些董事会成员真诚地认为 Altman 在与他们的沟通中不诚实，不可靠，消息来源告诉我。董事会的一些成员认为他们无法监督公司，因为他们无法相信 Altman 所说的话。然而，非营利董事会的存在是 OpenAI 的&lt;a href=&#34;https://x.com/martin_casado/status/1723112508234539270?s=20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;信誉&lt;/a&gt;的一个关键理由。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Newcomer 指出了我上面提到的董事会的宪章，Anthropic 的创始人觉得有必要首先离开 OpenAI，Musk 对 Altman 的敌意，以及 Altman 在离开 YCombinator 时仍然&lt;a href=&#34;https://www.newcomer.co/p/odds-and-ends?nthPub=1251&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;有些模糊和未解释清楚的离职&lt;/a&gt;。Newcomer 总结道：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我相信写这封警示信不会让我在硅谷的许多角落受欢迎。但我认为我们应该放慢脚步，获取更多的事实。如果 OpenAI 将我们引向人工通用智能或接近的领域，我们将希望花更多的时间来思考我们想要由谁引领我们去那里&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;Altman 拥有很大的权力，以及非营利组织的外衣，以及超过他更混杂的私人声誉的公开形象。他失去了董事会的信任。我们应该认真对待这一点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也许我因为上面提到的对微软分析的疏忽而感到有些谦卑，更不用说对周末深夜的命运逆转感到震惊了，但我要指出，&lt;a href=&#34;https://stratechery.com/2023/attenuating-innovation-ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我已经明确了立场&lt;/a&gt;，反对 AI 末日论者和呼吁监管的呼声；为此，我对确认本周末事件背后驱动力的假设性叙述感到警惕。并且，我要指出，我仍然担心那些试图在没有自己切身利益的情况下控制令人难以置信的能力的高管的哲学问题。&lt;/p&gt;
&lt;p&gt;为此，像 Altman 这样的初创生态系统固定成员加入微软当然令人惊讶：微软是唯一保留对 OpenAI 知识产权的地方，可以将其与有效无限的资金和 GPU 访问相结合，这无疑增加了权力控制人工智能是 Altman 主要动机的叙述的可信度。&lt;/p&gt;
&lt;h3 id=&#34;改变后的格局&#34;&gt;改变后的格局&lt;/h3&gt;
&lt;p&gt;显然，Altman 和 Microsoft 掌握了人工智能的主导权。微软拥有知识产权，并很快将拥有足够的团队，可以将其与资金和基础设施相结合，同时摆脱了他们与 OpenAI 之前合作中固有的协调问题（当然，他们仍然是 OpenAI 的合作伙伴！）。&lt;/p&gt;
&lt;p&gt;我也辩论了一段时间，外部公司建立在 Azure 的 API 上比建立在 OpenAI 的 API 上更有意义；微软天生就是一个开发平台，而 OpenAI 虽然有趣和令人兴奋，但很可能会克隆您的功能或淘汰旧的 API。现在，选择更加明显了。从微软的角度来看，这消除了企业客户避免使用 Azure 的主要原因之一，因为他们依赖 OpenAI；微软现在拥有完整的技术栈。&lt;/p&gt;
&lt;p&gt;与此同时，谷歌可能需要进行一些重大变革；公司的最新模型 Gemini 已经延迟推出，其云业务因支出转向人工智能而放缓，这正是公司所希望的完全相反的结果。公司的创始人和股东还能容忍公司进展太慢的看法多久，特别是与微软展示的灵活性和愿意承担风险的态度相比？&lt;/p&gt;
&lt;p&gt;这留给了 Anthropic，12 小时前看起来像是大赢家，现在作为一个独立实体感觉越来越脆弱。该公司已经与谷歌和亚马逊达成了合作协议，但现在面临着一个竞争对手微软，其拥有实际上无限的资金和 GPU 访问权限；很难摆脱这样一种感觉，即将其作为 AWS 的一部分是有道理的（是的，B 公司可以被收购，比非营利组织更容易）。&lt;/p&gt;
&lt;p&gt;然而，最终，可以提出这样的论点，即实际上并没有发生太大变化：很长一段时间以来，已经明显&lt;a href=&#34;https://stratechery.com/2023/ai-and-the-big-five/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AI 至少在短期和中期内&lt;/a&gt;是一种持续的创新，而不是一种颠覆性的创新，也就是说，它主要会使最大的公司受益并部署。成本如此之高，以至于其他人很难获得资金，甚至在考虑渠道和客户获取问题之前。如果有一家公司有望加入 Big Five 的行列，那就是 OpenAI，多亏了 ChatGPT，但现在似乎不太可能了（但不是不可能）。最终，这是纳德拉的洞察力：如果您很大，赢得胜利的关键不是像初创公司那样发明，而是利用自己的规模来收购或快速跟随它们；如果您可以以 0 美元的低价格做到这一点，那就更好了。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
