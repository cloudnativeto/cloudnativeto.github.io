<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>X-Protocol | 云原生社区（中国）</title>
    <link>https://cloudnative.to/tag/x-protocol/</link>
      <atom:link href="https://cloudnative.to/tag/x-protocol/index.xml" rel="self" type="application/rss+xml" />
    <description>X-Protocol</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Sun, 14 Oct 2018 14:53:04 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/media/sharing.png</url>
      <title>X-Protocol</title>
      <link>https://cloudnative.to/tag/x-protocol/</link>
    </image>
    
    <item>
      <title>SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（3）——TCP 协议扩展</title>
      <link>https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/</link>
      <pubDate>Sun, 14 Oct 2018 14:53:04 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是 SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（1）——DNS 通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（3）——TCP 协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;在 Istio 和 Envoy 中，对通讯协议的支持，主要体现在 HTTP/1.1 和 HTTP/2 上，这两个是 Istio/Envoy 中的一等公民。而基于 HTTP/1.1 的 REST 和基于 HTTP/2 的 gRPC，一个是目前社区最主流的通讯协议，一个是未来的主流，google 的宠儿，CNCF 御用的 RPC 方案，这两个组成了目前 Istio 和 Envoy（乃至 CNCF 所有项目）的黄金组合。&lt;/p&gt;
&lt;p&gt;而我们 SOFAMesh，在第一时间就遇到和 Istio/Envoy 不同的情况，我们需要支持 REST 和 gRPC 之外的众多协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOFARPC：这是蚂蚁金服大量使用的 RPC 协议 (已开源)&lt;/li&gt;
&lt;li&gt;HSF RPC：这是阿里集团内部大量使用的 RPC 协议 (未开源)&lt;/li&gt;
&lt;li&gt;Dubbo RPC: 这是社区广泛使用的 RPC 协议 (已开源)&lt;/li&gt;
&lt;li&gt;其他私有协议：在过去几个月间，我们收到需求，期望在 SOFAMesh 上运行其他 TCP 协议，部分是私有协议&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为此，我们需要考虑在 SOFAMesh 和 SOFAMosn 中增加这些通讯协议的支持，尤其是要可以让我们的客户非常方便的扩展支持各种私有 TCP 协议：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu8922947825122230872.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu7277406872245682737.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/supported-protocol_hu9228957397269479448.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/supported-protocol_hu8922947825122230872.webp&#34;
               width=&#34;594&#34;
               height=&#34;485&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;实现分析&#34;&gt;实现分析&lt;/h2&gt;
&lt;p&gt;我们来大体看一下，在 SOFAMesh/Istio 中要新增一个通讯协议需要有哪些工作：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/tbd_hu148373051036648928.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/tbd_hu17773021746254140319.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/tbd_hu9512056212887822031.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/tbd_hu148373051036648928.webp&#34;
               width=&#34;760&#34;
               height=&#34;327&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;protocol decoder：负责解析协议，读取协议字段&lt;/li&gt;
&lt;li&gt;protocol encoder：负责生成请求报文，注意通常会有改动，比如修改某些 header&lt;/li&gt;
&lt;li&gt;在 pilot 中需要为新协议生成 Virtual Host 等配置，有 inbound 和 outbound 两份，分别下发到 Sidecar&lt;/li&gt;
&lt;li&gt;在 Sidecar 中，根据下发的 Virtual Host 等配置，进行请求匹配，以决定请求该转发到何处&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：实际下发的配置不止 Virtual Host 配置，为了简单起见，我们仅以 Virtual Host 为例做讲解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其中，protocol encoder 和 protocol decoder 是容易理解的，对于新的通讯协议肯定需要有协议编解码层面的工作必须要完成，这块有工作量是很自然的。&lt;/p&gt;
&lt;p&gt;我们来看看第三块的工作量是什么，inbound 和 outbound 的 Virtual Host 配置示例如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/outbound_hu9183275080841250750.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/outbound_hu17188554199718176298.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/outbound_hu13251745042161154333.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/outbound_hu9183275080841250750.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;outbound 配置中，注意 domains 字段是各种域名和 ClusterIP，而 routes 中，match 是通过 prefix 来匹配。我们结合 HTTP/1.1，domains 字段是用来和请求的 Host header 进行域名匹配的，比如 &lt;code&gt;Host: istio-telemetry&lt;/code&gt;，这决定了哪些请求是要转发到 istio-telemetry 这个服务的。routes 的 match 用来进行路由匹配的，通过 HTTP 请求的 path 进行匹配。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/inbound_hu11331400421315493730.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/inbound_hu17190055243913245327.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/inbound_hu15766408145321837216.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/inbound_hu11331400421315493730.webp&#34;
               width=&#34;760&#34;
               height=&#34;526&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;inbound 配置类似，只是 inbound 更简单，domains 匹配&lt;code&gt;*&lt;/code&gt;就可以。&lt;/p&gt;
&lt;p&gt;从上面的例子中可以看到，Istio 和 Envoy 的设计有非常浓重的 HTTP 协议的味道，各种语义都是和 HTTP 直接相关。而当我们进行 TCP 协议的转发时，就需要将请求的协议字段进行映射，映射到 HTTP 的相应语义。&lt;/p&gt;
&lt;p&gt;比如，最基本的 Destination，原始语义是请求的目的地，在前面的文章中我们指出过这是请求转发最关键的字段。在 HTTP 协议中，通常是通过 Host header 和 Path 表示，对于 REST 而言还有重要的 Method 字段。&lt;/p&gt;
&lt;p&gt;下面的格式是其他各种协议对这个 Destination 原始语义的实际实现方式：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;协议&lt;/th&gt;
          &lt;th&gt;实现&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;原始语义&lt;/td&gt;
          &lt;td&gt;请求的目的地 (Destination)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HTTP/1.1&lt;/td&gt;
          &lt;td&gt;Host header，Method，Path&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HTTP/2&lt;/td&gt;
          &lt;td&gt;Header 帧中的伪 header &lt;code&gt;:authority&lt;/code&gt;，&lt;code&gt;:path&lt;/code&gt;和&lt;code&gt;:method&lt;/code&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Bolt 协议&lt;/td&gt;
          &lt;td&gt;header map 中 key 为”service”的字段&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HSF 协议&lt;/td&gt;
          &lt;td&gt;协议头中的服务接口名和服务方法名&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Dubbo 协议&lt;/td&gt;
          &lt;td&gt;data 字段（payload）中的 path/method&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这些通讯协议在下发规则和进行请求匹配时，就需要进行协调：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;定义好 Virtual Host 配置中的 domains 字段和 route 中的 match 用到的字段在当前通讯协议中的实际语义&lt;/li&gt;
&lt;li&gt;在 protocol encoder 中读取请求的协议字段，和上面的字段对应&lt;/li&gt;
&lt;li&gt;然后进行请求路由规则匹配（参照 HTTP/1.1 中的 domain 和 route match 的匹配）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而这些都是需要以代码的方式进行实现，以满足新通讯协议的要求。正规的做法，是每次新增一个通讯协议就将上述的工作内容重复一遍。这会直接导致大量的高度类似的重复代码。&lt;/p&gt;
&lt;h2 id=&#34;x-protocol-的实现&#34;&gt;x-protocol 的实现&lt;/h2&gt;
&lt;p&gt;在上述需要在协议扩展时修改的四个内容中，有一块是特别的：生成 Virtual Host 配置的工作是在 Pilot 中实现的，而其他三个是在 Sidecar（Envoy 或 MOSN）中。考虑到 protocol encoder 和 protocol decoder 的工作是必不可少的，必然会修改 Sidecar 来增加实现代码，因此简化开发的第一个想法就是：能不能做到不修改 Pilot？&lt;/p&gt;
&lt;p&gt;基本思路就是固定好原始语义，避免每个通讯协议都映射一遍。从前面我们列出来的各个协议的映射情况看，对于 RPC 协议而言，一般目的地信息都是服务名 (有些是接口名)+方法名居多，因此可以考虑直接将服务名和方法名固定下来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RPC 协议在 Virtual Host 配置中就固定为服务名对应 domains 字段，方法名对应 route 中的 match 用到的字段，这样只要修改一次然后各个 RPC 协议公用此配置，以后就不用再重复修改 Pilot。&lt;/li&gt;
&lt;li&gt;protocol encoder 在解析通讯协议完成之后，就直接将协议中对应服务名和方法名的字段提取出来，后面的匹配处理过程就可以公用一套通用实现，这样路由匹配这块也可以不用在重复开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，在 x-protocol 中，如果需要引入一个新的通讯协议，需要的工作内容只有必不可少的 protocol encoder 和 protocol decoder，和实现以下几个接口：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;img&#34; srcset=&#34;
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hu4203426381438260097.webp 400w,
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hu3048577906709066114.webp 760w,
               /blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hu5573556725073365288.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/xprotocol-interfaces_hu4203426381438260097.webp&#34;
               width=&#34;503&#34;
               height=&#34;517&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;X-protocol 在支持新通讯协议上的做法并无新奇之处，只是由于需求特殊有众多通讯协议需要支持，在开发时发现大量重复工作，因此我们选择了一条可以让后面更舒服一点的道路。&lt;/p&gt;
&lt;p&gt;目前这个方案在 SOFAMesh 中采用，我们将进一步检验实际效果，也会和合作的小伙伴时验证，看他们在自行扩展新协议时是否足够理想。这个方案理论上应该可以同样适用于 Istio、Envoy 体系，随着社区对 Istio 的接受程度的提高，在 Istio 上支持各种 TCP 通讯协议的需求会越来越多，有理由相信 Istio 后续可能也会出现类似的方案。毕竟，每次都改一大堆类似的东西，不是一个好做法。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（2）——快速解码转发</title>
      <link>https://cloudnative.to/blog/x-protocol-rapid-decode-forward/</link>
      <pubDate>Wed, 10 Oct 2018 11:45:26 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-rapid-decode-forward/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是 SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（1）——DNS 通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（3）——TCP 协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在 Istio 和 Envoy 中，对通讯协议的支持，主要体现在 HTTP/1.1 和 HTTP/2 上，而我们 SOFAMesh，则需要支持以下几个 RPC 协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOFARPC：这是蚂蚁金服大量使用的 RPC 协议（已开源）&lt;/li&gt;
&lt;li&gt;HSF RPC：这是阿里集团内部大量使用的 RPC 协议（未开源）&lt;/li&gt;
&lt;li&gt;Dubbo RPC: 这是社区广泛使用的 RPC 协议（已开源）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;更适合的平衡点性能和功能&#34;&gt;更适合的平衡点：性能和功能&lt;/h3&gt;
&lt;p&gt;对于服务间通讯解决方案，性能永远是一个值得关注的点。而 SOFAMesh 在项目启动时就明确要求在性能上要有更高的追求，为此，我们不得不在 Istio 标准实现之外寻求可以获取更高性能的方式，比如支持各种 RPC 协议。&lt;/p&gt;
&lt;p&gt;期间有两个发现：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Istio在处理所有的请求转发如REST/gRPC时，会解码整个请求的header信息，拿到各种数据，提取为Attribute，然后以此为基础，提供各种丰富的功能，典型如Content Based Routing。&lt;/li&gt;
&lt;li&gt;而在测试中，我们发现：解码请求协议的 header 部分，对 CPU 消耗较大，直接影响性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，我们有了一个很简单的想法：是不是可以在转发时，不开启部分功能，以此换取转发过程中的更少更快的解码消耗？毕竟，不是每个服务都需要用到 Content Based Routing 这样的高级特性，大部分服务只使用 Version Based Routing，尤其是使用 RPC 通讯协议的服务，没有 HTTP 那么表现力丰富的 header，对 Content Based Routing 的需求要低很多。&lt;/p&gt;
&lt;p&gt;此外，对于部分对性能有极高追求的服务，不开启高级特性而换取更高的性能，也是一种满足性能要求的折中方案。考虑到系统中总存在个别服务对性能非常敏感，我们觉得 Service Mesh 提供一种性能可以接近直连的方案会是一个有益的补充。为了满足这些特例而不至于因此整体否决 Service Mesh 方案，我们需要在 Service Mesh 的大框架下提供一个折中方案。&lt;/p&gt;
&lt;h2 id=&#34;请求转发&#34;&gt;请求转发&lt;/h2&gt;
&lt;p&gt;在我们进一步深入前，我们先来探讨一下实现请求转发的技术细节。&lt;/p&gt;
&lt;p&gt;有一个关键问题：当 Envoy/SOFA MOSN 这样的代理程序，接收到来自客户端的 TCP 请求时，需要获得哪些信息，才可以正确的转发请求到上游的服务器端？&lt;/p&gt;
&lt;h3 id=&#34;最关键的信息destination&#34;&gt;最关键的信息：destination&lt;/h3&gt;
&lt;p&gt;首先，毫无疑问的，必须拿到 destination/目的地，也就是客户端请求必须通过某种方式明确的告之代理该请求的 destination，这样代理程序才能根据这个 destionation 去找到正确的目标服务器，然后才有后续的连接目标服务器和转发请求等操作。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu16595229090798416673.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu1937889132407382780.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu7331189859521832309.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zu0jen9j30vs0d475q_hu16595229090798416673.webp&#34;
               width=&#34;760&#34;
               height=&#34;314&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Destination 信息的表述形式可能有：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. IP 地址&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可能是服务器端实例实际工作的 IP 地址和端口，也可能是某种转发机制，如 Nginx/HAProxy 等反向代理的地址或者 Kubernetes 中的 ClusterIP。&lt;/p&gt;
&lt;p&gt;举例：“192.168.1.1:8080”是实际 IP 地址和端口，“10.2.0.100:80”是 ngxin 反向代理地址，“172.168.1.105:80”是 Kubernetes 的 ClusterIP。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 目标服务的标识符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可用于名字查找，如服务名，可能带有各种前缀后缀。然后通过名字查找/服务发现等方式，得到地址列表（通常是 IP 地址 + 端口形式）。&lt;/p&gt;
&lt;p&gt;举例：“userservice”是标准服务名， “com.alipay/userservice”是加了域名前缀的服务名， “service.default.svc.cluster.local”是 k8s 下完整的全限定名。&lt;/p&gt;
&lt;p&gt;Destination 信息在请求报文中的携带方式有：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 通过通讯协议传递&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是最常见的形式，标准做法是通过 header 头，典型如 HTTP/1.1 下一般使用 host header，举例如“Host: userservice”。HTTP/2 下，类似的使用“:authority”header。&lt;/p&gt;
&lt;p&gt;对于非 HTTP 协议，通常也会有类似的设计，通过协议中某些字段来承载目标地址信息，只是不同协议中这个字段的名字各有不同。如 SOFARPC，HSF 等。&lt;/p&gt;
&lt;p&gt;有些通讯协议，可能会将这个信息存放在 payload 中，比如后面我们会介绍到的 dubbo 协议，导致需要反序列化 payload 之后才能拿到这个重要信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 通过 TCP 协议传递&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一种非常特殊的方式，通过在 TCP option 传递，上一节中我们介绍 Istio DNS 寻址时已经详细介绍过了。&lt;/p&gt;
&lt;h3 id=&#34;tcp-拆包&#34;&gt;TCP 拆包&lt;/h3&gt;
&lt;p&gt;如何从请求的通讯协议中获取 destination？这涉及到具体通讯协议的解码，其中第一个要解决的问题就是如何在连续的 TCP 报文中将每个请求内容拆分开，这里就涉及到经典的 TCP 沾包、拆包问题。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_hu7111372456793468023.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_hu2136221526930679236.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_hu12841472227534542920.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuc1molj30vw0ayaax_hu7111372456793468023.webp&#34;
               width=&#34;760&#34;
               height=&#34;261&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;转发请求时，由于涉及到负载均衡，我们需要将请求发送给多个服务器端实例。因此，有一个非常明确的要求：就是必须以单个请求为单位进行转发。即单个请求必须完整的转发给某台服务器端实例，负载均衡需要以请求为单位，不能将一个请求的多个报文包分别转发到不同的服务器端实例。所以，拆包是请求转发的必备基础。&lt;/p&gt;
&lt;p&gt;由于篇幅和主题限制，我们不在这里展开 TCP 沾包、拆包的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的解决方案。&lt;/p&gt;
&lt;h3 id=&#34;多路复用的关键参数requestid&#34;&gt;多路复用的关键参数：RequestId&lt;/h3&gt;
&lt;p&gt;RequestId 用来关联 request 和对应的 response，请求报文中携带一个唯一的 id 值，应答报文中原值返回，以便在处理 response 时可以找到对应的 request。当然在不同协议中，这个参数的名字可能不同（如 streamid 等）。&lt;/p&gt;
&lt;p&gt;严格说，RequestId 对于请求转发是可选的，也有很多通讯协议不提供支持，比如经典的 HTTP1.1 就没有支持。但是如果有这个参数，则可以实现多路复用，从而可以大幅度提高 TCP 连接的使用效率，避免出现大量连接。稍微新一点的通讯协议，基本都会原生支持这个特性，比如 SOFARPC、Dubbo、HSF，还有 HTTP/2 就直接內建了多路复用的支持。&lt;/p&gt;
&lt;p&gt;HTTP/1.1不支持多路复用（http1.1有提过支持幂等方法的pipeline机制但是未能普及），用的是经典的ping-pong模式：在请求发送之后，必须独占当前连接，等待服务器端给出这个请求的应答，然后才能释放连接。因此HTTP/1.1下，并发多个请求就必须采用多连接，为了提升性能通常会使用长连接+连接池的设计。而如果有了requestid和多路复用的支持，客户端和Mesh之间理论上就可以只用一条连接（实践中可能会选择建立多条）来支持并发请求：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu2986955239755459081.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu4890038539582506680.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu9215134684468927202.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zujxeh7j313x0dwtaz_hu2986955239755459081.webp&#34;
               width=&#34;760&#34;
               height=&#34;264&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;而 Mesh 与服务器（也可能是对端的 Mesh）之间，也同样可以受益于多路复用技术，来自不同客户端而去往同一个目的地的请求可以混杂在同一条连接上发送。通过 RequestId 的关联，Mesh 可以正确将 reponse 发送到请求来自的客户端。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu10516678681157447745.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu3997528419108751635.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu6184136219352741526.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zuxvz4lj310r0dzwgj_hu10516678681157447745.webp&#34;
               width=&#34;760&#34;
               height=&#34;289&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;由于篇幅和主题限制，我们不在这里展开多路复用的原理。后面针对每个具体的通讯协议进行分析时再具体看各个协议的支持情况。&lt;/p&gt;
&lt;h3 id=&#34;请求转发参数总结&#34;&gt;请求转发参数总结&lt;/h3&gt;
&lt;p&gt;上面的分析中，我们可以总结到，对于 Sidecar，要正确转发请求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;必须获取到 destination 信息，得到转发的目的地，才能进行服务发现类的寻址&lt;/li&gt;
&lt;li&gt;必须要能够正确的拆包，然后以请求为单位进行转发，这是负载均衡的基础&lt;/li&gt;
&lt;li&gt;可选的 RequestId，这是开启多路复用的基础&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，这里我们的第一个优化思路就出来了：尽量只解码获取这三个信息，满足转发的基本要求。其他信息如果有性能开销则跳过解码，所谓“快速解码转发”。基本原理就是牺牲信息完整性追求性能最大化。&lt;/p&gt;
&lt;p&gt;而结合上一节中我们引入的 DNS 通用寻址方案，我们是可以从请求的 TCP options 中得到 ClusterIP，从而实现寻址。这个方式可以实现不解码请求报文，尤其是 header 部分解码 destination 信息开销大时。这是我们的第二个优化思路：跳过解码 destination 信息，直接通过 ClusterIP 进行寻址。&lt;/p&gt;
&lt;p&gt;具体的实现则需要结合特定通讯协议的实际情况进行。&lt;/p&gt;
&lt;h2 id=&#34;主流通讯协议&#34;&gt;主流通讯协议&lt;/h2&gt;
&lt;p&gt;现在我们开始，以 Proxy、Sidecar、Service Mesh 的角度来看看目前主流的通讯协议和我们前面列举的需要在 SOFAMesh 中支持的几个协议。&lt;/p&gt;
&lt;h3 id=&#34;sofarpcbolt协议&#34;&gt;SOFARPC/bolt协议&lt;/h3&gt;
&lt;p&gt;SOFARPC 是一款基于 Java 实现的 RPC 服务框架，详细资料可以查阅 官方文档。SOFARPC 支持 bolt，rest，dubbo 协议进行通信。REST、dubbo 后面单独展开，这里我们关注 bolt 协议。&lt;/p&gt;
&lt;p&gt;bolt 是蚂蚁金服集团开放的基于 Netty 开发的网络通信框架，其协议格式是变长，即协议头+payload。具体格式定义如下，以 request 为例（response 类似）：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu11316910219480969855.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu11030177307992353777.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu2422683456690569084.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zv3sqhij312j0833zq_hu11316910219480969855.webp&#34;
               width=&#34;760&#34;
               height=&#34;160&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们只关注和请求转发直接相关的字段：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TCP 拆包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;bolt 协议是定长 + 变长的复合结构，前面 22 个字节长度固定，每个字节和协议字段的对应如图所示。其中 classLen、headerLen 和 contentLen 三个字段指出后面三个变长字段 className、header、content 的实际长度。和通常的变长方案相比只是变长字段有三个。拆包时思路简单明了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先读取前 22 个字节，解出各个协议字段的实际值，包括 classLen，headerLen 和 contentLen&lt;/li&gt;
&lt;li&gt;按照 classLen、headerLen 和 contentLen 的大小，继续读取 className、header、content&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Destination&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bolt 协议中的 header 字段是一个 map，其中有一个 key 为“service”的字段，传递的是接口名/服务名。读取稍微麻烦一点点，需要先解码整个 header 字段，这里对性能有影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RequestId&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Blot 协议固定字段中的&lt;code&gt;requestID&lt;/code&gt;字段，可以直接读取。&lt;/p&gt;
&lt;p&gt;SOFARPC 中的 bolt 协议，设计的比较符合请求转发的需要，TCP 拆包，读取 RequestID，都没有性能问题。只是 Destination 的获取需要解码整个 header，性能开销稍大。&lt;/p&gt;
&lt;p&gt;总结：适合配合 DNS 通用解码方案，跳过对整个 header 部分的解码，从而提升性能。当然由于这个 header 本身也不算大，优化的空间有限，具体提升需要等对比测试的结果出来。&lt;/p&gt;
&lt;h3 id=&#34;hsf-协议&#34;&gt;HSF 协议&lt;/h3&gt;
&lt;p&gt;HSF 协议是经过精心设计工作在 4 层的私有协议，由于该协议没有开源，因此不便直接暴露具体格式和字段详细定义。&lt;/p&gt;
&lt;p&gt;不过基本的设计和 bolt 非常类似：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用变长格式，即协议头+payload&lt;/li&gt;
&lt;li&gt;在协议头中可以直接拿到服务接口名和服务方法名作为 Destination&lt;/li&gt;
&lt;li&gt;有 RequestID 字段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基本和 bolt 一致，考虑到 Destination 可以直接读取，比 bolt 还要方便一些，HSF 协议可以说是对请求转发最完美的协议。&lt;/p&gt;
&lt;p&gt;总结：目前的实现方案也只解码了这三个关键字段，速度足够快，不需要继续优化。&lt;/p&gt;
&lt;h3 id=&#34;dubbo-协议&#34;&gt;Dubbo 协议&lt;/h3&gt;
&lt;p&gt;Dubbo 协议也是类似的协议头+payload 的变长结构，其协议格式如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu2177621619828147734.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu14623112270670110204.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu3993479085226785374.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvfi4g9j30oh03gmxj_hu2177621619828147734.webp&#34;
               width=&#34;760&#34;
               height=&#34;107&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;其中 long 类型的&lt;code&gt;id&lt;/code&gt;字段用来把请求 request 和返回的 response 对应上，即我们所说的&lt;code&gt;RequestId&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这样 TCP 拆包和多路复用都轻松实现，稍微麻烦一点的是：Destination 在哪里？Dubbo 在这里的设计有点不够理想，在协议头中没有字段可以直接读取到 Destination，需要去读取 data 字段，也就是 payload，里面的 path 字段通常用来保存服务名或者接口名。method 字段用来表示方法名。&lt;/p&gt;
&lt;p&gt;从设计上看，path 字段和 method 字段被存放在 payload 中有些美中不足。庆幸的是，读取这两个字段的时候不需要完整的解开整个 payload，好险，不然，那性能会没法接受的。&lt;/p&gt;
&lt;p&gt;以 hession2 为例，data 字段的组合是：dubbo version + path + interface version + method + ParameterTypes + Arguments + Attachments。每个字段都是一个 byte 的长度 + 字段值的 UTF bytes。因此读取时并不复杂，速度也足够快。&lt;/p&gt;
&lt;p&gt;基本和 HSF 一致，就是 Destination 的读取稍微麻烦一点，放在 payload 中的设计让人吓了一跳，好在有惊无险。整体说还是很适合转发的。&lt;/p&gt;
&lt;p&gt;总结：同 HSF，不需要继续优化。&lt;/p&gt;
&lt;h3 id=&#34;http11&#34;&gt;HTTP/1.1&lt;/h3&gt;
&lt;p&gt;HTTP/1.1的格式应该大家都熟悉，而在这里，不得不指出，HTTP/1.1协议对请求转发是非常不友好的（甚至可以说是恶劣！）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HTTP 请求在拆包时，需要先按照 HTTP header 的格式，一行一行读取，直到出现空行表示 header 结束&lt;/li&gt;
&lt;li&gt;然后必须将整个 header 的内容全部解析出来，才能取出&lt;code&gt;Content-Length header&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;Content-Length&lt;/code&gt; 值，才能完成对 body 内容的读取，实现正确拆包&lt;/li&gt;
&lt;li&gt;如果是 chunked 方式，则更复杂一些&lt;/li&gt;
&lt;li&gt;Destination 通常从&lt;code&gt;Host&lt;/code&gt; header 中获取&lt;/li&gt;
&lt;li&gt;没有 RequestId，完全无法实现多路复用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这意味着，为了完成最基本的 TCP 拆包，必须完整的解析全部的 HTTP header 信息，没有任何可以优化的空间。对比上面几个 RPC 协议，轻松自如的快速获取几个关键信息，HTTP 无疑要重很多。这也造成了在 ServiceMesh 下，HTTP/1.1 和 REST 协议的性能总是和其他 RPC 方案存在巨大差异。&lt;/p&gt;
&lt;p&gt;对于注定要解码整个 header 部分，完全没有优化空间可言的 HTTP/1.1 协议来说，Content Based Routing 的解码开销是必须付出的，无论是否使用 Content Based Routing。因此，快速解码的构想，对 HTTP/1.1 无效。&lt;/p&gt;
&lt;p&gt;总结：受 HTTP/1.1 协议格式限制，上述两个优化思路都无法操作。&lt;/p&gt;
&lt;h3 id=&#34;http2和grpc&#34;&gt;HTTP/2和gRPC&lt;/h3&gt;
&lt;p&gt;作为HTTP/1.1的接班人，HTTP/2则表现的要好很多。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：当然 HTTP/2 的协议格式复杂多了，由于篇幅和主题的限制，这里不详细介绍 HTTP/2 的格式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先HTTP/2是以帧的方式组织报文的，所有的帧都是变长，固定的9个字节+可变的payload，Length字段指定payload的大小：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu13677856098877281023.webp 400w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu3474016938300522598.webp 760w,
               /blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu10402703608312404714.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/006tNbRwly1fw2zvsjz65j30jg0650tg_hu13677856098877281023.webp&#34;
               width=&#34;700&#34;
               height=&#34;221&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;HTTP2 的请求和应答，也被称为 Message，是由多个帧构成，在去除控制帧之外，Message 通常由 Header 帧开始，后面接 CONTINUATION 帧和 Data 帧（也可能没有，如 GET 请求）。每个帧都可以通过头部的 Flags 字段来设置 END_STREAM 标志，表示请求或者应答的结束。即 TCP 拆包的问题在 HTTP/2 下是有非常标准而统一的方式完成，完全和 HTTP/2 上承载的协议无关。&lt;/p&gt;
&lt;p&gt;HTTP/2通过Stream內建多路复用，这里的&lt;code&gt;Stream Identifier&lt;/code&gt; 扮演了类似前面的&lt;code&gt;RequestId&lt;/code&gt;的角色。&lt;/p&gt;
&lt;p&gt;而 Destination 信息则通过 Header 帧中的伪 header &lt;code&gt;:authority&lt;/code&gt; 来传递，类似 HTTP/1.1 中的&lt;code&gt;Host&lt;/code&gt; header。不过 HTTP/2 下 header 会进行压缩，读取时稍微复杂一点，也存在需要解压缩整个 header 帧的性能开销。考虑到拆包和获取 RequestId 都不需要解包（只需读取协议头，即 HTTP/2 帧的固定字段），速度足够快，因此存在很大的优化空间：不解码 header 帧，直接通过 DNS 通用寻址方案，这样性能开销大为减少，有望获得极高的转发速度。&lt;/p&gt;
&lt;p&gt;总结：HTTP/2 的帧设计，在请求转发时表现的非常友好。唯独 Destination 信息放在 header 中，会造成必须解码 header 帧。好在 DNS 通用寻址方案可以弥补，实现快速解码和转发。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh-时代的-rpc-理想方案&#34;&gt;Service Mesh 时代的 RPC 理想方案&lt;/h2&gt;
&lt;p&gt;在文章的最后，我们总结并探讨一下，对于 Service Mesh 而言，什么样的 RPC 方案是最理想的？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;必须可以方便做 TCP 拆包，最好在协议头中就简单搞定，标准方式如固定协议头+length 字段 + 可变 payload。HSF 协议、bolt 协议和 dubbo 协议表现完美，HTTP/2 采用帧的方式，配合 END_STREAM 标志，方式独特但有效。HTTP/1.1 则是反面典型。&lt;/li&gt;
&lt;li&gt;必须可以方便的获取 destination 字段，同样最好在协议头中就简单搞定。HSF 协议表现完美，dubbo 协议藏在 payload 中但终究还是可以快速解码有惊无险的过关，bolt 协议和 HTTP/2 协议就很遗憾必须解码 header 才能拿到，好在 DNS 通用寻址方案可以弥补，但终究丢失了服务名和方法名信息。HTTP/1.1 依然是反面典型。&lt;/li&gt;
&lt;li&gt;最好有 RequestId 字段，同样最好在协议头中就简单搞定。这方面 HSF 协议、dubbo 协议、bolt 协议表现完美，HTTP/2 协议更是直接內建支持。HTTP/1.1 继续反面典型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，仅以方便用最佳性能进行转发，对 Service Mesh、sidecar 友好而言，最理想的 RPC 方案是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;传统的变长协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;固定协议头+length 字段 + 可变 payload，然后在固定协议头中直接提供 RequestId 和 destination。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于帧的协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以HTTP/2为基础，除了请求结束的标志位和RequestId外，还需要通过帧的固定字段来提供destination信息。&lt;/p&gt;
&lt;p&gt;或许，在未来，在 Service Mesh 普及之后，对 Service Mesh 友好成为 RPC 协议的特别优化方向，我们会看到表现完美更适合 Service Mesh 时代的新型 RPC 方案。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（1）——DNS 通用寻址方案</title>
      <link>https://cloudnative.to/blog/x-protocol-common-address-solution/</link>
      <pubDate>Mon, 08 Oct 2018 14:58:03 +0800</pubDate>
      <guid>https://cloudnative.to/blog/x-protocol-common-address-solution/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文是 SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列文章之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（1）——DNS 通用寻址方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-rapid-decode-forward/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（2）——快速解码转发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to/blog/x-protocol-tcp-protocol-extension/&#34;&gt;SOFAMesh 中的多协议通用解决方案 x-protocol 介绍系列（3）——TCP 协议扩展&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在 2018 年上半年，蚂蚁金服决定基于 Istio 订制自己的 ServiceMesh 解决方案，在 6 月底对外公布了 SOFAMesh，详情请见之前的文章：&lt;a href=&#34;https://skyao.io/publication/201806-service-mesh-explore/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;大规模微服务架构下的 Service Mesh 探索之路&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;在 SOFAMesh 的开发过程中，针对遇到的实际问题，我们给出了一套名为 x-protocol 的解决方案，定位是云原生、高性能、低侵入性的通用 Service Mesh 落地方案，依托 Kubernetes 基座，利用其原生的服务注册和服务发现机制，支持各种私有 RPC 协议低成本、易扩展的接入，快速享受 Service Mesh 所带来的红利。&lt;/p&gt;
&lt;p&gt;具体解决的问题包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多通讯协议支持问题，减少开发工作量，简单快捷的接入新协议&lt;/li&gt;
&lt;li&gt;尽量提升性能，提供更灵活的性能与功能的平衡点选择，满足特定高性能场景&lt;/li&gt;
&lt;li&gt;兼容现有 SOA 体系，提供通过接口进行访问的方式，实现不修改业务代码也能顺利接入 Service Mesh&lt;/li&gt;
&lt;li&gt;支持单进程多服务的传统 SOA 程序，可以在微服务改造之前，先受益于 Service Mesh 带来的强大功能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本系列文章中，我们将对此进行详细的讲解，首先是“DNS 通用寻址方案”。&lt;/p&gt;
&lt;h2 id=&#34;背景和需求&#34;&gt;背景和需求&lt;/h2&gt;
&lt;h3 id=&#34;soa-的服务模型&#34;&gt;SOA 的服务模型&lt;/h3&gt;
&lt;p&gt;在 SOFAMesh 计划支持的 RPC 框架中，SOFARPC、HSF、Dubbo 都是一脉相承的 SOA 体系，也都支持经典的 SOA 服务模型，通常称为”单进程多服务”，或者叫做”单进程多接口”。（备注：由于服务一词使用过于频繁，下文都统一称为接口以便区分）&lt;/p&gt;
&lt;p&gt;SOA 标准的服务注册，服务发现和调用流程如下：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-img&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://skyao.io/post/201809-xprotocol-common-address-solution/images/soa-standard-process.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      img
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在单个 SOA 应用进程内，存在多个接口&lt;/li&gt;
&lt;li&gt;服务注册时，以接口为单位进行多次独立的服务注册&lt;/li&gt;
&lt;li&gt;当客户端进行调用时，按照接口进行服务发现，然后发起调用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当我们试图将这些 SOA 架构的应用搬迁到 ServiceMesh 时，就会遇到服务模型的问题：微服务是单服务模型，也就是一个进程里面只承载一个服务。以 Kubernetes 的服务注册为例，在单进程单服务的模型下，服务名和应用名可以视为一体，Kubernetes 的自动服务注册会将应用名作为服务注册的标示。&lt;/p&gt;
&lt;p&gt;这就直接导致了 SOA 模型和微服务模型的不匹配问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOA 以接口为单位做服务注册和服务发现，而微服务下是服务名&lt;/li&gt;
&lt;li&gt;SOA 是”单进程多接口”，而微服务是”单进程单服务”&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;一步接一步的需求&#34;&gt;一步接一步的需求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;先上车后补票&lt;/p&gt;
&lt;p&gt;最理想的做法当然是先进行微服务改造，实现微服务拆分。但是考虑到现有应用数量众多，我们可能更愿意在大规模微服务改造之前，先想办法让这些应用可以运行在 ServiceMesh 下，提前受益于 Service Mesh 带来的强大功能。因此，我们需要找到一个合适的方案，让 ServiceMesh 支持没有做微服务改造依然是”单进程多接口”形式的传统 SOA 应用，所谓”先上车后补票”。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不修改代码&lt;/p&gt;
&lt;p&gt;考虑到原有的 SOA 应用，相互之间错综复杂的调用关系，最好不要修改代码，即保持客户端依然通过接口名来访问的方式。当然，SOA 架构的客户端 SDK 可能要进行改动，将原有的通过接口名进行服务发现再自行负载均衡进行远程调用的方式，精简为标准的 Servicemesh 调用（即走 Sidecar），因此修改 SDK 依赖包和重新打包应用是不可避免。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持带特殊字符的接口名&lt;/p&gt;
&lt;p&gt;Kubernetes 的服务注册，Service 名是不能携带”.“号的。而 SOA 架构下，接口名有时出于管理方便，有可能是加了域名前缀，如”com.alipay.demo.interface-2”。为了实现不修改原有代码，就只能想办法支持这种带特殊字符的接口名。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考-kubernetes-和-istio&#34;&gt;参考 Kubernetes 和 Istio&lt;/h2&gt;
&lt;p&gt;在进一步讨论解决方案之前，我们先来看一下 kubernetes 和 Istio 中的标准请求寻址方式。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：过程稍显复杂，涉及到 Kubernetes/Istio 的一些底层细节。但是了解这个过程对后续的理解非常重要，也可以帮助大家了解 Kubernetes 和 Kubernetes 的工作原理，强烈推荐阅读。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;kubernetes-下的-dns-寻址方式&#34;&gt;Kubernetes 下的 DNS 寻址方式&lt;/h3&gt;
&lt;p&gt;在 Kubernetes 下，如图所示，假定我们部署了一个名为 userservice 的应用，有三个实例，分别在三个 pod 中。则应用部署之后，Kubernetes 会为这个应用分配 ClusterIP 和域名，并在 DNS 中生成一条 DNS 记录，将域名映射到 ClusterIP：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kubernetes-下的-dns-寻址方式&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kubernetes 下的 DNS 寻址方式&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu5245460484958402320.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu5260408240694602437.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu15606559864490243573.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u1crhhoj30zz0grad5_hu5245460484958402320.webp&#34;
               width=&#34;760&#34;
               height=&#34;354&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Kubernetes 下的 DNS 寻址方式
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;当部署在 Kubernetes 下的某个充当客户端的应用发起请求时，如图中的 HTTP GET 请求，目标 URL 地址为“&lt;a href=&#34;http://userservice/id/1000221&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://userservice/id/1000221&lt;/a&gt;&amp;quot;。请求的寻址方式和过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先进行域名解析，分别尝试解析”userservice”/“userservie.default.svc.cluster.local”等域名，得到 ClusterIP&lt;/li&gt;
&lt;li&gt;然后客户端发出请求的报文，目标地址为 ClusterIP，源地址为当前客户端所在的 pod IP（简单起见，端口先忽略）&lt;/li&gt;
&lt;li&gt;请求报文随即被 kube-proxy 拦截，kube-proxy 根据 ClusterIP，拿到 ClusterIP 对应的多个实际服务实例所在的 pod ip，取其中一个，修改目标地址为这个 pod IP&lt;/li&gt;
&lt;li&gt;请求报文最终就被发送到服务实例所在的 pod IP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应答回来的方式类似，userservice 发出的应答报文会被 kube-proxy 拦截并修改为发送到客户端所在的 pod IP。&lt;/p&gt;
&lt;p&gt;我们详细看一下请求和应答全称的四个请求包的具体内容（简单起见继续忽略端口）：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kubernetes-dns-寻址&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kubernetes DNS 寻址&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu5731002030198952502.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu13676932617114857849.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu17363668050287708838.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u1t6ucmj31an0hs79k_hu5731002030198952502.webp&#34;
               width=&#34;760&#34;
               height=&#34;290&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Kubernetes DNS 寻址
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;重点关注请求和应答报文的源地址和目标地址：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端发出的请求，为”客户端到 ClusterIP”&lt;/li&gt;
&lt;li&gt;kube-proxy 拦截到请求后，将请求修改为”客户端到服务器端”&lt;/li&gt;
&lt;li&gt;服务器端收到请求时，表现为”客户端到服务器端”，ClusterIP 被 kube-proxy 屏蔽&lt;/li&gt;
&lt;li&gt;服务器端发送应答，因为收到的请求看似来自客户端，因此应答报文为”服务器端到客户端”&lt;/li&gt;
&lt;li&gt;应答报文被 kube-proxy 拦截，将应答修改为”ClusterIP 到服务器端”&lt;/li&gt;
&lt;li&gt;客户端收到应答，表现为”ClusterIP 到服务器端”，服务器端 IP 被 kube-proxy 屏蔽&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;kube-proxy 在客户端和服务器端之间拦截并修改请求和应答的报文，联通两者，但各自屏蔽了一些信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在客户端看来它是在和 ClusterIP 交互，userservice 的具体服务器端实例对客户端是无感知的&lt;/li&gt;
&lt;li&gt;在服务器端看来，客户端是直接在和它交互，ClusterIP 的存在对服务器端是无感知的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更深入一步，看 kube-proxy 在两个拦截和修改报文中的逻辑处理关系，即 kube-proxy 是如何在收到应答时正确的找回原有的 ClusterIP：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kube-proxy-与-clusterip&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;kube-proxy 与 ClusterIP&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu2029006950029865122.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu4352448221679612734.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu14046169307936967205.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u2dtdpuj317q0fhtcw_hu2029006950029865122.webp&#34;
               width=&#34;760&#34;
               height=&#34;269&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      kube-proxy 与 ClusterIP
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在拦截并修改请求报文之后，kube-proxy 会保存报文修改的 5 元组对应关系（5 元组指源 IP 地址，源端口，协议，目的地 IP 地址，目的地端口）&lt;/li&gt;
&lt;li&gt;在收到应答报文后，根据应答报文中的 5 元组，在保存的 5 元组对应关系中，找到对应信息，得到原有的 ClusterIP 和端口，然后修改应答报文&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总结，通过上述 Kubernetes 下的寻址方式，客户端只需发送带简单寻址信息的请求（如“&lt;a href=&#34;http://userservice/id/1000221%22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://userservice/id/1000221&amp;quot;&lt;/a&gt; 中的”userservice” ），就可以寻址到正确的服务器端。这期间有两个关注点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过 DNS，建立了域名和 ClusterIP 的关系。&lt;/p&gt;
&lt;p&gt;对于客户端，这是它能看到的内容，非常的简单，域名、DNS 是非常容易使用的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而通过 kube-proxy 的拦截和转发，又打通了 ClusterIP 和服务器端实际的 Pod IP&lt;/p&gt;
&lt;p&gt;对于客户端，这些是看不到的内容，不管有多复杂，都是 Kubernetes 在底层完成，对客户端，或者说使用者透明。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以客户端的视角看来，这个 DNS 寻址方式非常的简单直白：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-kube-proxy-与-dns&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;kube-proxy 与 DNS&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu1492205272194606524.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu13137042730641756976.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu14768077507583255774.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u2vhim9j319d0c8goz_hu1492205272194606524.webp&#34;
               width=&#34;760&#34;
               height=&#34;204&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      kube-proxy 与 DNS
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;istio-的-dns-寻址方式&#34;&gt;Istio 的 DNS 寻址方式&lt;/h2&gt;
&lt;p&gt;Istio 的请求寻址方式和普通 kubernetes 非常相似，原理相同，只是 kube-proxy 被 sidecar 取代，然后 sidecar 的部署方式是在 pod 内部署，而且客户端和服务器端各有一个 sidecar。其他基本一致，除了图中红色文本的部分：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio-的-dns-寻址方式&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio 的 DNS 寻址方式&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hu9063441160744045683.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hu5201133850897809455.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hu18397010341504573636.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u3qux0gj31bg0ijgrw_hu9063441160744045683.webp&#34;
               width=&#34;760&#34;
               height=&#34;297&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio 的 DNS 寻址方式
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;iptables 在劫持流量时，除了将请求转发到 localhost 的 Sidecar 处外，还额外的在请求报文的 TCP options 中将 ClusterIP 保存为 original dest。&lt;/li&gt;
&lt;li&gt;在 Sidecar（Istio 默认是 Envoy）中，从请求报文 TCP options 的 original dest 处获取 ClusterIP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过 TCP options 的 original dest，iptables 就实现了在劫持流量到 Sidecar 的过程中，额外传递了 ClusterIP 这个重要参数。Istio 为什么要如此费力的传递这个 ClusterIP 呢？&lt;/p&gt;
&lt;p&gt;看下图就知道了，这是一个 Virtual Host 的示例，Istio 通过 Pilot 将这个规则发送给 Sidecar/Envoy，依靠这个信息来匹配路由请求找到处理请求的 cluster：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio-中的-pilot-注册信息&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio 中的 Pilot 注册信息&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu17785581867930629578.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu1588201009244461265.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu17785845907660687928.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u495625j30rd0ldgot_hu17785581867930629578.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio 中的 Pilot 注册信息
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;domains 中，除了列出域名外，还有一个特殊的 IP 地址，这个就是 Kubernetes 服务的 ClusterIP！因此，Sidecar 可以通过前面传递过来的 ClusterIP 在这里进行路由匹配（当然也可以从报文中获取 destination 然后通过域名匹配）。&lt;/p&gt;
&lt;p&gt;总结，Istio 延续了 Kubernetes 的寻址方式，客户端同样只需发送带简单寻址信息的请求，就可以寻址到正确的服务器端。这期间同样有两个关注点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过 DNS，建立了域名和 ClusterIP 的关系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过 ClusterIP 和 Pilot 下发给 Virtual Host 的配置，Sidecar 可以完成路由匹配，将 ClusterIP 和目标服务器关联起来&lt;/p&gt;
&lt;p&gt;同样，对于客户端，这些是看不到的内容。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，以客户端的视角看来，Istio 的这个 DNS 寻址方式同样的简单直白！&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-客户端请求&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;客户端请求&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hu2175575208555374296.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hu6748251830230891580.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hu8569468339991494317.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5cxd61j30st03wmxk_hu2175575208555374296.webp&#34;
               width=&#34;760&#34;
               height=&#34;103&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      客户端请求
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;dns-通用寻址方案&#34;&gt;DNS 通用寻址方案&lt;/h2&gt;
&lt;h3 id=&#34;解决问题的思路&#34;&gt;解决问题的思路&lt;/h3&gt;
&lt;p&gt;在详细讲述了 Kubernetes 和 Istio 的 DNS 寻址方案之后，我们继续回到我们的主题，我们要解决的问题：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如何在不修改代码，继续使用接口的情况下，实现在 Service Mesh上运行现有的Dubbo/HSF/SOFA等传统SOA应用？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dns-通用寻址方案&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;DNS 通用寻址方案&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu5245460484958402320.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu5260408240694602437.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu15606559864490243573.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5kyafgj30zz0grad5_hu5245460484958402320.webp&#34;
               width=&#34;760&#34;
               height=&#34;354&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      DNS 通用寻址方案
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这里有一个关键点：Kubernetes 的服务注册是以基于 Service 或者说基于应用 (app name)，而我们的客户端代码是基于接口的。因此，在 Virtual Host 进行路由匹配时，是不能通过域名匹配的。当然，这里理论上还有一个思路，就是将接口注册为 Kubernetes Service。但是，还记得要支持接口特殊字符的需求吗？带点号的接口名，Kubernetes 是不能接受它作为 Service Name 的，直接堵死了将接口名注册到 Kubernetes Service 的道路。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio-中注册的服务名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio 中注册的服务名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu17785581867930629578.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu1588201009244461265.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu17785845907660687928.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u5v7kktj30rd0ldgot_hu17785581867930629578.webp&#34;
               width=&#34;760&#34;
               height=&#34;593&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio 中注册的服务名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这样，我们就只有一条路可以走了：效仿 Istio 的做法，通过 ClusterIP 匹配！&lt;/p&gt;
&lt;p&gt;而要将接口名（如”com.alipay.demo.interface-1”）和 ClusterIP 关联，最简单直接的方式就是&lt;strong&gt;打通 DNS&lt;/strong&gt; ：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-sidecar-注册-dns-名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Sidecar 注册 DNS 名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2244197986115660717.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2545333944335600773.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu4961338099553871936.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u6cxesmj31fn0ffgqm_hu2244197986115660717.webp&#34;
               width=&#34;760&#34;
               height=&#34;227&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Sidecar 注册 DNS 名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;只需要在 DNS 记录中，增加接口到 ClusterIP 的映射，然后就可以完全延续 Istio 的标准做法！其他的步骤，如域名解析到 ClusterIP，iptables 拦截并传递 ClusterIP，sidecar 读取 ClusterIP 并匹配路由，都完全可以重用原有方案。&lt;/p&gt;
&lt;h3 id=&#34;具体实现方案&#34;&gt;具体实现方案&lt;/h3&gt;
&lt;p&gt;实现时，我们选择了使用 CoreDNS 作为 Kubernetes 的 DNS 解决方案，然后通过 Service Controller 操作 CoreDNS 的记录来实现 DNS 解析。&lt;/p&gt;
&lt;p&gt;为了收集到 SOA 应用的接口信息，我们还提供了一个 Register Agent 给 Service Controller 收集信息。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-通过-coredns-注册接口名称&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;通过 CoreDNS 注册接口名称&#34; srcset=&#34;
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu15858468167016016920.webp 400w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu12819776995245023727.webp 760w,
               /blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu4537872358302529612.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/x-protocol-common-address-solution/006tNbRwly1fw0u6rzjygj30lb0dc75f_hu15858468167016016920.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      通过 CoreDNS 注册接口名称
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;详细的实现方案，不在本文中重复讲述，请参阅我们之前的分享文章 &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247484175&amp;amp;idx=1&amp;amp;sn=5cb26b1afe615ac7e06b2ccbee6235b3&amp;amp;chksm=faa0ecd5cdd765c3f285bcb3b23f4f1f3e27f6e99021ad4659480ccc47f9bf25a05107f4fee2&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0828t5isWXmyeWhTeoAoeogw&amp;amp;pass_ticket=DqnjSkiuBZW9Oe68Fjiq%2Bqa6fFCyysQTR7Qgd8%2BX9FfooybAg7NXVAQdLmfG6gRX#rd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOFAMesh 的通用协议扩展&lt;/a&gt; 中的 DNS 寻址方案一节。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;备注：暂时修改 CoreDNS 记录的方式是直接修改 CoreDNS 的底层数据，不够优雅。未来将修改为通过 CoreDNS 的 Dynamic updates API 接口进行，不过 CoreDNS 的这个 API 还在开发中，需要等待完成。详情见&lt;a href=&#34;https://github.com/coredns/coredns/pull/1822&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt; 。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;单进程多接口问题的解决&#34;&gt;单进程多接口问题的解决&lt;/h3&gt;
&lt;p&gt;上面的解决方案，在解决通过接口实现访问的同时，也将”单进程多接口”的问题一起解决了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原 SOA 应用上 Kubernetes 时，可以注册为标准的 Kubernetes Service，获取 ClusterIP。此时使用应用名注册，和接口无关。&lt;/li&gt;
&lt;li&gt;通过操作 CoreDNS，我们将该 SOA 应用的各个接口都添加为 DNS 记录，指向该应用的 ClusterIP&lt;/li&gt;
&lt;li&gt;当客户端代码使用不同的接口名访问时，DNS 解析出来的都是同一个 ClusterIP，后续步骤就和接口名无关了&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;欠缺微服务改造带来的限制&#34;&gt;欠缺微服务改造带来的限制&lt;/h3&gt;
&lt;p&gt;需要特别指出的是，DNS 通用寻址方案虽然可以解决使用接口名访问和支持单进程多接口的问题，但是这种方案只是完成了“寻址”，也就是打通端到端的访问通道。由于应用没有进行微服务改造，部署上是依然一个应用（体现为一个进程，在 Kubernetes 上体现为一个 Service）中包含多个接口，本质上：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务注册依然是以应用名为基础，对应的 Kubernetes service 和 service 上的 label 也是应用级别&lt;/li&gt;
&lt;li&gt;因此提供的服务治理功能，也是以 Kubernetes 的 Service 为基本单位，包括灰度，蓝绿，版本拆分等所有的 Version Based Routing 功能&lt;/li&gt;
&lt;li&gt;这意味着，只能进行&lt;strong&gt;应用级别&lt;/strong&gt;的服务治理，而不能继续细分到&lt;strong&gt;接口级别&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个限制来源于应用没有进行微服务改造，没有按照接口将应用拆分为多个独立的微服务，因此无法得到更小的服务治理粒度。这也就是我们前面说的“先上车后补票”的含义：在微服务改造前，先获得 Service Mesh 的服务治理的绝大部分功能，再慢慢进行微服务改造。&lt;/p&gt;
&lt;h2 id=&#34;dns-通用寻址方案-1&#34;&gt;DNS 通用寻址方案&lt;/h2&gt;
&lt;p&gt;我们将这个方案称为”DNS 通用寻址方案”，是因为这个方案真的非常的通用，体现在以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对使用者来说，通过域名和 DNS 解析的方式来访问，是非常简单直白而易于接受的，同时也是广泛使用的，适用于各种语言、平台、框架&lt;/li&gt;
&lt;li&gt;这个方案延续了 Kubernetes 和 Istio 的做法，保持了一致的方式，对用户提供了相同的体验&lt;/li&gt;
&lt;li&gt;这个寻址方案，不仅仅可以用于 Dubbo、SOFA、HSF 等 RPC 框架往 Service Mesh 的迁移，也可以适用于基于 HTTP/REST 协议的 SOA 应用，甚至最传统的 web 应用（例如 tomcat 下部署多个 war 包）迁移到 Service Mesh&lt;/li&gt;
&lt;li&gt;我们也在考虑在未来的 Serverless 项目中，将 Function 的寻址也统一到这套方案中，而无需要求每个 Function 都进行一次服务注册&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;概括的说，有了这套 DNS 通用寻址方案，不管需要寻址的实体是什么形态，只要它部署在 Service Mesh 上，满足以下条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有正常注册为 Kubernetes Service，分配有 ClusterIP&lt;/li&gt;
&lt;li&gt;为实体（或者更细分的子实体）分配域名或子域名，然后添加到 DNS，解析到 ClusterIP&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么我们的 DNS 通用寻址方案，就可以工作，从而将请求正确的转发到目的地。而在此基础上，Service Mesh 所有的强大功能都可以为这些实体所用，实现我们前面的目标：在不修改代码不做微服务改造的情况下，也能提前受益于 Service Mesh 带来的强大服务治理功能。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dubbo on x-protocol——SOFAMesh 中的 x-protocol 示例演示</title>
      <link>https://cloudnative.to/blog/dubbo-on-x-protocol-in-sofa-mesh/</link>
      <pubDate>Tue, 11 Sep 2018 19:06:22 +0800</pubDate>
      <guid>https://cloudnative.to/blog/dubbo-on-x-protocol-in-sofa-mesh/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文作者：彭泽文，阿里巴巴 UC 事业部高级开发工程师。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-sofamesh-x-protocol-dubbo&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;sofamesh x-protocol dubbo&#34; srcset=&#34;
               /blog/dubbo-on-x-protocol-in-sofa-mesh/0069RVTdgy1fv5t8by8rsj30kk0bkwez_hu13772695293062302726.webp 400w,
               /blog/dubbo-on-x-protocol-in-sofa-mesh/0069RVTdgy1fv5t8by8rsj30kk0bkwez_hu2822249926064381648.webp 760w,
               /blog/dubbo-on-x-protocol-in-sofa-mesh/0069RVTdgy1fv5t8by8rsj30kk0bkwez_hu9744902139409707663.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/dubbo-on-x-protocol-in-sofa-mesh/0069RVTdgy1fv5t8by8rsj30kk0bkwez_hu13772695293062302726.webp&#34;
               width=&#34;740&#34;
               height=&#34;416&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      sofamesh x-protocol dubbo
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;X-protocol 的定位是云原生、高性能、低侵入性的通用 Service Mesh 落地方案，依托 Kubernetes 基座，利用其原生的服务注册和服务发现机制，支持各种私有 RPC 协议低成本、易扩展的接入，快速享受 Service Mesh 所带来的红利。&lt;/p&gt;
&lt;p&gt;本文将以 &lt;a href=&#34;https://dubbo.incubator.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dubbo&lt;/a&gt; 为例，演示 Dubbo on x-protocol 场景下 Service Mesh 路由功能，涵盖 Version route、Weighted route 功能。&lt;/p&gt;
&lt;p&gt;关于 x-protocol 的介绍请参考 &lt;a href=&#34;http://www.servicemesher.com/blog/ant-financial-sofamesh-common-protocol-extension/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;蚂蚁金服开源的 SOFAMesh 的通用协议扩展解析&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;前期准备&#34;&gt;前期准备&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;安装 Minikube，推荐使用 Minikube v0.28 以上来体验，请参考 &lt;a href=&#34;https://github.com/kubernetes/minikube&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/kubernetes/minikube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;安装 kubectl 命令行工具，请参考 &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;安装 VM Driver，推荐安装 Virtual Box、Mac 用户也可以选择 hyperkit&lt;/li&gt;
&lt;li&gt;了解 Istio Traffic Management 相关概念，相关链接：&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://istio.io/zh/docs/tasks/traffic-management/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;部署&#34;&gt;部署&lt;/h2&gt;
&lt;p&gt;先看部署效果图：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-mosn-x-protocol-部署图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MOSN x-protocol 部署图&#34; srcset=&#34;
               /blog/dubbo-on-x-protocol-in-sofa-mesh/1536291419546-2aa160de-69cd-497f-a280-fae20a1f87a3_hu10885486757185231350.webp 400w,
               /blog/dubbo-on-x-protocol-in-sofa-mesh/1536291419546-2aa160de-69cd-497f-a280-fae20a1f87a3_hu15508053632650053798.webp 760w,
               /blog/dubbo-on-x-protocol-in-sofa-mesh/1536291419546-2aa160de-69cd-497f-a280-fae20a1f87a3_hu926973158096425820.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/dubbo-on-x-protocol-in-sofa-mesh/1536291419546-2aa160de-69cd-497f-a280-fae20a1f87a3_hu10885486757185231350.webp&#34;
               width=&#34;760&#34;
               height=&#34;389&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      MOSN x-protocol 部署图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;本示例中 dubbo-consumer 的部署方式采用直连模式，即不走注册中心，完全依托 kubernetes 平台提供的服务注册及服务发现能力。&lt;/p&gt;
&lt;h3 id=&#34;1-安装-kubernetes&#34;&gt;1. 安装 Kubernetes&lt;/h3&gt;
&lt;p&gt;安装 kubectl 命令行工具
推荐使用 Kubernetes 1.10 版本，并使用合适的 VM Driver，推荐使用默认的 VirtualBox。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;minikube start --memory&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8192&lt;/span&gt; --cpus&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; --kubernetes-version&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;v1.10.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --extra-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-cert-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/var/lib/localkube/certs/ca.crt&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --extra-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-key-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/var/lib/localkube/certs/ca.key&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Mac OSX 用户使用的 hyperkit 需要特别指定：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;minikube start --memory&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8192&lt;/span&gt; --cpus&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; --kubernetes-version&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;v1.10.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --extra-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-cert-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/var/lib/localkube/certs/ca.crt&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --extra-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-key-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/var/lib/localkube/certs/ca.key&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --vm-dirver&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;hyperkit
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待 Kubernetes 启动完毕，通过 kubectl 命令检查&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl get pods --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-部署-sofamesh&#34;&gt;2. 部署 SOFAMesh&lt;/h3&gt;
&lt;p&gt;本示例演示从源代码的 master 分支直接安装最新的 SOFAMesh，安装过程使用 Helm 完成。&lt;/p&gt;
&lt;p&gt;从 GitHub 拉取最新代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/alipay/sofa-mesh.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; sofa-mesh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建 SOFAMesh 需要的 CRD：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f install/kubernetes/helm/istio/charts/certmanager/templates/crds.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用 Helm 安装 SOFAMesh：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f install/kubernetes/helm/helm-service-account.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;helm init --service-account tiller
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;helm install install/kubernetes/helm/istio --name istio --namespace istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;安装 istioctl 命令行工具：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用 make 工具安装 istioctl&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make istioctl-install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-创建示例的命名空间&#34;&gt;3. 创建示例的命名空间&lt;/h3&gt;
&lt;p&gt;以下示例都将运行在 e2e-dubbo 命名空间下，如无 e2e-dubbo 命名空间，需先创建该命名空间：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f samples/e2e-dubbo/platform/kube/e2e-dubbo-ns.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;4-注入-mosn&#34;&gt;4. 注入 MOSN&lt;/h3&gt;
&lt;p&gt;部署 dubbo-consumer 和 dubbo-provider，部署前需要先使用 istioctl 进行 sidecar 注入，以下示例采用手动注入方式，也可以通过 istio namespace inject 功能来自动注入。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# mosn sidecar inject and deploy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f samples/e2e-dubbo/platform/kube/dubbo-consumer.yaml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f samples/e2e-dubbo/platform/kube/dubbo-provider-v1.yaml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f samples/e2e-dubbo/platform/kube/dubbo-provider-v2.yaml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-部署示例应用&#34;&gt;5. 部署示例应用&lt;/h3&gt;
&lt;p&gt;部署 dubbo consumer service 及 dubbo provider service。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# http service for dubbo consumer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f samples/e2e-dubbo/platform/kube/dubbo-consumer-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# dubbo provider service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f samples/e2e-dubbo/platform/kube/dubbo-provider-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;检查部署状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#kubectl get pods -n e2e-dubbo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                                     READY     STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;e2e-dubbo-consumer-589d8c465d-cp7cx      2/2       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          13s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;e2e-dubbo-provider-v1-649d7cff94-52gfd   2/2       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          13s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;e2e-dubbo-provider-v2-5f7d5ff648-m6c45   2/2       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          13s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#kubectl get svc -n e2e-dubbo    &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;     AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;e2e-dubbo-consumer   ClusterIP   192.168.1.7     &amp;lt;none&amp;gt;        8080/TCP    10s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;e2e-dubbo-provider   ClusterIP   192.168.1.62    &amp;lt;none&amp;gt;        12345/TCP   10s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e2e-dubbo-consumer 是一个 Dubbo 客户端应用，它暴露了一个 8080 端口的 HTTP 服务，方便我们进行验证，e2e-dubbo-provider 是一个 Dubbo 应用。
当 e2e-dubbo-consumer 通过 12345 端口调用 e2e-dubbo-provider 时，流量会被 IPtable 规则拦截，导流给 SOFAMosn。&lt;/p&gt;
&lt;h2 id=&#34;验证路由能力&#34;&gt;验证路由能力&lt;/h2&gt;
&lt;p&gt;本示例将验证 Version route 和 Weighted route 能力。&lt;/p&gt;
&lt;h3 id=&#34;1-验证-version-route-能力&#34;&gt;1. 验证 Version Route 能力&lt;/h3&gt;
&lt;p&gt;本例将演示控制 dubbo-consumer 的所有请求指向 dubo-provider-v1
配置 DestinationRule:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl create -f samples/e2e-dubbo/platform/kube/dubbo-consumer.destinationrule.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;dubbo-consumer.destinationrule.yaml&lt;/code&gt; 内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DestinationRule&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2 &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;配置 VirtualService：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl create -f samples/e2e-dubbo/platform/kube/dubbo-consumer.version.vs.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;dubbo-consumer.version.vs.yaml&lt;/code&gt; 内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VirtualService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;路由策略已经生效，可以 http 请求 dubbo consumer 来触发 rpc 请求观察效果，由于使用 Minikube 的关系，需要启动一个 Pod 用来测试&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动一个 busybox Pod 并登陆&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl run -i -t busybox --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;yauritux/busybox-curl --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Never
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用 e2e-dubbo-consumer 的域名访问服务&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl e2e-dubbo-consumer.e2e-dubbo.svc.cluster.local:8080/sayHello?name&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;dubbo-mosn
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;清理路由策略：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl delete -f samples/e2e-dubbo/platform/kube/dubbo-consumer.destinationrule.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl delete -f samples/e2e-dubbo/platform/kube/dubbo-consumer.version.vs.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;退出 Minikube shell&lt;/p&gt;
&lt;h3 id=&#34;2-验证-weight-route-能力&#34;&gt;2. 验证 Weight Route 能力&lt;/h3&gt;
&lt;p&gt;本例将演示控制 dubbo-consumer 的请求指向 dubo-provider-v1，dubo-provider-v2。并控制流量分配比例为 v1:20%，v2:80%。&lt;/p&gt;
&lt;p&gt;配置 DestinationRule:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 如果在上一示例中已经创建好了，请跳过这一步&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl create -f samples/e2e-dubbo/platform/kube/dubbo-consumer.destinationrule.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;dubbo-consumer.destinationrule.yaml&lt;/code&gt; 内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DestinationRule&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2 &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;配置 VirtualService：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl create -f samples/e2e-dubbo/platform/kube/dubbo-consumer.weight.vs.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;dubbo-consumer.weight.vs.yaml&lt;/code&gt; 内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VirtualService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;e2e-dubbo-provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;路由策略已经生效，可以 http 请求 dubbo consumer 来触发 rpc 请求观察效果：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动一个 busybox Pod 并登陆&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl run -i -t busybox --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;yauritux/busybox-curl --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Never
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用 e2e-dubbo-consumer 的域名访问服务&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl e2e-dubbo-consumer.e2e-dubbo.svc.cluster.local:8080/sayHello?name&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;dubbo-mosn
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;清理路由策略：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl delete -f samples/e2e-dubbo/platform/kube/dubbo-consumer.destinationrule.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;istioctl delete -f samples/e2e-dubbo/platform/kube/dubbo-consumer.weight.vs.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;更多功能，敬请期待。&lt;/p&gt;
&lt;h2 id=&#34;参考文档&#34;&gt;参考文档&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://preliminary.istio.io/zh/docs/setup/kubernetes/quick-start/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 Kubernetes 中快速开始 - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preliminary.istio.io/zh/docs/setup/kubernetes/sidecar-injection/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;注入 Istio sidecar - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dubbo.incubator.apache.org/en-us/docs/user/quick-start.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dubbo quick start - dubbo.incubator.apache.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
