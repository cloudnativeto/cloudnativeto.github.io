<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM | 云原生社区（中国）</title>
    <link>https://cloudnativecn.com/tag/llm/</link>
      <atom:link href="https://cloudnativecn.com/tag/llm/index.xml" rel="self" type="application/rss+xml" />
    <description>LLM</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Tue, 15 Apr 2025 11:33:31 +0800</lastBuildDate>
    <image>
      <url>https://cloudnativecn.com/media/sharing.png</url>
      <title>LLM</title>
      <link>https://cloudnativecn.com/tag/llm/</link>
    </image>
    
    <item>
      <title>平台工程师的 LLM 入门指南</title>
      <link>https://cloudnativecn.com/blog/a-gentle-introduction-to-llms-for-platform-engineers/</link>
      <pubDate>Tue, 15 Apr 2025 11:33:31 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/a-gentle-introduction-to-llms-for-platform-engineers/</guid>
      <description>&lt;p&gt;技术世界日新月异。如今最火的莫过于 AI。作为平台工程师，我们本身已经身处技术栈的洪流之中：容器、Kubernetes、Prometheus、Istio、ArgoCD、Zipkin、Backstage.io …… 技术名词一个接一个，每一个都复杂、抽象且需要深入理解。现在又来了个 AI，让人头大。大多数平台工程师根本没有时间或精力去琢磨什么是 LLM、大模型，更别说在系统中落地使用。&lt;/p&gt;
&lt;p&gt;但现实是：AI 正悄然渗透进平台工程的世界。我们终将需要理解和掌握它。本文尝试用通俗易懂的方式，帮助平台工程师快速建立起对 LLM（大语言模型）的基础认知，并思考它在云原生领域中的应用场景。&lt;/p&gt;
&lt;h2 id=&#34;1-ai-是智能助手而不是天外来物&#34;&gt;1. AI 是“智能助手”而不是“天外来物”&lt;/h2&gt;
&lt;p&gt;你可能用过 Siri，也可能在酒店网站上与机器人客服打过交道。大多数情况下，它们都让人失望——要么不理解你的问题，要么机械地回复固定答案。它们多数基于传统的机器学习或预设规则，无法真正理解你的意图。&lt;/p&gt;
&lt;p&gt;相比之下，现代的 LLM（如 ChatGPT）已经可以处理极为复杂的语言输入，甚至能根据上下文推理、总结信息，和人类进行近乎自然的对话。&lt;/p&gt;
&lt;p&gt;但问题来了：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对平台工程师来说，LLM 到底是什么？它跟传统 API、控制器、CI/CD 流水线有什么关系？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;别急，我们从一个核心问题讲起——“它能做什么”。&lt;/p&gt;
&lt;h2 id=&#34;2-llm-能做什么像人一样理解文档和日志&#34;&gt;2. LLM 能做什么：像人一样理解文档和日志&lt;/h2&gt;
&lt;p&gt;设想一个企业内部的聊天助手，帮助员工快速了解公司的规范、流程、产品特点。当客户提出技术问题时，员工可以通过这个助手快速定位问题、给出答案。这种助手背后就是一个被企业文档、知识库、过往案例、甚至源码“喂养”过的 LLM。&lt;/p&gt;
&lt;p&gt;对比一下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;功能&lt;/th&gt;
          &lt;th&gt;人工&lt;/th&gt;
          &lt;th&gt;LLM&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;阅读全部文档&lt;/td&gt;
          &lt;td&gt;慢&lt;/td&gt;
          &lt;td&gt;快&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;理解概念&lt;/td&gt;
          &lt;td&gt;可&lt;/td&gt;
          &lt;td&gt;可&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;回答问题&lt;/td&gt;
          &lt;td&gt;慢&lt;/td&gt;
          &lt;td&gt;快&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;LLM 的强大之处，在于它可以“吞掉”TB 级别的数据，然后从中提炼出概念与模式。听起来是不是像搜索引擎？不，它远远超过了搜索引擎。&lt;/p&gt;
&lt;h2 id=&#34;3-不只是搜索是理解&#34;&gt;3. 不只是搜索，是“理解”&lt;/h2&gt;
&lt;p&gt;传统搜索引擎依赖关键词匹配，比如你搜索“database timeout”，它只会返回包含这些词的文档。如果真实错误日志写的是“SQL connection lost”，你就查不到了。&lt;/p&gt;
&lt;p&gt;而 LLM 能理解“database timeout”与“SQL连接丢失”、“查询超时”、“数据库网络延迟”之间的语义联系。它不仅能从日志、trace 和文档中抓出相关内容，还能像一个资深工程师一样，总结出可能原因。&lt;/p&gt;
&lt;p&gt;这才是 LLM 的本事：&lt;strong&gt;不仅能搜索，还能理解、总结、推理。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;4-使用自然语言交互甚至可以生成代码&#34;&gt;4. 使用自然语言交互（甚至可以生成代码）&lt;/h2&gt;
&lt;p&gt;LLM 可以像人类一样理解自然语言，还能用自然语言输出答案。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;问：引擎故障灯亮了，启动时有咔哒声，怎么回事？
答：可能是电池电量不足或启动电机故障……（给出详细分析）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;更惊人的是，它还能生成代码、撰写文档、总结聊天记录、处理用户请求……它甚至可以读懂老旧系统的接口文档，然后自动生成集成代码！&lt;/p&gt;
&lt;p&gt;对于平台工程师而言，LLM 可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;帮你总结应用日志&lt;/li&gt;
&lt;li&gt;快速生成 Kubernetes YAML 或 Terraform 模板&lt;/li&gt;
&lt;li&gt;自动生成 CI/CD 流水线步骤说明&lt;/li&gt;
&lt;li&gt;撰写插件或脚本（例如 ArgoCD 的 Plugin、Backstage 的 Template）&lt;/li&gt;
&lt;li&gt;甚至为 SRE 分析告警和异常根因&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-如何接入-llm熟悉的-http-接口&#34;&gt;5. 如何接入 LLM？熟悉的 HTTP 接口！&lt;/h2&gt;
&lt;p&gt;最棒的是，LLM 通常通过 HTTP API 暴露服务。&lt;/p&gt;
&lt;p&gt;平台工程师早就熟悉这个套路了：写一个 HTTP 请求，传入 JSON，接收 JSON 响应。&lt;/p&gt;
&lt;p&gt;来看个例子，调用 OpenAI API 查询 Siri 是如何工作的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl https://api.openai.com/v1/chat/completions &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Authorization: Bearer &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;      {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#34;content&amp;#34;: &amp;#34;Do you know how Siri works?&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;      }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  }&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;返回内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;chatcmpl-Avpw5BwQ4HypBRJFpqg3pPeeqDRwS&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo-0125&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;choices&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Um... I mean... does it though?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;usage&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;prompt_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;completion_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;107&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;total_tokens&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;121&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你会注意到几个要点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求是一个标准的 HTTP API 调用&lt;/li&gt;
&lt;li&gt;请求体是自然语言，响应也是自然语言&lt;/li&gt;
&lt;li&gt;响应中包含 token 数量（因为使用 LLM 通常按 token 计费）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，作为平台工程师，你可以用 API Gateway 做调用限流、配额管理、成本控制，还可以做安全网关。&lt;/p&gt;
&lt;h2 id=&#34;6-背后的原理其实很简单但也很神奇&#34;&gt;6. 背后的原理其实很简单（但也很神奇）&lt;/h2&gt;
&lt;p&gt;虽然 LLM 看起来很“神”，但它的核心原理其实很简单：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;接收一串单词（tokens），然后预测下一个最可能的词。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The cow jumped over the ___” → “moon”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就是这么简单的过程，重复进行数百次，就组成了一个完整回答。&lt;/p&gt;
&lt;p&gt;这个过程背后依赖大量训练数据和昂贵的硬件，但核心机制就是概率预测。&lt;/p&gt;
&lt;p&gt;推荐阅读： 👉 &lt;a href=&#34;https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How LLMs work explained without math&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;7-注意事项不是银弹也有风险&#34;&gt;7. 注意事项：不是银弹，也有风险&lt;/h2&gt;
&lt;p&gt;LLM 带来了新的能力，也伴随着新的风险，尤其在平台工程中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;准确性&lt;/strong&gt;：LLM 可能自信满满地说错话，在合规或运维场景中可能带来严重问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据隐私&lt;/strong&gt;：若使用的是 SaaS 模型，输入的数据可能泄露（例如 OpenAI）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成本控制&lt;/strong&gt;：token 计费方式容易产生隐性费用，建议用网关管理配额&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应质量&lt;/strong&gt;：LLM 的输出不是文档原文，可能偏离主题或引入“幻觉”&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;品牌风险&lt;/strong&gt;：若未设置过滤机制，LLM 输出可能引发不当或带偏见内容&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;依赖过重&lt;/strong&gt;：部分用户过度依赖模型输出，忽略人工判断与验证&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合规问题&lt;/strong&gt;：如 GDPR、HIPAA 等法规限制使用 AI 处理敏感数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建议设立审计机制、明确边界、设定使用准则。&lt;/p&gt;
&lt;h2 id=&#34;结语llm-是平台工程师的又一个工具&#34;&gt;结语：LLM 是平台工程师的又一个工具&lt;/h2&gt;
&lt;p&gt;LLM 不是什么魔法，它是一个模式识别系统，用海量数据训练而成，具备强大的语义理解和生成能力。&lt;/p&gt;
&lt;p&gt;对平台工程师而言，它就像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;另一种“自动化”&lt;/li&gt;
&lt;li&gt;一种“超能运维助手”&lt;/li&gt;
&lt;li&gt;一种“文档理解引擎”&lt;/li&gt;
&lt;li&gt;一种“智能 CI/CD 脚本生成器”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以用它来增强现有平台的能力，提高团队效率，提升用户支持体验。
但你也需要理性对待它的局限，持续试验、迭代和评估其在你平台中的最佳用法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI 正在来到平台工程的世界——拥抱它，不如先理解它。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
