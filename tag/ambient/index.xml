<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ambient | 云原生社区（中国）</title>
    <link>https://cloudnativecn.com/tag/ambient/</link>
      <atom:link href="https://cloudnativecn.com/tag/ambient/index.xml" rel="self" type="application/rss+xml" />
    <description>Ambient</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Tue, 22 Oct 2024 10:49:22 +0800</lastBuildDate>
    <image>
      <url>https://cloudnativecn.com/media/sharing.png</url>
      <title>Ambient</title>
      <link>https://cloudnativecn.com/tag/ambient/</link>
    </image>
    
    <item>
      <title>云原生对比：Istio Ambient 模式与 Cilium 的扩展性能分析</title>
      <link>https://cloudnativecn.com/blog/ambient-vs-cilium/</link>
      <pubDate>Tue, 22 Oct 2024 10:49:22 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/ambient-vs-cilium/</guid>
      <description>&lt;p&gt;潜在的 Istio 用户经常会问：“Istio 与 Cilium 相比如何？”虽然 Cilium 最初仅提供 L3/L4 功能（如网络策略），但近来的版本增加了基于 Envoy 的服务网格功能以及 WireGuard 加密。与 Istio 一样，Cilium 也是 CNCF 认证的毕业项目，并在社区中存在多年。&lt;/p&gt;
&lt;p&gt;尽管表面上看这两个项目提供的功能相似，但它们的架构却有着显著不同，尤其是 Cilium 使用 eBPF 和 WireGuard 在内核中处理和加密 L4 流量，而 Istio 在用户空间通过其 ztunnel 组件处理 L4 流量。这些差异导致了关于 Istio 与 Cilium 在大规模下性能的广泛讨论。&lt;/p&gt;
&lt;p&gt;尽管已有关于租户模型、安全协议和基本性能的比较，但尚未有全面的企业级评估报告。与其强调理论性能，我们对 Istio 的 Ambient 模式和 Cilium 进行了测试，聚焦于延迟、吞吐量和资源消耗等关键指标。通过模拟一个繁忙的 Kubernetes 环境，我们施加了高负载场景，最后将 AKS 集群的规模扩展到 1000 个节点、11000 个核心，以了解这些项目在大规模下的表现。结果显示，两者各有需要改进的地方，但 Istio 明显表现更佳。&lt;/p&gt;
&lt;h2 id=&#34;测试场景&#34;&gt;测试场景&lt;/h2&gt;
&lt;p&gt;为了将 Istio 和 Cilium 推向极限，我们创建了 500 个不同的服务，每个服务支持 100 个 Pod。每个服务位于单独的命名空间中，且包含一个&lt;a href=&#34;https://fortio.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fortio&lt;/a&gt;负载生成客户端。我们将客户端限制在一个由 100 台 32 核机器组成的节点池中，以消除共同定位的客户端的干扰，并为服务分配了剩余的 900 台 8 核实例。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-测试场景&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;测试场景&#34; srcset=&#34;
               /blog/ambient-vs-cilium/scale-scenario_hu13804612610986617828.webp 400w,
               /blog/ambient-vs-cilium/scale-scenario_hu2793493080775659769.webp 760w,
               /blog/ambient-vs-cilium/scale-scenario_hu775628029952840790.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/ambient-vs-cilium/scale-scenario_hu13804612610986617828.webp&#34;
               width=&#34;760&#34;
               height=&#34;598&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      测试场景
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在 Istio 测试中，我们使用了 Ambient 模式，在每个服务命名空间中部署了&lt;a href=&#34;https://istio.io/latest/docs/ambient/usage/waypoint/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;waypoint 代理&lt;/a&gt;，并使用默认的安装参数。为了使测试场景尽可能相似，我们在 Cilium 中启用了几个非默认功能，包括 WireGuard 加密、L7 代理和节点初始化。我们还在每个命名空间中创建了一个 Cilium 网络策略，带有基于 HTTP 路径的规则。在两种场景下，我们通过随机地将一个服务扩展到 85 至 115 个实例并每分钟重新标记一个命名空间，生成了变化。要查看我们使用的精确设置并重现结果，请参阅&lt;a href=&#34;https://github.com/therealmitchconnors/tools/blob/2384dc26f114300687b21f921581a158f27dc9e1/perf/load/many-svc-scenario/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我的笔记&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;可扩展性评分&#34;&gt;可扩展性评分&lt;/h2&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-可扩展性评分&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;可扩展性评分&#34; srcset=&#34;
               /blog/ambient-vs-cilium/scale-scorecard_hu11511869128938331683.webp 400w,
               /blog/ambient-vs-cilium/scale-scorecard_hu7893995119246714117.webp 760w,
               /blog/ambient-vs-cilium/scale-scorecard_hu15779689091891454627.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/ambient-vs-cilium/scale-scorecard_hu11511869128938331683.webp&#34;
               width=&#34;760&#34;
               height=&#34;426&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      可扩展性评分
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Istio 能够以 20% 的较低尾延迟提供 56% 更多的查询。Cilium 的 CPU 使用率低 30%，但我们的测量并不包括 Cilium 用于加密的内核核心。&lt;/p&gt;
&lt;p&gt;考虑到资源使用情况，Istio 每核心处理 2178 个查询，而 Cilium 则是 1815 个，提升了 20%。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cilium 减速：&lt;/strong&gt; Cilium 在默认安装参数下展示了令人印象深刻的低延迟，但当启用 Istio 的基准功能（如 L7 策略和加密）时，其速度大幅下降。此外，即使网格中没有流量流动，Cilium 的内存和 CPU 利用率仍然较高，这可能会影响集群的整体稳定性和可靠性，尤其是在扩展时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Istio 稳健表现：&lt;/strong&gt; 相比之下，Istio 的 Ambient 模式在稳定性方面展示了其优势，即使增加了加密的开销，也能保持不错的吞吐量。在测试中，Istio 确实比 Cilium 消耗了更多的内存和 CPU，但在没有负载时其 CPU 利用率下降到 Cilium 的一小部分。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;幕后原因为何表现差异&#34;&gt;幕后原因：为何表现差异？&lt;/h2&gt;
&lt;p&gt;要理解这些性能差异的关键在于各工具的架构和设计。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cilium 的控制平面难题：&lt;/strong&gt; Cilium 在每个节点上运行一个控制平面实例，随着集群扩展，这导致 API 服务器压力增加和配置开销增加。这经常导致我们的 API 服务器崩溃，接着 Cilium 变得不可用，整个集群陷入不响应状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Istio 的效率优势：&lt;/strong&gt; Istio 通过集中控制平面和基于身份的方式简化了配置，减少了 API 服务器和节点的负担，将关键资源用于处理和保护流量，而不是处理配置。Istio 通过运行尽可能多的 Envoy 实例来进一步利用未在控制平面中使用的资源，而 Cilium 则限制为每个节点共享一个 Envoy 实例。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;更深入探讨&#34;&gt;更深入探讨&lt;/h3&gt;
&lt;p&gt;虽然这个项目的目标是比较 Istio 和 Cilium 的可扩展性，但一些限制使得直接比较变得困难。&lt;/p&gt;
&lt;h3 id=&#34;l4-不总是-l4&#34;&gt;L4 不总是 L4&lt;/h3&gt;
&lt;p&gt;尽管 Istio 和 Cilium 都提供 L4 策略强制，但它们的 API 和实现存在显著差异。Cilium 实现了 Kubernetes NetworkPolicy，它使用标签和命名空间来阻止或允许 IP 地址的访问。Istio 提供了一个 AuthorizationPolicy API，并根据签署每个请求的 TLS 身份做出允许和拒绝决定。大多数深度防御策略需要同时使用 NetworkPolicy 和基于 TLS 的策略来实现全面的安全性。&lt;/p&gt;
&lt;h3 id=&#34;加密的差异&#34;&gt;加密的差异&lt;/h3&gt;
&lt;p&gt;Cilium 提供了用于 FIPS 兼容加密的 IPsec，但大多数 Cilium 功能（如 L7 策略和负载均衡）与 IPsec 不兼容。Cilium 在使用 WireGuard 加密时具有更好的功能兼容性，但 WireGuard 无法在 FIPS 合规的环境中使用。另一方面，Istio 严格遵守 TLS 协议标准，默认情况下始终使用 FIPS 兼容的 mTLS。&lt;/p&gt;
&lt;h3 id=&#34;隐藏的成本&#34;&gt;隐藏的成本&lt;/h3&gt;
&lt;p&gt;虽然 Istio 完全在用户空间中运行，但 Cilium 的 L4 数据平面在 Linux 内核中使用 eBPF。Prometheus 的资源消耗指标仅测量用户空间资源，这意味着 Cilium 使用的所有内核资源在此测试中都未计入。&lt;/p&gt;
&lt;h2 id=&#34;建议选择合适的工具&#34;&gt;建议：选择合适的工具&lt;/h2&gt;
&lt;p&gt;那么，最终结论是什么？这取决于您的具体需求和优先事项。对于小型集群以及纯 L3/L4 用例且无需加密的情况，Cilium 提供了一个经济高效且性能良好的解决方案。然而，对于大型集群，以及注重稳定性、可扩展性和高级功能的情况，Istio 的 Ambient 模式配合替代的 NetworkPolicy 实现才是首选。许多客户选择将 Cilium 的 L3/L4 功能与 Istio 的 L4/L7 和加密功能结合，以实现深度防御策略。&lt;/p&gt;
&lt;p&gt;请记住，云原生网络的世界在不断发展。密切关注 Istio 和 Cilium 的进展，它们将继续改进和应对这些挑战。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用 Istio 的环境模式 —— 用更少的资源做更多的事！</title>
      <link>https://cloudnativecn.com/blog/istio-more-for-less/</link>
      <pubDate>Wed, 28 Aug 2024 17:35:23 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/istio-more-for-less/</guid>
      <description>&lt;p&gt;随着 Istio 的环境数据平面模式的推出，平台团队可以高效地采用服务网格功能，并以最小的资源和开销影响为终端用户提供增强功能。&lt;/p&gt;
&lt;h2 id=&#34;什么是-istio-环境模式&#34;&gt;什么是 Istio 环境模式？&lt;/h2&gt;
&lt;p&gt;Istio 的&lt;a href=&#34;https://www.solo.io/blog/istio-ambient-mesh-evolution-service-mesh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;环境模式&lt;/a&gt;最初于 2022 年 9 月发布。它是一种新的数据平面模式 —— 无需 sidecar —— 旨在简化操作、扩大应用兼容性和降低基础设施成本。环境模式将 Istio 的功能分为两个独立的层：零信任安全覆盖层（&lt;em&gt;ztunnel&lt;/em&gt;）和可选的第 7 层处理层（&lt;em&gt;waypoint&lt;/em&gt;）。与 sidecar 相比，分层方法允许用户从无网格逐渐采用到基于 mTLS 的零信任覆盖，再到完整的第 7 层处理，根据需要进行。这为服务网格用户提供了来自同一专用社区的两个出色选择：传统的 sidecar 方法的 Istio 或无 sidecar 的环境模式。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-istio-环境模式&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Istio 环境模式&#34; srcset=&#34;
               /blog/istio-more-for-less/f1_hu11836929386643823188.webp 400w,
               /blog/istio-more-for-less/f1_hu14368959289602612651.webp 760w,
               /blog/istio-more-for-less/f1_hu13051461677501106522.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f1_hu11836929386643823188.webp&#34;
               width=&#34;760&#34;
               height=&#34;327&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Istio 环境模式
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在这篇博客中，我们将探讨与资源成本和操作挑战相关的一些示例场景，这些场景在采用服务网格时常常会引起紧张。我们还将讨论如何采用环境模式来应对这些挑战，并改善平台的总拥有成本（TCO）。&lt;/p&gt;
&lt;h2 id=&#34;istio-的环境模式降低资源成本&#34;&gt;Istio 的环境模式降低资源成本&lt;/h2&gt;
&lt;p&gt;默认情况下，Istio 建议为每个 sidecar 分配 0.1 CPU 核心和 128MB 的内存。虽然服务网格的优势众所周知，但在真实生产工作负载中，资源需求很快就会累积起来。&lt;/p&gt;
&lt;p&gt;对于预算紧张的团队来说，遵守这一要求带来了显著的机会成本。他们面临的抉择包括在招聘额外人员或投资于业务的其他领域与承担应用增加的资源成本之间做出决定，这成为一个关键考量。&lt;/p&gt;
&lt;p&gt;务网格有一系列 7 层网络功能，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高级流量管理和路由控制&lt;/li&gt;
&lt;li&gt;在应用层的细粒度安全策略&lt;/li&gt;
&lt;li&gt;高效处理断路器和容错机制&lt;/li&gt;
&lt;li&gt;促进服务发现和动态服务路由的实施&lt;/li&gt;
&lt;li&gt;简化 A/B 测试和金丝雀发布策略的部署&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然而，如果你近期不需要这些功能，或者不是每个服务都需要？这些功能可能被视为附加价值，并可能不符合你的组织需求或成熟度水平。&lt;/p&gt;
&lt;p&gt;让我们考虑一些与实施服务网格成本相关的挑战场景：&lt;/p&gt;
&lt;h4 id=&#34;场景-1-控制螺旋升高的-sidecar-成本&#34;&gt;场景 1: 控制螺旋升高的 sidecar 成本&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“我们的安全团队要求整个组织采取零信任姿态，因此我们正在考虑采用服务网格。然而，我们发现采用 sidecar 方法将产生额外的成本（在每个应用的资源预留中）。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;为了遵守安全团队的零信任要求，使用 Istio 的环境模式，你无需为每个应用采用一个 sidecar。相反，你可以利用共享的、每节点 ztunnel 组件，它处理零信任网络的职责。然后，当你准备好时，或只针对需要的服务，可以选择安全地、按命名空间处理第 7 层策略。这种选择方法意味着从非 mTLS 到采用 mTLS 的增量成本现在大大降低了。&lt;/p&gt;
&lt;h4 id=&#34;场景-2-减少重复的资源成本&#34;&gt;场景 2: 减少重复的资源成本&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“我们的组织要求开发、测试和分层环境复制生产设置，以便及早发现问题并维持高质量的发布。采用服务网格意味着每个环境都会产生额外的资源和操作开销，导致整体成本急剧上升。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们经常看到客户环境复制其生产设置，其中较低级别的环境只接收少量的合成流量 —— 或在某些情况下根本没有流量。这对环境所有者来说是一个挑战，他们需要证明在这些流量低或无流量的环境中运行服务网格的价值。分配给 sidecar 代理的资源很大程度上被浪费，导致利用效率低下和更高的支出。通过移除 sidecar 的要求，环境模式降低了基础资源需求，使得在复制生产环境的标准下实施零信任更具成本效益。&lt;/p&gt;
&lt;h4 id=&#34;场景-3-在不同架构中驾驭变化的速率模式&#34;&gt;场景 3: 在不同架构中驾驭变化的速率模式&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“我们有一个复杂的微服务架构，不同的服务经历广泛不同的流量模式。一些服务每秒处理数千个请求，而其他服务只处理几百个。尽管如此，sidecar 代理通常在所有服务中分配相同的资源，导致资源利率不高。高流量服务遭受性能瓶颈，而低流量服务则浪费资源。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们看到的另一个常见场景是，sidecar 代理通常采用一刀切的方法进行配置，导致资源利用不效率。在缺乏机制（例如，在应用的 Helm chart中暴露 Istio pod 注解）来覆盖默认代理资源预留请求的情况下，以及开发团队缺乏使用可观察性数据来配置和调整这些资源预留的经验的情况下，应用开发团队能否成功取决于他们的应用特征。彻底移除 sidecar 消除了由资源利用不足造成的低效。此外，由于 ztunnel 是用 Rust 构建的高性能组件，它仍然可以处理高吞吐量的情况。&lt;/p&gt;
&lt;h4 id=&#34;场景-4-实施服务网格以在边缘环境中实现零信任&#34;&gt;场景 4: 实施服务网格以在边缘环境中实现零信任&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“在资源有限的边缘环境中部署服务网格具有挑战性，因为 sidecar 带来额外的开销。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;边缘计算将数据处理更靠近数据源，通常在较不安全或不受信任的网络中，且资源有限。实现零信任确保每次互动都经过身份验证和授权，显著降低了违规的风险，但在资源有限的环境中可能很困难。通过利用不需要 sidecar 的资源开销的 Istio 环境模式服务网格，IoT、零售和医疗保健等边缘计算用例可以真实地考虑实现零信任原则并达成合规，以增强其边缘环境的安全策略。&lt;/p&gt;
&lt;p&gt;这些只是 Istio 的环境模式可以帮助解决的一些常见 sidecar 挑战。Istio 的环境模式还可以帮助驾驭的其他资源障碍包括减少 sidecar 部署经历的应用程序停机时间和解决出口配置的复杂性。&lt;/p&gt;
&lt;h2 id=&#34;istio-的环境模式有助于简化应用操作&#34;&gt;Istio 的环境模式有助于简化应用操作&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/istio-more-for-less/f2_hu17324861449245618460.webp 400w,
               /blog/istio-more-for-less/f2_hu3044859019090512890.webp 760w,
               /blog/istio-more-for-less/f2_hu3604874795143997432.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f2_hu17324861449245618460.webp&#34;
               width=&#34;760&#34;
               height=&#34;220&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;安全地重启服务以升级 sidecar 版本涉及三种不同的设置：控制 Envoy 排出和拒绝新连接，为活动连接关闭提供宽限时间，以及在所有活动连接关闭时终止 pod。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们看到的服务网格采用中最常见的挑战之一是应用所有者管理 sidecar 生命周期的操作开销增加。例如，在从 Istio 1.19 升级到 1.20 时，集群中的每个应用 pod 都必须重新启动以应用新的代理版本。你必须考虑从工作负载中排出流量、终止连接以及如果 pod 因暂时不可用的依赖而无法重新启动会发生什么。&lt;/p&gt;
&lt;p&gt;采用无 sidecar 的服务网格架构时，所有这些考虑都消失了！环境模式显著减少了操作负担，为开发人员提供了更多时间专注于开发应用功能，而不是管理大规模代理的基础设施相关问题。&lt;/p&gt;
&lt;p&gt;为了帮助具体化这一点，让我们考虑一些与操作服务网格相关的挑战场景：&lt;/p&gt;
&lt;h4 id=&#34;场景-1-通过升级-istio-部署解决复杂性&#34;&gt;场景 1: 通过升级 Istio 部署解决复杂性&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“我们有一个复杂的 Istio 部署，其中包含许多自定义设置，升级到新版本一直是一个主要的痛点。升级过程经常导致停机、配置偏移和意外问题，这些都会扰乱我们的操作。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Istio 社区的支持时间表目前遵循 N-1 支持状态，这相当于大约每 7-9 个月升级一次 Istio。Istio 的频繁升级可能涉及高度参与，消除 sidecar 大大减少了仅因少数组件升级和管理而扰乱业务操作的风险。&lt;/p&gt;
&lt;p&gt;通过专注于节点级管理而不是服务级 sidecar，操作团队可以更高效地执行升级，并且无需依赖或协调应用团队就更有信心。值得考虑的是，操作成本节省可能真的很可观。例如，如果两名工程师完成 Istio 升级所需的时间从 16 小时减少到仅 2 小时，时间和成本的节省可能是实质性的。&lt;/p&gt;
&lt;h4 id=&#34;场景-2-管理-sidecar-的人才和资源有限&#34;&gt;场景 2: 管理 sidecar 的人才和资源有限&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“让新的开发团队使用服务网格耗时且需要广泛培训 sidecar 管理。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;开发人员经常表达对管理 sidecar 的挫败感，多年来的众多社区调查已证明这一点。Istio 的环境模式直接解决了这个问题；通过完全消除 sidecar，不再需要对 sidecar 管理进行广泛培训。使用无 sidecar 的服务网格的用户可以信任，如果应用部署在集群上，其流量默认加密。&lt;/p&gt;
&lt;h4 id=&#34;场景-3-集成遗留应用导致中断&#34;&gt;场景 3: 集成遗留应用导致中断&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;“我们有大量对业务运营至关重要的遗留应用。引入基于 sidecar 的服务网格会扰乱这些应用并需要广泛的修改。”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;使用 Istio 的环境模式，将服务添加到网格现在只需要在命名空间或 pod 上应用一个标签。然后，ztunnel 会拦截流量，而无需重启应用。这大大简化了对容忍中断或修改程度低的关键应用的引导，这些应用此前并未被视为网格的强有力候选者。应用所有者不再需要关心其工作负载中的 sidecar 的存在、sidecar 的生命周期或 sidecar 资源的成本。&lt;/p&gt;
&lt;h2 id=&#34;比较环境模式的使用成本&#34;&gt;比较环境模式的使用成本&lt;/h2&gt;
&lt;p&gt;为了评估服务网格的资源使用情况，我们将在规模上部署一个示例应用。这代表了用户在生产环境中实际使用服务网格的方式，并基于我们与客户关于他们如何使用 Istio 和 Gloo Mesh 的讨论。&lt;/p&gt;
&lt;p&gt;我们的测试工作负载代表了一个在 Namespace-Per-Tenant 模式下配置的应用，其中每个租户在一个隔离的命名空间中操作，以确保资源和安全分离。该应用设计为经典的 3 层扇出架构，其中一个初始服务向多个下游服务发送请求，与客户端针对单个服务的简单基准相比，提供了更具代表性的预期性能评估。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/istio-more-for-less/f3_hu8313275760897035267.webp 400w,
               /blog/istio-more-for-less/f3_hu5652853074685285988.webp 760w,
               /blog/istio-more-for-less/f3_hu15704182144860879846.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f3_hu8313275760897035267.webp&#34;
               width=&#34;760&#34;
               height=&#34;597&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们在每个租户中部署了 8 个容器，分为两个“应用”，每个应用有四个 pod，安排在三层中。在集群中，我们总共有 200 个微服务。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/istio-more-for-less/f4_hu812153239131258086.webp 400w,
               /blog/istio-more-for-less/f4_hu10141221879140687171.webp 760w,
               /blog/istio-more-for-less/f4_hu10512267036798277917.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f4_hu812153239131258086.webp&#34;
               width=&#34;760&#34;
               height=&#34;596&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;为了确保“保证”的服务质量类别，每个应用都配置为具有相同的 pod 请求和限制：0.7 CPU 核心和 500MB 内存。（我们使用的应用是 &lt;a href=&#34;https://github.com/nicholasjackson/fake-service&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fake-service&lt;/a&gt;，一个由 CNCF TAG Network 联合主席 Nic Jackson 构建的用于测试服务网格的示例应用。）&lt;/p&gt;
&lt;p&gt;考虑到用户倾向于以中等利用率运行他们的集群，我们将我们基线应用在负载下的目标 CPU 利用率设为 &amp;lt; 30%，这相当于一个拥有 n2-standard-8 实例的 21 节点集群。&lt;/p&gt;
&lt;p&gt;为了生成合成负载，我们使用 &lt;a href=&#34;https://github.com/tsenart/vegeta&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vegeta&lt;/a&gt;，每个应用有一个实例（每个命名空间两个）。还有四个节点用于负载生成器，向每个第 1 层副本每秒发送 200 个请求。这些请求在显示的边缘生成后续请求到第 2 层和第 3 层，给每个租户带来 2000 RPS 的负载，整个集群总共 50000 RPS。我们确保我们在测试中看到的延迟结果符合我们定义的预期，没有请求在 p50 超过 10ms 或在 p95 超过 15ms。&lt;/p&gt;
&lt;p&gt;我们对我们的应用进行了基线读数，我们可以从网格数字中减去，以了解每个选项的成本。&lt;/p&gt;
&lt;p&gt;然后，我们分别在 Istio sidecar 和环境模式下部署了我们的应用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/solo-io/doing-more-for-less&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;你可以在 GitHub 上找到我们的脚本和输出&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;istio-的环境模式比-sidecar-节省超过-70&#34;&gt;Istio 的环境模式比 Sidecar 节省超过 70%&lt;/h2&gt;
&lt;p&gt;除了我们上面列出的所有操作节省之外，&lt;strong&gt;在环境模式下运行的 Istio 显著地比在 sidecar 模式下运行的 Istio 更便宜&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/istio-more-for-less/f5_hu1703597395058763853.webp 400w,
               /blog/istio-more-for-less/f5_hu17684752221851402439.webp 760w,
               /blog/istio-more-for-less/f5_hu2994559504061492112.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f5_hu1703597395058763853.webp&#34;
               width=&#34;600&#34;
               height=&#34;371&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;即使在一个负载重的、配置良好的集群中，L4 下的环境模式使用的 CPU &lt;strong&gt;比 sidecar 模式少 73%&lt;/strong&gt;。在我们的示例集群中，Istio 的环境模式每个命名空间减少了 1.28 个核心。鉴于我们 25 个命名空间的环境，这相当于节省 32 个核心，或相当于 4 台 8 核机器。那是每个月节省 1100 美元！&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/istio-more-for-less/f6_hu16177736285739299000.webp 400w,
               /blog/istio-more-for-less/f6_hu5603653459885451271.webp 760w,
               /blog/istio-more-for-less/f6_hu17650931593125420850.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/istio-more-for-less/f6_hu16177736285739299000.webp&#34;
               width=&#34;600&#34;
               height=&#34;371&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;而且，CPU 利用率极低：仅增加 4.78% 的 CPU 以在我们的工作负载中添加 mTLS，而添加 sidecar 相比增加了 24.3%。假设你的集群中的所有节点都至少有 5% 的空闲开销，&lt;strong&gt;你可以在不增加任何额外节点的情况下安装 Istio 的环境模式，从而使其实际上免费运行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;用户希望在 Istio 的环境模式下实施完整的第 7 层功能和特性，可以放心地进行。你可以按命名空间选择加入，但即使我们为所有租户运行了一个 waypoint —— 与完整的 sidecar 部署的特性相当 —— 我们仍然看到了实质性的 CPU 节省。请留意我们即将发布的博客，它将更深入地讨论第 7 层的成本和价值。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;我们的研究验证了构建环境数据平面的目标：简化服务网格的操作（无 sidecar），以及降低基础设施成本（与 sidecars 相比的显著成本节省，从基线上满足 mTLS 要求的额外成本很少）。&lt;/p&gt;
&lt;p&gt;如果用户决定通过采用 waypoint 代理采用完整的第 7 层功能集，资源成本将远低于 Istio 的传统 sidecar 部署，更不用说更易于管理和改善开发人员的体验了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>无需 Kubernetes 测试 Kubernetes 网络实现</title>
      <link>https://cloudnativecn.com/blog/ztunnel-testing/</link>
      <pubDate>Mon, 22 Jul 2024 18:46:32 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/ztunnel-testing/</guid>
      <description>&lt;p&gt;由于在开发过程中我&lt;a href=&#34;https://blog.howardjohn.info/posts/ideal-ci/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;真的不喜欢等待&lt;/a&gt;，所以在构建 Ztunnel（一个为 Istio 的新&lt;a href=&#34;https://istio.io/latest/blog/2022/introducing-ambient-mesh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ambient 模式&lt;/a&gt;设计的底层网络代理）时，我的首要任务之一便是确保测试的快速进行（包括运行和编写测试），并且易于调试。&lt;/p&gt;
&lt;p&gt;这一任务颇为棘手，因为在大多数真实场景中，Ztunnel 高度依赖 Kubernetes。虽然它能够完全独立于 Kubernetes 运行，但许多关键代码路径的行为完全不同，使得仅通过这种方式进行测试变得不可行。&lt;/p&gt;
&lt;p&gt;下图为典型的 Ztunnel 部署架构：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ztunnel-架构概览&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ztunnel 架构概览&#34;
           src=&#34;https://cloudnativecn.com/blog/ztunnel-testing/ztunnel-architecture.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ztunnel 架构概览
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在此架构中，用户将运行一个包含多个节点的 Kubernetes 集群。每个节点上都运行着一个 Ztunnel，配置了宿主机和每个 pod 的网络栈。&lt;/p&gt;
&lt;p&gt;此外，Ztunnel 实际上进入了每个 pod 的网络命名空间，并代表其发送/接收流量。这一点非常奇特且酷炫，但也大大增加了测试的难度！（&lt;a href=&#34;https://www.youtube.com/watch?v=cuMeEhpyH5s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;详细信息&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;加速测试&#34;&gt;加速测试&lt;/h2&gt;
&lt;p&gt;启动完整的 Kubernetes 环境、重建镜像、部署到每个节点的过程非常缓慢且难以调试。&lt;/p&gt;
&lt;p&gt;黄金标准应该是将所有操作运行在一个简单的单一二进制文件中——仅需执行 &lt;code&gt;cargo test&lt;/code&gt;。这种方式避开了复杂的设置和缓慢的重建，并使调试变得轻而易举（当然，你可以将调试器连接到正在运行的 pod，但这很麻烦）。&lt;/p&gt;
&lt;h2 id=&#34;设置网络&#34;&gt;设置网络&lt;/h2&gt;
&lt;p&gt;如果我们去除无尽的抽象层，Kubernetes pods 实际上只是几个 Linux 命名空间和挂载的组合。Docker 在这方面管理得很好，&lt;a href=&#34;https://github.com/p8952/bocker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bash&lt;/a&gt;也可以。&lt;/p&gt;
&lt;p&gt;我们特别关注的是&lt;a href=&#34;https://man7.org/linux/man-pages/man7/network_namespaces.7.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;网络命名空间&lt;/a&gt;，它可以实现网络栈的隔离。每个 pod 都有自己的网络命名空间，通过各种机制连接，允许与同一节点上的其他 pod、其他节点以及外部目的地通信。&lt;/p&gt;
&lt;p&gt;好消息是创建网络命名空间非常简单。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ sudo ip netns add testing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们的最终目标是设置一系列的网络命名空间，外观与我们在 Kubernetes 上的真实架构类似：&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-所需的网络命名空间设置&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;所需的网络命名空间设置&#34;
           src=&#34;https://cloudnativecn.com/blog/ztunnel-testing/ztunnel-network-namespaces.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      所需的网络命名空间设置
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在网络命名空间之间建立连接稍微复杂一些。像 &lt;a href=&#34;https://www.cni.dev/docs/cnitool/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;cnitool&lt;/code&gt;&lt;/a&gt; 这样的工具可以帮助我们完成（它实际上执行了一些 Kubernetes 环境中用于设置网络的相同逻辑，但作为 CLI 工具），但你也可以完全手动操作。我们选择了后者。&lt;/p&gt;
&lt;p&gt;最终，我们的设置如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个测试都拥有自己的网络命名空间，通过一个桥接设备（&lt;code&gt;br0&lt;/code&gt;）来促进节点之间的流量。&lt;/li&gt;
&lt;li&gt;每个节点配置了一个 &lt;code&gt;veth&lt;/code&gt; 设备。一端成为节点上的 &lt;code&gt;eth0&lt;/code&gt;，另一端连接到根命名空间中的 &lt;code&gt;br0&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;每个 pod 都配置了一个 &lt;code&gt;veth&lt;/code&gt; 设备。一端成为 pod 上的 &lt;code&gt;eth0&lt;/code&gt;，另一端位于节点网络命名空间中。&lt;/li&gt;
&lt;li&gt;为每个 pod 设置路由以将流量发送到节点。&lt;/li&gt;
&lt;li&gt;为每对节点设置路由，以实现跨节点流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-所需的网络连接设置&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;所需的网络连接设置&#34;
           src=&#34;https://cloudnativecn.com/blog/ztunnel-testing/ztunnel-network-devices.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      所需的网络连接设置
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;除了根命名空间/桥接设备外，这与许多现实世界中的 Kubernetes 集群的运行方式相同（在现实世界中，根命名空间是两台机器之间的物理网络）。&lt;/p&gt;
&lt;p&gt;你可以在&lt;a href=&#34;https://github.com/istio/ztunnel/blob/34fce85a6a2b2a85eb170a04096731e2ea4e0e9f/src/test_helpers/netns.rs#L194&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;找到所有细节。&lt;/p&gt;
&lt;h2 id=&#34;运行测试&#34;&gt;运行测试&lt;/h2&gt;
&lt;p&gt;一旦我们有了这些命名空间，我们仍然需要一种实际使用它们的方法。幸运的是，Linux 允许在运行时更改当前命名空间线程（这是接下来重要的内容）。这让我们建立了一个基本的帮助函数（真实的代码稍微更复杂）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_current_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;有了这个，我们可以轻松地从任意的“pods”或“nodes”执行代码。&lt;/p&gt;
&lt;p&gt;然而，我们仍然面临一个问题。我们的所有代码都运行在 &lt;a href=&#34;https://tokio.rs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tokio&lt;/a&gt; 异步运行时中，它会根据需要将我们的各种任务安排到物理操作系统线程上（类似于 Go 运行时的工作方式）。由于网络命名空间是线程相关的，所以当我们的任务在线程之间跳转时，这一切都会崩溃。&lt;/p&gt;
&lt;p&gt;幸运的是，Rust 给了我们比 Go 更多的关于异步运行时的灵活性——我们可以同时拥有多个！借此，我们能够构建一个能够异步执行 &lt;code&gt;run_in_namespace&lt;/code&gt;。对于我们想要执行的每个函数，我们启动一个新线程并构建一个专用的单线程异步运行时来处理它：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;async_run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;thread&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;spawn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;move&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokio&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;runtime&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Builder&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new_current_thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enable_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;block_on&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们为每个命名空间运行一次这个函数，因此这里的开销是最小的。如果我们想要运行许多小函数，可以在顶层构建一个抽象来发送工作到线程以执行。&lt;/p&gt;
&lt;p&gt;我们需要的最后一件事是一种合理的方法来识别如何调用每个目的地。虽然它们都会被分配一个 IP（基于我们代码中的简单 IPAM 策略），但我们不希望每个测试都必须猜测 IP。为了处理这个问题，我们构建了一个简单的名称解析器。这就像 DNS，但简单得多：对于我们创建的每个“pod”，我们记录一个&lt;code&gt;name -&amp;gt; IP&lt;/code&gt;的映射，并允许查找 IP。&lt;/p&gt;
&lt;p&gt;将所有这些放在一起，一个简单的测试启动了3个 pods（客户端、服务器和 ztunnel）在一个单一节点上看起来像这样：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#[tokio::test]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;simple_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(){&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ztunnel&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;deploy_ztunnel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;workload_builder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;server&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_tcp_server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;workload_builder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;client&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_tcp_client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;server&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// ... some assertions here }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;放弃权限&#34;&gt;放弃权限&lt;/h2&gt;
&lt;p&gt;上述设置效果很好，但也带来了一些问题。&lt;/p&gt;
&lt;p&gt;基本上设置的每一步都需要提升的 root 权限；这让简单的 &lt;code&gt;cargo test&lt;/code&gt; 案例的开箱即用变得乏味，通常也不可取。&lt;/p&gt;
&lt;p&gt;此外，这会在主机环境中污染大量的命名空间。虽然我们有一些清理过程，但这些并不是100%可靠，可能会导致悬挂的命名空间阻碍未来的执行。&lt;/p&gt;
&lt;p&gt;解决拥有太多命名空间的问题的方法？更多的命名空间！为此，我们需要的不仅仅是网络命名空间。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://man7.org/linux/man-pages/man7/user_namespaces.7.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;用户命名空间&lt;/a&gt; 允许我们实质上假装是 UID 0 (root)，同时实际上将其映射回我们原始的 UID。这里的力量在于，在该命名空间中，我们可以做一些本来需要 root 权限的事情——特别是创建新的网络命名空间。&lt;/p&gt;
&lt;p&gt;然而，我们不能做的一件事是修改主机-root 拥有的文件（这将是明显的权限违规）。尽管我们可能可以绕过它们，但我们在测试中使用的很多工具喜欢触摸 root 文件。这再次可以通过 &lt;a href=&#34;https://man7.org/linux/man-pages/man7/mount_namespaces.7.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mount 命名空间&lt;/a&gt; 解决，它允许我们将我们拥有的文件绑定挂载到主机-root 拥有的文件上，而不会影响命名空间外的事物。&lt;/p&gt;
&lt;p&gt;将所有这些放在一起，我们有这样的东西：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_uid&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 首先，进入一个新的用户命名空间。 unshare(CloneFlags::CLONE_NEWUSER).unwrap(); // 将用户命名空间中的 root 映射到我们原始的 UID File::create(&amp;#34;/proc/self/uid_map&amp;#34;).write(format!(&amp;#34;0 {original_uid} 1&amp;#34;)); // 设置一个新的网络命名空间 unshare(CloneFlags::CLONE_NEWNET).unwrap(); // 设置一个新的挂载命名空间 unshare(CloneFlags::CLONE_NEWNS).unwrap(); // 将一个文件夹在我们的每个测试目录中挂载到 /var/run/netns mount(tmp_dir.join(&amp;#34;netns&amp;#34;), &amp;#34;/var/run/netns&amp;#34;, MS_BIND); // 一个方便手动调试的好帮手信息，如果需要的话。 let pid = get_pid(); eprintln!(&amp;#34;Starting test in {tmp_dir}. Debug with `sudo nsenter --mount --net -t {pid}`&amp;#34;);
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如上所述，一个技巧是，进入命名空间是按线程进行的。我们需要在生成任何额外线程之前设置这一点。&lt;/p&gt;
&lt;p&gt;Rust 实际上为我们提供了这样做的能力，但这意味着我们失去了 &lt;code&gt;#[tokio::test]&lt;/code&gt; 宏帮助。我们可以写自己的宏，但这有点痛苦。幸运的是，通过 &lt;a href=&#34;https://crates.io/crates/ctor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;链接器的花招&lt;/a&gt; 我们可以迫使我们的代码在进程执行的非常早期运行。&lt;/p&gt;
&lt;p&gt;Go 中的类似方法也有效（请参见 &lt;a href=&#34;https://github.com/howardjohn/unshare-go&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我写的帮助库&lt;/a&gt;），实际上在那里是必需的，因为设置必须在 Go 运行时启动之前完成（这通常在任何用户代码运行之前很久）。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;有了所有这些设备，一个完整的测试只需要大约 200 毫秒。一切都在一个单一进程中运行，使调试变得轻而易举。所有的测试也都是完全隔离的，因此可以完全并行运行测试（包括相同的测试，用于压力测试以消除测试缺陷）。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
