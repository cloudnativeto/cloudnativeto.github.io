<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BGP | 云原生社区（中国）</title>
    <link>https://cloudnativecn.com/tag/bgp/</link>
      <atom:link href="https://cloudnativecn.com/tag/bgp/index.xml" rel="self" type="application/rss+xml" />
    <description>BGP</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Tue, 30 Jan 2024 08:00:00 +0800</lastBuildDate>
    <image>
      <url>https://cloudnativecn.com/media/sharing.png</url>
      <title>BGP</title>
      <link>https://cloudnativecn.com/tag/bgp/</link>
    </image>
    
    <item>
      <title>使用 Cilium 和 BGP 为 Kubernetes 服务进行负载均衡</title>
      <link>https://cloudnativecn.com/blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/</link>
      <pubDate>Tue, 30 Jan 2024 08:00:00 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/</guid>
      <description>&lt;p&gt;本文译自 &lt;a href=&#34;https://sue.eu/blogs/expose-loadbalanced-kubernetes-services-with-bgp-cilium/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Exposing Load-Balanced Kubernetes Services with Cilium&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Cilium 是一个开源项目，旨在为云原生环境提供网络、安全和可观测性，例如 Kubernetes 集群和其他容器编排平台。本博客展示了如何使用 Cilium 和 BGP 将您的 Kubernetes 服务暴露给外部世界。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BGP&lt;/strong&gt;
边界网关协议（BGP）是一种标准化的外部网关协议，旨在在互联网上的自治系统（AS）之间交换路由和可达性信息。该协议被分类为路径矢量协议，因此它根据由网络管理员配置的路径、网络策略或规则集来做出路由决策。它参与制定核心路由决策，这使得它对互联网的正常运行至关重要。&lt;/p&gt;
&lt;p&gt;BGP 专为健壮性和可扩展性而开发，用于在大型网络之间路由数据，包括 ISP 和其他大型组织。它确保了无环的域间路由，并有助于维护稳定的网络结构。BGP 可以处理数千个路由，并以其随着网络增长而扩展的能力而脱颖而出。由于其灵活性和对路由策略的控制，它被广泛使用，使其能够快速响应网络变化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cilium 和 BGP&lt;/strong&gt;
在版本 1.10 中，Cilium 集成了对 MetalLB 的 BGP 支持，从而使其能够宣布 Kubernetes 服务的 IP 地址类型为&lt;a href=&#34;https://sue.eu/insights/bgp-load-balancing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 BGP 的 LoadBalancer&lt;/a&gt;。其结果是，服务可以从 Kubernetes 网络外部访问，无需额外的组件，例如 Ingress 路由器。特别是“无需额外组件”的部分是令人振奋的消息，因为每个组件都会增加延迟，因此没有额外组件会减少延迟。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f1_hu17139992351346066106.webp 400w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f1_hu12620491286267683060.webp 760w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f1_hu12416264946635966108.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f1_hu17139992351346066106.webp&#34;
               width=&#34;760&#34;
               height=&#34;664&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;此示例中显示的网络配置代表了具有用于服务负载均衡的 BGP 集成的基于 Kubernetes 的环境。以下是配置的详细信息：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;客户端网络（LAN 网络）：&lt;/strong&gt; 存在一个具有 IP 范围 192.168.10.0/24 的本地区域网络（LAN），连接了多个客户端。该网络包含了设置的用户端，用户和其他设备可以在其中访问托管在 Kubernetes 集群上的服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kubernetes 网络：&lt;/strong&gt; Kubernetes 集群具有自己的网络空间，由子网 192.168.1.0/24 指定。该网络包括 Kubernetes 主节点（k8s-master1）和多个工作节点（从 k8s-worker1 到 k8s-worker5）。这些节点托管了 Kubernetes 集群的实际容器和工作负载。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;管理网络：&lt;/strong&gt; 一个独立的管理网络，至少有一个设备（k8s-control）用于控制和管理 Kubernetes 集群。这与 Kubernetes 数据平面分开，以确保安全性和管理效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BGP 路由器：&lt;/strong&gt; bgp-router1 桥接了外部网络/互联网和 Kubernetes 网络。它负责使用 BGP 来广播路由将流量路由到 Kubernetes 集群中的适当服务。IP 范围 172.16.10.0/24 保留供 Kubernetes 集群内的 LoadBalancer 服务使用。当将 Kubernetes 服务公开为 LoadBalancer 时，它会分配一个来自此池的 IP 地址。然后，BGP 路由器将此 IP 广播到外部网络，从而使流量路由到 LoadBalancer 服务。&lt;/p&gt;
&lt;p&gt;此网络配置允许通过利用 BGP 进行 IP 地址管理和路由来实现运行在 Kubernetes 集群上的服务的可扩展和灵活的负载均衡。它将客户端访问、集群管理和服务流量分别分隔到不同的网络中，以进行组织和安全性目的。&lt;/p&gt;
&lt;h2 id=&#34;暴露服务&#34;&gt;暴露服务&lt;/h2&gt;
&lt;p&gt;一旦构建了上述基础架构，就可以创建一个部署并使用 BGP 将其暴露给网络。让我们从一个部署开始，其中包含一个简单的 NGINX Web 服务器，提供默认的 Web 页面。我们还添加了一个类型为 LoadBalancer 的 Service。这将导致使用 BGP 向我们的路由器宣布外部 IP 地址。&lt;/p&gt;
&lt;p&gt;一旦构建完成，命令 &lt;code&gt;kubectl get svc&lt;/code&gt; 显示我们的服务具有外部 IP 地址：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;NAME          TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)         AGE
kubernetes    ClusterIP      10.96.0.1        &amp;lt;none&amp;gt;            443/TCP         7d3h
web1-lb       LoadBalancer   10.106.236.120   172.16.10.0       80:30256/TCP    7d2h
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;172.16.10.0 这个地址看起来很奇怪，但没问题。通常会跳过.0 地址，而使用.1 地址作为第一个地址。其中一个原因是在早期，.0 地址用于广播，后来改为.255。由于.0 仍然是一个有效的地址，负责地址池的 MetalLB 会将其分配为第一个地址。在路由器 bgp-router1 上运行的命令 &lt;code&gt;vtysh -c &#39;show bgp summary&#39;&lt;/code&gt; 显示它已接收到一个前缀：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;IPv4 Unicast Summary:
BGP router identifier 192.168.1.1, local AS number 64512 vrf-id 0
BGP table version 17
RIB entries 1, using 192 bytes of memory
Peers 6, using 128 KiB of memoryNeighbour V AS MsgRcvd MsgSent TblVer InQ OutQ Up/Down State/PfxRcd PfxSnt
192.168.1.10 4 64512 445 435 0 0 0 03:36:56 1 0
192.168.1.21 4 64512 446 435 0 0 0 03:36:54 1 0
192.168.1.22 4 64512 445 435 0 0 0 03:36:56 1 0
192.168.1.23 4 64512 445 435 0 0 0 03:36:56 1 0
192.168.1.24 4 64512 446 435 0 0 0 03:36:56 1 0
192.168.1.25 4 64512 445 435 0 0 0 03:36:56 1 0

Total number of neighbors 6
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;路由表的以下片段（ip route）告诉我们，对于特定的 IP 地址 172.16.10.0，存在 6 个可能的路由/目标。换句话说，所有 Kubernetes 节点都宣布它们正在处理该地址的流量。太棒了！！&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;172.16.10.0 proto bgp metric 20
nexthop via 192.168.1.10 dev enp7s0 weight 1
nexthop via 192.168.1.21 dev enp7s0 weight 1
nexthop via 192.168.1.22 dev enp7s0 weight 1
nexthop via 192.168.1.23 dev enp7s0 weight 1
nexthop via 192.168.1.24 dev enp7s0 weight 1
nexthop via 192.168.1.25 dev enp7s0 weight 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;实际上，现在从我们的路由器上可以看到 Web 页面。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ curl -s -v http://172.16.10.0/ -o /dev/null

* Trying 172.16.10.0…
* TCP_NODELAY set
* Connected to 172.16.10.0 (172.16.10.0) port 80 (#0)
&amp;gt; GET / HTTP/1.1
&amp;gt; Host: 172.16.10.0
&amp;gt; User-Agent: curl/7.61.1
&amp;gt; Accept: */*
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Server: nginx/1.21.3
&amp;lt; Date: Sun, 31 Oct 2023 14:19:17 GMT
&amp;lt; Content-Type: text/html
&amp;lt; Content-Length: 615
&amp;lt; Last-Modified: Tue, 07 Sep 2023 15:21:03 GMT
&amp;lt; Connection: keep-alive
&amp;lt; ETag: “6137835f-267”
&amp;lt; Accept-Ranges: bytes&amp;gt;
{ [615 bytes data]}
* Connection #0 to host 172.16.10.0 left intact
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;而且，位于我们客户端网络中的客户端也可以访问相同的页面，因为它使用 bgp-router1 作为默认路由。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f2_hu12330485717108373314.webp 400w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f2_hu8752192660279871172.webp 760w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f2_hu16388573192024680154.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f2_hu12330485717108373314.webp&#34;
               width=&#34;598&#34;
               height=&#34;345&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;更多细节&#34;&gt;更多细节&lt;/h2&gt;
&lt;p&gt;现在一切都运作正常，大多数工程师都想看到更多细节，所以我不会让你失望。&lt;/p&gt;
&lt;h3 id=&#34;ping&#34;&gt;Ping&lt;/h3&gt;
&lt;p&gt;你将注意到的第一件事是，LoadBalancer 的 IP 地址无法通过 ping 访问。深入挖掘一下可以揭示原因。我们创建了源端口 80 和目标端口 80 之间的映射。此映射在接口上使用 eBPF 逻辑执行，并存在于所有节点上。此映射确保只有端口 80 的流量被均衡。所有其他流量，包括 ping，都不被接收。这就是为什么你可以看到 icmp 数据包到达节点，但从未发送响应的原因。&lt;/p&gt;
&lt;h3 id=&#34;观察流量&#34;&gt;观察流量&lt;/h3&gt;
&lt;p&gt;Hubble 是建立在 eBPF 和 Cilium 之上的网络和安全性可观测平台。通过命令行和图形 Web GUI，可以查看当前和历史流量。在这个示例中，Hubble 放置在 k8s-control 节点上，该节点直接访问 Hubble Relay 的 API。Hubble Relay 是从 Cilium 节点获取所需信息的组件。请注意，Hubble 命令也存在于每个 Cilium 代理 Pod 中，但那个命令只会显示特定代理的信息！以下输出显示了从路由器上执行 curl http://172.16.10.0/ 命令后的观察者信息。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ hubble observe –namespace default –follow

Oct 31 15:43:41.382: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: SYN)
Oct 31 15:43:41.384: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK)
Oct 31 15:43:41.384: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK, PSH)
Oct 31 15:43:41.385: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK)
Oct 31 15:43:41.385: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK)
Oct 31 15:43:41.386: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK, FIN)
Oct 31 15:43:41.386: 192.168.1.1:36946 &amp;lt;&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-overlay FORWARDED (TCP Flags: ACK)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;之前，我警告过不要在 Cilium 代理 Pod 内使用 hubble 命令，但在特定节点流量中看到具体的情况也可以非常有信息价值。在这种情况下，每个 Cilium 代理 Pod 中都执行了 &lt;code&gt;hubble observe –namespace default –follow&lt;/code&gt;，并且路由器的 curl 执行了一次。&lt;/p&gt;
&lt;p&gt;在托管 Pod 的节点（k8s-worker2）上，我们看到与上面的输出相同的输出。但是，在另一个 Pod（k8s-worker1）上，我们看到以下输出：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Oct 31 15:56:05.220: 10.0.3.103:48278 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: SYN)
Oct 31 15:56:05.220: 10.0.3.103:48278 &amp;lt;- default/web1-696bfbbbc4-jnxbc:80 to-stack FORWARDED (TCP Flags: SYN, ACK)
Oct 31 15:56:05.220: 10.0.3.103:48278 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK)
Oct 31 15:56:05.221: 10.0.3.103:48278 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Oct 31 15:56:05.221: 10.0.3.103:48278 &amp;lt;- default/web1-696bfbbbc4-jnxbc:80 to-stack FORWARDED (TCP Flags: ACK, PSH)
Oct 31 15:56:05.222: 10.0.3.103:48278 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Oct 31 15:56:05.222: 10.0.3.103:48278 &amp;lt;- default/web1-696bfbbbc4-jnxbc:80 to-stack FORWARDED (TCP Flags: ACK, FIN)
Oct 31 15:56:05.222: 10.0.3.103:48278 -&amp;gt; default/web1

-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK)
Oct 31 15:56:12.739: 10.0.4.105:36956 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: SYN)
Oct 31 15:56:12.739: default/web1-696bfbbbc4-jnxbc:80 &amp;lt;&amp;gt; 10.0.4.105:36956 to-overlay FORWARDED (TCP Flags: SYN, ACK)
Oct 31 15:56:12.742: 10.0.4.105:36956 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK)
Oct 31 15:56:12.742: 10.0.4.105:36956 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Oct 31 15:56:12.745: default/web1-696bfbbbc4-jnxbc:80 &amp;lt;&amp;gt; 10.0.4.105:36956 to-overlay FORWARDED (TCP Flags: ACK, PSH)
Oct 31 15:56:12.749: 10.0.4.105:36956 -&amp;gt; default/web1-696bfbbbc4-jnxbc:80 to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Oct 31 15:56:12.749: default/web1-696bfbbbc4-jnxbc:80 &amp;lt;&amp;gt; 10.0.4.105:36956 to-overlay FORWARDED (TCP Flags: ACK, FIN)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们在这里看到的是，我们的路由器将 IP 地址 172.16.10.0 的流量发送到 k8s-worker1，但该工作节点不托管我们的 web1 容器，因此它将流量转发到处理流量的 k8s-worker2。所有的转发逻辑都使用 eBPF 处理 - 附加到接口的一个小的 BPF 程序将在需要时发送流量和路由到另一个工作节点。这也是为什么在 k8s-worker1 上运行 tcpdump，初始接收到流量的地方，不会显示任何流量的原因。它已经在进入 k8s-worker1 的 IP 堆栈之前被重定向到 k8s-worker2。&lt;/p&gt;
&lt;p&gt;我们的合作伙伴 &lt;a href=&#34;https://docs.cilium.io/en/stable/network/ebpf/intro/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Isovalent&lt;/a&gt; 有很多关于 eBPF 和内部工作原理的信息。如果你还没有听说过 eBPF，而且你对 Linux 和/或网络感兴趣，请务必探索一下基础知识。在我看来，eBPF 将在不久的将来彻底改变 Linux 的网络，特别是对于云原生环境！&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cilium.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cilium.io &lt;/a&gt;上有很多关于 eBPF 和内部工作原理的信息。如果你还没有听说过 eBPF，而且你对 Linux 和/或网络感兴趣，请务必了解至少基础知识。在我看来，eBPF 将在不久的将来彻底改变 Linux 的网络，特别是对于云原生环境！&lt;/p&gt;
&lt;h3 id=&#34;hubble-web-gui&#34;&gt;Hubble Web GUI&lt;/h3&gt;
&lt;p&gt;通过一个工作正常的 BGP 设置，使 Hubble Web GUI 对外界也很简单。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f3_hu1142106117073934098.webp 400w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f3_hu4509585424755433923.webp 760w,
               /blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f3_hu9447684038416519056.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/expose-loadbalanced-kubernetes-services-with-bgp-cilium/f3_hu1142106117073934098.webp&#34;
               width=&#34;760&#34;
               height=&#34;419&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;最后的话&#34;&gt;最后的话&lt;/h2&gt;
&lt;p&gt;通过 MetalLB 的集成，使用 BGP 设置 Cilium 变得非常简单，消除了昂贵的网络硬件的需求。Cilium/BGP 的这种组合，特别是与停用 kube-proxy 结合使用，显著降低了到云端服务的延迟。它还通过仅宣布 LoadBalancer 的 IP 地址来增强安全性和透明性。虽然这种设置不需要 Ingress Controller，但对于大多数 HTTP 服务仍然建议使用一个。像 NGINX 或 Traefik 这样的控制器，通过 BGP 公开，提供协议级别的重写和请求速率限制等重大优势。&lt;/p&gt;
&lt;p&gt;这种云原生和基于 Linux 的网络的进步确实是一个飞跃，标志着网络技术的激动人心的时代！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>深入了解 Cilium 多集群</title>
      <link>https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/</link>
      <pubDate>Wed, 03 Jul 2019 10:59:29 +0800</pubDate>
      <guid>https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/</guid>
      <description>&lt;p&gt;本文是对 ClusterMesh（Cilium 的多集群实现）的深入研究。简而言之，ClusterMesh 提供：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过隧道或直接路由，以本地性能对多个 Kubernetes 集群进行 Pod IP 路由，而无需任何网关或代理。&lt;/li&gt;
&lt;li&gt;使用标准Kubernetes服务和coredns/kube-dns的透明服务发现。&lt;/li&gt;
&lt;li&gt;跨多个集群的网络策略实施。策略可以指定为 Kubernetes NetworkPolicy 资源或扩展的 CiliumNetworkPolicy CRD。&lt;/li&gt;
&lt;li&gt;透明加密，用于本地集群中的节点之间以及跨集群边界的所有通信。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-f7dca3e31d252eb9_hu17085129932418850627.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-f7dca3e31d252eb9_hu5826251090128261030.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-f7dca3e31d252eb9_hu6777756629970641623.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-f7dca3e31d252eb9_hu17085129932418850627.webp&#34;
               width=&#34;736&#34;
               height=&#34;213&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;多集群功能以层为单位构建，您可以选择使用所有层，也可以仅选择和使用所需的层。&lt;/p&gt;
&lt;h2 id=&#34;用例&#34;&gt;用例&lt;/h2&gt;
&lt;p&gt;在深入研究实现细节之前，让我们回顾一下连接多个 Kubernetes 集群的一些用例。&lt;/p&gt;
&lt;h3 id=&#34;用例高可用性&#34;&gt;用例：高可用性&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-5d69ac8aba6c7b47_hu16901984189218755898.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-5d69ac8aba6c7b47_hu5313086969820559805.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-5d69ac8aba6c7b47_hu12347367708238975283.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-5d69ac8aba6c7b47_hu16901984189218755898.webp&#34;
               width=&#34;760&#34;
               height=&#34;254&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;对于大多数人来说，高可用性是最明显的用例。此用例包括在多个区域（regions）或可用区（availability zones）中运行 Kubernetes 集群，并在每个集群中运行相同服务的副本。一旦失败，请求可以故障转移到其他集群。此用例中涵盖的故障情形主要不是整个区域或故障域的完全不可用。更可能的情况是一个集群中资源暂时不可用或配置错误导致无法在一个集群中运行或扩展特定服务。&lt;/p&gt;
&lt;h3 id=&#34;用例共享服务&#34;&gt;用例：共享服务&lt;/h3&gt;
&lt;p&gt;基于 Kubernetes 的平台的最初趋势是构建大型多租户 Kubernetes 集群。为每个租户构建单个集群或为不同类别的服务构建集群越来越普遍，例如，不同级别的安全敏感度。
















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-c950c8dfbc5a9b0d_hu8136292475997423128.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-c950c8dfbc5a9b0d_hu3155154496986589740.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-c950c8dfbc5a9b0d_hu15667908027497430175.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-c950c8dfbc5a9b0d_hu8136292475997423128.webp&#34;
               width=&#34;760&#34;
               height=&#34;330&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;

但是，某些服务（如密钥管理，日志记录，监控或 DNS）通常仍在所有集群之间共享。这避免了在每个租户集群中维护这些服务的操作开销。&lt;/p&gt;
&lt;p&gt;此模型的主要动机是租户集群之间的隔离，为了维持该目标，租户集群连接到共享服务集群但未连接到其他租户集群。&lt;/p&gt;
&lt;h3 id=&#34;用例拆分有状态和无状态服务&#34;&gt;用例：拆分有状态和无状态服务&lt;/h3&gt;
&lt;p&gt;运行有状态或无状态服务的操作复杂性是非常不同的。无状态服务易于扩展，迁移和升级。完全使用无状态服务运行集群可使集群保持灵活和敏捷。从一个云提供商迁移到另一个云提供商非常简单。&lt;/p&gt;
&lt;p&gt;有状态服务可能会引入潜在的复杂依赖链。迁移服务通常涉及存储迁移。
















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-98e2a381af81e811_hu17853829345605420170.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-98e2a381af81e811_hu9569792165351749812.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-98e2a381af81e811_hu475704729387347530.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-98e2a381af81e811_hu17853829345605420170.webp&#34;
               width=&#34;760&#34;
               height=&#34;358&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;

为无状态和有状态分别运行独立的集群允许将依赖复杂性隔离到较少数量的集群，并使无状态集群依赖性保持自由。&lt;/p&gt;
&lt;h2 id=&#34;控制平面&#34;&gt;控制平面&lt;/h2&gt;
&lt;h3 id=&#34;要求&#34;&gt;要求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;必须为所有 Kubernetes 工作节点分配唯一的 IP 地址，并且所有工作节点必须在彼此之间具有 IP 连接。&lt;/li&gt;
&lt;li&gt;必须为所有集群分配唯一的 PodCIDR 区间。&lt;/li&gt;
&lt;li&gt;必须将 Cilium 配置为使用 etcd 的 kvstore。&lt;/li&gt;
&lt;li&gt;集群之间的网络必须允许集群间通信。防火墙的具体配置要求将取决于 Cilium 是否配置为以直接路由或隧道模式运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;
&lt;p&gt;控制平面基于 etcd 并尽可能保持简约：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Kubernetes 集群都维护自己的 etcd 集群，包含该集群的状态。来自多个集群的状态永远不会在 etcd 本身中混淆。&lt;/li&gt;
&lt;li&gt;每个集群通过一组 etcd 代理公开它自己的 etcd。在其他集群中运行的 Cilium 代理连接到 etcd 代理以监视更改并将多集群相关状态复制到自己的集群中。使用 etcd 代理确保了 etcd 观察者的可扩展性。访问受 TLS 证书保护。&lt;/li&gt;
&lt;li&gt;从一个集群到另一个集群的访问始终是只读的。这确保了故障域保持不变，即一个集群中的故障永远不会传播到其他集群中。&lt;/li&gt;
&lt;li&gt;配置通过简单的 Kubernetes secrets 资源进行，该资源包含远程 etcd 代理的寻址信息以及访问 etcd 代理所需的集群名称和证书。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-47bf320d6635c354_hu1250032299561384066.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-47bf320d6635c354_hu6632571961826616296.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-47bf320d6635c354_hu7027712234457394568.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-47bf320d6635c354_hu1250032299561384066.webp&#34;
               width=&#34;760&#34;
               height=&#34;261&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;pod-ip-路由&#34;&gt;Pod IP 路由&lt;/h2&gt;
&lt;p&gt;pod IP 路由是多集群能力的基础。它允许跨集群的 pod 通过其 pod IP 相互联系。Cilium 可以在多种模式下运行以执行 pod IP 路由。所有这些模式都能够执行多集群 pod IP 路由。&lt;/p&gt;
&lt;h3 id=&#34;隧道模式&#34;&gt;隧道模式&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-1488d363a7db42ae_hu6591244851198071406.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-1488d363a7db42ae_hu976974157135323844.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-1488d363a7db42ae_hu17382070923324712533.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-1488d363a7db42ae_hu6591244851198071406.webp&#34;
               width=&#34;706&#34;
               height=&#34;239&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;隧道模式将 pod 中发出的所有网络数据包封装在所谓的封包头中。封包头可以包含 VXLAN 或 Geneve 帧。然后通过标准 UDP 包头传输该封装帧。该概念类似于 VPN 隧道。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：pod IP 在底层网络上永远不可见。网络只能看到工作节点的 IP 地址。这可以简化安装和防火墙规则。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：所需的额外网络标头将降低网络的理论最大吞吐量。确切的成本取决于配置的 MTU，与使用 MTU 9000 的巨型帧相比，使用 1500 的传统 MTU 时会更加明显。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：为了不消耗过多 CPU，包括底层硬件在内的整个网络堆栈必须支持校验和和分段卸载，以计算校验和并在硬件中执行分段，就像对“常规”网络数据包所做的那样。如今，这种卸载功能的可用性非常常见。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;直接路由模式&#34;&gt;直接路由模式&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-51340f50bb80261e_hu1627120453731555862.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-51340f50bb80261e_hu1781074282010314897.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-51340f50bb80261e_hu5550878918420657340.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-51340f50bb80261e_hu1627120453731555862.webp&#34;
               width=&#34;706&#34;
               height=&#34;240&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在直接路由模式中，所有网络数据包都直接路由到网络。这要求网络能够路由 pod IP。可以使用多个选项实现跨节点传播 pod IP 路由信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;--auto-direct-node-routes&lt;/code&gt;选项，这是通过 kvstore 的超轻量级路由传播方法，如果所有工作节点共享一个单一的 2 层网络，该选项将起作用。对于所有形式的基于云提供商的虚拟网络，通常都满足此要求。&lt;/li&gt;
&lt;li&gt;使用&lt;a href=&#34;http://docs.cilium.io/en/stable/gettingstarted/kube-router/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kube-router 集成&lt;/a&gt;运行 BGP 路由守护进程。&lt;/li&gt;
&lt;li&gt;使用任何其他路由守护进程将路由注入标准 Linux 路由表（bird，quagga，&amp;hellip;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当网络不再理解 pod IP 时，网络数据包地址需要伪装。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：减少的网络数据包标头可以优化网络吞吐量和延迟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：整个网络必须能够路由 pod IP，这会增加操作的复杂性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;混合路由模式&#34;&gt;混合路由模式&lt;/h3&gt;
&lt;p&gt;混合路由模式允许在可用时使用直接路由，这通常在本地集群或同一 VPC 中的其他集群中，而当跨越 VPC 或云提供商时可以回退到隧道模式。这可以限制操作复杂性并且允许仅在需要时支付优化成本。&lt;/p&gt;
&lt;h2 id=&#34;服务发现&#34;&gt;服务发现&lt;/h2&gt;
&lt;p&gt;Cilium 的多集群模型的服务发现是使用标准的 Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;services&lt;/a&gt; 构建的，旨在对现有的 Kubernetes 应用程序部署完全透明：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rebel-base&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium/global-service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rebel-base&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Cilium 通过一个注释&lt;code&gt;io.cilium/global-service: &amp;quot;true&amp;quot;&lt;/code&gt; 来监控 Kubernetes 服务和端点以及监听服务。对于此类服务，具有相同名称和命名空间信息的所有服务将自动合并在一起，并形成跨集群可用的全局服务。&lt;/li&gt;
&lt;li&gt;根据标准 Kubernetes 运行状况检查逻辑，任何到全局服务的 ClusterIP 的流量都将自动负载平衡到所有集群中的端点。&lt;/li&gt;
&lt;li&gt;每个集群继续为每个服务维护自己的 ClusterIP，这意味着 Kubernetes 和 kube-dns / coredns 不知道其他集群。DNS 服务器继续返回仅在本地集群中有效的 ClusterIP，Cilium 将透明地执行负载平衡。&lt;/li&gt;
&lt;li&gt;对于细粒度控制存在若干附加注释，例如单向暴露或亲和策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-b027eb4bd91ead46_hu9853474422339413216.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-b027eb4bd91ead46_hu13838925419315329125.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-b027eb4bd91ead46_hu4403931876543021256.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-b027eb4bd91ead46_hu9853474422339413216.webp&#34;
               width=&#34;760&#34;
               height=&#34;255&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;从&lt;code&gt;frontend-1&lt;/code&gt;到 ClusterIP &lt;code&gt;30.1.1.1&lt;/code&gt;的所有流量将自动负载均衡到集群 1 的后端 pod IP&lt;code&gt;[10.0.0.1,10.0.0.2]&lt;/code&gt;以及集群 2 的后端 pod IP&lt;code&gt;[20.0.0.1,20.0.0.2]&lt;/code&gt;。每个集群将执行本地后端实例的运行状况检查，并在容器创建，销毁或变得不健康时通知其他集群。&lt;/p&gt;
&lt;h2 id=&#34;透明加密&#34;&gt;透明加密&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cilium.io/blog/2019/02/12/cilium-14/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cilium 1.4&lt;/a&gt;中引入的透明加密与多集群兼容。确保使用公共密钥配置所有集群中的所有节点，如此节点之间的所有通信都会自动加密。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-be3e56c01fa1ef78_hu4728088998317063515.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-be3e56c01fa1ef78_hu8858938170330283975.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-be3e56c01fa1ef78_hu6593934408789683492.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-be3e56c01fa1ef78_hu4728088998317063515.webp&#34;
               width=&#34;709&#34;
               height=&#34;209&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;多集群的网络策略&#34;&gt;多集群的网络策略&lt;/h2&gt;
&lt;p&gt;简单版本是您从单个集群中熟悉的策略实施将简单地扩展并跨集群工作。由于策略是使用 pod 标签指定的，因此允许&lt;code&gt;frontend&lt;/code&gt;与&lt;code&gt;backend&lt;/code&gt;通信的策略将应用于集群流量，就像流量跨越集群一样。&lt;/p&gt;
&lt;p&gt;Cilium&lt;strong&gt;不会&lt;/strong&gt;跨集群自动传播 NetworkPolicy 或 CiliumNetworkPolicy。用户有责任将策略导入所有集群。这是有意为之，因为这意味着每个集群都可以决定是否允许集群接收来自远程集群的通信或者发出到远程集群的通信。&lt;/p&gt;
&lt;h3 id=&#34;允许特定集群的交叉路径&#34;&gt;允许特定集群的交叉路径&lt;/h3&gt;
&lt;p&gt;可以仅建立适用于特定集群中的 pod 的策略。集群名称由 Cilium 表示为每个 pod 上的标签，允许匹配的集群名称可以是&lt;code&gt;endpointSelector&lt;/code&gt;或者是由&lt;code&gt;toEndpoints&lt;/code&gt;和&lt;code&gt;fromEndpoints&lt;/code&gt;构造的&lt;code&gt;matchLabels&lt;/code&gt;标签：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cilium.io/v2&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CiliumNetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;allow-cross-cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Allow x-wing in cluster1 to contact rebel-base in cluster2&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;endpointSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;x-wing&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.cluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;egress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;toEndpoints&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rebel-base&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.cluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的示例策略将允许 cluster1 中的&lt;code&gt;x-wing&lt;/code&gt;与 cluster2 中的&lt;code&gt;rebel-base&lt;/code&gt;对话。除非存在将通信列入白名单的附加策略，否则 x-wing 将无法与本地集群中的 rebel-base 通信。&lt;/p&gt;
&lt;h2 id=&#34;与-istio-多集群的关系&#34;&gt;与 Istio 多集群的关系&lt;/h2&gt;
&lt;p&gt;这两个项目都是独立的，但可以很好地相互补充。组合 Cilium 和 Istio 多集群的常用方法是使用 Cilium 的多集群 Pod IP 路由层来满足&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/multicluster-install/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 多集群指南&lt;/a&gt;的以下要求：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;每个集群中的所有 pod CIDR 必须可以相互路由。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;此外，Cilium 策略执行功能可用于保护与 Istio 控制平面之间的通信，以及通过不支持的协议（如 UDP 或 IPV6）保护 sidecar 的旁路尝试，以及防止受损的 sidecar 代理。&lt;/p&gt;
&lt;p&gt;还可以同时运行全局 Istio 服务和 Cilium 全局服务。所有 Istio 托管服务都可以获得 Cilium 的全局服务，因为它们可以像常规服务一样通过 DNS 发现。&lt;/p&gt;
&lt;h2 id=&#34;准备开始&#34;&gt;准备开始&lt;/h2&gt;
&lt;p&gt;要开始使用，请按照手把手的&lt;a href=&#34;http://docs.cilium.io/en/stable/gettingstarted/clustermesh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ClusterMesh 教程&lt;/a&gt;进行操作，该教程将指导您完成将集群连接在一起的过程。请务必加入我们的&lt;a href=&#34;https://cilium.herokuapp.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slack 频道&lt;/a&gt;，提出问题并展示您的设置。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-imagepng&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image.png&#34; srcset=&#34;
               /blog/deep-dive-into-cilium-multi-cluster/14871146-112faa9f90a9352b_hu7403041704781936186.webp 400w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-112faa9f90a9352b_hu5777493007704777402.webp 760w,
               /blog/deep-dive-into-cilium-multi-cluster/14871146-112faa9f90a9352b_hu4993875526942778769.webp 1200w&#34;
               src=&#34;https://cloudnativecn.com/blog/deep-dive-into-cilium-multi-cluster/14871146-112faa9f90a9352b_hu7403041704781936186.webp&#34;
               width=&#34;760&#34;
               height=&#34;264&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      image.png
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
