<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>网易 | 云原生社区（中国）</title>
    <link>https://cloudnative.to/tag/%E7%BD%91%E6%98%93/</link>
      <atom:link href="https://cloudnative.to/tag/%E7%BD%91%E6%98%93/index.xml" rel="self" type="application/rss+xml" />
    <description>网易</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Thu, 10 Feb 2022 09:24:17 +0800</lastBuildDate>
    <image>
      <url>https://cloudnative.to/media/sharing.png</url>
      <title>网易</title>
      <link>https://cloudnative.to/tag/%E7%BD%91%E6%98%93/</link>
    </image>
    
    <item>
      <title>网易开源 Envoy 企业级自定义扩展框架 Hango Rider 简介</title>
      <link>https://cloudnative.to/blog/hango-rider/</link>
      <pubDate>Thu, 10 Feb 2022 09:24:17 +0800</pubDate>
      <guid>https://cloudnative.to/blog/hango-rider/</guid>
      <description>&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;：王凯，网易数帆高级工程师，主要负责轻舟微服务、轻舟 API 网关等相关产品数据面研发、扩展增强等工作。对于数据面 Envoy 扩展增强、实践落地具备丰富的经验。&lt;/p&gt;
&lt;p&gt;可扩展性是网络代理软件最为关键的特性之一，灵活强大的可扩展性可以大大拓展网络代理软件的能力边界。作为新兴的开源高性能网络代理软件，Envoy 本身提供了相对丰富的可扩展能力，如基于 C++ 的原生扩展，基于 WASM/Lua 的动态扩展。但是 Envoy 现有可扩展能力都各自存在其局限性。在大规模落地实践 Envoy 网关/网格过程中，网易数帆为 Envoy 实现了一套基于 Lua 的企业级自定义扩展框架-Rider，应用于轻舟微服务平台，满足业务方所需要的易开发、高性能、功能丰富等各项要求。
目前，&lt;a href=&#34;https://github.com/hango-io/rider&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rider&lt;/a&gt; 扩展框架已经全面开源，并且被集成于开源 API 网关 &lt;a href=&#34;https://github.com/hango-io/hango-gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hango&lt;/a&gt; 当中，为 Hango 网关提供了灵活、强大、易用的自定义扩展能力。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/000_hud068544e2ecba73232901d83c215d324_29890_41c9acce0e6ca9c274005931422ab137.webp 400w,
               /blog/hango-rider/000_hud068544e2ecba73232901d83c215d324_29890_9fcbc950c44748b3cf41fdaa91501c39.webp 760w,
               /blog/hango-rider/000_hud068544e2ecba73232901d83c215d324_29890_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/000_hud068544e2ecba73232901d83c215d324_29890_41c9acce0e6ca9c274005931422ab137.webp&#34;
               width=&#34;708&#34;
               height=&#34;285&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;1-envoy-的可扩展性现状&#34;&gt;1. Envoy 的可扩展性现状&lt;/h2&gt;
&lt;p&gt;在互联网体系下，凡是需要对外暴露的系统几乎都需要网络代理：较早出现的 HAProxy、Nginx 至今仍在流行；进入微服务时代后，功能更丰富、管控能力更强的 API 网关又成为流量入口必备组件。Envoy 因为其优异的性能、可扩展性、可观察性等优势，成为大量 API 网关的数据面选型，并且除了流量代理所需的基本功能外，Envoy 原生已经实现了很多代理所需高级功能，如高级负载均衡、熔断、限流等。因此，基于 Envoy 构建的 API 网关本身已经具备较为丰富的功能，能满足大部分应用代理的需求。但是在 API 网关的实际使用场景中，某些应用或者业务会根据自己的需求扩展出新的功能，可能是对 HTTP 的某些 Header 做些简单的处理，也可能是对接自己的 APM 等，因此 API 网关必须具备可扩展的能力以支撑应用或者业务根据自己的需求扩展相应的功能，而这个能力 Envoy 依然可以胜任，可以说基于 Envoy 实现的 API 网关的可扩展性强依赖于 Envoy 提供的可扩展能力。那么接下来我们就看一下目前 Envoy 提供的扩展机制。&lt;/p&gt;
&lt;h3 id=&#34;11-原生-c-扩展&#34;&gt;1.1 原生 C++ 扩展&lt;/h3&gt;
&lt;p&gt;Envoy 通过可插拔的过滤器机制实现了原生 C++ 插件扩展的能力，如下图所示，L4 过滤器负责扩展协议代理能力及 L4 流量治理能力，L7 过滤器实现对流量的丰富治理功能。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/001_huda6021e5a7d2ae4f48956bc652f702e7_31403_a8889f51b4e5708b7319b7040580828d.webp 400w,
               /blog/hango-rider/001_huda6021e5a7d2ae4f48956bc652f702e7_31403_cd522ee7744cd01892d58df3327fd427.webp 760w,
               /blog/hango-rider/001_huda6021e5a7d2ae4f48956bc652f702e7_31403_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/001_huda6021e5a7d2ae4f48956bc652f702e7_31403_a8889f51b4e5708b7319b7040580828d.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这种扩展方式由于是 Envoy 原生提供的能力，因此性能自然是最佳的，但同时面临两个主要的问题，一个是插件开发者需要具有 C++ 语言的开发能力，另外是插件开发完后需要重新编译 Envoy 二进制文件再升级部署，无法做到插件功能的动态加载。为了解决这两个问题，Envoy 社区陆续实现了基于 Lua 和 WASM 的扩展机制，我们先看社区 Lua 扩展的原理。&lt;/p&gt;
&lt;h3 id=&#34;12-社区-lua-扩展&#34;&gt;1.2 社区 Lua 扩展&lt;/h3&gt;
&lt;p&gt;要想使用 Lua 语言开发原本使用 C++ 语言实现的 Envoy 插件，直观来看需要考虑以下两点：一个是 Lua 脚本如何在 Envoy 进程中执行；另一个是 Lua 脚本如何获得 Envoy 的内部数据和功能，比如 Header、Body 的获取。从这两个角度出发可以比较清晰的看一下 Envoy 社区 Lua 扩展的实现（其实 WASM 和 Rider 也是从这两个角度出发）。&lt;/p&gt;
&lt;p&gt;如下图，和上面介绍的原生 C++ 扩展方案不同的是在 Envoy 的七层插件中多了个 Lua 插件，而这个用 C++ 开发的 Lua 插件就是回答上面两个问题的关键。首先 Lua 脚本如何在 Envoy 进程中执行，答案是通过 Lua 插件，Envoy 的 Lua 插件本身依然是用 C++ 开发的，因此可以在 Lua 插件中加载并运行 Lua 脚本；其次是 Lua 脚本如何获得 Envoy 的内部数据和功能，答案是 Lua 插件会通过 Lua CAPI 的形式提供 Envoy 内部数据和功能给 Lua 脚本。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/002_hua1fac75071c8379a6a80e88e85895623_30201_b8e1fad6b21b547c94f748a2e6524358.webp 400w,
               /blog/hango-rider/002_hua1fac75071c8379a6a80e88e85895623_30201_5d08ee321a6a7ebc048de3603985c21e.webp 760w,
               /blog/hango-rider/002_hua1fac75071c8379a6a80e88e85895623_30201_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/002_hua1fac75071c8379a6a80e88e85895623_30201_b8e1fad6b21b547c94f748a2e6524358.webp&#34;
               width=&#34;760&#34;
               height=&#34;245&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;社区 Lua 扩展一方面提供给了用户基于 Lua 语言开发插件的能力，相比 C++ 要简单很多，另一方面支持 Envoy 动态加载 Lua 脚本，无需重新编译升级。但同时由于 C++ 和 Lua 虚拟机交互带来的开销，Lua 扩展的性能自然会比原生 C++ 扩展差，而且 Envoy 社区当前的 Lua CAPI 交互方式会进一步加剧性能问题。除了性能问题，社区的 Lua 扩展还有个更大的缺陷 —— 不支持插件配置，直接导致社区 Lua 扩展的实用性大大下降。相比之下，WASM 和 Rider 实现了插件的可配置化，并且 Rider 针对 Lua 扩展的性能做了一定的优化，使得 Rider 的 Lua 扩展在性能和功能方面都能满足企业级扩展的需求。&lt;/p&gt;
&lt;h3 id=&#34;13-社区-wasm-扩展&#34;&gt;1.3 社区 WASM 扩展&lt;/h3&gt;
&lt;p&gt;WASM 是源自前端的技术，是为了解决日益复杂的前端 Web 应用以及有限的 JS 脚本解释性能而诞生的技术。WASM 并不是一种语言，而是字节码标准。理论上任何一种语言，都可以被编译成 WASM 字节码，然后在 WASM 虚拟机中执行。&lt;/p&gt;
&lt;p&gt;WASM 扩展的实现原理和 Lua 扩展本质上差不多，在 Envoy 自身的四层或者七层插件中会实现一个 WASM 插件，该插件会嵌入 WASM 虚拟机用于动态加载和运行可拔插的扩展代码（被编译为 WASM 字节码），并且也会通过 WASM 虚拟机暴露获取 Envoy 内部数据和功能的接口。其原理如下图所示：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/003_hu4cef6522171451d36f81dfcb97a2193c_63279_272302fefc414aacaccdf22ff8ebd632.webp 400w,
               /blog/hango-rider/003_hu4cef6522171451d36f81dfcb97a2193c_63279_761caf0d6871cf996b9995750005cc41.webp 760w,
               /blog/hango-rider/003_hu4cef6522171451d36f81dfcb97a2193c_63279_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/003_hu4cef6522171451d36f81dfcb97a2193c_63279_272302fefc414aacaccdf22ff8ebd632.webp&#34;
               width=&#34;760&#34;
               height=&#34;224&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;WASM 看上去似乎完美解决了 Envoy 可扩展性遇到的各种问题，它支持多语言，支持插件动态加载，同时支持插件配置，但是经过我们的测试，WASM 倒在了性能的血泊中，它基于 C++ 扩展的插件性能甚至都要比 Lua 扩展差，更不用说基于其他语言实现的插件（具体的性能对比结果会在第三部分）。&lt;/p&gt;
&lt;h3 id=&#34;14-总结&#34;&gt;1.4 总结&lt;/h3&gt;
&lt;p&gt;如下表，我们总结了当前各种扩展性方案的特性：原生 C++ 扩展虽然性能最优，但是不支持插件的动态加载；社区 Lua 扩展支持了插件的动态加载，但是却不支持插件配置，几乎不可使用；社区 WASM 扩展既支持插件的动态加载，又支持插件配置，但是性能很差。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;扩展方案&lt;/th&gt;
&lt;th&gt;是否支持插件配置&lt;/th&gt;
&lt;th&gt;是否支持动态扩展&lt;/th&gt;
&lt;th&gt;性能&lt;/th&gt;
&lt;th&gt;支持语言&lt;/th&gt;
&lt;th&gt;开发复杂度&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;原生 C++&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;最优&lt;/td&gt;
&lt;td&gt;C++&lt;/td&gt;
&lt;td&gt;复杂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;社区 Lua&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;较差&lt;/td&gt;
&lt;td&gt;Lua&lt;/td&gt;
&lt;td&gt;简单&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;社区 WASM&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;C++/Rust/Go 等&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;根据上述各种扩展性方案的优劣势，网易轻舟微服务设计并实现了自己的可扩展框架 Rider，主要的设计目标如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持 Lua 语言扩展&lt;/li&gt;
&lt;li&gt;支持 Envoy 动态加载、更新、移除 Lua 插件&lt;/li&gt;
&lt;li&gt;支持定义 Lua 插件配置&lt;/li&gt;
&lt;li&gt;支持自定义 Lua 插件生效范围，网关级/项目级/路由级&lt;/li&gt;
&lt;li&gt;性能优于 Envoy 社区 Lua 扩展和 WASM 扩展&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来具体看一下 Rider 可扩展框架的设计、优化及实践。&lt;/p&gt;
&lt;h2 id=&#34;2-rider-可扩展框架的设计优化及实践&#34;&gt;2. Rider 可扩展框架的设计、优化及实践&lt;/h2&gt;
&lt;h3 id=&#34;21-早期探索&#34;&gt;2.1 早期探索&lt;/h3&gt;
&lt;p&gt;针对社区 Lua 扩展存在的性能差、不支持插件配置的问题，Rider 早期架构设计并实现了两个模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rider Filter：Rider Filter 是 Envoy 的七层插件，用于初始化和调用 Lua 代码，并且将 Envoy 内部的数据和功能通过 Lua CAPI 或 FFI 接口的形式提供给 Lua SDK 调用。注意这里 Rider 利用 FFI 实现了大部分接口，理论上性能优于基于 CAPI 实现的社区 Lua 扩展；&lt;/li&gt;
&lt;li&gt;Lua SDK：Lua SDK 是一个 Lua 插件代码框架，用户可以通过调用 Lua SDK 提供的 API 实现请求处理。注意 Lua SDK 提供了获取全局以及路由级插件配置的 API，使得 Rider 的 Lua 扩展支持插件配置的获取，解决了社区 Lua 扩展的大难题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是整体的架构图：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/004_hubc5f5af8f9dbb225d7b49183134b4b4b_109708_c1a248771ef97fdfc69874894eafb335.webp 400w,
               /blog/hango-rider/004_hubc5f5af8f9dbb225d7b49183134b4b4b_109708_3814c427d420be230291646244d7ee24.webp 760w,
               /blog/hango-rider/004_hubc5f5af8f9dbb225d7b49183134b4b4b_109708_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/004_hubc5f5af8f9dbb225d7b49183134b4b4b_109708_c1a248771ef97fdfc69874894eafb335.webp&#34;
               width=&#34;760&#34;
               height=&#34;597&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;尽管我们的早期架构基本满足了 Envoy 可扩展性的需求：支持多语言 Lua、支持 Lua 插件动态加载、支持 Lua 插件配置等。但是仍然存在以下几个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rider Filter 仍然存在部分接口没有使用 FFI，性能可能略有不足；&lt;/li&gt;
&lt;li&gt;Lua SDK 需要进一步完善以支持更多的插件功能开发；&lt;/li&gt;
&lt;li&gt;在解决第一个问题过程中发现的 Rider 巨大性能问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对这几个问题，我们进一步细化了 Rider 的架构，详细分析了 Rider 的性能，并衍生出了新的架构。&lt;/p&gt;
&lt;h3 id=&#34;22-实践优化&#34;&gt;2.2 实践优化&lt;/h3&gt;
&lt;p&gt;Rider 新架构要解决的第一个问题就是试图将 FFI 进行到底，根据之前的调研，Lua 调用 C 有两种方式，一种是通过原生的 CAPI，每次调用时都会分配一个栈空间 (和 Stack Frame 不同，是向 Heap 申请的一块连续内存)，通过栈空间传递参数和返回值。另一种方式是通过 Luajit 提供的 FFI 调用。FFI 的好处是，可以直接在 Lua 中调用 C 函数，使用 C 数据结构，代码可以获得 Jit 优化的 Buff，性能较原生的 Lua 有比较大的提升。因此，我们想把 Rider 中使用 CAPI 实现的接口改造成 FFI。&lt;/p&gt;
&lt;p&gt;改造的第一步便遇到了问题，早期的 Rider 架构貌似无法使用 FFI 实现 Envoy Body 相关接口的暴露，我们先看一下早期 Rider 不得不使用原生的 CAPI 暴露 Envoy Body 相关接口的原因。早期 Rider 的架构图中 Lua Code 有两个主要的函数：on_request 和 on_response，这两个函数是 Rider 架构规定的 Lua 代码中需要实现的函数，因为 Rider Filter 在执行 Lua Code 时，Rider Filter 只会尝试从 Lua 虚拟机中获取这两个函数，然后分别在 decodeHeaders 阶段和 encodeHeaders 阶段执行，那么如果在 on_request 或者 on_response 函数中有 Body 相关的接口调用，此时 Rider Filter 还没执行到 decodeData 或者 encodeData 阶段，Body 的数据还获取不到，只能将 Lua 协程先挂起，等到 Rider Filter 执行到 decodeData 或者 encodeData 阶段时再 Resume，而这种方式 FFI 实现不了，只能通过和 Lua 虚拟机交互的方式实现。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/005_hu3726cd9308e2b4b8c39fd3a97f66f6f5_74059_14f43dbbfbff4ed131a81f8552a1d79b.webp 400w,
               /blog/hango-rider/005_hu3726cd9308e2b4b8c39fd3a97f66f6f5_74059_c9cdfdb44f601612c343272b6843fd05.webp 760w,
               /blog/hango-rider/005_hu3726cd9308e2b4b8c39fd3a97f66f6f5_74059_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/005_hu3726cd9308e2b4b8c39fd3a97f66f6f5_74059_14f43dbbfbff4ed131a81f8552a1d79b.webp&#34;
               width=&#34;760&#34;
               height=&#34;681&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;基于上述问题，Rider 新架构在早期架构基础上进行了一些细化，如上图所示，整体架构的模块没有改变，改变的是 Rider 框架规定的 Lua 插件中需要实现的函数以及这些函数在 Rider Filter 中的执行时机。如上图所示，将原来 on_request 和 on_response 函数进一步拆分成 Header 和 Body 的阶段函数，并且在 Rider Filter 处理 Header 和 Body 阶段分别去调用，这样可以避免 Body 的处理需要挂起 Lua 协程（后来发现 WASM 的实现也是类似的细分）。因此新架构的请求处理流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rider 插件配置 (其中包含 Lua 插件配置) 作为 LDS 和 RDS 的一部分，通过 Pilot 下发；&lt;/li&gt;
&lt;li&gt;Envoy 对每个 HTTP 请求构造一条七层 Filter Chain, 其中包含 Rider Filter。Rider Filter 初始化时，会将 Lua SDK 模块和相应的插件从文件系统加载到 Lua VM 中；&lt;/li&gt;
&lt;li&gt;在请求处理阶段，Rider Filter 会在 Decode 和 Encode 阶段分别调用 Lua 代码的 on_request_header、on_request_body 和 on_response_header、on_response_body 方法；&lt;/li&gt;
&lt;li&gt;在用户 Lua 代码执行过程中，通过 Lua SDK 调用 Rider Filter 封装的相应接口，如获取，修改请求、响应信息，调用外部服务等，打印日志等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;221-性能优化&#34;&gt;2.2.1 性能优化&lt;/h4&gt;
&lt;p&gt;新架构设计的初衷是性能的提升，因此我们在新架构开发完第一时间便进行了性能测试，测试场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;环境：本地容器环境&lt;/li&gt;
&lt;li&gt;后端：Nginx 4 核&lt;/li&gt;
&lt;li&gt;Envoy：4 核&lt;/li&gt;
&lt;li&gt;Client：Wrk 4t 32c&lt;/li&gt;
&lt;li&gt;Lua 插件：调用 100 次 get_body 接口&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对比实现方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CAPI：Rider 的 CAPI 实现，原始的 Lua 和 C 的交互方式，通过栈空间传递参数和返回值；&lt;/li&gt;
&lt;li&gt;FFIOld：Rider 的早期 FFI 实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;测试结果如下图，经典负优化，而且负的很多（当然也是因为调用了 100 次的原因），FFIOld 相比 CAPI QPS 下降了 30%。第一想法是不是代码写的有问题，新架构引入了很多开销？所以又测试了一下 Rider 之前基于 FFIOld 实现的 Header API，性能和基于 FFIOld 实现的 Body API 差不多，那说明 FFIOld 出问题了，早期的 Rider FFI 实现的 API 可能性能都还不如 CAPI！&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/006_hu34c5620f4f05ba05876b80b347eebd11_195966_4cfef43a51e2e0eb46d392728337b388.webp 400w,
               /blog/hango-rider/006_hu34c5620f4f05ba05876b80b347eebd11_195966_41f30e0510e78c101bc3ec3cbeffe587.webp 760w,
               /blog/hango-rider/006_hu34c5620f4f05ba05876b80b347eebd11_195966_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/006_hu34c5620f4f05ba05876b80b347eebd11_195966_4cfef43a51e2e0eb46d392728337b388.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;于是去了解了一下 FFI 的基本原理，FFI 是 Luajit 提供的特性，Luajit 是运行 Lua 的虚拟机，和 Java 虚拟机一样，Luajit 有两种运行模式：编译模式和解释模式（编译模式的性能比解释模式好，原因感兴趣可自行查找）。Luajit 默认运行在解释模式下，在运行过程中会记录可以编译的热点代码，在之后的运行中会尝试把热点代码直接翻译成机器码执行，性能会得到提升。&lt;/p&gt;
&lt;p&gt;回到 Rider 中来，Rider 的 Lua 插件也是运行在 Luajit 虚拟机中，并且几万的 QPS 请求一定会使 Lua 插件代码成为热点代码，那么 Luajit 会尝试把 Lua 插件翻译成机器码，同时 FFI 定义的 C 函数也会被翻译成机器码被执行，这么看起来性能确实会提升，但实际不符合预期，原因在于 Luajit 会 &lt;strong&gt;尝试&lt;/strong&gt; 把热点代码翻译成机器码，尝试就可能不成功，不成功就会退化成解释模式，那么性能会大打折扣。Luajit 提供了确认程序是否运行在编译模式下的方法，在 Lua 代码的前面加上如下代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;local verbo = require(&amp;#34;jit.v&amp;#34;)
verbo.start()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后继续压测，发现 Luajit 输出如下内容：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/007_hu53a3af6b1dfd514bca4cf5b50ebbd19d_196291_1decf1fda3d3d78bf9bebd311b338356.webp 400w,
               /blog/hango-rider/007_hu53a3af6b1dfd514bca4cf5b50ebbd19d_196291_7a7cb59e56f223587ba2489686a7c941.webp 760w,
               /blog/hango-rider/007_hu53a3af6b1dfd514bca4cf5b50ebbd19d_196291_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/007_hu53a3af6b1dfd514bca4cf5b50ebbd19d_196291_1decf1fda3d3d78bf9bebd311b338356.webp&#34;
               width=&#34;760&#34;
               height=&#34;131&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这张图可以看出两个关键信息，一个是如果 TRACE 输出 &amp;mdash; ，那么说明 Luajit 退出了编译模式；另一个是退出编译模式的原因是 FFI 定义的 C 函数中的某个形参类型转换不支持。接着往下定位到这个参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;function&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_header_map_value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_context_handle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;no context&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;string&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;header name must be a string&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;buffer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ffi_new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;envoy_lua_ffi_str_t[1]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;envoy_http_lua_ffi_get_header_map_value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FFI_OK&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ffi_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;C.envoy_http_lua_ffi_get_header_map_value(ctx, source, key, #key, buffer) 中传入的 ctx 是 Lua 的 light userdata 类型，而 envoy_http_lua_ffi_get_header_map_value 函数声明的时候是某个类的指针类型，Luajit 在翻译的时候无法完成转换因此退出了编译模式。真相大白，接下来就是解决这个问题，具体的设计过于细节不在这里阐述，感兴趣可以移步我们的开源社区。接下来看一下优化后的效果。&lt;/p&gt;
&lt;p&gt;首先还是接着上面的 get_body 性能测试，多加了一组 FFINew（优化后的 FFI 实现方式）的数据，如下图所示，FFINew 的性能比 FFIOld 的性能提升了 &lt;strong&gt;66%&lt;/strong&gt; ，相比 CAPI 的性能提升了 &lt;strong&gt;16%&lt;/strong&gt; ，FFI 的优势总算体现了出来。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/008_hud321333e57eea104a124e7791369c814_213764_a9d4624c988b021c40b811ec366fbbc8.webp 400w,
               /blog/hango-rider/008_hud321333e57eea104a124e7791369c814_213764_ada29b8f9bbdcedee2091868a64e37bb.webp 760w,
               /blog/hango-rider/008_hud321333e57eea104a124e7791369c814_213764_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/008_hud321333e57eea104a124e7791369c814_213764_a9d4624c988b021c40b811ec366fbbc8.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上面的性能提升可能只能作为参考，毕竟是调用了 100 次 get_body 接口，因此我们针对不同复杂度的插件分别进行了简单的性能测试：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;simple filter：调用 10 次 get_header；&lt;/li&gt;
&lt;li&gt;normal filter：调用 20 次 set_header，调用 10 次 get_header，最后再 remove 掉这 20 个 header；&lt;/li&gt;
&lt;li&gt;complex filter：normal filter + 调用 30 次 get_body；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结果如下图所示，FFINew 的性能都优于 FFIOld 的性能，分别有 15% ，22% ，29% 的性能提升。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/009_hu9f1ba0cd6098408e8e39a82191257a26_224663_1600fa91ab4e31f37ba1716936454c54.webp 400w,
               /blog/hango-rider/009_hu9f1ba0cd6098408e8e39a82191257a26_224663_0c8768dd09912bc5e3eca7210c9f8e3f.webp 760w,
               /blog/hango-rider/009_hu9f1ba0cd6098408e8e39a82191257a26_224663_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/009_hu9f1ba0cd6098408e8e39a82191257a26_224663_1600fa91ab4e31f37ba1716936454c54.webp&#34;
               width=&#34;760&#34;
               height=&#34;425&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后我们进一步将 Rider 和社区 WASM 和 Lua 的性能进行了对比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RiderOld：Rider 早期架构的实现；&lt;/li&gt;
&lt;li&gt;RiderNew：当前 Rider 的实现；&lt;/li&gt;
&lt;li&gt;WASMC++：社区 1.17 版本的 WASM 实现；&lt;/li&gt;
&lt;li&gt;RawLua：社区 1.17 版本的 Lua 扩展实现；&lt;/li&gt;
&lt;li&gt;RawC++：Envoy 原生 C++ 扩展实现；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/hango-rider/010_hucf3779113ecee7d037937dc405a605e5_262678_3067f19e4060c490e0010bb8247d26c4.webp 400w,
               /blog/hango-rider/010_hucf3779113ecee7d037937dc405a605e5_262678_066aa7287c28050057e07dc4754f03ff.webp 760w,
               /blog/hango-rider/010_hucf3779113ecee7d037937dc405a605e5_262678_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/hango-rider/010_hucf3779113ecee7d037937dc405a605e5_262678_3067f19e4060c490e0010bb8247d26c4.webp&#34;
               width=&#34;760&#34;
               height=&#34;426&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;如上图所示，Rider 的性能优于社区的 WASM 和 Lua，大概有 10% 左右的性能提升，且相比于 Envoy 原生 C++ 插件性能也只有 10% 左右的下降。这里 WASM 的插件是用 C++ SDK 实现的，而根据我们的内部测试，WASM 其他语言 SDK 实现的插件性能会更差。另外，Rider 性能只比社区 Lua 提升了不到 10%，个人感觉是因为性能测试的插件在 Lua 和 C++ 之间的数据交互比较简单，基本都是简单字符串的传递，体现不出 FFI 的优势。&lt;/p&gt;
&lt;h4 id=&#34;222-功能增强&#34;&gt;2.2.2 功能增强&lt;/h4&gt;
&lt;p&gt;性能问题解决后，接下来就是功能的增强，也就是 Lua SDK 的丰富，这里总结了当前 Rider 支持的所有 Lua SDK：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;envoy.req.get_header(name)&lt;/li&gt;
&lt;li&gt;envoy.req.get_header_size(name)&lt;/li&gt;
&lt;li&gt;envoy.req.get_header_index(name, index)&lt;/li&gt;
&lt;li&gt;envoy.req.get_headers()&lt;/li&gt;
&lt;li&gt;envoy.req.get_body()&lt;/li&gt;
&lt;li&gt;envoy.req.get_metadata(key, filter_name)&lt;/li&gt;
&lt;li&gt;envoy.req.get_dynamic_metadata(key, filter_name)&lt;/li&gt;
&lt;li&gt;envoy.req.get_query_parameters(max_args)&lt;/li&gt;
&lt;li&gt;envoy.req.set_header(name, value)&lt;/li&gt;
&lt;li&gt;envoy.req.set_headers(headers)&lt;/li&gt;
&lt;li&gt;envoy.req.clear_header(name)&lt;/li&gt;
&lt;li&gt;envoy.resp.get_header(name)&lt;/li&gt;
&lt;li&gt;envoy.resp.get_header_size(name)&lt;/li&gt;
&lt;li&gt;envoy.resp.get_header_index(name, index)&lt;/li&gt;
&lt;li&gt;envoy.resp.get_headers()&lt;/li&gt;
&lt;li&gt;envoy.resp.get_body()&lt;/li&gt;
&lt;li&gt;envoy.resp.set_header(name, value)&lt;/li&gt;
&lt;li&gt;envoy.resp.set_headers(headers)&lt;/li&gt;
&lt;li&gt;envoy.resp.clear_header(name)&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.start_time()&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.current_time_milliseconds()&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.downstream_local_address()&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.downstream_remote_address()&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.upstream_cluster()&lt;/li&gt;
&lt;li&gt;envoy.streaminfo.upstream_host()&lt;/li&gt;
&lt;li&gt;envoy.logTrace(message)&lt;/li&gt;
&lt;li&gt;envoy.logDebug(message)&lt;/li&gt;
&lt;li&gt;envoy.logInfo(message)&lt;/li&gt;
&lt;li&gt;envoy.logWarn(message)&lt;/li&gt;
&lt;li&gt;envoy.logErr(message)&lt;/li&gt;
&lt;li&gt;envoy.filelog(msg)&lt;/li&gt;
&lt;li&gt;envoy.get_base_config()&lt;/li&gt;
&lt;li&gt;envoy.get_route_config()&lt;/li&gt;
&lt;li&gt;envoy.httpCall(cluster, headers, body, timeout)&lt;/li&gt;
&lt;li&gt;envoy.respond(headers, body)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;23-rider-的实践&#34;&gt;2.3 Rider 的实践&lt;/h3&gt;
&lt;p&gt;网易内部传媒业务已基于 Rider 开发并上线使用多个 Lua 插件，其中用于打印全链路追踪日志的 Trace 插件 2020 Q1 上线，目前已接入全部网关，处理数十万 QPS，运行稳定。&lt;/p&gt;
&lt;h2 id=&#34;3-rider-可扩展框架的未来规划&#34;&gt;3. Rider 可扩展框架的未来规划&lt;/h2&gt;
&lt;p&gt;未来我们会在稳定性、性能、功能等方面持续进行 Rider 的维护和优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;稳定性：目前 Rider 已经在网易内外部多个业务方大规模落地，后续我们也会进一步提升并保障 Rider 稳定性；&lt;/li&gt;
&lt;li&gt;性能：尽管 Rider 的性能已经优于社区 Lua 和 WASM，但后续我们会持续进行性能优化，进一步缩小和原生 C++ 扩展的性能差距；&lt;/li&gt;
&lt;li&gt;功能：在 Rider API 方面和社区 Lua 以及 WASM 对齐，提供最全面的 API 能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Hango Rider 项目地址：&lt;a href=&#34;https://github.com/hango-io/rider&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/hango-io/rider&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hango 网关项目地址：&lt;a href=&#34;https://github.com/hango-io/hango-gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/hango-io/hango-gateway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>网易开源 Istio 扩展项目 Slime 简介——基于 Istio 的智能服务网格管理器</title>
      <link>https://cloudnative.to/blog/smart-istio-management-plane-slime/</link>
      <pubDate>Tue, 30 Nov 2021 10:03:00 +0800</pubDate>
      <guid>https://cloudnative.to/blog/smart-istio-management-plane-slime/</guid>
      <description>&lt;p&gt;最近我在研究 Istio 生态中的开源项目，&lt;a href=&#34;https://github.com/slime-io/slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime&lt;/a&gt; 这个项目开源与 2021 年初，是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无须对 Istio 做任何定制化改造，就可以定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。&lt;/p&gt;
&lt;h2 id=&#34;slime-试图解决的问题&#34;&gt;Slime 试图解决的问题&lt;/h2&gt;
&lt;p&gt;Slime 项目的诞生主要为了解决以下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;网格内所有服务配置全量下到所有 Sidecar Proxy，导致其消耗大量资源使得应用性能变差的问题&lt;/li&gt;
&lt;li&gt;如何在 Istio 中实现高阶扩展的问题：比如扩展 HTTP 插件；根据服务的资源使用率做到自适应限流&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Slime 解决以上问题的答案是构建 Istio 的控制平面，具体做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建可拔插控制器&lt;/li&gt;
&lt;li&gt;数据平面监控&lt;/li&gt;
&lt;li&gt;CRD 转换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过以上方式 Slime 可以实现&lt;strong&gt;配置懒加载&lt;/strong&gt;和&lt;strong&gt;插件管理器&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;slime-架构&#34;&gt;Slime 架构&lt;/h2&gt;
&lt;p&gt;Slime 内部分为三大模块，其架构图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-内部架构图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Slime 内部架构图&#34; srcset=&#34;
               /blog/smart-istio-management-plane-slime/slime-internal-arch_hu5d1cbc5df9122628bb2bf4ff5994223c_48290_fe0eabd364a775fea6c74f24bd6712e3.webp 400w,
               /blog/smart-istio-management-plane-slime/slime-internal-arch_hu5d1cbc5df9122628bb2bf4ff5994223c_48290_11ffd18f9a301ffbb31feec43ccee4ba.webp 760w,
               /blog/smart-istio-management-plane-slime/slime-internal-arch_hu5d1cbc5df9122628bb2bf4ff5994223c_48290_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/smart-istio-management-plane-slime/slime-internal-arch_hu5d1cbc5df9122628bb2bf4ff5994223c_48290_fe0eabd364a775fea6c74f24bd6712e3.webp&#34;
               width=&#34;760&#34;
               height=&#34;403&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 内部架构图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Slime 内部三大组件为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;slime-boot&lt;/code&gt;：在 Kubernetes 上部署 Slime 模块的 operator。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-controller&lt;/code&gt;：Slime 的核心组件，监听 Slime CRD 并将其转换为 Istio CRD。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-metric&lt;/code&gt;：用于获取服务 metrics 信息的组件，&lt;code&gt;slime-controller&lt;/code&gt; 会根据其获取的信息动态调整服务治理规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;目前 Slime 内置了三个控制器子模块：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;配置懒加载（按需加载）&lt;/strong&gt;：用户无须手动配置 &lt;code&gt;SidecarScope&lt;/code&gt;，Istio 可以按需加载服务配置和服务发现信息；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP 插件管理&lt;/strong&gt;：使用新的 CRD——&lt;code&gt;pluginmanager/envoyplugin&lt;/code&gt; 包装了可读性，摒弃了可维护性较差的 &lt;code&gt;envoyfilter&lt;/code&gt;，使得插件扩展更为便捷；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自适应限流&lt;/strong&gt;：结合监控信息自动调整限流策略；&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;什么是 SidecarScope？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SidecarScope 是在 Istio 1.1 版本中引入的，它并不是一个直接面向用户的配置项，而是 Sidecar 资源的包装器，具体来说就是 &lt;a href=&#34;../config/networking/sidecar.md&#34;&gt;Sidecar 资源&lt;/a&gt;中的 &lt;code&gt;egress&lt;/code&gt; 选项。通过该配置可以减少 Istio 向 Sidecar 下发的数据量，例如只向某个命名空间中的某些服务下发某些 hosts 的访问配置，从而提高应用提高性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;使用-slime-作为-istio-的控制平面&#34;&gt;使用 Slime 作为 Istio 的控制平面&lt;/h2&gt;
&lt;p&gt;为了解决这些问题，Slime 在 Istio 之上构建了更高层次的抽象，相当于为 Istio 构建了一层管理平面，其工作流程图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-工作流程图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Slime 工作流程图&#34; srcset=&#34;
               /blog/smart-istio-management-plane-slime/slime-flow-chart_hu35062adaad3687f4a88e5321e1afdec6_63944_b689cbccf9e8c408f0e9515f0de805bb.webp 400w,
               /blog/smart-istio-management-plane-slime/slime-flow-chart_hu35062adaad3687f4a88e5321e1afdec6_63944_b7106a785a26283f3beb6af044347112.webp 760w,
               /blog/smart-istio-management-plane-slime/slime-flow-chart_hu35062adaad3687f4a88e5321e1afdec6_63944_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/smart-istio-management-plane-slime/slime-flow-chart_hu35062adaad3687f4a88e5321e1afdec6_63944_b689cbccf9e8c408f0e9515f0de805bb.webp&#34;
               width=&#34;760&#34;
               height=&#34;417&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 工作流程图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；&lt;/li&gt;
&lt;li&gt;开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；&lt;/li&gt;
&lt;li&gt;Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；&lt;/li&gt;
&lt;li&gt;Istio 监听 Istio CRD 的创建；&lt;/li&gt;
&lt;li&gt;Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上只是一个对 Slime 工作流程的一个笼统的介绍，更多详细信息请参考 &lt;a href=&#34;https://github.com/slime-io/slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime GitHub&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;配置懒加载&#34;&gt;配置懒加载&lt;/h2&gt;
&lt;p&gt;为了解决数据平面中 Sidecar Proxy 资源消耗过大及网络延迟问题，Slime 使用了配置懒加载（按需加载 Sidecar 配置）的方案。该方案的核心思想是向每个 Sidecar Proxy 中只下发其所 Pod 中服务所需的配置，而不是将网格中的所有服务信息全量下发。所以 Slime 需要获取每个服务的调用关系这样才能得到其所需的 Sidecar Proxy 配置。&lt;/p&gt;
&lt;p&gt;Slime 实现 Sidecar Proxy 配置懒加载的方法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让数据平面中的所有服务的首次调用都通过一个 Global Proxy，该 Proxy 可以记录所有服务的调用和依赖信息，根据该依赖信息更新 Istio 中 Sidecar 资源的配置；&lt;/li&gt;
&lt;li&gt;当某个服务的调用链被 VirtualService 中的路由信息重新定义时，Global Proxy 原有记录就失效了，需要一个新的数据结构来维护该服务的调用关系。Slime 创建了名为 &lt;code&gt;ServiceFence&lt;/code&gt;  的 CRD 来维护服务调用关系以解决服务信息缺失问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用-global-proxy-初始化服务调用拓扑&#34;&gt;使用 Global Proxy 初始化服务调用拓扑&lt;/h3&gt;
&lt;p&gt;Slime 在数据平面中部署 Global Proxy（也叫做 Global Sidecar，但其与应用的 Pod 不是一对一的关系，笔者更倾向于称其为 Global Proxy），该代理同样使用 Envoy 构建，在每个需要启动配置懒加载的命名空间中部署一个或在整个网格中只部署一个，所有缺失服务发现信息的调用（你也可以手动配置服务调用关系），都会被兜底路由劫持到 Global Proxy，经过其首次转发后，Slime 便可感知到被调用方的信息，然后根据其对应服务的 VirtualService，找到服务名和真实后端的映射关系，将两者的都加入 SidecarScope，以后该服务的调用就不再需要经过 Global Proxy 了。&lt;/p&gt;
&lt;h3 id=&#34;使用-servicefence-维护服务调用拓扑&#34;&gt;使用 ServiceFence 维护服务调用拓扑&lt;/h3&gt;
&lt;p&gt;在使用 Global Proxy 初始化服务调用拓扑后，一旦服务调用链有变动的话怎么办？对此 Slime 创建了 ServiceFence 的 CRD。使用 ServiceFence 可以维护服务名和后端服务的映射关系。Slime 根据其对应服务的 VirtualService，找到 Kubernetes 服务名和真实后端（host）的映射关系，将两者的都加入 Sidecar 的配置中。ServiceFence 管理生成的 SidecarScope 的生命周期，自动清理长时间不用的调用关系，从而避免上述问题。&lt;/p&gt;
&lt;h3 id=&#34;如何开启配置懒加载&#34;&gt;如何开启配置懒加载&lt;/h3&gt;
&lt;p&gt;配置懒加载功能对于终端用户是透明的，只需要 Kubernetes  Service 上打上 &lt;code&gt;istio.dependency.servicefence/status:&amp;quot;true&amp;quot;&lt;/code&gt; 的标签，表明该服务需要开启配置懒加载，剩下的事情交给 Slime Operator 来完成即可。&lt;/p&gt;
&lt;h2 id=&#34;http-插件管理&#34;&gt;HTTP 插件管理&lt;/h2&gt;
&lt;p&gt;Istio 中的插件扩展只能通过 EnvoyFilter 来实现，因为它是 xDS 层面的配置，管理和维护这样的配置需要耗费大量的精力，也极容易出错。因此，Slime 在 EnvoyFilter 的基础上做了一层面向插件的抽象。&lt;/p&gt;
&lt;p&gt;Slime 共有两个 CRD 用于 HTTP 插件管理，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PluginManager&lt;/strong&gt;：配置为哪些负载开启哪些插件，插件的配置顺序即为执行顺序；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EnvoyPlugin&lt;/strong&gt;：EnvoyPlugin 不关心每个插件的具体配置，具体配置会被放在 EnvoyFilter 资源的 &lt;code&gt;patch.typed_config&lt;/code&gt; 结构中透传），EnvoyPlugin 的核心思想是将插件配置在需要的维度中做聚合，从而限定插件的生鲜范围。这样做一方面更加贴合插件使用者的习惯，另一方面也降低了上层配置的冗余，&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于 Slime 中插件管理的详细使用方式请见 &lt;a href=&#34;https://github.com/slime-io/slime/blob/master/doc/zh/plugin_manager.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime GitHub&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;自适应限流&#34;&gt;自适应限流&lt;/h2&gt;
&lt;p&gt;Envoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。&lt;/p&gt;
&lt;p&gt;Slime 自适应限流的流程图如下所示。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-slime-的自适应限流流程图&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Slime 的自适应限流流程图&#34; srcset=&#34;
               /blog/smart-istio-management-plane-slime/slime-smart-limiter_hu45e88bc7e2a84db69797e09780c97010_68035_999717e1406c666d6ef592dae8408170.webp 400w,
               /blog/smart-istio-management-plane-slime/slime-smart-limiter_hu45e88bc7e2a84db69797e09780c97010_68035_cb134211aa3749eddba870c2cfc488d5.webp 760w,
               /blog/smart-istio-management-plane-slime/slime-smart-limiter_hu45e88bc7e2a84db69797e09780c97010_68035_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://cloudnative.to/blog/smart-istio-management-plane-slime/slime-smart-limiter_hu45e88bc7e2a84db69797e09780c97010_68035_999717e1406c666d6ef592dae8408170.webp&#34;
               width=&#34;760&#34;
               height=&#34;571&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Slime 的自适应限流流程图
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Slime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 EnvoyFilter 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的 CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。&lt;/p&gt;
&lt;p&gt;Slime 创建的 CRD &lt;code&gt;SmartLimiter&lt;/code&gt; 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的 SmartLimiter 定义如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;microservice.netease.com/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SmartLimiter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;descriptors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fill_interval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;seconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;quota&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;30/{pod}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 30 为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{cpu}&amp;gt;0.8&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 根据监控项{cpu}的值自动填充该模板&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;Slime 开源于 2021 年初，本文发稿时该项目仍处于初级阶段，本文大量参考了杨笛航在云原生社区中的分享 &lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能&lt;/a&gt; 及 Slime 的 &lt;a href=&#34;https://github.com/slime-io/slime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;。感兴趣的读者可以关注下这个项目的 GitHub，进一步了解它。&lt;/p&gt;
&lt;p&gt;另外欢迎关注服务网格和 Istio 的朋友加入&lt;a href=&#34;https://cloudnative.to/sig-istio/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区 Istio SIG&lt;/a&gt;，一起参与讨论和交流。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能 - cloudnative.to&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/slime-io/slime/blob/master/README_ZH.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime GitHub 文档 - github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/sidecar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sidecar - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
